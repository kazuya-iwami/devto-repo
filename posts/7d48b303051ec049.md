---
title: 'AWS re:Invent 2025 - Transforming Integrated Diagnostics: Philips'' AI Journey with AWS (IND219)'
published: true
description: 'In this video, AWS and Philips demonstrate how AWS HealthImaging transforms integrated diagnostics in healthcare. The session covers breaking down data silos across radiology, cardiology, and pathology to enable patient-centric care. Philips showcases their cloud-native Enterprise Pathology Solution, which reduces diagnosis time from 11 hours 35 minutes to 36 minutes by digitizing glass slides into DICOM whole slide images. AWS HealthImaging provides managed DICOM storage with sub-200 millisecond tile retrieval, eliminating undifferentiated heavy lifting. The solution enables real-time collaboration between pathologists globally, supports multi-modal AI training, and powers tumor boards with unified data access. Philips has migrated 134 petabytes representing 34 million patient exams to AWS, with 100% of surveyed pathologists preferring digital over microscope-based workflows and achieving 21% more case diagnoses.'
tags: ''
series: ''
canonical_url:
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Transforming Integrated Diagnostics: Philips' AI Journey with AWS (IND219)**

> In this video, AWS and Philips demonstrate how AWS HealthImaging transforms integrated diagnostics in healthcare. The session covers breaking down data silos across radiology, cardiology, and pathology to enable patient-centric care. Philips showcases their cloud-native Enterprise Pathology Solution, which reduces diagnosis time from 11 hours 35 minutes to 36 minutes by digitizing glass slides into DICOM whole slide images. AWS HealthImaging provides managed DICOM storage with sub-200 millisecond tile retrieval, eliminating undifferentiated heavy lifting. The solution enables real-time collaboration between pathologists globally, supports multi-modal AI training, and powers tumor boards with unified data access. Philips has migrated 134 petabytes representing 34 million patient exams to AWS, with 100% of surveyed pathologists preferring digital over microscope-based workflows and achieving 21% more case diagnoses.

{% youtube https://www.youtube.com/watch?v=y8g9gY9pOzY %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/0.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=0)

### Breaking Down Healthcare Data Silos: The Challenge of Integrated Diagnostics

 Welcome everybody. Welcome to Reinvent. It's an absolute pleasure to be here today, and I hope you had a fantastic first day of Reinvent so far. I've heard all the greatest stories already from folks traveling to four or five different sessions. This is probably your last session today, but for me, this is my highlight of course, and I'm really hoping that by the end of this session, it will be your highlight as well. That's because we have a fantastic topic to cover today: transforming integrated diagnostics. How can we improve healthcare and quality of care for patients if we make it easier to access the right data and break down the data silos?

It's really cool because we're not just talking here from an AWS perspective about pure technology and how things could be done in theory. We're also having our partner Philips on stage to help us explain how they're building their solutions to actually drive clinical care for patients and physicians in the field. We've got a great team with the AWS HealthImaging team joining me: Jaron Nix and Wilson To, PhD, and Predrag Angelovski from Royal Philips. My name is Sam Kool. I'm a Senior Solution Architect here at AWS supporting our healthcare customers like Philips.

[![Thumbnail 70](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/70.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=70)

 Whenever we start anything within Amazon, we always work backwards from the customer. Within healthcare, that's fairly simpleâ€”the customer has to be the patient, either directly or indirectly. It always boils down to how can we best serve our patients and provide the best possible outcomes for them. There are a couple of challenges in healthcare that make this more difficult, and these are all probably known to you if you've read the news or seen the stories about the rising cost of care.

[![Thumbnail 100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/100.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=100)

[![Thumbnail 110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/110.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=110)

 There's the aging population, the cost of medication, and more complex disease states that we're treating, which are taxing our services and our healthcare system.  Then there are disparate data silos. As we've moved from a paper-based system into an electronic system, we've done so one step at a time, creating all these solutions that generate different data silos. While we have moved over, it's now up to us to break down those data silos. How can we take the next step and integrate it all?

[![Thumbnail 130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/130.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=130)

 There are also shortagesâ€”not just in staffing, but in medication and supplies. Staffing is a key one that I want to call out, because we see all these news articles about nurses, specialists, and physicians not having the time to actually work with patients. How can we give them the time back to really focus on delivering the right quality of care?

[![Thumbnail 150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/150.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=150)

 There's a great quote that provides substance to that point. It's from the Philips Future Health Index, and it says that 77% of healthcare professionals across almost 2,000 surveyed globallyâ€”so the vast majorityâ€”see a near 10% loss of productivity by not being able to access the right data. At Reinvent you'll see all kinds of talks about generative AI and how we're transforming industries, but if I look at this, we're still losing so much productivity simply by not being able to access the right data. It's such a simple problem you might think.

[![Thumbnail 190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/190.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=190)

 But then you have a deeper look at medical care and all the data that powers it, and it's incredibly complex. It's not just one type of data; it's multiple modes of data within different spaces. It's electronic health records data, laboratory data, all from different systems. Even within the imaging space, it's all types of different data, whether you have radiology, pathology, or cardiology. As we move more and more towards precision medicine and take the next steps in our healthcare system, we're going to bring in more and more genomics to complete the entire picture.

### The Evolution of Digital Pathology: From Microscopes to Cloud

What we want to do with breaking down those data silos is move away from point solutions that we built around a specific type of data for a specific specialism and build an integrated shell of data that's patient-centric. Any physician can tap into it and get the right data as they need it. I want to take one example that's key to how we're innovating and how Philips is innovating together with AWS, and that's pathology.

[![Thumbnail 250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/250.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=250)

 Pathology is incredibly cool for so many different aspects. It's very cool from a science perspective. The usual flow for those who are not familiar with pathologyâ€”it's usually used in cancer care. You take a biopsy, a little piece of tissue, and send that over to the pathology lab where it's prepared, sandwiched between a glass slide as a thin sliver of tissue, and then looked at under a microscope. The pathologist can distill from that sample whether a patient has cancer.

[![Thumbnail 280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/280.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=280)

 What type of cancer are we looking at? How advanced is the disease? What type of treatments might work best, or what type of treatments might not work, making better outcomes for the patients? All of that data gets collected and aggregated with all the other data that's already collected within lab systems and patient history, then sent over to the treating physician who makes a definitive diagnosis.

[![Thumbnail 310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/310.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=310)

It's incredibly cool to look at from a scientific perspective, a healthcare perspective, and a technology perspective.  Digital pathology itself is going through an entire evolution, breaking down across multiple steps, and it's actively growing across all of these steps. Currently, most healthcare institutions are still microscopy pathology based, using the traditional setup that's labor intensive because it's all manual to some extent. There are limited options for automation, and because it's purely based around glass slides, there is some loss of data quality over time.

That's why we're slowly starting to move toward digital pathology. We're still in very early stages, and Philips has been a great pioneer in that space. We essentially move from a microscope to a super high resolution camera, and instead of looking through a microscope, we look at pixels on the screen. That has a lot of potential because now that we have data, we can reason on top of that. We can let computers run machine learning to do automated analysis, or even have multi-modal data be collected and presented into one view for the clinician.

[![Thumbnail 410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/410.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=410)

The next step to evolve further is opening up the data and unleashing its full potential through cloud pathology. We no longer are confined to the limits of a single healthcare institution. We break it open and make it accessible for clinicians across cities, states, and internationally to collaborate or build research clusters where we can collect data across various domains and healthcare institutions to drive forward cancer research or develop new machine learning algorithms to better predict and diagnose. Of course, once you're in the cloud, you can take advantage of so much more than just a solution by using all the different services from AWS. 

### AWS HealthImaging: A Purpose-Built Solution for Medical Imaging

That's roughly how we see the cloud playing a role within our integrated diagnostics vision. If we zoom out a little bit and take a broader view, there are about four pillars that we can define: interoperability, unified access and compute, and value-added services. Interoperability really speaks to the essentials within healthcare. We're always going to have all types and modalities of data. So how do we integrate them? We already have the standards. How do we actually make it work as one unified dataset? How do we properly make this work together?

That's why we've built all of our different services on AWS specific to the healthcare industry and how we've partnered with all these partner solutions to be able to quickly build a data foundation. We're leveraging all of our storage services to be able to open up the data, whether it's small volumes or massive volumes, and then layering on the compute to be able to easily transcode, stream, access, and process all the images or data being collected. The core of it is moving beyond that into value-added services. That's the power of the cloud, bringing together all of our partners, solutions, and services to be able to layer on more and more value, whether it's AI, big data analysis, or other capabilities.

[![Thumbnail 490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/490.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=490)

If we zoom out from there a little bit and go into an architectural perspective,  this is what we see a lot of customers build nowadays. This is a very simplistic view of what any medical imaging setup on the cloud could look like, whether it's pathology or any other different type of specialty. Essentially, there are a couple of key components: a flavor of compute, some flavor of storage, and a database to be able to capture the images, process them, store them, and manage them. We see that over and over again, and there are a million ways to architect around this. There are probably good choices, less good choices, and every customer makes their own to create their own basic foundation.

[![Thumbnail 560](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/560.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=560)

Then on top of that, we start to layer all of the value-added services: the great user experience to make it simple, generative AI to add value, and your custom models to be able to add differentiation. Repeating that same foundation every time again is what we call AWS undifferentiated heavy lifting. It's creating the same foundations over and over again that don't differentiate your offering from any competitors. That's not where we want our customers to focus. That's why we focus on building out different services to help accelerate that. That's why we've built AWS HealthImaging. 

AWS HealthImaging is a purpose-built service as a DICOM store on AWS to be able to take away all of that complexity. You no longer have to build your own for each and every product that you have within an imaging space. Instead, you can take the advantages of a managed service that handles everything for you. I've listed a couple: pixel metadata, encoding, decoding, DICOMweb as a vending mechanism, and there's so much more within that. But the core of it is that you can directly onboard onto a managed service that takes away the complexity, so you can focus on what's important: those value-added services and components, building out what makes your product different, and what really drives forward clinical care.

[![Thumbnail 620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/620.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=620)

What really drives forward clinical care is understanding how you can help patients be better. We can do that not just across one data set, but from a multidisciplinary perspective. We're not looking at just one type of data, whether it's pathology, radiology,  cardiology, but once we have one common data set or data platform with medical imaging on the cloud, we're going to start to leverage that and unify it and have that integrated foundation to build upon. I think it's worthwhile to dive a little bit deeper into this, and that's why I'm really pleased to have our next speaker able to talk to you about AWS HealthImaging in more detail. Please give a warm welcome to Jaron Nix, our Senior Product Manager for AWS HealthImaging.

[![Thumbnail 670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/670.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=670)

### Understanding the Complexity of DICOM Data Management

Hi everybody. I'm Jaron Nix. I'm Senior Product Manager here at AWS, and every day I work with partners like Philips to make medical imaging in the cloud faster, more cost effective, and vastly less complex. Today I'm going to run you through an  example of how we can help customers like Philips who work with petabytes of medical imaging data to make their cloud workloads more effective.

[![Thumbnail 700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/700.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=700)

[![Thumbnail 710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/710.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=710)

[![Thumbnail 720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/720.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=720)

The basic challenge in medical imaging is this: you need images from a specific patient. Let's say you have Alice and you have Bob, and Bob's data is related to other data. So you want Bob's biopsy data from pathology and you also want to pull historical data such as the T2 axial MR from some time in the past.  Ostensibly, this looks relatively simple, but there are two implicit requirements. Your data needs to be loaded in under one second, regardless of how long in the past it was required.  And you need to  acquire this data across petabytes and hundreds of millions or even billions of images if you're operating at Philips' scale.

What we think of as a medical image is typically a series of images, and these are images that are related to one another through metadata. Metadata can be patient name, the date by which it was acquired, the modality that acquired it, and there's a lot of other clinical context in metadata. There are hundreds of thousands of attributes that come with each of these images. You can have everything from the voltage used or the table height, and this provides radiologists or physicians in general important clinical context.

What you're actually seeing on a screen if you're a physician are files stored in a data center somewhere. The reason that these are stored as files and separate files at that is because DICOM is a relatively old standard, thirty to forty years now, and it was originally designed as a network standard. How do you send data between modalities to golden copy storage to the viewports of a physician, and then between institutions? We've co-opted this standard to store this data, and this has presented some complexity. CT scanners typically gather data incrementally. They reconstruct slices and as that data is prepared, they're sending it to PACS. I'll run through a few examples of how this can get quite complex.

[![Thumbnail 790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/790.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=790)

 You have your oldest modality of digital radiology: X-ray. Let's say that every study, so every time that you visit a hospital and you need data acquired, the X-ray is typically a lateral and a frontal view. So a chest X-ray is a great example of this. You have a few files that are all related to each other, and this is all the physician needs in order to have the comprehensive view of the study that was just acquired.

[![Thumbnail 820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/820.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=820)

[![Thumbnail 840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/840.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=840)

More modern modalities with volumetric data like PET, CT, and MR are hundreds of images, and the study can  often combine both. So PET CT is a common dual modality study, and the data gets bigger with hundreds of files all related to each other, all stored in individual objects in a cloud data store or as files in a file system on premises. And then you have more modern modalities like digital pathology.  It's gigapixel images, so you're imaging cancer tissue, tissue specimen, mounting it on a glass slide and imaging this data in micron resolution. This is important because we'll touch on this throughout the presentation. The cardinality of data is there are fewer files, but these files are huge. They're typically up to four gigabytes per file, depending on the resolution that you're imaging the tissue, and each file contains one hundred thousand or more images, especially if you're imaging a twenty X or forty X objective magnification. This presents a challenge: how do you get specific data contained within that vast image to a client for a physician to review, a pathologist to review in under a second.

[![Thumbnail 890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/890.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=890)

Here's what's happening in a microcosm. So you need to find Alice's CT scan acquired in September.  Here are four files, and we will walk through how the DICOM standard would have you navigate this data. So we can very clearly see these are four different images and from our past example, we know that two of these belong to Bob. So what we can do is we can read the file and look in the metadata header because in DICOM, metadata and pixels can never be separate.

[![Thumbnail 920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/920.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=920)

[![Thumbnail 940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/940.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=940)

[![Thumbnail 950](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/950.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=950)

[![Thumbnail 970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/970.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=970)

[![Thumbnail 1000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1000.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1000)

[![Thumbnail 1030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1030.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1030)

[![Thumbnail 1040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1040.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1040)

[![Thumbnail 1090](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1090.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1090)

[![Thumbnail 1140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1140.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1140)

[![Thumbnail 1150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1150.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1150)

[![Thumbnail 1180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1180.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1180)

Two of these belong to Bob. What we can do is read the file and look in the metadata header because in DICOM, metadata and pixels can never be separate. All images must come with the important clinical context. We can look at the patient and determine that this is Bob, therefore it does not reconcile and we can move on.  We iterate down the hierarchy and look at the study. These two might be the same. For example, Alice could have visited the hospital and had a chest X-ray taken just before she was laid down into a CT machine for imaging. Then we drill down further into the metadata hierarchy and match at the series attributes.  We can tell that one is an X-ray and one is a CT, but the problem does not quite stop there because CT data, as I mentioned, is volumetric, and this metadata will tell you that there  are 500 more instances, for example, in your universe of data. This is across millions of patients, petabytes of data, and potentially billions of objects. So how can you give a physician the data they need fast and without breaking the bank in terms of cost? I will walk you through a sample architecture, and this is  typically how our customers are approaching it. This is a DIY architecture and is intended to represent the average approach to this problem. We start with S3. S3 is a great product for storing bytes with high durability and retrieving them, but the DICOM resource hierarchy is what is difficult. It is relating the metadata to the patient and then providing fast access to the pixels. How do you know which of these objects belong to which patient and which series? You might start  with Lambda, and you would have Lambda detect when new objects are written to the bucket. Lambda would grab the files, parse the metadata headers, and insert them into a relational database like RDS. But RDS is not quite sufficient to navigate this hierarchy. For example, John Doe and Doe, John are the same patient. RDS will not understand that, but a managed service like OpenSearch will. It provides semantic search.  Let us say you have that patient name that needs to be reconciled. You might use serverless services like Lambda and Step Functions to grab the data that needs to be reconciled, edit the metadata headers, and upsert the objects in the bucket.  Medical imaging has been digital for 30 or 40 years. Much of those images are compressed in ways that are no longer compatible with web browsers. A lot of your pixel data may have been corrupted. It is an unfortunate part of storing this data for 30 or 40 years. You might use Fargate to ingest this data, and what we mean by ingest would be to detect whether pixel data has been corrupted. If so, you notify and then build software that could correct that. Also, recompress legacy data. For example, uncompressed data from decades past or JPEG baseline or other data may need to be in a more modern compression codec like JPEG 2000 or high throughput JPEG 2000. And of course, you need APIs for interoperability and data  access, and you would use EC2, API Gateway, and Verified Permissions. This is the most basic architecture that presents a sufficient data management layer for medical imaging in the cloud. Remember, this is just the data management layer. Business and application logic still need to be built on top of this. When we see this architecture being repeated across all of our customers, we start to question whether this is the right experience. We work backwards from the customer, and this undifferentiated heavy lifting that was alluded to is probably not the right customer experience for these repetitive workloads.  The answer is potentially a managed service, a domain-specific managed service like AWS HealthImaging, which helps customers automatically organize, normalize, and harmonize their data, and stream that data with low latency and standards-based API interfaces. This replaces the S3-based architecture. It is intended for golden copy storage of medical imaging in the cloud.  We provide this bundling of services. For example, ingest: you have petabytes of data you need to get it into this data store fast. We can ingest petabytes a month of data. We also have stores for synchronous writes to the data store from modalities. We present rich search for clinical data as well as data management APIs and fast retrieval with standards-based interfaces.  Here is what is happening under the hood. Data from S3 is being ingested into the service, similar to the architecture we presented earlier, and metadata is automatically being populated into search indexes. Image frames are being recompressed, they are being parsed and given unique IDs so that you can retrieve them directly. We are presenting a single JSON of metadata that is also versioned, so an immutable record of all changes throughout the history of these groups of images is being kept for you to retrieve and easily update patient demographics.

### How AWS HealthImaging Simplifies Medical Image Storage and Retrieval

These updates, for example, a patient name change, reflect across all relevant objects in your data store when you update this concept that we'll introduce in the next slide. If you update this group of images, the harmonized metadata reflects the patient name change across all relevant objects in your data store.

[![Thumbnail 1230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1230.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1230)

Going into our example, what AWS HealthImaging does is create a patient  concept called Alice. We take relevant metadata such as study date and modality and group images together into one AWS resource called an image set. The image set is where you perform access control, modify the image set metadata, and delete it. We'll show you an example of what this looks like on the next slide.

[![Thumbnail 1250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1250.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1250)

[![Thumbnail 1260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1260.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1260)

We also have Bob, and we know Bob has  two studies in the data store. We know he had his MR, and we do the same thing we did with Alice's CT. We bundle these together. We also know he had his pathology,  and we create an image set out of all these pathology frames. In this example, this is over 100,000 frames, and this is actually quite small for a pathology modality. We give these frames a UID as I mentioned, and here's why.

[![Thumbnail 1280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1280.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1280)

Pathology is enormous, as I've mentioned. This roughly approximates how you access pixel  data in pathology. A pathologist's job is more akin to searching for a single star in the night sky, and they have to do it very quickly. Algorithms do much the same. So the access patterns are unpredictable. You have gigabytes of data, hundreds of thousands of frames, and you need fast access.

[![Thumbnail 1300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1300.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1300)

The way AWS HealthImaging organizes this data  is in the DICOM hierarchy, and we call this normalized metadata. For example, you can see the patient concept at the top, study information, series information, and all the image frames contained within the instances are directly accessible via image frame get APIs so that you can get this data to your client fast. You can request frames in batches, and each frame is delivered to your client in about 200 milliseconds.

What AWS HealthImaging helps you do is bypass file operations and bypass managing these objects DIY with your own architecture on AWS. The service exists so that you can move faster with your application build. We want our customers to focus on exceptional patient care and differentiated features and leverage a managed service like AWS HealthImaging. We can take care of the healthcare data plumbing. We'll operate the foundational health data capabilities.

[![Thumbnail 1360](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1360.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1360)

[![Thumbnail 1380](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1380.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1380)

This is not just specific to AWS HealthImaging. We  have many domain-specific healthcare and life sciences managed services. For example, AWS HealthLake for storing patient records in the FHIR format, AWS HealthOmics for genomics storage and bioinformatics workflows, AWS HealthImaging for DICOM storage and low-latency retrieval, and AWS HealthScribe for generating notes from doctor-patient interactions.  We lay the foundation for our partners to build on, and we offer scalable data services. Our customers and the end customer ultimately being the patient. This is enabled by highly specialized software in a highly regulated field. We deliver patient impact through our partners.

[![Thumbnail 1420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1420.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1420)

[![Thumbnail 1430](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1430.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1430)

### Philips Healthcare Informatics: Improving 2.5 Billion Lives Through Innovation

No one can speak to this better than Philips, and I'll invite Wilson To to the stage to speak about his part. Hello everyone. It's great to see a lot of familiar faces in this room again because it has been a long time since last year since we actually gave a talk around some of the work that we're doing across our healthcare  informatics portfolio. I'm happy to dive a little deeper today and really showcase the progress that the team has been making through our partnership and dive deeper into what we're doing for our patients and our clinicians that we're working  with.

For those that haven't been familiar with Philips, it's probably a name and a brand that you've seen and heard, whether it's through bottles for babies or toothbrushes in your bathroom. But one thing that we're going to focus on today is a little bit more across our entire healthcare informatics portfolio. So for better or for worse, if you've been in a hospital, chances are you probably have seen and heard Philips as a brand, whether it's from a device, a modality, or even from a software perspective.

I say that because the core mission that we have at Philips is to improve the lives and well-being of 2.5 billion people around the world. Every single year that's what we strive to do, and we're on a mission to do that. We're making great progress in that. In fact, 95 of the top 100 hospitals in the US are using healthcare informatics solutions from Philips. In fact, 82% of the top 250 hospitals are also doing the same, and that spans across many different modalities that we have.

So specialties like radiology, where we work with radiologists to better understand what pixels mean and how we help service that so we can make their lives easier.

This also crosses everything into cardiology, for example, where we work with our cardiology patch systems in order to provide visualizations and echoes with the team here attending and moving that to the cloud. As Jared mentioned and what the team had mentioned earlier, we're also doing that in pathology. Working with glass slides and making that fundamental shift into the cloud and digitizing that is no small feat, and that's something that we're continuing to usher in across our entire portfolio.

[![Thumbnail 1560](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1560.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1560)

Whether it's with pixel data or even waveform data, such as what some of our solutions in the acute care space provide, we're working very closely with AWS in order to make sure that the entire digital transformation in hospitals is one that's going to change and shift the notes that our clinicians are working on together. We don't stop there. In fact, a lot of how we innovate is very similar to how many of you innovate  and how AWS innovates, and it really starts with the customer and working backwards. For us, it is actually even more so with clinicians and patients. We actually start from the bedside and work backwards from that.

This is important because it takes into account how we think and how we work with our long-standing clinical partners around the world in order to work alongside shoulder to shoulder with clinicians, nurses, technologists, IT teams, and staff across the board. As we think about what that means from co-creation and co-innovation, all of our partnerships with every single hospital and health system in the world outlast everyone at that table. When we highlight the focus of that type of relationship and partnership, it really helps crystallize the type of work that we're doing, not so much that we're focusing on the design and the technology, but really the experiences that every single clinician is going to have with useful solutions.

As we think about how that evolves over time, it's not so much that we're just running the same system in the cloud, but here's our chance to reinvent how things are being done. This really anchors on the fact that clinical workflows change over time and they change with the thought that things can be done differently if you have access to infinite compute or infinite storage. As you think about how we deploy AI algorithms and AI models nowadays, it's not so much that we're augmenting existing workflows that have existed over the past ten to twenty years and just placing them there, but how do we rethink clinical workflows from the ground up with AI first in mind and with clinicians in mind so that we can do things differently now.

[![Thumbnail 1680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1680.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1680)

### Two Decades of Partnership: Philips and AWS Transform Healthcare in the Cloud

I'm going to share a little bit about how we are approaching that because these three pillars anchor everything that we do with AWS, and it isn't something that has been going on overnight. In fact, the partnership with AWS actually spans nearly two decades now.  In 2008, that's when AWS and Philips started working together. Since then, we've pushed each other to innovate very aggressively on behalf of our customers.

In 2014 and 2015, Philips was actually the first company to launch production medical workloads into the cloud. From there, we've actually challenged the teams to work together to think about how do we co-innovate and design differently to continue to remove that undifferentiated heavy lifting in areas where our customers and hospital systems are accessing data or in ways in which they are surfacing that data to run AI algorithms. The relationship and partnership actually extends quite a number of years in order for us to get to the point in time that you see on the right-hand side of the screen.

Over the past three years since the enterprise informatics business formed within Philips, we've actually moved very aggressively in order to shift our entire healthcare informatics portfolio into the cloud. In 2023, we launched our HealthSuite Imaging PACS into the cloud and migrated over 150 customer sites into the cloud. The same thing goes for pathology. We've started going down the path of trying to understand what it means to have these capabilities like the use of health imaging in order to think about the different types of access patterns so that we don't have to worry about that on our own, and Predrag is going to go into that a little bit more deeply.

[![Thumbnail 1800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1800.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1800)

Even just last week we announced our Cardiovascular Workspace in the cloud as well. So all of a sudden our entire portfolio is now accessible in the cloud and the cloud becomes the backbone by which all of our customers can actually engage and interact and access data differently now. Within that space, we've pushed at least the work that we were doing in terms of the momentum to a completely different level  and scale.

Darren kind of mentioned this a little earlier where the entire informatics stack we have in terms of integrated diagnosis is now in the cloud. What that means for us and our customers is that 134 petabytes of data have been shifted to the cloud, enabling customers to access, process, compute, and transmit data in ways they haven't been able to do before. Behind that 134 petabytes of data are 34 million patient exams that continue to grow over time. All the sites that have migrated are continuing to work with us very closely to build on the momentum that the partnership has created for us.

[![Thumbnail 1880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1880.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1880)

As we think about the root of our core mission, we ask how do we impact the lives and improve the health and well-being of those 2.5 billion lives annually. Software allows us to scale, and cloud allows us to scale. Behind that 134 petabytes of data are 11 billion medical records and images that help correspond how patients can be treated differently with their clinicians now. When we zoom out, as Sam had this slide earlier,  the medical device and medical care space is completely data driven. Everything I mentioned in the previous slide was all about data, bits and bytes, and we understand that behind every bit and byte is a patient.

[![Thumbnail 1930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/1930.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=1930)

The way we're stitching together the direction for Philips and the healthcare informatics portfolio is through the lens of integrated diagnosis. We see a future in which clinicians are able to access and see through a single pane of glass the different types of data elements that help them make decisions more easily. On the bottom left corner in that box, Sam mentioned that these are critical components as we think about modalities and how they shift into the cloud and the importance of those. That's exactly what you saw in the previous slide in which we announced different  shifts into the cloud on our portfolio.

What that means at the end of the day is that Philips, as we work with hospitals and every single department in those spaces, is shifting from the work we've done in converting biological signals into data into ways in which we're allowing that data to transcend different data silos to help clinicians look at data differently now. There's no need for clinicians to pull up 16 different systems to get a good picture of what's going on with the patient. With our solutions, our direction, and our vision of integrated diagnosis, we see a workspace in which whether it's a referring clinician or an oncologist, they're able to overlay everything on the left side of the screen.

Whether it's coming from radiology modalities or pathology scanners, all of that is able to be overlaid into how clinicians can look at patients differently. That fusion of data actually drives a different type of discussion, not only between clinicians as they're working to figure out what is the best treatment plan for their patients, but also the conversation between clinicians and patients. With that, we think about how therapy can be done differently. We see how we can equip and enable clinicians to rethink how data-driven imaging modalities can convert into really different treatment plans.

With that in mind, we think about how whether it's patient surveillance and monitoring at home or in the hospital, it all comes together to rethink how our clinicians are behaving and operating in the hospital today and more importantly, the future they have going forward into the different spaces within radiology, cardiology, or pathology. With that, I'm going to invite Predrag to come to the stage to go a little deeper into specifically the pathology space, and we'll dive into how we're approaching our journey to the cloud and more importantly, how we're looking at integrated diagnostics.

[![Thumbnail 2070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/2070.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=2070)

### Integrated Diagnostics: Unifying Radiology, Cardiology, and Pathology Data

Thank you, Wilson. Hi, everybody. First of all, an apology. I'm a little bit sick, so if my voice gets raspy or I cough in the mic, I apologize.  My name is Predrag Angelovski. I'm the Chief Technology Officer of Philips for Healthcare Informatics, and I would like to take some time today from you to talk about integrated diagnostics. What does it mean and how does it actually affect both the work of hospitals, patients, and the future of precision care. Then I'll dive in a little bit deeper into our pathology solution and then explain how AWS HealthImaging actually helps us remove some of the burden that my colleagues were talking about and really focus on clinical value and clinical innovation.

I would like to talk about the architecture and explain why we should focus on what we do best: providing the best tools for clinicians to help patients rather than burdening them with questions regarding where we store the data, how we manage the data lifecycle, and how we keep hot versus cold data. With that being said, I would first like to take a moment to talk about integrated diagnostics, because I think it's a word that you've heard many times here. On the surface, it's a very simple thing. When you think about integrated diagnostics, you're thinking about a system where a bunch of solutions work together.



However, when we really think about integrated diagnostics, we should not think of it as a system where radiology, cardiology, and digital pathology work in semi-isolated silos stitched together by point-to-point integrations and data movement. When we talk about integrated diagnostics, we really have to talk about all of these disciplines coming together in a unified fabric to provide a longitudinal view of a patient with radiology data, cardiology data, pathology data, and data from any other imaging modality. Digital pathology is the key fragment that brings this all together.

Just as an example, 70% of imaging decisions are made based on digital pathology data. 100% of tumor or cancer diagnosis requires some level of digital pathology in order for a proper diagnosis and treatment to be defined. Yet pathology was the last of the specialties to be digitized. Radiology digitized decades ago, cardiology soon followed, but pathology was always seen as difficult and cumbersome. A pathology slide is 10 to 20 times the size of a radiology study. The slides are big, and there was simply not proper architecture and proper resources on premise in hospitals to build a solution like this.

Recent advancements in technology and specifically in cloud have made it possible for us to develop a digital pathology solution. By joining the fray, we finally can build a proper integrated diagnostics solution. Now, what does this mean for a hospital and for the work of clinicians? Well, in any of these layers that are on the topic, there is a certain impact that is different from the way things work today.

If you look at the workflow layer, today, if you would like to bring and see images from multiple disciplines, you are dependent on either operating different systems, taking screenshots, doing printouts, or sharing data offline in different reports. By having a unified viewer that allows you to see radiology and pathology data next to each other, clinicians can derive better information and make better decisions. If we look at the workflow layer again, you can now have workflows across specialties. You can have triggers in digital pathology being sent directly to a radiologist or to a physician who is then going to perform the following task.

Today, that is either a very cumbersome and error-prone point-to-point integration or a manual step of passing patient records or notes around. One of the big important pieces is also in the infrastructure. Instead of managing four, five, six, or seven different solutions with different software upgrades, different database software, different standards, and different networking requirements, now you're going to work with one integrated solution that is much easier to manage and operate.

Finally, there is data, and this is the most underestimated thing. Today, data lives in silos. Radiology data lives in the PACS. Cardiology data lives in the cardiology solution. Pathology data, if it's digitized, lives in its own solution. If you would like to do any meaningful research or develop meaningful AI models, especially across modalities, you are really dependent on copying that data. You have to bring that data from multiple sources into one new location where you are actually going to be performing those operations.

With integrated diagnostics, the data is in one place, and not just the data, but the metadata is in one place. It is all connected, well described, and predefined. So things like training multi-modal AI models becomes much easier because the access to the data is there. Now, before I go into explaining what Philips's Enterprise Pathology solution is, I would like to take you to this slide that I call, ironically, the story of the slide. I think as someone previously or one of my colleagues mentioned,

a slide is a piece of glass which, after a biopsy, the technician or pathologist puts the sample on, smears it together, and that becomes the single truth for that procedure. If the slide is damaged, everything is gone. If the slide is exposed to higher level humidity, it is gone. So that slide is literally the only proof of any finding or anything that happens down the process.

### The Story of the Slide: From Manual Microscopy to Digital Pathology

Once the slide is taken, especially in manual pathology, you have to prepare that slide. Every slide has to be hard labeled, which identifies the patient and what it is. Of course, it's not all on the slide, but it's labeled with a reference. Then it's quality control. Has the slide been properly smeared? Has the sample been properly prepared? Then after that, it's probably all loaded in a trolley. When enough slides are there, it gets moved to the next step of the process.

Then comes the work of the pathologist. The work of pathologists today is looking through a microscope, trying to find a needle in a haystack, and they're extremely good at this. However, it is still a very difficult and tedious job. Not just because it is difficult to find the parts that are interesting, but also they cannot write a report at the same time that they are doing analysis.

So they take notes, either mental or written, and then they continue the analysis, constantly zooming in under an electronic microscope. They do measurements manually or well, supported by electronic microscopes. And then finally they have to write a report. All the work that happened before, all the notes they've taken, everything that they remember that they saw, they write a report which is not connected to the image. This is, as you can imagine, not just potentially error prone, but also not very efficient.

Digital pathology changes this in a very fundamental way. The moment the slide is smeared and ready, it goes into a scanner. These are high performance scanners. And the moment the slide is digitized, it becomes part of the cloud native imaging fabric. It's enriched with metadata. We have AI assisted algorithms that start the automatic measurements and measurements taking.

There are other Philips and third-party algorithms that help with dyeing, that help with identifying and categorization. And even algorithms that do automatic pre-quality control. So that means that even before the slide reaches the next step, which is the quality control, a lot of work has already been done on the slide to help the technician and then the pathologist following that to actually perform their work.

Quality control becomes verification of previously done AI assisted control. And then the work is immediately, instantaneously available for the pathologist. I say instantaneously, let's say near instantaneously. There is always some time that takes place. The pathologist's work is the one that is most impacted in a positive way.

Instead of zooming in and out on a microscope, they are looking at a screen of a high resolution image. Thanks to AI, they are able to pull in slides, focus on specific areas, and easily switch between different areas of the slide. Not only that, they can take bookmarks, they can add notes. They can write the report in parallel to the slide.

Not only are they writing the report while they are looking at the real source of data, but thanks to bookmarks, the report can be linked directly to the slides. So when you are reading the report, because it is all running on the same platform, you can actually click on different bookmarks and directly zoom back to the source of truth.

And finally, efficiency. This is what we were saying all along. In a very strained healthcare system, every minute counts. An average manual digital pathology workflow, and keep in mind this is an average from multiple surveys, it's about 11 hours and 35 minutes from slide to report. A lot of this is because there is manual movement of the slide, manual notes, and you have to gather a bunch of slides to move them forward.

In digital pathology, this goes down to 36 minutes. This is a very important time save. Not just for the sake of pure efficiency, but this means that now pathologists can handle more cases and help more people, reducing the time between sample taking and the potential diagnosis. And specifically in digital pathology, every minute counts. So, what is Philips Enterprise Pathology Solution?

[![Thumbnail 2710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/2710.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=2710)

### Philips Enterprise Pathology Solution: Architecture and Clinical Impact

 It is important to notice that Philips Enterprise Pathology Solution is not a software. Philips Enterprise Pathology Solution is a full solution from slide to report. We produce a high-performing scanner that generates a DICOM whole slide image in under a minute. That is integrated with our back end where we support a fully automated workflow and worklist that allow people based on rules or on AI algorithms to move this data to the next proper steps.

We have AI algorithms for automatic quality control and measurement, as well as pre-diagnosis and categorization. It is fully integrated with other laboratory information systems and EHRs. And then finally, it is integrated with other systems where you are able to use this data to train AI and deploy it back into the system. It is a cloud-native solution built fully on AWS and thanks to our partners, I believe it is the future of precision diagnostics and digital pathology.

[![Thumbnail 2790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/2790.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=2790)

 To talk about the architecture, going back to the slides and everything that was presented, I will focus on three things: ingestion, storage, clinical diagnosis and review, and tumor boards and secondary clinical use cases. On ingestion, as I said before, Philips has a very high-performance scanner that generates whole slide images in under one minute. This does not sound like much, but when we compare that to the numbers that were shown, we end up with almost one gigabyte of data per minute per scanner. Hospitals run ten or more scanners, and some hospitals could be multi-site operations. There could be thousands of hospitals in our ecosystem.

We need an architecture that is able to scale and ingest all of this data. That is why we have decided to partner with AWS HealthImaging. AWS HealthImaging removes that whole burden of ingestion from us. We stream the data directly into S3 buckets from which AWS HealthImaging actually consumes the data. If you are wondering why the S3 bucket in between when AWS HealthImaging actually has a DICOMweb interface, well, for the size of data in pathology, it is actually better to stage the data in the cloud first because data can get corrupted during transfer and metadata can be changed or corrupted.

So if something happened during the scanning of the slide image, it is better for us to have the data in one place where we can figure out what happened than to go back to the hardware, locate it, and reupload it if it only requires, for example, a metadata re-upload or a metadata fix. The other important part is the lifecycle management. AWS HealthImaging actually provides a full hot and mid-tier storage for us. That means it makes sure that the images we need are always available to us at the highest potential speed.

I will go a little bit into consumption in the next section, but one of the larger problems when you are dealing with data of this size is you never know when you are going to need what image. If you try to store them all in very hot storage, it is very difficult. They are large and it gets expensive. AWS HealthImaging removes that problem for us. It adds an abstraction layer in which we can request whatever we want and we always get it with a specific amount of speed.

Finally, thanks to other AWS services, we have actually designed the rest of our solution to be fully stateless as well. Most of our logic runs on containers and the rest of it runs in Lambda. We use Aurora Serverless for some of the patient metadata storage. This means that with our partners from AWS we are designing and building a system that is virtually endlessly scalable. This is important because not only is the data large, but the number of patients is increasing. We need a system that is going to be sufficient not just for today, but also for tomorrow and for the future.

[![Thumbnail 3000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/3000.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=3000)

Now on clinical diagnostic and review,  there are two important pieces that I want to revisit.

The first is tile consumption. A tile is what was referred to earlierâ€”when you look at the whole slide, there are these tiny boxes that represent zoomed-in images, all indexed by AWS HealthImaging. We can request any tile from any slide and get a sub-200 millisecond response. This means that pathologists can literally click through a slide at any speed and never notice any latency in image loading.

The other part involves lifecycle management. Once we upload slides into AWS HealthImaging, we upload the metadata. AWS HealthImaging then ensures the data is moved to proper storage tiers. Thanks to other AWS services like Glacier, we can also move this data into archival storage. Pathology data is important when it's hot, when a diagnosis is made, but it also becomes important in the future when clinicians want to evaluate whether a tumor has progressed, whether something has changed, grown, or developed new features. Data is always important, but holding that amount of data in hot storage is practically impossible.

Thanks to AWS and AWS HealthImaging's integration with other native AWS services, we can design workflows that smartly move data to different storage layers, such as S3, AWS HealthImaging, and then Glacier for archiving. On the clinical diagnosis side, which is extremely important, the integration of AWS HealthImaging with services like AWS Security Token Service and AWS Identity and Access Management allows us to have zero-footprint viewers. Clients don't have to install softwareâ€”it's all web-based. Our software goes directly to AWS HealthImaging to fetch these images.

This is important for several reasons. In digital pathology, it allows real-time access to data for multiple pathologists, enabling them to collaborate in real time because it's cloud-based. It allows pathologists from different regions to collaborate with each other. A pathologist from the US can actually seek advice from a pathologist in the Netherlands. Today, if you want to do that, you have to physically move the slide. You can send screenshots, but then you end up asking, "Can you send a screenshot of that? Can you take a screenshot of this? Can you zoom in on this region?" But if you want to get a second opinion, you have to move the physical slide. With digital pathology in the cloud on AWS, we make collaboration between clinicians seamless and effective.

In the integrated diagnostic workspace, the same capabilities allow radiologists to look at pathology data and cardiologists to look at pathology data. I go back to pathology because radiology gives us an image, and pathology gives us the truth. You can see a misshapen cell or a tumor, but until you do a biopsy, you don't know if it's cancerous or what stage it is. Pathology is the glue that binds the entire integrated diagnostic solution together.

[![Thumbnail 3210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/3210.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=3210)

### Real-World Results: Pathologists Embrace Digital Transformation



Finally, there are two more important aspects, and I'll also talk a little bit about research. A tumor board is a process where specialists from different areas meet in an offline meeting. They bring all patient records together and then discuss the findings to determine the best path forward for the patient in terms of treatment and further diagnosis. Today, a tumor board is an offline meeting where you bring the data you have and think will be important. You could forget data, take the wrong images from the slides, or get questions you're not prepared to answer because they're not in the report.

In digital pathology, tumor boards become fully online, fully digital, and fully enabled. Thanks to bookmarks in the reports, we can zoom into the slides. Thanks to the digitization of images, we're always looking at the same source of truth. Last but not least is research. Having the data in one place without needing to copy it to multiple separate locations is what distinguishes AWS HealthImaging for us. Connecting that with other systems such as Amazon SageMaker allows us to bring that data, train or specialize a model, evaluate that model, and then deploy it back in the solution without having to worry about where that data resides and manage it.

So what does this mean for the work of pathologists?

[![Thumbnail 3310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/3310.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=3310)

This is based on a survey of 52 pathologists and lab agents.  I won't go through the entire survey since I know everyone is eager to end the last session of the day. One hundred percent of the surveyed pathologists do not want to go back to a microscope once they experience digital pathology. There is approximately 21% more cases diagnosed in digital versus manual pathology. One hundred percent of pathologists surveyed expressed that digital pathology helps them reach diagnostic consensus by enabling digital online collaboration.

[![Thumbnail 3350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7d48b303051ec049/3350.jpg)](https://www.youtube.com/watch?v=y8g9gY9pOzY&t=3350)

Last but not least,  I hope that from what we have all discussed and demonstrated, you understand that this is a very complicated and complex topic. In a complex area, you cannot do everything by yourself. It is all about partnerships. We started with partnerships and I want to end with partnerships. Philips brings our clinical expertise and clinical knowledge, our understanding of operating in highly regulated environments, our partnerships with hospitals and clinical institutions, and our years of tradition in innovation.

AWS brings us a secure, scalable environment and continuously keeps innovating. They bring us the storage we need, they remove the complexity from our lives, and they allow us to focus on what we are good at. That is why solutions like this are only possible through real partnerships. With that, I want to thank you for your time. If you have any questions, we will be happy to answer them, and we look forward to seeing you around. Thank you.


----

; This article is entirely auto-generated using Amazon Bedrock.
