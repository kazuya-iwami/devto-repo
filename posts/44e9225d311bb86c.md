---
title: 'AWS re:Invent 2025 - Trading innovation: Jefferies'' AI assistant on Amazon Bedrock (IND3315)'
published: true
description: 'In this video, Alex Mirarchi from AWS and Sanjay Nagraj from Jefferies present their AI Trade Assistant built on Amazon Bedrock. The solution addresses traders'' challenges in accessing real-time insights from millions of daily trades across fragmented data stores. Using Titan embeddings model and Strands agents, the assistant converts natural language queries into SQL, retrieves data from GridGain in-memory database, and generates visualizations through conversational analytics. The architecture leverages AWS EKS, Amazon Bedrock Knowledge Base, and integrates with Jefferies'' Global Flow Monitor platform. Beta deployment to 50 users achieved 80% reduction in routine analytical tasks. Key learnings include avoiding LLM-generated visualizations to prevent hallucinations, using in-memory databases for speed, and building LLM interactions with Python. Future plans include multi-product expansion beyond equities and global rollout with enhanced governance capabilities.'
tags: ''
series: ''
canonical_url:
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Trading innovation: Jefferies' AI assistant on Amazon Bedrock (IND3315)**

> In this video, Alex Mirarchi from AWS and Sanjay Nagraj from Jefferies present their AI Trade Assistant built on Amazon Bedrock. The solution addresses traders' challenges in accessing real-time insights from millions of daily trades across fragmented data stores. Using Titan embeddings model and Strands agents, the assistant converts natural language queries into SQL, retrieves data from GridGain in-memory database, and generates visualizations through conversational analytics. The architecture leverages AWS EKS, Amazon Bedrock Knowledge Base, and integrates with Jefferies' Global Flow Monitor platform. Beta deployment to 50 users achieved 80% reduction in routine analytical tasks. Key learnings include avoiding LLM-generated visualizations to prevent hallucinations, using in-memory databases for speed, and building LLM interactions with Python. Future plans include multi-product expansion beyond equities and global rollout with enhanced governance capabilities.

{% youtube https://www.youtube.com/watch?v=F5DIH9mD2vo %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/0.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=0)

### Introduction: Jefferies and AWS Partnership Driving Trading Innovation

 Hello, everyone. It's great to be here with all of you today. Thank you for joining us in today's session, which is the last of the day and of course the best. This is Trading Innovations: Jefferies' AI Assistant on Amazon Bedrock. My name is Alex Mirarchi, and I'm a Principal Industry Specialist for Capital Markets at AWS.

[![Thumbnail 20](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/20.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=20)

 In my role, I lead business development for trading and financial market infrastructure providers globally, and I've been doing that for a little over four years now. I'm really looking forward to today's session, not just because I'm presenting it with Sanjay, but because it showcases how the industry is trying to adopt generative AI into trading workflows. Before I pass things to Sanjay to introduce himself, I'll quickly share our agenda. Today, you're going to hear how Jefferies built a trade assistant agent on AWS to solve a common problem that the front office faces: accessing and analyzing massive amounts of data for trading purposes.

[![Thumbnail 60](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/60.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=60)

 You'll hear about how Jefferies' trade assistance capabilities work, and you'll also see its architecture and a demo. Then to wrap up, we'll share with you the impacts that the AI Trade Assistant is already having and some of the next steps that Jefferies has in store for the solution. Our goal here is for you to leave with some fresh ideas and strategies that you can use in your own organizations. As a quick housekeeping note, we won't be taking Q&A during the session, but Sanjay and I will be available afterwards to answer any questions you might have.

With that, let me invite Sanjay to talk first about the partnership between Jefferies and AWS and then the trade assistant agent. Thank you, Alex. Hello, everyone. My name is Sanjay Nagraj, and I'm a Senior Vice President of Electronic Trading at Jefferies. I lead innovation in Jefferies' equity technology space where we design and support multiple mission-critical applications. Our focus spans messaging, processing, distribution, and visualization, all essential for enabling fast and reliable trading workflows.

[![Thumbnail 120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/120.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=120)

 A bit about Jefferies: Jefferies is a 60-year-old full-service investment bank. Over that period, we have built a reputation for delivering top-ranked capital markets and investment banking capabilities across a wide range of industries and geographies. The key to our success has been our motto: clients first, always. It's not just a tagline; it's a mindset that drives us in every decision we make. Our mission is to help every client we represent fulfill their maximum potential, whether it's trading, investment banking, or analytics. Every solution we build is designed to empower our sales and advisory teams to deliver sharper insights and better outcomes for our clients.

[![Thumbnail 180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/180.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=180)

 I'll take a few moments to discuss Jefferies and AWS's partnership. AWS has played an increasingly important role in helping us drive continuous innovation for our customers. Our journey began in 2022 with an initial infrastructure buildout, and today AWS is in every aspect of Jefferies' innovations. You'll find cloud-native solutions running on AWS in every corner of Jefferies. For example, in trading, Jefferies built our fixed income algorithmic trading platform right from scratch. It responds to RFQs, executes trades, and runs complex algorithms natively on the cloud.

Our equities and options team uses AWS to calculate multi-factor pricing scenarios in an extremely volatile market. Beyond that, we've also democratized generative AI across Jefferies with the rollout of our enterprise-grade AI platform that offers a secure, modular system for generative and agentic AI. It supports tasks like smart retrieval, document summarization, and automated workflows. Employees can build custom bots, conduct deep research, and streamline operations. This platform seamlessly integrates with many of our internal systems and supports leading AI models for maximum flexibility.

The use case that I'm personally most proud of is the trade assistant, which we're going to discuss today. Here we are deploying generative AI to improve business user engagement through a chatbot that provides traders with AI-driven insights on trading patterns and market liquidity, while also dramatically reducing analyst and developer toil. In short, AWS is not just a technology partner; it's a catalyst for innovation across Jefferies.

[![Thumbnail 300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/300.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=300)

### Building the Trade Assistant: Solving Data Access Challenges with AI on Amazon Bedrock

 Let me talk about the trader system now.

So why did we partner with AWS to build a solution for the equity front office? The reason is to solve a set of challenges that Jefferies equities traders face today. It's hard to access real-time insights about client behavior, trade patterns, and market trends because the amount of data is so vast and so fractured. We're talking about millions of trades a single day which are stored in multiple different data stores and visualization tools, and this is global. It's also impossible to have the end-to-end visibility that all the traders want.

Traders need a way to coalesce around all of this data and generate insights, but oftentimes they don't have the time during the day or the coding ability to generate and maintain a system capable of delivering this. The result is that traders find it difficult to arrive at the insights that they need when they need them. They face barriers that slow down their decision making and impact both trading and providing services. What we set out to do is solve these exact problems and we built a solution that reduces these barriers to providing insights that empower our traders to access real-time conversation analytics with JNAI. This is how the Trade Assistant was born.

[![Thumbnail 400](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/400.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=400)

Let me ask Alex to walk you through the solution capabilities and architecture. Ease of use and accelerating time to insights were key drivers in the design here.  When the trader submits a query to the Trade Assistant, the underlying LLM, which in this case is the Titan embeddings model, generates the resulting SQL query. It then queries the underlying data and services the answer in a variety of form factors: text, tabular outputs, charts and graphs.

The solution has a conversational analytics interface which allows traders to drill down on topics and explore data insights conversationally. The system maintains conversational context to provide relevant insights and suggestions for deeper analysis over the entire lifetime of the user's session. The solution also uses Strands agents, which enables Jefferies technical teams to build and run AI agents with minimal code. There's also flexibility for Jefferies to easily choose different LLMs for specific use cases through Amazon Bedrock as the Trade Assistant evolves.

From a security perspective, the solution has advanced guardrails coupled with low-level data entitlements to prevent accidental access to customer sensitive data through intelligent access controls. All conversations are logged with complete audit trails to meet compliance requirements. I'll pass it back to you, Sanjay, maybe to walk us through a demo.

[![Thumbnail 490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/490.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=490)

Thanks, Alex. So I'll show you how this works. What you'll see here is a user interface  with a sample question that the trader will post to the assistant. The interface is part of our existing BI platform called the Global Flow Monitor or GFM for short. The GFM contains a trove of real-time trading data that our front office traders rely on every day.

When the traders log in, their credentials are verified to ensure the right entitlements so that they only see their data that they are authorized to see. The experience is simple and intuitive. A trader can type in a question like, "Give me the sector breakdown for trading in the US today." Behind the scenes, the assistant uses the power of LLM to generate the appropriate SQL query and run it against our relevant data sources.

[![Thumbnail 540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/540.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=540)

[![Thumbnail 550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/550.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=550)

In our case,  we host everything on GridGain, our in-memory data grid that retrieves the data instantly. But we don't stop there. The response is then  passed on to a Python library that converts the raw data into a visual story: charts, tables, and insights that are displayed right on the screen. This charting feature combined with conversational analytics and rich visualization has been received well by the trading community.

[![Thumbnail 580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/580.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=580)

I'll pass it on to Alex to walk us through the architecture. So let's look at the architecture in a bit more detail. First, we establish a connection between the Trade Assistant and Jefferies on-premises business intelligence  platform, GFM, which Sanjay just mentioned, with an AWS Direct Connection in step one. Once a trader logs into GFM, they have a UI widget to interact with a Trade Assistant agent. As you can see in steps 2 through 4, we build several services using AWS EKS to authenticate users and create user sessions and query LLM agents. Once a user successfully authenticates,

the request is routed to the Bot Service in step 3, which establishes a user session and invokes the query agent. Let me double-click on step 4 for a second. The query agent here is actually a Strands agent, which I mentioned a few slides ago, that operates at the core of that LLM interaction. It takes a question from a trader and interacts with multiple MCP tools to decide which data source to pick to best answer the trader's question. We selected Strands agents for their simplicity and advanced functionality, but I think we didn't start with Strands agents, right Sanjay?

[![Thumbnail 690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/690.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=690)

We started off with LangChain, and then eventually pivoted to Strands basically based on the recommendation from the AWS team. We observed a lot of improvements in the processing and having that ability. We decided since we're starting from scratch, we might as well use the latest. It makes sense and is easier to orchestrate. So back to Strands. Strands plans and executes the agent's steps using the advanced reasoning capabilities of the underlying model, which I mentioned earlier is the Titan embeddings model. We also decided to use Amazon Bedrock Knowledge Base as a vector store, as you can see in step 6.  Once the query agent identifies the right data source and creates the SQL query, the query executor service queries the underlying data. The LLM chooses the visualization to display, and we use a markdown UI library to render the visualizations in step 8.

[![Thumbnail 730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/730.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=730)

### Impact, Future Roadmap, and Key Learnings from Deployment

I'll pass it back to Sanjay to talk about the impact and some of the next steps that Jefferies has in store for the solution. We are already seeing significant benefits from the trade assistant in our beta rollout to around 50 users across sales and trading operations. We delivered an 80% reduction in the time spent on routine analytical tasks. That time savings unlocks massive efficiency and translates directly into increased revenue generation capacity.  The adoption rate has also been high, which speaks to the solution's effectiveness and user satisfaction. We're planning for a global rollout to our trading user base.

[![Thumbnail 810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/810.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=810)

Beyond the time savings, the solution has reduced the technical burden for producing custom dashboards across multiple trading desks. Its self-service capabilities also mean lesser dependency on technical resources while creating a consistent user experience across multiple desks. We also democratized data access. Business users can now query millions of records of equity trading data using simple natural language, which enables real-time discovery of trading patterns and market opportunitiesâ€”something that was previously out of reach. Importantly, the architecture is future-proof. It's self-learning, so it continuously improves and adapts. It integrates easily with Jefferies' existing BI platforms and infrastructure, ensuring scalability and maintainability. In short, the solution bridges the gap between complex financial data and business user needs, providing a platform that's not only powerful today but built for continued growth. 

Throughout the journey, we have learned a lot about agentic AI from the architecture patterns to prompt engineering best practices and performance trade-offs. This was possible thanks to the deep collaboration with Alex and the AWS account team where we experimented, iterated, and refined our approach. Looking ahead, our global rollout strategy focuses on three key pillars. First, multi-product expansion, extending the trade assistant beyond equities to support diverse trading desks. Second, global deployment, bringing proven efficiency gains to international trading operations. Third, enhanced governance, strengthening observability and audit capabilities to meet our regulatory and compliance requirements. We're also exploring advanced code generation, which means transitioning from UI-based tools to sophisticated NLP-driven code generation for a better user experience.

[![Thumbnail 890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/44e9225d311bb86c/890.jpg)](https://www.youtube.com/watch?v=F5DIH9mD2vo&t=890)

At the heart of our technology organization is innovation and reusability. We are identifying similar opportunities across other business areas and aiming to turn this solution into a generic AI API that can be used firm-wide. In short, we are not just solving for today's challenges; we are building a foundation for the future.  There are a few key learnings that we wanted to share with you today, which we put on the screen in front of you. The first is don't rely on LLM to generate visualizations because of the risk of hallucinations. Use a faster data store like an in-memory database to maximize the speed of result output. Build LLM interactions with Python for flexibility, and everything else can be in Java so that we can port your existing code to the Java interface.

Before we go to the next slide, can you just double-click on takeaway number one? Jefferies leverages the LLM to select the specific agenda output for the query, but doesn't generate it itself. It's the Python library, the markdown library, that generates that so that way we have more control over what can be generated. We can leverage the open source available, which can make that difference and minimize the hallucinations. Yes, perfect. Well, thank you Sanjay. We look forward to continuing our partnership with Jefferies and supporting you as you roll out the trade assistant to more desks and more product types. Thank you everyone for joining us today. That concludes our talk and our presentation. Please be sure to fill out the survey which is in the app. Sanjay and I will be available offstage to answer any questions you have. Enjoy the rest of your re:Invent, everybody. Thanks. Thank you.


----

; This article is entirely auto-generated using Amazon Bedrock.
