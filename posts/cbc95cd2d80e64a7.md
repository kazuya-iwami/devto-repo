---
title: 'AWS re:Invent 2025 - Everything you''ve wanted to know about performance on EC2 instances  (CMP405)'
published: true
description: 'In this video, AWS experts Seth Fox and Arthur Petitpierre explain EC2 instance performance optimization, covering the decoder ring for instance naming (C/M/R families, generation numbers, processor types), processor evolution across generations (Graviton, Intel, AMD), and critical hardware concepts like hyperthreading differences between Intel (SMT-enabled) and Graviton/AMD GENOA (single-threaded cores). They demonstrate how memory topology, particularly AMD''s CCX architecture and NUMA nodes, impacts application performance, showing cases where larger instances can paradoxically perform worse. Key insights include same processors across C/M/R within generations, price-performance improvements despite higher per-vCPU costs, and practical advice on avoiding two-socket instances for Kubernetes unless NUMA-aware.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/0.jpg'
series: ''
canonical_url: null
id: 3085411
date: '2025-12-05T05:42:05Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Everything you've wanted to know about performance on EC2 instances  (CMP405)**

> In this video, AWS experts Seth Fox and Arthur Petitpierre explain EC2 instance performance optimization, covering the decoder ring for instance naming (C/M/R families, generation numbers, processor types), processor evolution across generations (Graviton, Intel, AMD), and critical hardware concepts like hyperthreading differences between Intel (SMT-enabled) and Graviton/AMD GENOA (single-threaded cores). They demonstrate how memory topology, particularly AMD's CCX architecture and NUMA nodes, impacts application performance, showing cases where larger instances can paradoxically perform worse. Key insights include same processors across C/M/R within generations, price-performance improvements despite higher per-vCPU costs, and practical advice on avoiding two-socket instances for Kubernetes unless NUMA-aware.

{% youtube https://www.youtube.com/watch?v=BKgG8DSdNUo %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/0.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=0)

### Introduction: Understanding Hardware Performance Beyond Cloud Abstractions

 Welcome everybody. Can everyone hear me? Great. This is a code talk, so I want to make sure everyone realizes this is not a dark room to hide and just look at slides. This is interactive. I'm going to start off with some questions that we're going to ask, and we have a few slides to go through, but the more questions you ask us, the more we'll get out of it. I have a way to encourage that. I've got stickers, so ask a question, get a sticker. That's how this is going to work today.

We want to get through a little bit of setup here to set up the conversation. We're going to talk about performance, obviously. But after that, we really want you to ask us questions. That's the idea behind today. That's going to be more of a console talk than a code talk, but we'll get there. Before we dive into it, I just want to get a sense of who's in the room today. Show of hands: have you ever looked at your application's performance metrics and thought you weren't really sure why it's running as fast as it should be running faster than it is? I see a few hands up. For those of you that didn't raise your hands, I'm going to say you're either incredibly lucky or optimistic, but we're going to figure out which one today.

Hands up again if you ever tried to optimize performance by throwing more computer at the problemâ€”maybe a bigger instance, more cores, more memory. Lots of hands up for that. Thank you. That's why the stock is so high. Last question: how many of you have heard of terms like NUMA nodes, cache lines, and CPU affinity but honestly weren't quite sure exactly how that impacts your application performance? I see a few hands for that. I think you've all come to the right place based on the show of hands.

There's a persistent myth in our industry that modern compilers and cloud infrastructure have abstracted away the need to really understand hardware. We just write clean code, deploy it to the cloud, and magic happens. But here's the thing, and this is what we're going to explore today: the difference between code that runs and code that flies often comes down to understanding the hardware beneath these abstractions. Imagine you have two identical servers running identical code, processing identical workloads, but one consistently performs 40 percent better than the other one. No visible errors, no obvious bottlenecks in your tools. What's going on? The answer might be as simple as which CPU cores your threads landed on or how your data structures align with cache lines.

When you're pushing the limit of what's possible, when every millisecond of latency matters, when you're trying to squeeze every drop of performance out of your infrastructure budget, that's when understanding these low-level details transforms from interesting trivia into critical knowledge. Today we're going to pull back the curtain and explore memory topology and explain why your RAM isn't just one big pool. We'll examine the art of hyperthreading and why sometimes using fewer cores gives you better performance. We'll talk about how to actually measure performance in a way that gives you more than just pretty pictures. Most importantly, we're going to learn how to make informed decisions on when these optimizations matter and when they don't.

[![Thumbnail 200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/200.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=200)

[![Thumbnail 210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/210.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=210)

### Decoding the EC2 Instance Portfolio: Naming Conventions and Processor Consistency

My name is Seth Fox. I'm joined by Arthur Petitpierre. Let's dive in. I want to talk for a second about how to read the EC2 instance portfolio. Over the years we have lots of instances and lots of instance families to dive into, but there is a decoder ring, and that's the sticker you'll get.  It's going to look a lot like this. Let me break this down for folks so that we understand what we're looking at.  I've highlighted three of our workhorses: the C's, M's, and R's. Those are compute optimized, general purpose, and memory optimized instances. What does that mean exactly? It's basically a vCPU to RAM ratio. You can see the ratios up there, and as you move through those, the vCPU to RAM ratio doubles as you go up that stack.

This decoder will work across our instance families. If we look at this, we've got a c8gn.2xlarge. What does that mean? I've got a compute-based instance because I see the C. It's 8th generation, so you can see where it fits in the lineage of compute-based instances. Then there are a couple of options for this instance: G and N. The G tells us this is a Graviton instance, so it's got a Graviton processor in it. The N tells me this instance has some difference in networking, some specialized networking. Now we get into the numbers. The 2xlarge is going to tell us how many vCPUs there are. Everything doubles. We start with 1 for medium, 2 for large, 4 for xlarge, and 8 for 2xlarge. So now I know I've got 8 vCPUs and because of that, I've got 16 gigabytes of RAM because I know the ratio for those things.

When I break this down, this is an 8th generation compute-based instance with 8 vCPUs, 16 gigabytes of RAM, and specialized networking up to 50 gigabits.

Looking at one compute-based instance, this will cover your entire instance portfolio as you're looking across that, and you can use that to break down different pieces as you're making those instance choices. One last comment before we go to the next one: we mentioned in the table at the top left that C, M, or R instances have different amounts of memory. There's a myth that we encounter extremely often that dates back to 5th generation, which is that the processors on the C series might be faster than the other ones. The last time that was true was for Intel 5th generation AWS instances. Starting from generation 6, we have the exact same processor on C, M, and R instances. So if you're using an M6I, you have the exact same processor on a C6I and the exact same processor on an R6I.

This makes your life as someone analyzing performance much easier. It's also much easier when you're using things like Spot and you want to diversify. That's still the same processor. As much as possible, we will try to keep that a real thing for the next generation, so that's definitely true for 7th generation across the board. On the Graviton side, the 7th generation Graviton-based instance is a Graviton 3, and that's the same one for C7G, M7G, and R7G. That's the exact same thing on the AMD side: the same Genoa-based processor on AMD 7G. We've done that again with generation 8, and we will do that again with generation 9. I cannot promise that it's going to be the same for generation 15, but for as long as we can do that, we will try to do it.

We tend also to make that broader, so with the I instances, for example, we've been using the same processors as in C, M, and R. So you have AMD, Intel, and Graviton, and even within Intel and AMD you have multiple families and multiple lineages. Even within different CPU brands, they are still the same performance? No, that would be too simple. The processor is exactly the same within the same brand of processor. So C8I, M8I, and R8I: that's the same processor and the same performance profile within the generation. Now if you move from an Intel to an AMD, they're going to be super different. If you move from an AMD to a Graviton, they will be super different.

I cannot tell you there's one that's going to be better at everything compared to the other. I can give you guidance. I can tell you that in general, a Graviton processor will be more cost effective, but in some cases, an AMD processor will be more expensive but will be faster. And there will be other combinations with Intel. There's never going to be an easy answer to that question because they are optimized for different things, and they behave differently. You will have cases where you have plenty of cores in the same memory domain on a Graviton-based instance, whereas AMD has done a totally different type of optimization with clusters of eight cores. It will have a different performance profile when you access the memory, and it will have an impact on your applications.

Within vendors, server chips have different SKUs and they have different TDP and clock speeds, but you're saying that these easy-to-use VMs have uniform underlying hardware as a single SKU across the board, so there's no variation. I know the lower core count tends to have higher boost frequency and that sort of thing, but going lower core count on these instance types will never yield higher performance in single-threaded applications versus higher core count because the underlying hardware is uniform. As usual, it won't be a straightforward answer, but

### Instance Type Categories: From General Purpose to Flex Instances

a VM is a slice of a big server. When you run on an EC2 instance, what you get is a slice of the big server. Internally, we call those big servers droplets because the cloud is made out of droplets. That big droplet is going to have as many cores as the biggest sizes in the family. If I take the example of a CAG 48 XL, that's going to be a two-socket server with two Graviton 4 processors, each having 96 cores. Now if you take a CAG large, that's a 2 vCPU instance, which is one slice of that two-socket, 192 core server.

In a sense, it's not because you select small VMs that you will get a higher frequency, because they're taken as slices of a bigger one. Those bigger ones have all the exact same underlying processor within a generation and for a specific vendor. Those droplets are homogeneous across the entire infrastructure. However, if you really care about super high frequency, we do have special instance types like the R7IZ. They're usually postfixed by Z, and those have been designed for high frequency, usually above 4 gigahertz. We used to have M5ZN, which was one such instance, and Z1D. They tend to be instances that we designed for things like EDA, where getting the highest possible single thread performance is very beneficial.

Talking about type families and processors, we started discussing this a little bit, but basically what we call general purpose regroups three different types. The T series are the burstable instances, and they are the only type with the flex type of instances in AWS to be overcommitted. This means that on those ones, we run more VMs and we sell more vCPUs than there are actual physical cores. This is great for cost and great when you have an application that has limited performance requirements, but probably not good for anything where you really care about performance.

The other general purpose instances are not overcommitted. When I mean not overcommitted, it means that every time you get, let's say a two vCPU based instance, we've carved for you two vCPUs on that instance. We do it the right way, meaning that those allocations are static. The VMs are not floating around. When you get allocated two cores, you stay on those two cores, so when the cache is warm, it's going to stay warm for you. We never allocate anything across the boundaries of a NUMA node, so you will never end up on an AMD instance with 4 cores on one CCX and 4 cores on another. It's always within the boundaries. If you have a VM with 16 cores in 7th generation AMD, that's going to span over 2 CCXs.

Compute optimized instances don't mean that the processors are faster just because the name says compute optimized. It just means that if what you care most about is having compute power and you don't care much about having a lot of memory, that's what you need, with 2 gigabytes of memory per vCPU. Memory optimized again doesn't mean that the memory is faster. It just means that you get more. On an R instance type, you get 8 gigabytes of memory per core. That can be much more than that. X instances have 16 gigabytes, and Z instances have 8 gigabytes of memory. Accelerated compute is where you will get GPUs, FPGAs, and various other types of accelerators that we have introduced.

Storage optimized means that you get local discs that are physically inside the server, not the virtual discs that you have with things like EBS. HPC optimized instances are very special instance types made out of the same hardware but have a special ring fencing mechanism for HPC applications. Flex instances are another option where some of the M and R instances exist as a flex version with exactly the same hardware as the normal class, except we overcommit them and load balance them so that most of the time you will get 100% of the performance, but you can go down to 80% of the performance of the underlying hardware.

Flex instances are super convenient when you are not super critical on the performance side, and they are cheaper. However, if you want perfect reproducibility on the performance side, then probably they are not for you. They are better than the T series in the sense that you do not have that mechanism where you credit CPU cycles and then you consume it and then reach a stage where you are out of credits and then have that unlimited mode. It is a more steady type of utilization, so it is more predictable. Staging is a great place to use flex instances, especially where you are mostly doing functional tests and do not need the maximum throughput.

If you really want to evaluate the maximum throughput that you can get from an M series instance, do not take the M Flex. Sometimes you will get 100%, sometimes you will get only 80%. However, for a staging environment where you are mostly doing functional tests, it does not change anything. When you know that only getting 80% of the max is sufficient for you, that is also a great fit. Most of the time you will get more than 80%. They work with the same interface as normal instances. You just name it whatever dash Flex, and the biggest sizes are not available as Flex.

Regarding visibility into performance, yes, it is visible when you are being throttled and not getting the full 100%. However, to be honest, nowadays do not use the T classes anymore unless you really do things that are non-critical. Use the flex instances instead. They are a much better proposition. For flex instances, if you want to know where in that 80 to 100% range your workloads are getting, you have to trust us. There is a bottom. What happens behind the scene is that we are load balancing those instances with transparent migration. We have a pretty efficient mechanism to ensure that you are not all of a sudden in a droplet that is so hot that you are down to 60%. We just transparently migrate things.

[![Thumbnail 1190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/1190.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=1190)

### Processor Generations and Evolution: From Sky Lake to Granite Rapids

Transparent migration has been something that AWS has been shy to talk about. We have been doing it for quite a long time, mostly for reliability purposes. It is now in the EC2 FAQ, but we were doing it a long time before it was in the FAQ. We do not expose it to customers in the sense that you cannot schedule the migration of one of your instances, but we use it a lot behind the scene and it is a really reliable mechanism. The way to think about it is that an instance is a completely virtual construct. It does not live in a place. It lives in the cloud.  Let us talk a little bit about what are the actual processors on those different instance types, and here I am going to mostly focus on C, M, and R, and

that's probably 90% of what you're using. For those of you who are more familiar with the code names of the different vendors, we often get the question of what is behind your 5th gen, 6th gen, whatever. When you're doing performance comparison, even though I would tell you to use the latest because that would probably be the right thing to do, if you do comparison with different processor types, there's a generation gap.

A Graviton Gen 6, for example, would be comparable to an Intel or AMD Gen 5. This is true across the board. Gen 6 is comparable to a Graviton Gen 7. Gen 7 Intel and AMD is comparable to a Graviton Gen 8. For the rest, Gen 9 Graviton is not yet there, but that will come at some point. On Intel and AMD Gen 5, we had Sky Lake and Cascade Lake. That was a weird thing that hopefully we won't do anymore. We introduced it with Sky Lake, and then we did a silent refresh with Cascade Lake. It had almost the same performance profile, but in some cases, Cascade Lake was a little faster. That was a little weird for customers. We've not done it again because customers complained and we listened.

AMD Gen 5 was Rome. On the Graviton side, Gen 6 was Graviton 2. One recommendation I would have is don't use those any longer unless you're using them through Spot. The price performance ratio of those instances is no longer worth it. Switch to things that are more recent and you will get better performance. Gen 6 Intel and AMD is priced exactly the same way as Gen 5 and it's faster, not extremely faster, but faster. There's absolutely no good reason, unless there's no capacity available, to use Gen 5 on Intel or AMD or to use a Graviton 2 on the Graviton side.

Even Gen 6, compared to what we have released recently, starts to be old. They're cheaper than Gen 7, but in terms of price performance ratio, you would be better off using a Gen 7 or Gen 8. On the Intel side, that's Ice Lake. On the AMD side, that's Milan. On the Graviton side, Gen 7 is Graviton 3. More recently, Gen 7 on Intel is Sapphire Rapids. Gen 7 on AMD is Genoa, a great processor. On Graviton, that's Graviton 4. Then the latest that we have released a couple of months ago, we have Granite Rapids on the Intel side and we have Turin on the AMD side. On Graviton, well, it's easy to guess and that will come.

A couple of trends that we have seen over the last years: the number of cores per socket is going up. This is true across the board. You've seen that on Intel, you've seen that on AMD, and you've seen that on Graviton. That won't stop. It's going to be true for the next generation of the various instance types. The dollar per vCPU is also increasing. The manufacturing technology, the memory technology, all of that is more expensive. So the price on a per vCPU basis has gone up.

That being said, the dollar per amount of performance has decreased because the performance has increased. Even though on a per vCPU basis it's more expensive, if your application actually benefits from the performance of the processor, you get a better value proposition. The power consumption per unit of work has also decreased. If you want to be a little bit less intensive from a power consumption standpoint and be a better planet citizen, you'd better use the latest generation of instances. They're a little bit better in that regard. Does anybody have sustainability goals in the organization? There's Graviton and taking advantage of the latest processors will help with a lot of that.

Another trend that we've seen, and we'll see how that will evolve, is that some of our processors are using simultaneous multi-threading, which is the ability to use two or more threads of execution per physical core.

[![Thumbnail 1530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/1530.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=1530)

Some of us do not, and that has an impact on the performance and how you measure the performance. We'll see that a little bit deeper later in the presentation. 

[![Thumbnail 1550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/1550.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=1550)

### Q&A Session: Spot Markets, Pricing Models, and Instance Configuration

So a couple of thingsâ€”oh well, we pause. We get that questions. What questions? Where can we go next? Everyone's going to be quiet today. It's the first date. Everyone should be excited, not tired yet. Here we go down in front. 

OK, so a couple of things about the virtualization right here. Are all of the families that we've been discussing available in spot instances and where does the Sapphire Rapids name come from? So they're all available as spot right from the beginning. When we release spot, the spot market is enabled, but the question is not so much technically available as spot as much as whether the capacity is sufficient for a healthy spot market. When we release and some of those things are very successful from the release and customers are massively moving over to the new generations, there might be very little capacity for spots. Before you get a healthy spot market, it usually takes a couple of weeks, more realistically a couple of months.

Though I would say that in general, the very early adopters of new generations are the spot customers who have the ability to use Capacity Commitment Discounts or the very early adopters. When you use an allocation mechanism with Capacity Commitment Discounts saying I want everything starting from Generation X, the day we release before any on-demand customer has started to use those instances, you're using it. The price is low and the performance is great. Then the on-demand customers start to switch, and then the spot market kind of disappears for a couple of weeks until we launch enough capacity that you start to have a healthy spot market.

Now about your second question, the code names from Intel. I think that most of the code names are coming from rivers and lakes in Washington state. That used to be true for sure. Nowadays I don't know because I don't remember whether there's a Fire Rapids anywhere in Washington. I was in Seattle until six months ago and I've never seen any Sapphire Rapids. Our processor name is a little bit more straightforward: Graviton 1, 2, 3, 4. It's pretty easy to track and you know where it came from. You have another question here?

Real quick, a reply to what you just said. Why is Graviton 2 generation 5? Because there was no Graviton when we released the first generation of EC2-based instances. Don't ask me why the first generation of Graviton-based instances was called A1. Because that was our first ARM processor and maybe at that time we had the idea that we would call the next one A2, but we never did that. We had A1, which was a porting vehicle, and then the next generation we had C and M and R that were C6G and M6G and R6G. Honestly, I would not want to be the one within the EC2 product management team having the responsibility to name the instances because however you choose to do it, you'll screw up at some point.

My other question was, so you said that as generations increase, the price per vCPU goes up, but the price per performance goes down. How do you evaluate whether you'll save money going to a new generation? Like if you're on an 8-core workload, you have to go down to 4 cores in order to decrease your price, right? It depends. If your application is really running on a single instance, yes, that would be a problem. There's the trick where if the performance goes up, because usually you have multiple parameters. It's not only the performance of the CPU, but it's also, OK, I might really need that amount of memory.

If network is not really the bottleneck, potentially you can go to an M with half the number of cores, and maybe that's the sweet spot for your application. More often than not, you might have a pool of servers, a pool of web servers that are serving a given workload with a certain number of requests that you have to serve coming from your customers, and it's fluctuating.

Let's say that on average you're using 100 of those services. If you have one that is faster now, maybe on average you will be using 80 of them. They're more expensive on a per instance basis, but you're using less of them. The idea is not necessarily to worry about the CPU load on your machines. Worry about what is the API request per second, what is the business measurement of that instance, the throughput of the instance. If that increases and then you test it and that goes up, then you're getting that price performance metric.

If you have that single server, only one, and there's no way you can distribute that, then you're right, you get better performance, but you pay more. I've got a question about spot markets and the health of them. At what point do you guys start tearing old server racks out? I run a lot of bioinformatics workloads. They need boxes and memory, but they don't really care about speed. I've got everything going back to like M4s. Is there a point where there's a deprecation, stop using these, we're going to start tearing them out?

If you're running things on an M4, it's probably no longer running on M4 hardware. It's now running on Xeon Nitro, where we emulate our previous generation of virtualization system and we make you believe that you're still running on an M4, and it works. If you're in a company where you had to validate that software with that specific piece of hardware, it still worked the same way, but on our side it's probably no longer an M4. We try as much as possible not to retire instances for customers who need them.

So there are accounts where you can still launch an M2, but that's no longer a real M2. From a price performance standpoint, don't run on anything that old because it makes absolutely no sense. There are other reasons to do it, but otherwise, we don't think we ever retire instances. Well, we did, but for some specific instances like old GPU instances where we can't emulate that and we could no longer maintain the hardware, and then we have retired those instances. In general, we try our best to make them available for as long as we can.

I have one question. You mentioned that the price for the latest instance type would be lower, right? But one observation I made is when you're going with reserved instances, I saw the older generation are much cheaper. I think what you mentioned is very true for RDS where they changed their pricing model for DRIs. I don't think I've seen that for EC2. My experience with EC2 instances, I also observed it's possible, and we've been trying also to shift customers away from RIs and to Savings Plans.

What I mentioned in terms of pricing was applying specifically to on-demand. The way we've chosen to price those long-term commitments can be a little different. The second question is, all the instance types are like one CPU, like memory and CPU are strictly restricted, right? Is there any plan for AWS to change so I can select the memory? GPU would be like, let's say 2, memory could be 4 or 8, the same way as GCP does it. Not that I would be aware of. Thank you. But we offer more diversity also.

It's the two ways to handle that problem. Either you have a very small number and then you make that customizable, or you offer a lot of different combinations. I believe that we cover a very broad number of possible combinations. If there's something that is really missing, please let your account team know. We have a mechanism called PFRs where we signal our teams that there might be that thing that is missing. Our teams may identify missing features, and if we feel the demand is significant enough, we might implement them.

My understanding is they may be moving away from the choose-your-own instance configuration approach. I cannot confirm this, but they may be moving away from that. It is a challenge to maintain, certainly. However, with 950 instance types available in increments of 100, you can find something that meets your needs within our existing portfolio. At the end of the day, it comes down to where we choose to expose complexity. If we decide to expose that level of flexibility, it means we add complexity in how we carve instances on the physical hardware, since the physical hardware is fixed. So it really comes down to where we put the complexity. So far, we have chosen to put the complexity on you in some way, where we offer fixed sizes and plenty of them, and you choose among those.

### Performance Optimization: Socket Counts, Hyperthreading, and the Nitro Virtualization Stack

Regarding your first question about socket count at maximum: on Intel-based X class instances, you have 4 sockets. On U class instances, which are very specific and cannot be obtained on demand and are mainly targeted for SAP, you can get up to 8 sockets. For your other question about hyperthreading, I will talk specifically about that and show you how to identify it.

Without increasing the vCPUs and moving from the previous generation to the new generation, performance improves because all those vendors are improving how their CPUs are designed. There are plenty of ways to do that. Generation over generation, there are usually bigger caches. L1 has been pretty much fixed on the latest generations, but L2 has grown and L3 has grown significantly. You have massive L3 cache on the latest generation of Intel and AMD, which helps a lot when dealing with memory accesses and making your workloads usually faster.

Another area that can be improved is changing how the branch predictor works. Many applications are super sensitive to how the CPU predicts the next set of branches your code will go through. The memory network has also improved and become more scalable. Memory latency has stayed pretty much at the same level, but memory bandwidth has increased massively. On G5 Intel, if I remember correctly, you had 4 memory channels. The latest generation has 8 memory channels. The latest generation of AMD-based instances has 12 memory channels. By improving these different areas in the processor, you make them better and faster.

If your application has performance issues, simply throwing more CPU at it does not always help. Giving more CPU to an application is not always going to make it faster because to benefit from more vCPUs, you need an application that has some level of parallelism. If it is able to use multiple CPUs, that will potentially make it faster, but only up to a certain level. You almost never have 100 percent of your application that can be parallelized, so part of that application will still be sequential and you will not be able to accelerate that infinitely.

One thing I forgot to mention about how processors have improved is that they have also improved in how many instructions they can execute in parallel. Many people have a mental model of the processor where at every cycle, you do one thing. However, modern CPUs can execute multiple instructions in parallel.

They perform memory loads and stores, additions, multiplications, and some processors can execute up to six instructions per cycle. Some applications are built and optimized in a way where they can only extract a couple of instructions per cycle from a given processor. Unless you significantly optimize them, they are actually underutilizing the CPU. So there is not a straightforward answer to your question. It requires more analysis and lower level optimization.

Most of our instances are now using the latest generation of our virtualization stack. When we moved from fourth to fifth generation, we changed the way we do virtualization. We moved from Xen to Nitro. This definitely has an impact on performance because we offloaded a bunch of the virtualization primitives to dedicated hardware. It has lowered the noise of the virtualization system. You could not really do a comparison because we never exposed the two virtualization systems on top of the same processor, but there was a significant gain when moving to the Nitro virtualization stack.

It also reduced the noisy neighbor effect that you could get from the previous system. There is almost no noisy neighbor problems with Nitro, except at the memory bandwidth level. Nitro also made possible bare metal instances. Because we moved all the virtualization primitives outside of the instance, everything with regards to network access, EBS, and all of that is offloaded, so there is nothing that we really need to do at the hypervisor level from a security standpoint. We can offer instances as a metal option where we remove the hypervisor and you get full control over the CPU.

The drawback is that we only offer them as full instances, so they do not come in small chunks. However, in some cases, if you need to get full control over the processor, it is possible with the metal instances. From a performance standpoint, do not expect the metal instances for normal workloads to be faster. The level of performance penalty introduced by the network and the Nitro IP advisor is extremely limited. There is a little bit of an impact for people having very strong requirements at the network level. People doing high frequency trading, for example, will see a difference.

[![Thumbnail 2620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/2620.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=2620)

But for normal people doing normal web applications and databases, there is absolutely no point in going to metal unless you need for other reasons to run your own virtualization system, which becomes more of a functional requirement and not so much a performance requirement.  There was a question before about hyperthreading that we were going to answer. Is this the slide to talk about it? The title of the slide, by the way, is wrong. You had a question about hyperthreading, and I think I forgot who asked, but this thing has changed quite a lot.

[![Thumbnail 2680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/2680.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=2680)

[![Thumbnail 2690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/2690.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=2690)

[![Thumbnail 2700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/2700.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=2700)

### Hyperthreading Deep Dive: Comparing Intel, AMD, and Graviton Performance Profiles

Before we introduced Graviton, all our instances had hyperthreading enabled. So for each physical core, you had two threads mapped to a physical core. Starting with Graviton, we introduced instances that were single threaded, so each vCPU is mapped to a physical core. Starting with AMD GENOA, AMD is also without hyperthreading. That has a bunch of consequences on the performance side. I can show you a quick demo on that.  What I am going to do is connect on a  C7I, so seventh generation Intel-based instances. If we look at what we have in /proc/cpuinfo,  that is a C7I large, so that one exposes two vCPUs.

[![Thumbnail 2730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/2730.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=2730)

[![Thumbnail 2750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/2750.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=2750)

Those vCPUs are actually threads of the same physical core. I'm going to launch a quick OpenSSL speed test.  Next, I'm going to do exactly the same on a Graviton-based instance.  That one is also the same size, so it's a large instance again, but this time we have two vCPUs where each of those vCPUs is a physical core.

[![Thumbnail 2780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/2780.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=2780)

[![Thumbnail 2790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/2790.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=2790)

[![Thumbnail 2800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/2800.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=2800)

We get a certain level of performance with that one.  Looking at what we were able to do in terms of signatures per second, we're roughly 39,000. Now I'm going to do a second test where I will do that, but this time with two execution threads. OpenSSL has the ability to parallelize what it is doing, so it's actually using two processes to do that now, and we'll see what we get from there.  

[![Thumbnail 2820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/2820.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=2820)

[![Thumbnail 2840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/2840.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=2840)

[![Thumbnail 2850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/2850.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=2850)

[![Thumbnail 2860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/2860.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=2860)

We get slightly higher performance at 42,000 signatures per second, but we don't double what we had. On the Graviton side where we have one vCPU mapped to one physical core, if we do exactly the same,  first what we can observe is that in terms of signatures per second we were slightly slower with a single thread of execution. Now if we do it on two threads of execution,   we have almost doubled, not quite, but almost. 

I don't want to use that test to say Graviton 4 is better than Intel in that case. What I want to illustrate here is that SMT versus no SMT has an influence on performance. If you test your application at low levels of loads, you'll see two different types of design. Intel has big, beefy cores and potentially they will give you extremely good latency at low levels of utilization. On the Graviton side, we have smaller cores, but we have more of them, allowing us to map one vCPU to one physical core. At low levels of loads, potentially we are not as fast. However, we scale higher. So these are two different designs leading to two different performance profiles.

I'm not saying use one versus the other, that's not the point. There are plenty of other metrics and there are cases where the Intel processors will be faster and there are cases where the Graviton processors will be faster, but keep that in mind when you're evaluating the performance of those instances. The same would be true of AMD processors. AMD processors are a little different. We have chosen, because AMD had very high core count processors, to expose them as non-SMT starting from generation 7. They're more expensive on a per vCPU basis, but the performance you will extract if you're parallel enough and if you run them hard enough is going to be extremely good.

[![Thumbnail 2990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/2990.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=2990)

I think that's a key point for this demo. This was parallelized, right? Like if the application can't be parallelized, it's not going to be able to take advantage. Going back to Arthur's point earlier, if that's a key distinction, whether the application can take advantage of having those bigger, larger cores is important.  Yes, so this information about hyperthreading, for example, and probably CPU instructions and other things, I'm pretty sure if I look, I'll help everyone else here. My question was, so this information about hyperthreading and probably CPU instructions and other things, yeah, I can probably find it on the internet. Probably there's a blog post from AWS saying this. Is that exposed in any APIs that could, it's not exposed in APIs, but the processor tells you. But then I'll have to launch an instance to check it. Yes, if I have, there are plenty of things that the APIs are not exposing.

### API Limitations and Processor Feature Discovery

The API is not exposing the amount of L1, L2, and L3 cache that you get on any instance. The API is not exposing the NUMA topology. The API is not giving you the memory latency or the theoretical memory bandwidth. There are plenty of characteristics of a processor that the API is not giving you.

Each of those processors has options in their instruction set. Some generations of Intel processors have the ability to expose a 57-bit virtual address space, but not all of them. It is not in the EC2 API. If you launch an EC2 instance, you can check whether the operating system has been able to detect that specific feature. But there is way more to a processor than what we can realistically expose in the API.

One possible use case would be if I have quite a few EKS clusters, for example. I could create my own catalog and do the homework to get exactly the instructions I care about. I could create node pools that would expose those instructions as labels so I could schedule specific workloads onto a specific set of processors. It is not like you are doing this indefinitely per processor per family. Remember, if it is a C8M8 or R8, they are going to have the same processor in them. It is not that complicated, but with a 910, I have to do the work. When we refresh, absolutely you need to, and that is true any time we have launched something new. Always test before you proceed.

I understand the request and I get it. There is a question of to which depth we want to go there. So far we have chosen to limit ourselves to exposing the frequency and exposing the CPU type. Once you launch the instances, you can get all that information because it was exposed to the operating system, but we do not make it available as an API. There is an internal discussion on whether we want to make it part of the documentation, which could be a way to do it. The reality is that our team has that documentation for ourselves because we find it useful. So yes, we could expose that.

[![Thumbnail 3170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/3170.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=3170)

With your demonstration,  it was a benchmarking on OpenSSL and you compared a 7th generation to an 8th generation Graviton. That was on purpose. If you tried the 7th generation Graviton, I think you would have probably lost significantly. The 2 vCPU, I would not. The 1 vCPU would be even slower, but the 2 vCPU, no, I would still win that with a Graviton 3.

### The Graviton 2 RSA Challenge: Lessons Learned from SSL Performance

Once upon a time I tried to migrate a load balancer to Graviton. But that was another problem. I know which instructions you will be talking about. The problem you probably have seen with an SSL load balancer was a Graviton 2 problem. On Graviton 2, we made a mistake that we did not anticipate would have that kind of consequences. We did not anticipate that RSA would be that much slower on Graviton 2 compared to Intel-based instances.

The reason behind that was that RSA uses a lot of 64-bit integer multiplications. We had a single 64-bit integer multiplier on the Graviton 2 core. When running an SSL or TLS connection, at the session establishment, Graviton 2 was much slower. The AES part of an SSL session was much faster on Graviton 2 compared to Intel-based instances. So if you had long connections, nothing was visible and Graviton was doing great. If you had short connections, like a gateway for a bunch of IoT devices or a gateway for an observability system where you re-establish an SSL connection every time you send metrics, Graviton 2 was terrible.

We fixed that with Graviton 3 by adding one multiplication unit on the core, making Graviton 3 much faster. We also fixed it partially.

We also partially mitigated that on Graviton 2 by optimizing RSA for Graviton 2. Within AWSLC, which is a crypto library from AWS, we have a much faster RSA implementation on Graviton 2. So that issue no longer exists, and Graviton 4 is doing great on crypto. We've closed that gap, but it definitely existed at the beginning of Graviton 2's life.

[![Thumbnail 3370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/cbc95cd2d80e64a7/3370.jpg)](https://www.youtube.com/watch?v=BKgG8DSdNUo&t=3370)

### Memory Topology and NUMA Awareness: Why Earth Isn't Flat on AWS Instances

We have about 5 minutes to talk about memory topology. Earth isn't flat, and it's very visible on some AWS instances. The memory topology on a C7A processor is structured with groups of eight cores called CCX, or compute core complex. Those eight cores share a slice of L3 cache and a connection to the memory die. 

When you run on an AMD-based instance of that generation, your application won't see a flat topology. If you have an application thread that runs on that first block and accesses something in memory, that part of the memory will stay warm in the cache. If you try to access the same part of the memory from the next CCX, the information won't be in the cache.

I've seen cases of customers moving from 2 XL instances, which would be one single slice, to 4 XL instances. Now they are spanning across 2 slices and seeing their application become slower because they were across two memory domains. If they were trying to access memory from one domain where things had already been warmed up from the other domain, they had a cache miss and had to replenish the cache first, which wasn't as fast as they expected.

On a 24 XL instance, you have this non-uniformity. On a 48 XL, you would have another level of non-uniformity because you would have a second socket, and you would have an even greater distance between the cores on the first socket and the memory associated with those two sockets. When you deploy things on AWS, pay attention to this. The maximum sizes of our instances tend to be two sockets.

When going from, let's say, 24 to 48 in that generation of instances, there are cases that may not be faster. You will get more cores and more memory, but if your application doesn't take into account the fact that the memory is no longer flat and uniform, you might have weird surprises. I had a customer a couple of weeks ago who moved their database from a 24 XL to a 48 XL, and the P50 latency of their database doubled because memory was now spread across the two sockets.

They had more memory and more vCPU, but the database on average was slower. Some requests were just the same speed. The overall throughput was higher, but the latency was definitely higher. This can also be an issue with Kubernetes since someone was talking about using that before. If your containers land on different domains, on different sockets now, the connectivity between them is slower than you might expect.

Kubernetes has new features becoming NUMA aware, which is something to look at. This is something that can become super important. These are some of those low-level differences that start to make a big difference. My recommendation, unless you know exactly what you're doing, would be to avoid the two-socket sizes on your Kubernetes cluster. If you know what you're doing, then go do it, but otherwise stay with the single sockets.

We don't expose that in the API, but even with multiple sockets, if you land on a multi-socket host but have a small on-demand instance, the advice doesn't apply as strongly to keeping it to a single complex size. The difference in terms of latency and memory bandwidth between two CCX is much lower compared to between two sockets. Thank you everybody. We are out of time. Please fill out your surveys, and for those of you that want a sticker but didn't ask a question, come see me. I'm happy to give them out.


----

; This article is entirely auto-generated using Amazon Bedrock.
