---
title: 'AWS re:Invent 2025 - No More Orphans: Bringing Work and People Data Into Decisions with MCP (ISV319)'
published: true
description: 'In this video, Kinman Lam from AWS and Ike Bennion from Visier demonstrate how Visier leverages AWS Model Context Protocol (MCP) to solve the "orphan data problem" where critical workforce information is scattered across multiple systems. Visier, a leader in AI people analytics serving 60,000 customers in 75 countries, built an MCP server using Amazon ECR, EC2, Route 53, and CloudWatch to unify siloed HR data. The demo shows Claude using Visier''s MCP server to identify high-risk employees and exit drivers through natural language queries. Key lessons include the importance of tool descriptions for agent behavior, API observability challenges, and cost management through rate limits. Visier plans to enhance their MCP implementation by integrating their own LLM for richer context and preparing for scaled enterprise deployments beyond current pilot phases.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/0.jpg'
series: ''
canonical_url: null
id: 3088720
date: '2025-12-06T11:18:41Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - No More Orphans: Bringing Work and People Data Into Decisions with MCP (ISV319)**

> In this video, Kinman Lam from AWS and Ike Bennion from Visier demonstrate how Visier leverages AWS Model Context Protocol (MCP) to solve the "orphan data problem" where critical workforce information is scattered across multiple systems. Visier, a leader in AI people analytics serving 60,000 customers in 75 countries, built an MCP server using Amazon ECR, EC2, Route 53, and CloudWatch to unify siloed HR data. The demo shows Claude using Visier's MCP server to identify high-risk employees and exit drivers through natural language queries. Key lessons include the importance of tool descriptions for agent behavior, API observability challenges, and cost management through rate limits. Visier plans to enhance their MCP implementation by integrating their own LLM for richer context and preparing for scaled enterprise deployments beyond current pilot phases.

{% youtube https://www.youtube.com/watch?v=8JQUek4V2uQ %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/0.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=0)

### The Orphan Data Problem: Why Scattered Information Prevents Better Decision-Making

 Hello. Hi, my name is Kinman Lam. I'm a Senior Solutions Architect here at AWS. Welcome to ISV319, No More Orphans: Bringing Your Work and People Data to Decisions with MCP. So you are tasked or you've been asked to form a new team of existing employees for a critical project. Great. Who's interested? Who has the capacity and the bandwidth? Who has the skills to ensure that this project is a success?

Many managers and leaders make decisions without the full picture because data is scattered across multiple systems. That's the orphan data problem, and it's costing you the ability to make better decisions. Today, we're going to learn about Visier and how they leverage AWS Model Context Protocol, or MCP, to unify siloed data and surface insights when you need them.

Joining me is Ike Bennion. Ike Bennion is the VP of Product Management at Visier. Ike has a rich history of product development, strategy, and go-to-market and is a recognized thought leader in the HR analytics space. He's contributed to the success of Cornerstone OnDemand, HireVue, and Instructure. He's passionate about data and using it to make intelligent and equitable decisions, leading him to join Visier.

Visier is a global leader in AI people analytics, workforce planning, and compensation allocation. Founded in 2010 by business intelligence pioneers, they're trusted by 60,000 customers in 75 countries. Visier gives you the ability to understand the relationship between people and their work, how to boost productivity, and adopt change quicker. Ike, I'll hand it off to you.

Thank you, Kinman. I appreciate not only the introduction but also the help from AWS in making this MCP server that we're going to talk about today a reality, and to also Adam and Peter and Sonia, the others of the team. I appreciate a lot the support. And then also I have my dev counterpart, Vincent Chu, who of course without development this would not be a reality, and so excited to have him as well for this session. I will defer some of the questions over to him undoubtedly about MCP and enablement.

[![Thumbnail 190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/190.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=190)

 But to start us off, and from the great introduction by Kinman, I'm excited to introduce to you sort of how we thought about this as a case study and also highlight a demo, a use case of the power of artificial intelligence, the MCP server, and our tech stack together. Because it wasn't too long ago, three years, it's hard to believe when our collective minds were blown at our first LLM experience, and we're living in a pretty remarkable time. Businesses and people were immediately tantalized by the idea of not only can we put our pets into various costumes of various historical periods and timelines, but how can we also make this productive? How can we take the mundane day-to-day and automate it through artificial intelligence?

[![Thumbnail 240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/240.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=240)

And just like any person that you would hire off the street, you can't just immediately set them to work. You have to give them the right information. You have to give them access to tools. You have to give them access to workflows to actually drive productivity. It's not enough to just be intelligent. And so that's where MCP comes in. That's where the natural inclination from wow, this is a powerful new technology that we can use  to this is a thing that we need to now enable with specific context, tools, and workflows. And so with that, again in the session, excited to talk more about that with you today.

[![Thumbnail 250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/250.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=250)

 So our general flow that we're going to walk through is up here. We'll talk through the challenge of why this is key, the solution that we implemented to give you just a flavor, a perspective of how you might approach a similar implementation, and then seeing it in action. So we'll do a demo with you through Claude, one of our favorites in using with our MCP. We'll talk about our lessons learned so that you can hopefully not trip over some of the same things that we have experienced, and then lastly think about what it means for the future, how we're thinking about evolving our current implementation into new horizons of opportunity with MCP.

[![Thumbnail 290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/290.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=290)

 So as Kinman did a great job of highlighting, there is a lot of disparate information in various places that could be useful in the decision-making process.

It's not very contrived to say that everyone believes everything should be more data-driven, but it doesn't happen as a reality because of these three problems. First, siloed data across the ecosystem is a major issue still today, even after decades of trying to consolidate it all into one place, and this represents a big opportunity of missed impact. The second is the time challenge, where a lot of pre-built processes have ingrained development of data for decisions, but for ad hoc decisions, which represent a lot of the decisions that are made every day with people, it's not there. It doesn't have that data available to help support managers and leaders and users in the time that they need that data.

And then lastly, there's a struggle with data literacy itselfâ€”the data that's available, how to use that data, how to think about the definitions of different metrics and relationships across data. It ultimately comes down to the challenge, the decider challenge, of helping them to become more literate and capable with that data. And all of these three things, as you'll see through the presentation, have a big opportunity to be fixed in different enterprise implementations of MCP and agents, as you'll see through our presentation.

[![Thumbnail 370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/370.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=370)

### Visier's MCP Server Implementation: Architecture, Demo, and Real-World Application

So this is where  Visier enters with our MCP server. As Kinman did a great job of introducing, let me give you just a double click. As you can see here in the bottom, we take data from various sources across enterprise ecosystemsâ€”your HCM, ERPs, EDWsâ€”and then we ingest it into our data ingestion layer to help reconcile and cleanse that data and prepare it for use. We have a semantic layer that has thousands of metrics, concepts, and dimensions that are ready to go for any organization to open up the box and start to use to answer questions across the entire employee lifecycle. And then we have a caching and distribution layer, because if you've ever done analytics, working on a huge database like that requires a lot of horsepower. It can mean delays in wanting that data and getting that data back, so we put a lot of effort into making sure it's speedy. And then ultimately, that's where we stack our MCP deployment on top of, using some of those APIs that are already existing from that caching and distribution layer.

So to break down what exactly we did with the help of AWS, this is basically like any other server that you'd be familiar with. We took the open source code, modified it for a specific use case, and then built a server using, of course, things like the Amazon Elastic Container Registry to manage our MCP server containers for release. And then those containers are deployed on EC2 for each of our global regions and availability zones, and then we use Elastic Load Balancer and Auto Scaling Group to manage the EC2 instances as demand changes. And then finally, since we're a multi-tenant hierarchy, so each organization has their own environment, we use Route 53 to manage domain names and Amazon CloudWatch to observe to make sure that we're seeing the performance, the uptime, things like that that we need from our servers for MCP.

[![Thumbnail 490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/490.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=490)

So let's actually look at what  this looks like. So this is a recorded demo, mostly for the fact that, as you know, of using different agents, there's a lot of thinking time. And so for our benefit here of not watching an agent think, I cut out a lot of that but left everything else so that you can see the full experience. And again, this is going to flow through to what we need to do in the future and lessons learned, and so I intentionally kept warts and all in just to give you that benefit.

[![Thumbnail 520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/520.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=520)

[![Thumbnail 530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/530.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=530)

[![Thumbnail 540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/540.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=540)

[![Thumbnail 550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/550.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=550)

So let's imagine that I am an engineering team lead, and I had a very notable exit of somebody who's a high performer,  so that's startling to me, of course, and I want to make sure that we're keeping all the key performers that we need. So I go to Claude, I input my prompt,  and then as you can see here, Claude has gone to Visier's MCP server and it started to pick up tools. And that's one of the notable things about MCP versus using an API, is that  MCP allows you to put additional context for what the tool is for and when the agents should use it, which causes better behavior for many of the APIs that you might be thinking about,  but then also makes it more stable over time so you can continue to build against the MCP, improve your APIs without having to go back and reconfigure every integration that you have with agents across your ecosystem.

[![Thumbnail 570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/570.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=570)

[![Thumbnail 580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/580.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=580)

[![Thumbnail 590](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/590.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=590)

So as you can see here, it's picking up different tools like searching for analytic objects, filtering down  those objects, things like that, and then getting down to the organizational level. And then in a few minutes here, we'll begin to see it spit out an output  of who are the top five employees that we have, what's the risk of exit across next year,  and then ultimately it will start to feed into observations that are really critical and key of what can actually be done. But I want more. It's not enough for me to know. It's more important for me to know what to do as a result.

[![Thumbnail 610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/610.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=610)

As a result, I go back and ask for the drivers. What is actually causing these people to be at risk of exit according to Visier's predictive  model? Now the agent goes back to work. It'll be a little quicker this time. It's taking those five high-risk engineers and it's now going to look for those key drivers. As you can see here, it's still picking up tools, still thinking, and then it will start to return back the result.

Now the thing that I haven't shown you here that I'm actually really impressed with in the Model Context Protocol open source protocol is that authentication for end users is actually pretty straightforward and easy. We use and have implemented OAuth, so you literally just authenticate like you would into Visier every day, and then it hooks you up. You can choose which tools you can use. It gives you a description. It's really easy to manage even for end users, so it's a really straightforward, easy protocol to use, at least for the end users you're trying to serve. As you can see here, it's ticking through those engagement risks. It's identifying career stagnation, and here comes back that result again.

[![Thumbnail 670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/670.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=670)

[![Thumbnail 680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/680.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=680)

[![Thumbnail 690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/690.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=690)

It's showing you, okay,  here's who is really at risk here. There are compensation issues, career stagnation, poor manager relationships, performance concerns. Now I'm not just having a poke around in the dark  trying to figure out what's the problem. Now I have something that I can really drive, and I can even, this is also one of my favorite parts, go ask for agendas. If you hook up your Google Calendar, you can have  Claude set up your meetings for next week to say, hey, what's going to cause you to stay. It's a really powerful tool to help managers to again have a higher elevated literacy into what they can do with data.

You can also imagine this and the real value proposition here that organizations have come to us with is they want to hook up MoveWorks with ServiceNow. They want to hook up Atlassian. They want to have all these other systems that have MCP servers so you can start to pull data from across the ecosystem into a single workflow, which is really powerful for a lot of use cases and making that data more usable.

[![Thumbnail 730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/730.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=730)

### Lessons Learned and Future Directions for Enterprise MCP Deployment

So lessons learned. As you saw through that use case, we wrapped APIs, which isn't an  uncommon approach, but APIs were built for a specific use case, and this use case is fundamentally different in how agents approach those. The first thing is that depending on who your users are, what they hire you for, and how your APIs are configured, that's the first thing to know. You're probably going to have to do some work on giving additional tools through APIs, consolidating endpoints, dividing out different MCPs according to use cases to help make that use more straightforward.

The second is that agents are not friendly in giving you back what went wrong. If you're thinking that you can go just find that within your typical interfaces, you're not going to. It's more helpful to have observability on the API side, so make sure that you have all the answers that you can to not only make sure that it's behaving as appropriate, but it's also delivering predictable, high-quality results over time through the MCP server.

The second, tool descriptions matter a lot. Again, this is kind of the net new thing in my perspective of what makes MCP really interesting. The error you saw in that demo, you may have seen it, kept warts and all, is because of a dependency between two APIs. The best way to help that is to provide better instruction through the tool going forward, but it's also important to note that even as you improve and think about these instructions, if you have a multi-agent landscape, what we've observed is that agents pick up and use those tools differently inconsistently across all of those agent use cases. So be strategic in how not only you're implementing, but if you're serving customers, how they're implementing as well, and what to look for.

Third is potential cost is a big consideration. Vincent and I talked about this quite a bit about how to anticipate this and how to ensure that we're not incurring anything unnecessary in terms of new costs. What we did was more of a preventative measure to mitigate until we could, to mitigate with typical things like caps, rate limits, things like that, so that you didn't have an agent, for instance, that errored out and then caused performance issues on our servers. Make sure that you're also considering that in advance because the only way to really see what the use case against these APIs are going to be is to do it.

Even still, as we've been working with enterprises, everyone's still sort of in the pilot phase. There's a lot of promise. There's a lot of valuable use cases, but in terms of actually going live, there's still a little bit of work to go on everybody's part. Luckily we've been able to see a lot of really good uptake and feedback to drive us forward into the future.

[![Thumbnail 890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/890.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=890)

Which brings to what are we going to do next.  First we're asking ourselves questions about how do we move towards other ways of widening out the return that we provide to agents because as you know they're very pinpointed and direct many times in what they're trying to get from your systems which may actually limit the value that the end user receives.

That would be different than if they were coming to your UI. I think this is an inevitability of the future that we just need to be prepared for, given the attitudes that many enterprises and organizations have towards agents and MCP.

So what we are thinking about is how do we take our own LLM that we've built that's really smart on our data, the context of our users, and what they're asking for. We want to understand what to ask them about to ensure that we're providing a wider value proposition back, so that the agent has the right context to provide a better story around the data that will help managers.

The second question, as I mentioned, is that we are still seeing a lot of pilot use cases with our enterprise partners and enterprise customers that we're working with. So we're already asking the questions and trying to use our crystal ball to look into the future of how do we see a scaled use case world. How do we see both the number and diversity of customers and MCP serving a broader audience in true in-the-wild use cases?

And lastly, what are the implications of using tools beyond even the ones that we've surfaced up already as part of our original API landscape? This includes things like providing tools for visualization and other capabilities alongside a simple query. What does that look like, and how do users digest and put weight of authority against the output of an agent with those additional tools that we provided? So it's a really exciting opportunity, and again, one that we're really focused on, not just providing a wrapper but also thinking about how do we create a new value proposition through MCP and the agents that our customers may use.

[![Thumbnail 1000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/b7c8ad1a6d246e4a/1000.jpg)](https://www.youtube.com/watch?v=8JQUek4V2uQ&t=1000)

 So in conclusion, we are always eager, as you can tell, to work with others in trying to learn more about what this landscape and use case looks like. And so if that's you, or if you'd like to learn and understand more about how to use data with your own teams, please visit us at visier.com/demo. Or of course, I'm happy to answer questions, and Kinman as well, as well as Vincent. Thank you so much for your time today.


----

; This article is entirely auto-generated using Amazon Bedrock.
