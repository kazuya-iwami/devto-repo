---
title: 'AWS re:Invent 2025 - Experience T-Mobile''s Digital Commerce in Action (IND358)'
published: true
description: 'In this video, T-Mobile engineers Glen, Nick, and Vipin share their digital commerce transformation journey, scaling from 0.4% to near 100% digital commerce. They detail their evolution from eight disconnected platforms to one cloud-native platform on AWS with Elastic Path, handling 10x traffic spikes during iPhone launches. Key innovations include an active-active multi-region architecture using Kinesis, Lambda, and DynamoDB for cart streaming, enabling sub-minute deployments and rollbacks. Their ephemeral environment strategy automates full stack lifecycle every sprint, rotating through development, production, and decommission in four weeks. This approach eliminates traditional DR exercises and implements automatic secret rotation. The presentation concludes with their AI-powered Easy Switch feature, enabling carrier switching in seven minutes.'
tags: ''
cover_image: https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/0.jpg
series: ''
canonical_url:
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Experience T-Mobile's Digital Commerce in Action (IND358)**

> In this video, T-Mobile engineers Glen, Nick, and Vipin share their digital commerce transformation journey, scaling from 0.4% to near 100% digital commerce. They detail their evolution from eight disconnected platforms to one cloud-native platform on AWS with Elastic Path, handling 10x traffic spikes during iPhone launches. Key innovations include an active-active multi-region architecture using Kinesis, Lambda, and DynamoDB for cart streaming, enabling sub-minute deployments and rollbacks. Their ephemeral environment strategy automates full stack lifecycle every sprint, rotating through development, production, and decommission in four weeks. This approach eliminates traditional DR exercises and implements automatic secret rotation. The presentation concludes with their AI-powered Easy Switch feature, enabling carrier switching in seven minutes.

{% youtube https://www.youtube.com/watch?v=duDT75jvaaE %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/0.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=0)

### The Challenge: Scaling Digital Commerce for 130 Million T-Mobile Subscribers

 Good afternoon everyone. Thank you so much for joining us today. My name is Matt Kozbielak, and I'm so excited to be on the stage today because we're not only going to be talking about digital commerce at scale, but I will show you how it's done by T-Mobile, one of the largest carriers. Now, I'm not going to be doing that alone. I have the privilege to be joined by three absolute rock stars, the engineers who designed, built, and operate this platform. Please help me welcome Glen, Nick, and Vipin from T-Mobile.

[![Thumbnail 60](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/60.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=60)

 So today we are telling you a story. Now the exciting part is some of you already know pieces of that story. Some of you, well, you are the story. We will share the challenges that we faced, but more importantly, how we solved them. This is the journey of innovation at scale. What happens when AWS meets T-Mobile digital commerce platform serving more than 130 million subscribers? Now my hope when you walk out of here is that you actually learn something that you can use and implement yourself, whether that's an architectural pattern, a scaling strategy, or just one thing, one idea that changes how you think about and deploy your own code.

[![Thumbnail 120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/120.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=120)

 So before we go to the details, let me explain to you what the plan is. I will kick us off telling you the T-Mobile challenge that started it all, essentially the why behind everything you're going to hear today. Then Glen will walk us through the T-Mobile digital transformation journey, the pivots, the iterations, and the lessons learned along the way. Nick will reveal their battle-hardened architecture, essentially what's powering their success. Then Vipin will talk about how cloud native architecture has completely revolutionized how they think about their code and how they approach their deployments. And finally, Glen will take us all home, talking about the exciting future that is ahead of T-Mobile and their platform. Now, fair warning, he's tying it to something absolutely extraordinary that literally just happened. So you really want to stick around and hear this one.

[![Thumbnail 210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/210.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=210)

 So let me start with that. I'm going to ask you a couple of questions. How many of you are like me, cracked screen all the time, dying battery, or simply you just couldn't resist getting a new device upgrade? Could you please raise your hands, who purchased a new phone this year? There you go, yes. So we have new iPhones, we have new Pixels, maybe even those foldable Samsungs. You can always count on technology people, right? Show us something new, and we're all in.

[![Thumbnail 250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/250.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=250)

[![Thumbnail 260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/260.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=260)

 So with that said, let me ask you a second question. How many of you are actually T-Mobile customers?  Beautiful again, thank you so much for joining us today. Now think back to that moment in the past, whether that was in February when Samsung had their launch, maybe August when Google dropped their Pixel, or just a few months ago in September during the Apple iPhone launch. Whether you were in New York, Chicago, or Seattle, you woke up early in the morning, you got yourself your favorite cup of coffee, you logged into the T-Mobile app, you browsed through the product catalog, you found a device that you wanted to purchase, added it to the shopping cart,

submitted, and boom, done. Great experience, right? Low latency, smooth and fast. Here is something maybe you didn't know or you haven't even thought about. At that exact moment, there were millions and millions of other customers doing the exact same thing, and the platform behind it didn't even break a sweat.

[![Thumbnail 340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/340.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=340)

 So here is where the story gets very real. Just please look around the room. We are all IT people here: builders, engineers, operations. We all share one job, keep those workloads running all the time, no matter what. So let me take you for a couple of seconds into Glen's, Nick's, and Vipin's world.

Think again. Picture that it's a major device launch day. 5 a.m. Pacific Coast hits, the East Coast people wake up, and those shopping carts start lighting up. Look at the transactions. They don't just increase, they just explode in minutes. We are talking 10 times more than the average traffic. Think about your Kubernetes clusters scaling really, really hard, your DynamoDB tables, your read and write spiking. What about your databases, your RDS, MySQL, Postgres? The queries are piling up faster than you could ever add more capacity.

And here's the thing, it's not just one app. It's T-Mobile T-Life, it's T-Mobile.com, and thousands of retail stores across the whole country hitting exactly the same backend, exactly the same APIs, simultaneously coast to coast. So think about yourself. Those are the days that define your career. Your company is counting on you. Your customers are counting on you. Trust me, nobody wants to be that engineer in the hot seat explaining why the checkout page timed out during the most important launch of the year.

So here is the multi-million dollar engineering question. How do you design, build, and operate a platform that never goes down, that scales to infinity and delivers the same flawless experience coast to coast? Glen, Nick, and Vipin, you guys built something incredible to answer that question. Glen, do you mind helping us understand how you actually make it happen?

[![Thumbnail 530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/530.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=530)

### From Eight Platforms to One: T-Mobile's Digital Transformation Journey and the 2018 NPI Crisis

Absolutely. Thank you, Matt. What an amazing intro there. It's amazing to have our partners speak about it like they pretty much have built it, and I know you've been part of this journey, so thank you. Folks, I would like to take you on a journey. March 26th, 2013, John Legere,  the T-Mobile CEO at that time, said, "Love your customers." A simple statement. It came from a genuine sentiment. This was called the Uncarrier movement.

[![Thumbnail 570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/570.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=570)

For those of you who don't know what that is, it pretty much revolutionized the whole landscape of the wireless industry. For example, we were the first to take away all contracts from the US. We were the first to provide unlimited talk, text, and data. And this journey continued for a while. We started out on this journey about 12 years ago.  At that time, we had eight commerce platforms and multiple disconnected customer experiences.

Now imagine this. We kind of joke about it now, but back in the day when John was about to make an announcement, all of us IT geeks would be huddled up in a room, the Uncarrier war room, and talking amongst each other, wondering what is he going to sign us up for now. Those launches were announced first and built later. It was crazy. Those days were really crazy.

[![Thumbnail 630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/630.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=630)

We call it the chaotic days. Imagine the complexity around an industry-changing capability that had to be built in eight commerce platforms and multiple disconnected user experiences. Right in the middle of that chaos evolved our whole mission, which was the T-Mobile digital transformational journey in commerce.  We had one vision, and that was to take it from eight commerce platforms to one platform that rules it all. Our digital share of commerce at that time was 0.4%. That's right, a measly 0.4%. We built this platform from the ground up, fully headless, built and powered by Elastic Path, 100% cloud native, all on AWS.

[![Thumbnail 680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/680.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=680)

All right, since we are always about show of hands, a quick show of hands. How many in the audience here have been through a major tech transformational journey?  That's right, we all have been through that now. Keep your hands raised because that's the next question. In case you've been through this journey and that journey has been completely painless, you can keep your hands raised. That was a trick question. I wasn't sure if people would respond to it, so that was awesome. You're right, transformation is extremely painful. Most transformations come with their own fair share of war stories, and we at T-Mobile have our own fair share of war stories.

Matt here talked about some of the key events that take place within T-Mobile, and so we have a few events that take place each year. For example, the Super Bowl is one such event. The T-Mobile ad places and folks dash right into the website or on the app, and we experience what we call burst volumes of traffic. But the one event that we at T-Mobile obsess about is the Apple iPhone launch, also known as NPI or New Product Introduction.

So here's my war story. NPI of 2018. It now looks like a long time ago, but that was one of the most difficult days of my professional career. Our platform at that time was not quite mature enough to handle the loads coming from a large event like the iPhone launch, and no matter what we tried with respect to loading the catalog into our platform, it just kept crapping out. Yeah, crapping out was a technical term we used a lot those days. It got to a point where our CIO actually asked us, "Hey, should I be calling the business and let them know that we won't have an NPI this year?" So talking about that actually gives me goosebumps because, like I said, it was an extremely difficult day.

[![Thumbnail 820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/820.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=820)

Well, we survived that day because we're here.  But we made a promise to ourselves and to our customers to never ever go through that again. Out of that resolution was coined a very popular term at T-Mobile: YAML. It's not the YAML that everyone here is familiar with. For us, it stands for Yet Another Market Launch. We decided to take a high-stress, high-anxiety event like the Apple iPhone launch and turn it into a boring YAML.

[![Thumbnail 890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/890.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=890)

As we progressed on this journey, and for those geeks in the room here, my awesome team here is going to get into the gory details, we started seeing light at the end of the tunnel. And as a really smart TPM on my team joked and said, that light is not a freight train anymore.  For those of you here in the audience that are about numbers, and I'm a numbers guy, meaning for the life of me I just can't remember numbers, but I do recognize patterns, and so what we see here is what I call the pattern of force.

Our journey took us from below 0.4% to 0.4%, to 4%, to 40%. Now, while I can't quite share the exact percentage we are at right now because that's not public information, the gap to getting to 100% is shrinking rapidly day by day. In fact, we are extremely close to being 100% digital on commerce. Folks, T-Mobile has now evolved from a telco to a techco.

[![Thumbnail 960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/960.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=960)

### Blue Collar Architecture: Moving Beyond Active-Passive with Golden Gate

With that, I'm going to hand it to my head of commerce, Nicholas Criss. Take it away, Nick. Thank you, sir. Appreciate it. Hey folks, as Glenn explained, we had a bumpy start. We definitely did not have it all perfect and figured out from day one,  but what I think we had going for us was we've always had this willingness to try something different when the standard approach wasn't working, and then I think we've always had sort of an obsessive drive to just keep improving, no matter how bad it is, just keep improving.

I call this philosophy blue collar architecture. What that means is we're not overly concerned about appearances, but instead we just focus on what's practical and gets the job done. So today what we want to do is focus on two aspects of our platform that I think do a good job of illustrating this approach. I'm going to talk for a bit on our active-active system, and then I'm going to hand it to Vipin, and Vipin's going to talk about our release process, which makes use of ephemeral cloud environments.

[![Thumbnail 1010](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/1010.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=1010)

 So before we get into that though, I just want to give you a little more background on kind of what our platform is and where it fits into the whole equation here. As Glenn kind of alluded to, we're not the UI. We're the core APIs that power all of the various UIs, so you can think about products, pricing, promotions, and of course carts and checkout. More often than not though, we are the ones in the whole ecosystem that are either making it or breaking it, and we take it really personally when it does fall short.

[![Thumbnail 1050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/1050.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=1050)

So now let's get into the active-active journey. We're going to make you guys do more  show of hands here. By quick show of hands, is anybody here today running a platform that's multi-region active-active? Oh, good number. We'd definitely like to compare notes after the talk. Who's doing active-passive? Anybody? Yeah. And anybody in any of those groups using Golden Gate? Okay, good for you. And who's generally happy with their setup these days? Half a hand. Okay, that's great.

So where we started was active-passive, and we used Golden Gate to replicate two SQL databases across regions. And I have to tell you, that was painful. The releases were complicated, especially when there were database schema changes involved. It was brittle to operate. There was always sort of this drain on performance of running that system, and you definitely did not have any horizontal scaling. But that's not even the worst part. The worst part is when you needed it most, we were always too afraid to use it.

So if you're talking about resetting after a stack failover or after a release rollback, we were so afraid of doing that because we didn't want to have to worry about the resync later that in the end we always ended up just trying to fix forward and avoid that scenario. And so finally, after several years, we just got fed up and we said we're going to build our own process from the ground up.

[![Thumbnail 1140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/1140.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=1140)

### Building Active-Active Architecture with Kinesis, Lambda, and DynamoDB Global Cart

 So a key insight we had that we used in our approach was that we're actually not the source of truth for as much data as we worried about in the beginning. Some background for this: we kind of think of all the data that we deal with in three big buckets. So one bucket is config, and that's the simplest. It's basically, for the most part, the same on all the copies of the running application. Then we have what we call context data. That's mostly for existing customers, if you think about any information that might affect the pricing, the promotions, eligibility of what we're selling in the cart.

Then finally there's the cart itself, and so anything that we need for you to be able to check out must be in the cart. And so with the insight that we really only needed to worry about that last category, that small subset of data, we wanted to build a system that basically streams just our cart changes. So we use Kinesis with Lambda.

We basically stream anytime a change happens on that local stack cart to a DynamoDB table, which we refer to as the global table or global cart. Basically, as you're shopping, any cart changes that are happening are streamed asynchronously, and because it's asynchronous, it's not affecting your performance on the stack at all. So let's walk through how it works.

[![Thumbnail 1230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/1230.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=1230)

 As a user, when you first start shopping, you're going to hit one stack, and our traffic routing component is going to keep you mostly sticky, so you'll continue to be on the same stack. Now that's not critical. You actually would be fine to bounce between stacks, but for the most part, that's the approach. Then as you're shopping, you're making changes locally. As the system's working, it's just streaming out any changes to that cart. On a regular normal day, that's it. It sounds too good to be true or like there's a big piece missing, but for the most part, when we're in normal operations mode, there's not a lot that we are doing with that data once it's in the global cart.

So let's talk about when it's not so good of a day. That's where I think the scenario gets interesting. Let's imagine, for example, that there might be a regional outage, and so now what we want to do is fail over 100% of the traffic to another live stack. In that scenario, for us to switch over, it's simply one very small config change in that traffic router component that says we no longer want to do 50-50%, we just want to put 100% of traffic on the other stack. So what's going to happen now is, as you were in the middle of shopping and suddenly now you're hitting a new stack, we're going to be checking, and we're going to notice that the global cart has more recent changes than your local cart. Then we call that rehydrating, where we will just pull those changes in, and then after that, you're going to basically continue operating as normal.

Because the process is very fast, even if we suddenly end up having, say, 50% of our current active users all rehydrating at the same time on a stack, it's still very negligible from an impact. In the worst case scenarios where we have a very chatty scenario, you might get that initial request for each customer taking a little bit longer, but then once they get through that part, it's back to normal. With this setup, we don't really think anymore about primary or secondary or flipping backward or forth. The only thing we ever think about is what percentages of traffic do we want to route to which copies of the application stack.

Besides the sort of reliability scenarios, we also use this for our zero downtime blue-green releases. For us, a deployment or, if necessary, a rollback is an action that really takes less than a minute because, when you think about it, all you're doing for the actual deployment is making that traffic change. Beyond that, we actually use this as a foundation for a lot of other very cool things, and I'm going to let Vipin kind of get into that.

[![Thumbnail 1410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/1410.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=1410)

### Evolution of Release Strategy: From Blue-Green to Canary Testing and Four-Stack Deployments

All right, thank you, Nick. So once we got to active-active, we soon moved from blue-green  to canary testing. For those who do not know, this is where, when we go live, we introduce a small amount of traffic to our new release, and then we wait and let it bake in. Once we are comfortable about its health and its customer impact, we open up the traffic for the rest of the customers.

Soon after that, we also got to a point where we used AB testing configuration. This is a case where we set different business scenarios on different stacks. We compare and contrast the customer impact and KPIs, and once we are comfortable and we know how it's impacting the customer, we make an informed business decision on which configuration we want to go forward with.

Then came our four-stack releases. We used four stacks in our go-live, where we have a stack assigned for each combination of release and region. This fortified our release because it made us capable of handling issues that might be rooted to either a release or a region. So last month, any given Monday, we had no problems, right?

[![Thumbnail 1520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/1520.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=1520)

Now, a four-stack release might sound a little rich, right? And that's because an environment is an expensive commodity. It takes a lot of time and effort to manage a stack. And this was absolutely true for us at  one point in time, given our environment size. At any given time, our core application has almost half a million lines of code in production, and we're not even counting the supporting applications. For example, our test automation suite has almost 5,000 Gherkin scenarios, either validating partially or fully our current business scenarios. It's about 125,000 lines of code, and this is not counting the test data that we store as JSON files in the repository. If you count them, it's 1.5 million lines of code.

[![Thumbnail 1580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/1580.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=1580)

It used to take us almost four to five weeks to create an environment. And the idea of deleting it after a short run was not even conceivable. So  we treated environments as fixed and tried to work around it, which means many long-running environments specifically assigned to certain parts of the whole release process. And we move code from one environment to another as part of different stages where we go through those painful environment refreshes. That means one refresh and then functional testing in the release branch, in the release environment, then another refresh and then performance testing on the perf lab. Yet another refresh, finally to the Blue stack, do a quick sanity test on Blue stack, and then open it up to our customer as the new production environment.

Now, another question here. How many of you are really unhappy about how much time it takes to get an environment ready after a new release and get to the actual part, which is the validation of the new features? Yeah. And that's one of the main reasons for that, which is essentially because a refresh usually doesn't cover the whole environment, just parts of it. And the long-running configurations and data honestly drift between environments, so the environments that are supposed to be identical are really not. And let's consider this in the perspective of Blue stack. What that essentially means is we take a stack live without doing a full regression testing, end-to-end regression testing on that same stack. And canary testing is where, unfortunately, we are using our customers as guinea pigs.

[![Thumbnail 1710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/1710.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=1710)

### Ephemeral Cloud Environments: Automating the Full Stack Lifecycle with Cerberus

So obviously that's not what we want, and we attack the root of the problem  that our environments are fixed by fully automating the whole stack lifecycle. And now we're starting a new cycle every sprint, for every release. What this means is once a stack is created, we let it live in development and release evaluation for two weeks. Then it goes live and it serves customer traffic for another two weeks. Then, when the next stack is ready as part of the next cycle, we suspend the existing stack and then for a short while before we destroy it safely. The whole process lives as infrastructure as code, which means it's predictable and reliable. This also means that any kind of change to this process is code reviewed just like any other functional code that goes to production.

[![Thumbnail 1780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/1780.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=1780)

So what does our automation look like? What we aspire for  is a Lambda-driven, worker-based architecture, but for now, it's a big GitLab pipeline. It has many jobs trying to fulfill some kind of a purpose, some different types of purposes. One of them is, for example, validating state.

Now that is essentially checking if the environment at any given point is up to the mark for us to move forward to the next state. Then there are others that are essentially doing the main part, which is creating and destroying resources. Then there are those that load data or run some kind of test execution at different stages. Then those that are owning the go live activities. Many of these jobs accomplish their work by triggering more downstream pipelines.

[![Thumbnail 1850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/1850.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=1850)

Okay, let's talk about the resources in our environment.  I would want to break this up into two parts. The ones which are in the scope of the environment and their life cycle is the same as the environment, and the environment itself, the stack owns them, like our application pods and our data stores. Our data stores are created from scratch, and all the data that they hold are either generated or loaded at that same time. Well, most of the data stores, and I'll get to that.

Now, the other kind are the shared resources. And as we talked about just before, one of them is our proxy, which our customers use to connect to us. Any time we want to take a stack live, we just connect it as a target to that proxy and then control the flow of traffic all the way to 100%. And as Nick mentioned earlier, if in any case there's a rollback required, we just switch back to the old stack.

The other key resource that we share across these stacks is our global DynamoDB tables, especially for cart information. Again, as we mentioned earlier, the cart information is the only kind of information that we, as DCD or digital commerce domain, truly own. All the other kind of information come from our partner domains. And cart information needs to last longer than a stack life cycle.

Now imagine this scenario. You are switching to T-Mobile, all the family lines on your account. And you just have to, and you get these lines for just $25 per line per month, and it just takes 15 minutes for you to switch. On top of that, what you get is one month to choose and decide which iPhone 17 would you want and your family would want, on us, no trading required. Of course you will use the whole time to choose your phones.

Over the next few weeks, you will keep visiting the cart with your family, adding and swapping different phones based on color or sizes that your family wants. Our stack does not last for one month, it just lasts for two weeks. It would be a terrible experience if you come in to log in on your perfect iPhone configurations, only to find your cart empty because our stacks changed. We want to avoid that, and that's the reason why we connect the stacks to global DynamoDB tables for our cart information. Any time a candidate stack is ready to go live, we connect it to these tables before bringing it to our customers.

[![Thumbnail 2060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/2060.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=2060)

 So that's our environment. It's actually three environments in one, just like that three-headed dog Cerberus. Instead of moving code across environments and incurring the penalty of repeated error-prone refreshes and the risk of missed use cases or tests due to code and config drift, we create a stack for every release in every sprint. And then move it across the different stages and bring the same stack to our customer when it goes live.

Okay, so what other advantages when it goes live.

[![Thumbnail 2110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/2110.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=2110)

Okay, so what other advantages do we have, apart from  it being ephemeral, deterministic, and light? It does not cost as much as long-running environments. All right, what else? For that, I'll ask another question. How many of you have to do some kind of a disaster recovery exercise in production from time to time? Yep. In our case, we do not do an explicit exercise. It's just part of our normal operations. It essentially happens every sprint automatically.

And this guard dog is also secure by design because the secrets are just another resource of the same stack, sharing the same lifecycle. So instead of having a special project every six months to rotate production secrets, our secrets get rotated every sprint as part of our normal operations. So to sum it up, by treating our environments as real, short-lived, and fully automated assets, we have changed that scary three-headed monster into our favorite guard dog for releases, reliability, and security. With that, I hand it back to Glen.

[![Thumbnail 2230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/2230.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=2230)

### The Future with AI: Easy Switch and Fifteen Minutes to Better

Thanks, Vipin. So every time I hear Cerberus, our favorite three-headed guard dog, it makes me realize and takes me back to that day which I talked about earlier, NPI of 2018, when things were just completely  crapping out. And I look at today and I realize the journey that we've gone through and how fortunate we are to have traversed this amazing journey from back in 2016 when we first started. Folks, T-Mobile is now a deeply data-informed, AI-enabled, digital-first company. It only makes sense for us to have AI embedded into every future activity from here on. And like our CIO Jeff Simon says, we like to sprinkle a little bit of pixie dust in everything, pixie dust meaning AI.

[![Thumbnail 2280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/2280.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=2280)

But I'm going to leverage a very corny phrase since we are here in Vegas, and that is,  what happens in Vegas? You don't have to repeat that. About two weeks ago, right here in Vegas at the Las Vegas Grand Prix, T-Mobile made our latest on-carrier announcement, and that again has revolutionized the wireless industry. Fifteen minutes to better. For those of you who haven't seen it, I would encourage you to go look it up. There's a whole bunch of cool features that we have launched when we made that announcement. But the one that I'm super proud to talk about is what we call the Easy Switch.

[![Thumbnail 2340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/2340.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=2340)

[![Thumbnail 2350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/2350.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=2350)

[![Thumbnail 2360](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/2360.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=2360)

[![Thumbnail 2370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/2370.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=2370)

It's essentially a feature that heavily leverages AI to smash a very, very painful customer experience, and that's the switching experience when you switch from your existing carrier to a new one.  As you see this video playing back, which is the Easy Switch experience, what we allow our prospects to do is log into AT&T or Verizon.  We go in there using pixie dust and we pull in your existing information, plans, and services. We take it through AI  and we come back with a recommendation on the best plan that we think is right for you. We also show you why we recommend that plan. We also walk you through  all the benefits, including the cost savings that you're going to experience when you switch.

[![Thumbnail 2380](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/2380.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=2380)

[![Thumbnail 2440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/2440.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=2440)

And finally, using pixie dust,  we also show you exactly which phones you should get. In some cases, we ask you to stay on your existing phone because it's a newer phone. Essentially, we set up your cart for you and we make it extremely frictionless to switch to T-Mobile. I know the campaign talks about fifteen minutes, but in reality, folks, we have experienced folks that have switched up to five lines in as little as seven minutes. Now imagine this, a painful existing experience where someone wants to switch from one carrier to another. You spend a whole weekend at a store with your family, bitching and moaning, going through that experience, and here we are today where you can switch in the luxury of your home, in the comfort of your couch, in about seven minutes. That whole thought process is just  mind-blowing for me.

[![Thumbnail 2460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/aa0a0617dcf85c82/2460.jpg)](https://www.youtube.com/watch?v=duDT75jvaaE&t=2460)

All right, folks, thank you so much for joining us today, and I know you're thinking, what should your takeaway be from this presentation? So here are three things that I would offer up. Resilience is built, not bought.  Automation is the new scaling lever, and finally, remember the pixie dust. AI-driven experiences is the new normal. Thank you, folks. We really appreciate you joining us today, and we are going to be hanging out in the back there if you want to come chat with us. If you have stories to share, we can also talk about other stories that we couldn't share on stage. But thank you once again. Really appreciate it.


----

; This article is entirely auto-generated using Amazon Bedrock.
