---
title: 'AWS re:Invent 2025 - Improve DevEx for GenAI Deployments: Dynatrace + Amazon Bedrock (SEC207)'
published: true
description: 'In this video, Sean O''Dell from Dynatrace and Simone, a principal solution architect at AWS, discuss Amazon Bedrock AgentCore and observability solutions for agentic AI workloads. They address key challenges in moving AI agents from proof-of-concept to production, including infrastructure management, memory capabilities, tool integration, and monitoring. Bedrock AgentCore provides runtime, identity, gateway, memory, browser, and code interpreter services to address these challenges. The session emphasizes how Dynatrace extends AgentCore''s observability through OpenTelemetry integration, offering end-to-end visibility across multiple LLMs and infrastructure layers, meeting developers in their preferred environments like IDEs.'
tags: ''
cover_image: https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/0.jpg
series: ''
canonical_url:
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Improve DevEx for GenAI Deployments: Dynatrace + Amazon Bedrock (SEC207)**

> In this video, Sean O'Dell from Dynatrace and Simone, a principal solution architect at AWS, discuss Amazon Bedrock AgentCore and observability solutions for agentic AI workloads. They address key challenges in moving AI agents from proof-of-concept to production, including infrastructure management, memory capabilities, tool integration, and monitoring. Bedrock AgentCore provides runtime, identity, gateway, memory, browser, and code interpreter services to address these challenges. The session emphasizes how Dynatrace extends AgentCore's observability through OpenTelemetry integration, offering end-to-end visibility across multiple LLMs and infrastructure layers, meeting developers in their preferred environments like IDEs.

{% youtube https://www.youtube.com/watch?v=WJVsbB_2FAw %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/0.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=0)

### Introduction: Partnership Between Dynatrace and AWS for Agentic AI Observability

 Hey, good afternoon, everybody. You are surviving AWS re:Invent and we're glad you're here. This is the last day. Let's power through. I'm Sean O'Dell. I lead our developer experience team at Dynatrace, and I have Simone who actually, go ahead and introduce yourself, Simone. Hi, everyone, Simone here. I'm a principal solution architect at AWS. Perfect. Go ahead and go to the agenda slide if you don't mind.

[![Thumbnail 30](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/30.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=30)

One thing I want to mention real quick, this is a very loose agenda, but what we do want to cover is a few of the announcements  that have been made this week, specifically from AWS and Dynatrace. Three straight days of main stage keynote introductions and conversations. We'll talk a little bit about how we work together and some of the things around agents and obviously Bedrock AgentCore. Then I want to introduce a little bit of how we at Dynatrace add value and supplement what the Amazon team and specifically Simone, myself, and a few others have been working on. We'll go from there and then we'll have Q&A after the session, preferably in the Dynatrace booth just to help out here in the room. But glad to have you here today.

[![Thumbnail 70](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/70.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=70)

[![Thumbnail 90](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/90.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=90)

Perfect.  So thank you very much, Sean, for introducing this. Yes, here we can see a slide with the partnership between Dynatrace and AWS. It's a very strong partnership. Dynatrace is one of the very valuable partners of AWS. Let's dive into the topic for today. So, Amazon Bedrock AgentCore, how many  of you are familiar with this service? Nice, quite a few. Some of you. And how many of you are using the service today? All right, some of you. Perfect.

[![Thumbnail 110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/110.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=110)

So, Bedrock AgentCore is a service that helps you to run your agentic workload in production, and today with Sean, we will talk about how you can use Dynatrace to observe your agents.  All right, let's start from the challenges when building agentic applications. Actually, what we hear from customers is that building agents for proof of concept is very easy because, you know, putting together an agent is not a big deal. However, what is difficult is moving those agents to production.

[![Thumbnail 160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/160.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=160)

[![Thumbnail 170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/170.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=170)

Think about the scenario that you see on the slide here. So you may have an agent in your department that needs to access many tools and potentially other agents, maybe within your department or maybe within your organization, and potentially even outside of your organization, right? And all of this can prove very complex to do at scale if you need to manage all the layers, including the infrastructure and the application layer. And actually this is one of the reasons why  Gartner believes that by 2027, more than 40% of the agentic AI projects will be canceled. And the reason why is because moving from POC,  where there is a lot of excitement and potential, to production where you get to the business value is quite challenging.

### Amazon Bedrock AgentCore: Addressing the Challenges of Moving Agents to Production

So there are a lot of challenges in that. Let's take a look at the main challenges, and then how Bedrock AgentCore addresses those challenges and how Dynatrace further improves that with their observability capabilities. All right, so talking about the challenges. So the first challenge is that when you actually build your agents, you need a dedicated infrastructure and runtime to run them on, and agents are very different from traditional applications.

Because agents require dedicated infrastructure that can run maybe for minutes, maybe for hours. You don't really know how long an agent will run. You don't even know how many parallel executions the agent will do. So this can be very challenging to do with traditional infrastructure. Also, LLMs are stateless, the LLMs behind the agent. So when you build an agent, you need the memory capabilities, right, for the agent to know about the session, to know about the past interactions, and in order to do that, you also need capabilities, and this also takes time.

The third one is that agents need to access third party tools or potential internal tools such as, think about databases, think about Google Drive, think about maybe your storage system, and in order to access those tools, the agents need identities, and this can also be challenging to manage in such a setup. The fourth point is that agents need to discover tools and interact with those tools. So actually connecting to, discovering and managing all those tools at scale can also prove very challenging.

And then the fifth point is that these agents may need to go beyond interaction with basic tools that I mentioned before, and they may do more advanced things, for example, using a browser or I don't know, generating code and running such code, so more advanced capabilities, and even managing all of that can prove quite difficult. And then last but not least, you need to be able to observe your agent, right? So you need to know what your agent is doing, what steps it's taking, how it's reasoning, where it's going well, where it's going wrong.

[![Thumbnail 320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/320.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=320)

And you need observability for that. Doing all of this and reinventing the wheel can be quite challenging, and that's why we have released Amazon Bedrock AgentCore,  which is a set of AWS services that help you with those challenges.

[![Thumbnail 340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/340.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=340)

Bedrock AgentCore has services in three categories: deploying your agents, enhancing your agents, and monitoring your agents. For deploying your agents, Bedrock AgentCore provides two families of services: runtime and identity.  The runtime is a capability that allows you to provide your agent code. You simply bring the code to AgentCore, including the framework that you need to use and the model that you need to use. It can be any framework, any model on AWS or also not on AWS Bedrock, and AgentCore will basically take care of running this for you on a serverless runtime that scales as needed.

Then you have AgentCore Identity. Think about your agent being able to interact with various tools. This agent needs identities, right? It needs an identity that the services it interacts with will use to authenticate the agent, and then it also needs potentially federation with things like OAuth or API keys. Bedrock AgentCore provides all of these as part of the identity component.

[![Thumbnail 400](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/400.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=400)

With these new components, you have the possibility to run your agents at scale, and what comes next? You need your agents  to be able to access various tools. For that, the main component is the AgentCore Gateway. The AgentCore Gateway is basically a central MCP server where you can see, and the agent can see, all the tools that are available for the agent to use, and those tools are called targets. Those targets can be APIs, can be databases that your agent will query, and can also be external tools like Google Drive or Salesforce or Slack that your agent will interact with.

Then you have AgentCore Memory, where you have short-term memory and long-term memory. Think about an agent doing transactions on an e-commerce website. This agent would have a short-term memory, and this short-term memory allows the agent to remember what products are being added to the shopping cart, who is the user making the shopping, how many products have been added, and where to ship them before actually placing the order. Then you have long-term memory. Long-term memory is basically about the agent remembering past interactions so that any new shopping experience in the future, for example, can be personalized based on the user preference and the past interactions.

Then you may need the agent to do more advanced things, for example, accessing the browser, and there we have AgentCore Browser, which is a fully managed browser within the AgentCore service that scales to tens or hundreds of parallel sessions, all isolated, where your agent can interact with web applications. If you need things like code execution, we have the AgentCore Code Interpreter. The idea here is that language models are very effective in generating code, but they are not necessarily the best tool in doing deterministic things, for example, calculations. Think about an LLM generating code for a calculator in Python, and then this code will be executed in the AgentCore Code Interpreter to get a deterministic calculation of, let's say, a mathematical expression. So this is the idea.

[![Thumbnail 540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/540.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=540)

[![Thumbnail 550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/550.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=550)

Now you have your agent running securely, you have your agent enhanced with additional tools. How do you ensure that this is working well? How do you monitor it once it's operational? For that, you can use Bedrock AgentCore Observability, which is the capability  that allows you to monitor the status and the performance of your agent. AgentCore Observability gives you a dashboard for basic observability,  but also, and most importantly for this session, it exposes a number of metrics, logs, spans, traces, and sessions that Dynatrace would then use to do the more advanced observability via their platform. And now Sean will talk about this part.

[![Thumbnail 570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/570.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=570)

### Dynatrace's Approach to End-to-End Observability Beyond AgentCore

In the case of what we are  expanding upon, and what I actually appreciate from an AWS perspective, I've been in the observability space for about eight or nine years now. When we look at each of these new technologies, the challenge has always been, as a developer, as a consumer, as an end-user practitioner, how do I get the information out of it? Now, Dynatrace, obviously focusing on end-to-end observability, we have a care and a concern of that exact problem or challenge, depending on how you look at it.

The way AWS is built, both Bedrock AgentCore and specifically some of the other things around the other announcements this week for the DevOps agent, is giving the power to you as the end user, as the developer, of where you want to get the information from. Obviously, CloudWatch is fantastic and I'm a big fan of it. If you need to expand this beyond CloudWatch, I believe in Simone's slide it mentioned OpenTelemetry, specifically those logs, those traces, and metrics. We at Dynatrace believe you can bring those in beyond just the scope of Bedrock AgentCore.

We do this in a couple of ways. I personally focus in and around AI observability and specifically, yes, based upon my title, the Developer Experience. So in my world, it's not about dashboards, it's not about the power of a dashboard. It's let me start in my IDE, let me get the information when and where I want to. But at the end of the day, we all know we have to see the data, and I think that's where I love about CloudWatch, obviously seeing the CloudWatch specific data for AgentCore plus Dynatrace.

[![Thumbnail 670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/670.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=670)

When we look at this a little bit further, there are some challenges.  While you and I probably care about AgentCore, Bedrock AgentCore specifically, we realize that our enterprises, our organizations, leverage far more than just this new technology and or application. So at Dynatrace, our goal is to really take that and not abstract it, but provide value to it. And so in this slide, our idea is we've got cloud native digital services, we've got AI agents, and we all need to communicate together.

I was having a conversation earlier this morning, and we still have applications that are sitting on mainframes and so on. And so what we want to make sure is you have visibility to all of this. Depending on your use case and scenario, you might say I only care about an agent that sits in my IDE and I'm never going anywhere else. Perfect. I believe Simone and the AWS team have built a fantastic way to do that. If you need to go beyond that, that's where we sit. That's our goal for end to end observability.

I want to mention two things, and I think this is an interesting slide or an interesting statistic, is that 95% of AI pilots are failing. Now, I don't know if I actually agree holistically just based upon the conversation. Maybe it's a little bit loose or maybe it's historical data, but the intelligence that AgentCore provides, I actually believe lends to a better success. But along with that information is leveraging an open source solution like OpenTelemetry allows for the consumption of that information.

The catch here is because we're talking about experimental or development, this is not a day two conversation, this is a day zero conversation. And where we at Dynatrace believe, and obviously AWS believes, is those numbers are going to continue to improve from a failure rate. The second thing I would mention here, as a developer, and this is where I focus, I'm not looking for complexity. I don't want to have to go from this screen to this screen or from this IDE to another option. I want it to be where I am, and we at Dynatrace believe we want to meet you at that location.

[![Thumbnail 810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/810.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=810)

So whether it's your IDE, obviously we had the announcement yesterday in conjunction with AWS around Quiro, the idea is to meet you  in that specific location. The other thing about this is many organizations, and probably all of you in this room, are leveraging more than simply Bedrock AgentCore. You're testing multiple LLMs, you're testing small language models, you have a variety of consumption. And so what we want to help you understand is not only Bedrock AgentCore, but we also realize you have all of these others.

And so whether it's some of the third parties, NVIDIA is a specific great example, our goal is to meet you at Dynatrace where you are. And so from an observability perspective, yes, I have two different agentic applications. Maybe one is Amazon, maybe the other one's leveraging NVIDIA technology or Anthropic or OpenAI or one of the many vendors on the floors today. We want you to be able to have visibility and understanding of both of those. And so at Dynatrace, our goal is just to continue to meet you where you are.

We're doing this in two different ways, obviously OpenTelemetry as I mentioned, and OpenLLMetry. And I always have a funny way I say this, but I'm going to be nice and put it in the proper term today. So this is where we believe observability goes beyond just AgentCore, and so just depending on where you are and where you need to be met.

[![Thumbnail 890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/890.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=890)

### Developer Experience and Infrastructure Observability: Meeting Users Where They Are

The last thing I wanted to show is a very simple  screen. I am sitting here in a very simple to understand, and as you can tell, this happens to be the Dynatrace dashboard. What I want to articulate here is I've got a couple of tasks, I've got some chats, I've got some mention and information, and at the end of the day, hey, this is a LangGraph workflow.

I see the relative and appropriate observability information in this example, followed by some of the details, the metadata, and the attributes. This is a visual representation. I love to sit in my IDE using natural language search. I want to be able to do this from my IDE, and obviously the integration with an MCP from an AWS perspective, from a Dynatrace perspective, means now I can get it in a GUI, but I can also get it inside of my preferred location, whether it's Claude, whether it's VS Code or Windsurf, or depending on what you're using.

And so that is our goal, to meet you not only from an Amazon Bedrock AgentCore perspective, but with the variety of LLMs and observability, the LLMs, small language models, and AI capabilities in every one of our organizations. The other side of this is, what if I'm leveraging another solution like a ServiceNow or a variety of the ecosystem? Our goal is to provide you the information from an observability perspective, not only for AgentCore but beyond, in the same fashion that's usable and predictable for you. And we as developers and engineers love some decent predictability, at least I hope you do.

[![Thumbnail 990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/990.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=990)

 The last thing I would mention at Dynatrace, just to summarize this, is we're about experience. I was having a conversation last night, and one of the things that we struggle with in the industry is complexity. As a developer, as an engineer, I want to reduce complexity. I want to be back in the flow. I realize I have to troubleshoot. I have to debug because things are going to happen. But the quickest way for me to get in and out of a debug mode, troubleshooting mode, is to do it in a quick instant, in a really simple, easy-to-use fashion.

And so one of the things we've continued to build upon as the AgentCore team and as the Bedrock team has developed this is to ensure usability or experience, whether that's developer experience and beyond. I think the last piece I would mention before we close it out is all of this runs on infrastructure. Now, as a developer, do I love to interact with infrastructure? Probably not. Maybe I have to, but it's all been abstracted to me. But from an observability perspective, I care, and it's a concern to me.

And what we realize is from an end-to-end observability perspective, it's not just the LLM or the AI observability. It's not just the logs, traces, and metrics. It's the relative infrastructure information and relative infrastructure data in context. And so having each of these layers, depending on your scenario, depending on the use case, depending on the problem, we want to meet you where you are. And every job, every developer I talked to about this, in some cases it's I need to start with logs, or I need to start with a metric or a span.

For the record, there is no single point that I have ever found in this. It really depends on the day, it depends on the scenario, and the situation. And so what we want to do is make it readily available and easy to you. Because it would never be the AWS infrastructure and it would never be the network, right? But we want to make sure you start where you need to be, and that's how we position this as the Dynatrace difference.

[![Thumbnail 1120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/1120.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=1120)

Lastly, I will say this, come meet us at the booth. The team has got about two more hours, well, I got about an hour and a half now to go, but we have a free giveaway at a raffle  here in about ten minutes. So if you want to run by there, have a conversation with myself, have a conversation with Simone, or join the raffle and win some things, we would love to have you. But I would say this last and not least, it has been a long week. We at Dynatrace and at AWS realize it's been long. You've been in a lot of meetings. You've been in a lot of sessions, but I want to say thank you for stopping by towards the end of the day.

[![Thumbnail 1150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/29ee5dd1c6ddb794/1150.jpg)](https://www.youtube.com/watch?v=WJVsbB_2FAw&t=1150)

Come find us, come find me, come find Simone. We'd love to talk with you, and we hope you have a great trip home, and we'll see you again next year. 


----

; This article is entirely auto-generated using Amazon Bedrock.
