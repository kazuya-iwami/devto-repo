---
title: 'AWS re:Invent 2025 - Elevating application reliability (COP336)'
published: true
description: 'In this video, Matheus Canela and Jay discuss building resilient systems on AWS and effective observability practices. They highlight that 90% of enterprises lose $300,000+ per hour during downtime. Key topics include multi-AZ architecture using Elastic Load Balancing and RDS Multi-AZ, infrastructure as code with CDK and CloudFormation, AWS Fault Injection Service, and Resilience Hub for testing failure scenarios. The session covers observability fundamentals including business metrics, user experience monitoring with Core Web Vitals, and Service Level Objectives (SLOs). They demonstrate Amazon CloudWatch Application Signals for automatic service discovery using OpenTelemetry, anomaly detection for leading and lagging indicators, and CloudWatch Investigationâ€”an AI-powered tool that automatically correlates metrics, logs, traces, and CloudTrail events to generate root cause analysis. The presentation concludes with a live demo using Kiro CLI to troubleshoot an ECS-based translation application, showing how AI agents can autonomously investigate AWS infrastructure, identify issues like zero desired count in ECS tasks, and resolve problems without manual intervention.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/0.jpg'
series: ''
canonical_url: null
id: 3093236
date: '2025-12-08T21:35:55Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Elevating application reliability (COP336)**

> In this video, Matheus Canela and Jay discuss building resilient systems on AWS and effective observability practices. They highlight that 90% of enterprises lose $300,000+ per hour during downtime. Key topics include multi-AZ architecture using Elastic Load Balancing and RDS Multi-AZ, infrastructure as code with CDK and CloudFormation, AWS Fault Injection Service, and Resilience Hub for testing failure scenarios. The session covers observability fundamentals including business metrics, user experience monitoring with Core Web Vitals, and Service Level Objectives (SLOs). They demonstrate Amazon CloudWatch Application Signals for automatic service discovery using OpenTelemetry, anomaly detection for leading and lagging indicators, and CloudWatch Investigationâ€”an AI-powered tool that automatically correlates metrics, logs, traces, and CloudTrail events to generate root cause analysis. The presentation concludes with a live demo using Kiro CLI to troubleshoot an ECS-based translation application, showing how AI agents can autonomously investigate AWS infrastructure, identify issues like zero desired count in ECS tasks, and resolve problems without manual intervention.

{% youtube https://www.youtube.com/watch?v=-P2hll4zioI %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/0.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=0)

[![Thumbnail 40](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/40.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=40)

### The Business Impact of Downtime and Session Overview

 What is the cost of downtime? I would like to start with the reality we are all facing in today's digital world. What you see on this slide represents the true impact of system failure. According to the Information Technology Intelligence Consulting, 90% of enterprises are losing $300,000 or more per hour of downtime, plus 41% of enterprises are losing between $1 to $5 million per hour of downtime.  But these are just numbers. These are missed opportunities, damage to customer relationships, loss of productivity, and also a hit to the brand's reputation. Think like this: this is not just an IT problem, it's business survival.

[![Thumbnail 70](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/70.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=70)

[![Thumbnail 80](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/80.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=80)

Today we're going to talk about building resilient systems, doing effective observability, and then at the end, we're going to show you two demos using generative AI. My name is Matheus Canela.  I'm a Senior Solutions Architect based in Sydney, and today with me I have Jay, who is a Senior Cloud Support Engineer based in India. Jay, so what do we have  for today's agenda?

First, I'll go through the resilience foundations and best practices, and Jay will take control and talk about how to observe, detect, and investigate. Think about metrics, logs, and traces, also how to use the alarms and tools for you to investigate. And at the end, I'll show you a demo on how to do a full troubleshoot and then solve a problem with a generative AI tool.

[![Thumbnail 110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/110.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=110)

[![Thumbnail 120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/120.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=120)

[![Thumbnail 130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/130.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=130)

### A Personal Story: When Home Automation Failed at 5 AM

 All right, first is resilience foundations and best practices. Before we dive deep into the technical aspects,  I want to share with you a personal real story that demonstrates how resilience is critical for every technology implementation. So stay with me. One year ago, I decided to fully automate my house.  As you can see that represented by the house, and because my house is not that new, I had to use wireless protocol. I couldn't use cables to connect to the lights or to the appliances.

[![Thumbnail 150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/150.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=150)

[![Thumbnail 160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/160.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=160)

If you see, I had a wireless switch, and this wireless switch used a dedicated  channel with a specific protocol. I also had Wi-Fi lights which use the Wi-Fi signal. So you have an idea, if you press the wireless  switch, that goes to the home controller. The home controller will then decide which lights in the house we need to turn on. So as you can see, it turns on the lights.

[![Thumbnail 170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/170.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=170)

[![Thumbnail 180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/180.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=180)

[![Thumbnail 190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/190.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=190)

As we're all busy, I had to do  this after hours, and around 1 a.m. when I was about to finish, I just deployed an update and then I went straight to bed.  During the night, the server failed, and then what happened is the network used by the wireless switches also failed.  And you can start guessing what happened, right? So the wireless switches became unavailable.

[![Thumbnail 200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/200.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=200)

[![Thumbnail 210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/210.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=210)

And then my wife woke up at 5 a.m., right? She needs to go to work  and then take a shower, prepare her breakfast. And in Sydney, there's no sunlight around 5 a.m., so she relies on the lights to do her stuff, but I was sleeping.  And then she had no light, and you can start expecting that she was really, really upset. And it also made me think about what happened to me at that time.

[![Thumbnail 220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/220.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=220)

[![Thumbnail 230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/230.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=230)

 I think you're in trouble, Matheus. Yeah, I was in big trouble at that time. But what I want to do now is just go a little bit deeper in a conversation I had with her between when she actually figured  out that problem. So one to two minutes of that discussion, and you'll see how that relates to your day-to-day business.

[![Thumbnail 240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/240.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=240)

[![Thumbnail 250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/250.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=250)

So she first woke me up saying, Matheus, what happened to the lights?  I just woke up a little bit nervous, 5 a.m., don't like waking up in the morning, and said, I don't know, why? And then she just said, they're not working. Good until now, right? So it's expected as we  discussed. But I wanted you to pay attention to the next thing that I said to her, which is basically what customers are doing nowadays to their customers.

[![Thumbnail 260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/260.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=260)

[![Thumbnail 270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/270.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=270)

I just said, well,  the SLA for the lights is five hours, and then you have to wait. And then you see the next conversation, we're like, what, what is that SLA?  Right? And that's what happens to a lot of businesses nowadays when you have that type of issue. They don't know that SLA exists. She may be expecting the lights to be 24/7. Who would expect the lights to have a failure or a server that would impact that work?

[![Thumbnail 290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/290.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=290)

[![Thumbnail 300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/300.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=300)

But now, let's start bringing that personal  story into how can we build on AWS. So first, if you see, my home controller was a single point of failure.  When it crashed, every light stayed off, right?

[![Thumbnail 310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/310.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=310)

[![Thumbnail 330](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/330.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=330)

### Building Resilience on AWS: Multi-AZ Architecture and Infrastructure as Code

So if you think about this, we have the availability zone impairments.  Availability zones are isolated failure domains with independent power, cooling, and network. But availability zones can also fail, and that's why it's important for you to think about having a multi-AZ discussion. Resiliency starts with redundancy across multiple Availability Zones. 

[![Thumbnail 340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/340.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=340)

So I want to talk about two services. They're not the only ones available for talking about multi-AZ discussion, but the first one is Elastic Load Balancing.  So imagine if one AZ fails or one node has an issue, Elastic Load Balancing can shift the load to the next node in a different AZ if that's a healthy node. And it also applies to RDS Multi-AZ. So imagine if you have an instance of a database failing in one AZ, it can shift the load to the other AZ.

[![Thumbnail 370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/370.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=370)

[![Thumbnail 380](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/380.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=380)

[![Thumbnail 410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/410.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=410)

So the next one is I deployed things using ClickOps, which makes it harder to rollback. So that links to misconfiguration and bugs.  Human error remains the major source of incidents, and the best defense is treating infrastructure like application code. So no more ClickOps, right? In that case,  we can talk about two things. The first one is using a repository to store your code, but we also talk about Cloud Development Kit, which is the CDK. So if you're writing your infrastructure like your database, your servers, your network, all as code in TypeScript, for example, you can then, once you deploy, it becomes CloudFormation, but it can also become Terraform. And you can even use CloudFormation directly if you like. 

[![Thumbnail 420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/420.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=420)

[![Thumbnail 430](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/430.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=430)

So the next one is alarms could have triggered my home lab recovery before my wife discovered the outage, right?  And that links to excessive loads. So in that case, we can have, for example, Auto Scaling. If you're having a spike in connections to your web server,  you can add and remove servers to cope with that load. And then not everyone is aware of this, but we also have Application Auto Scaling. So you have the Auto Scaling, as I mentioned, for your EC2s, but if you have Aurora with replicas or Lambdas or even DynamoDB, Application Auto Scaling can also help you with that. And talking about Lambdas, it's important to think about managed services like Lambda, DynamoDB, or those services can help you manage the requests without managing the infrastructure.

[![Thumbnail 470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/470.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=470)

And lastly, I never tested my lighting recovery playbook until 5:00 a.m., so game days could have helped the family.  So think with me. If you remember, the network for the switches was failing, right? But my wife was not aware that using an app could have turned on the lights. And that's why game days are really important, so you get the whole, in my case, the family, but you can have the whole company getting together to understand if there's a bad day, what should I do?

[![Thumbnail 500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/500.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=500)

[![Thumbnail 530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/530.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=530)

So in that case, I want to talk about two services. AWS Fault Injection Service, which  allows you to inject faults in your environment in a controlled manner. So it can terminate instances, you can isolate an AZ. And we also have the Resilience Hub. So in that case, you can import your application and run a report on that, and you can understand how your application will behave in case of a failure. 

[![Thumbnail 550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/550.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=550)

All right, so this screenshot here represents the Fault Injection Service if you open that in the console. And I want to highlight two of the services, not just those two, but they have many, as you can see that page has two pages there. The first one is the Availability Zone Power Interruption. So in that case, you can inject  a failure in the AZ and see how your application behaves. And then the second one is the EC2 Stress that you can do on a CPU. So you can simulate the stress in your environment to see how your application behaves. And then those faults that you can inject help you think about what happens if one part of my application fails, how is that going to behave?

[![Thumbnail 580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/580.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=580)

### AWS Resilience Hub in Action: Assessing Recovery Capabilities

All right, I want to jump now to the other service that we mentioned before, which is the Resilience Hub.  Before I show you reports generated by Resilience Hub, I want to show you the infrastructure that I ran the reports on. So think about this as a single AZ, right? And in that single AZ I have a single RDS, so a single instance of the database. I also have Elastic Load Balancer, Auto Scaling group, and S3, but they are irrelevant for the reports I'm going to show you.

[![Thumbnail 610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/610.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=610)

So in that case here, once I import that application into Resilience  Hub, I can generate a report about the infrastructure. And then I set up the RPO and the RTO, which is the Recovery Time Objective and the Recovery Point Objective, to be only 5 minutes.

So if I run the reports, you see that it says it's unrecoverable, right? And you may start thinking, why is it unrecoverable? So if you look down the report, it's saying the database cannot recover within that 5 minutes. If you remember my infrastructure, I only had one database in one Availability Zone. So if that database fails, you won't be able to recover. And that's where the Resilience Hub is really important to help you with your resilience posture.

[![Thumbnail 660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/660.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=660)

All right, let's change gears a little bit, because I don't want to forget to talk about trade-offs and risks.  If you remember my use case, imagine if I want to have multiple servers, multiple wireless networks, just in case I have an issue with the lights. Is that cost effective? And that's why you need to think about that when you talk about resilience. So if you have critical applications, it's really important to invest time, engineering time, and make that resilient. But if it's not a critical application, it's also important to understand the risks and take that into consideration.

[![Thumbnail 700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/700.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=700)

[![Thumbnail 710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/710.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=710)

[![Thumbnail 720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/720.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=720)

[![Thumbnail 730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/730.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=730)

Right, before handing that to Jay, I want to talk about the reliability improvement cycle. So first, resilient architecture from the ground up. We already discussed that.  And then next is how to observe. So think about the metrics you can collect, what are the information you can get out of your platform. And then how you detect, right? So if you  have that information, are you getting an alert? How do you know that there's a problem with your environment? And then how you investigate. How you get to the root cause. And lastly,  how do you resolve, how do you get this back to where it's supposed to be. But if you link that in a circle, that's why it's really important to keep, you  know, getting stronger and more reliable. So now I'll give that to Jay, who will continue with the presentation.

[![Thumbnail 740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/740.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=740)

[![Thumbnail 750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/750.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=750)

### Understanding Observability: From Flying Blind to Full Visibility

Thanks, Matias.  All right, so let's talk about observability. So I think it's a little hard to spell, I think, but let's try to make it simpler in the next few slides.  So how many of you are operating and managing microservices or distributed systems? Can I get a raise of hands? Yeah, quite a few hands raised, right? So you know that managing and operating these systems is really complex. There are multiple services that communicate with each other, like you have lots of microservices, your databases, maybe your queuing systems, all distributed and scattered as you can see like these blocks, and then they try to communicate with each other. And you might even not know when a new dependency is even added to that, right?

[![Thumbnail 810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/810.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=810)

So when something breaks in that system, you are just guessing that, okay, is it the service that is causing the problem, or is it the dependency that is failing? Or is it the network? It can be DNS, or it's always the DNS, right? So yeah, without observability, you are actually flying blind. So this is where we want to get with proper observability, right? So now everything changes. You now see  the exact shape of your application, like how each and every service is interacting and how each and every dependency is interacting with your services. And then if something fails, you are immediately able to understand where to look and what is breaking, right? But to get here, you need to track or monitor the right signals, right? So let's look at that.

[![Thumbnail 840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/840.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=840)

So to elevate your application reliability, you need to measure what actually matters, right? So let's talk about some of the key signals. So  first, we always start with the business, right? Metrics like, let's say, revenue impact, the number of transactions, or the number of orders that you process can be something that actually shows you some business outcomes, or anything that relates to your business. So for example, let's say if your checkout service fails, you exactly know how many orders you are losing with the customer and what is the revenue impact, right? So this helps you to also drive your Service Level Agreements with your customer, which is nothing but the promise that you make to them that, hey, my platform or my service will be up for, let's say, 99.9% of the time. And if you're not able to deliver that promise, you know exactly what is going to impact you.

[![Thumbnail 890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/890.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=890)

The next set of signals are user experience. So these are very critical because this helps you to understand how your  customers are experiencing your application or, let's say, your website. So you can monitor the core web vital metrics like Largest Contentful Paint, Interaction to Next Paint, or Cumulative Layout Shift. So let us take an example of how this actually helps. So let's say if your metric, let's say Largest Contentful Paint,

is increasing from 2 seconds to 5 seconds. That means that whenever a user is loading your website, it is taking a longer time for them to load your content on the website, and that means that they might abandon the session and go somewhere else and drop from the platform. So that's why it is very important to measure the customer experience, like how they're actually using the application, using these Core Web Vitals. And these are standard metrics that you can always use and monitor.

[![Thumbnail 940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/940.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=940)

The next set of services are your service health metrics. So these are metrics such as  the number of requests, how the service is handling the request, how many errors it is observing, or your latency, your P50, P95, or P99 percentiles. Always use percentiles. Don't use averages because averages can hide your bad customer experiences. So measuring these will help you to understand how your services are performing, and it will tell you exactly whether your service is healthy or not. So once you start tracking all these signals together, you can actually understand and completely understand how your reliability is working.

[![Thumbnail 980](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/980.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=980)

[![Thumbnail 1000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1000.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1000)

[![Thumbnail 1010](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1010.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1010)

### Measuring Reliability with SLAs, SLOs, and SLIs

 And then finally you have your reliability targets. So who here measures SLOs? Can I see a raise of hand? Okay, very few. But yeah, that's good. So I really want to dive deep into why SLOs are important for measuring reliability. So let's take a look at that.  When you're defining your SLOs, you always start with your end customers, like what they are expecting from your application or your platform. So you start with that and then you decide or give a  promise to them like, hey, our platform would be up for 99.5% of the time. That's a promise that you're making. And if you're not able to meet that promise, we will give you, let's say, some kind of credits.

[![Thumbnail 1030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1030.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1030)

[![Thumbnail 1050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1050.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1050)

So in order to then achieve this promise that you're making to your customer, you define the Service Level Objectives.  So this is an internal target that you take and you work with your engineering team. For example, this would be slightly higher than the actual SLA, let's say 99.9%. And the difference between your internal target and the actual customer promise will give you the error budget. So this is something that will help you to deploy new features, new versions of your application, and still be able to  make sure that the applications are reliable.

[![Thumbnail 1060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1060.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1060)

But how do you know you are meeting these targets? So for that, you start measuring SLIs or Service Level Indicators.  So these are actual metrics like latency, error, and uptime. So you basically create SLOs which will track these Service Level Indicators over a period of time. And then that will give you an understanding of whether you are able to meet the targets or not. So doing all this will help you to actually make your reliability measurable, and you can always track and improve it as and when you are not able to deliver your promises.

[![Thumbnail 1090](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1090.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1090)

### Amazon CloudWatch Application Signals: Auto-Instrumentation and Service Level Objectives

 Measuring these metrics or deriving these metrics can be challenging because you might have to maybe change your application code, add some libraries to it, create some custom code, that sort of thing. That's why we introduced Amazon CloudWatch Application Signals. So this is a tool that you can now start to use to basically monitor the health and performance of your system, and it will allow you to track your business goals as well alongside your system performance. So let us see what you get out of the box for Application Signals.

[![Thumbnail 1120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1120.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1120)

[![Thumbnail 1140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1140.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1140)

 The very first thing is, once you enable Application Signals, it uses OpenTelemetry auto-instrumentation method to derive or extract all the metrics and traces from your services. So you don't have to make any application code changes, and you can literally get started within minutes to get those critical metrics and traces out of your system.  Second, once you enable it, it allows you to discover all your services and dependencies, and you can visualize them in a graphical way or a map view. And then it also gives you some pre-built dashboards, for example, what is the health of the services, how they're performing, how many faults they have, all these things into this dashboard.

[![Thumbnail 1160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1160.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1160)

[![Thumbnail 1190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1190.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1190)

 And finally, you actually track what matters. So it gives you the golden signals like your latency, errors, and faults, and then you also enable distributed tracing to get end-to-end visibility. And then finally it allows you to natively track and monitor Service Level Objectives within Amazon CloudWatch. So let us now see actually how Application Signals works. So this is one of the screenshots that I've taken from my sample application. You can see here at the bottom, in the highlighted section, that  we have five services that got automatically discovered once you enable Application Signals. And then in the same dashboard you also get these widgets that will quickly show you which all services are observing some faults. So here you can see that there are a few services like let's say the front-end service is observing approximately 2 to 2.5% of faults.

[![Thumbnail 1220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1220.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1220)

If you want to dive deeper into what is happening with the services, you can go and check the individual service health dashboard  from Application Signals. Here in the center, you see all the golden signals which I mentioned earlier. When I observe here, I see a request spike which the service handled, and at the same time, I see this spike in the number of faults that were observed on the service. This means that there was some problem and the service might be overwhelmed because of the spike.

When you click on this particular data point or point in time, you will be automatically taken to the correlated traces. You can see here in the bottom right, you get the list of trace IDs or the traces that are correlated to this particular point in time. Now you can use these traces and easily identify how the request traveled from one service to another and at which point the fault was introduced. Without you doing the correlation manually, this gets automatically added using Application Signals.

[![Thumbnail 1280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1280.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1280)

[![Thumbnail 1300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1300.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1300)

Here is an example of an application map that you get once you enable  Application Signals. Using this, you actually see how each and every service is connected and communicates with each other. In the earlier part, I mentioned how it is critical for you to visualize and understand how each service is connected. Every node here, as highlighted, is your service that you are running as part of your application.  Every line here shows the dependencies which the services are interacting with. Again from here, you can go from this map view to the individual service health dashboard very easily.

[![Thumbnail 1320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1320.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1320)

[![Thumbnail 1340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1340.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1340)

Finally, as we were talking about SLOs, using Application Signals, now you have a native way to define, track,  and measure SLOs. Using this, you can easily see which SLOs you are able to meet the target for, what your remaining error budgets are. The SRE team can keep tracking and monitoring this dashboard, and they can work with the development team if you are close to exhausting your error budget.  Now we have got the right signals for our systems, so let us try to see how we can use the signals to quickly detect any failures so that we can act upon it if something goes wrong.

[![Thumbnail 1380](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1380.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1380)

### Detecting Failures: Leading vs. Lagging Indicators with Anomaly Detection

In distributed systems, failures are inevitable. You never know when a dependency or service will go down, but the real question is, do you know about it before your actual customers come to you and complain about it? That's why we need to detect these failures as fast as we can. There are two approaches I want to talk about, so let's start with talking about lagging indicators.  These indicators are basically telling you that something is already broken in your system.

For example, let's say we saw a spike in the request. When a spike hits, it elevates your error rate, let's say from 0.5% to 20%. That's a huge difference, from 0.5% to 20%. Or let's say your team deployed a new version of the code and that broke a critical service, which then cascaded to further services which were relying on it. Once this kind of failure happens, you are actually firefighting and your customers are already impacted through these indicators. Most of the teams are here. We all start with identifying lagging indicators, but let's talk about leading indicators and how they can help.

[![Thumbnail 1430](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1430.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1430)

Leading indicators are something that will tell you that a problem is going to develop  and it can be critical, so you can identify it before it actually impacts your customers. Things like, let's say your API latency is gradually increasing, from 100 milliseconds to 200 to 300 over a week of time or a day or some time. Or let's say your disk space utilization, a very simple metric, but it can also grow in size, let's say 5% day by day, and then gradually it will hit the limit and there will be something going wrong with the service. All these indicators, if you are able to identify them, will give you enough time to act upon it. You can, for example, scale your capacity, tune the performance, and prevent the problem before it actually hits your customers.

[![Thumbnail 1500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1500.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1500)

The key takeaway here is as a team or as an SRE engineer, for example, you can start to evolve. We always start with lagging indicators because that is mandatory, but then we can try to shift left to these leading indicators as well in order to get more time to prevent any issues before they actually hit your customer. Amazon CloudWatch gives you some building blocks to detect both kinds of indicators, so  let us see what they are.

[![Thumbnail 1510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1510.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1510)

We'll start with detecting leading indicators using anomaly detection with machine learning algorithms.  The first feature we have is Logs Anomaly Detection. It allows you to surface any anomalies within an application log. Once you enable it, it's always on and keeps scanning your logs to surface any new anomalies within these logs. The second feature that we want to talk about is Metrics Anomaly Detection. When you enable this on your CloudWatch metrics, it constantly goes and understands what the past values of the metric are, and based on that, it predicts the future values or the baseline behavior. Then if any metric goes above or beyond that particular threshold, it will show you as an anomaly. So together, they always watch your data, your logs, your metrics, and they are always learning based on the past data that you have.

[![Thumbnail 1560](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1560.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1560)

Let us see Logs Anomaly Detection in action. Here is one of the screenshots  that I took from my log group. You can see here that once you enable log anomaly, there are three anomalies that were detected. Let's try to focus on this particular one. You see here that an unexpected pattern got detected with the severity of error, and then the priority is also set to medium, and then this is the pattern that the feature was able to detect. You can also see how these anomalies are actually trending, how frequently they are occurring, so you can take action upon them.

[![Thumbnail 1600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1600.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1600)

[![Thumbnail 1610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1610.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1610)

[![Thumbnail 1620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1620.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1620)

Next is Metrics Anomaly Detection. Here you can see that we have enabled metric anomaly on a standard metric called TargetResponseTime, which you might be  using in your load balancers. Then you can see this gray band here,  which shows you the baseline performance or expected values, and then anything outside of it, either above or below, can be treated as an anomaly as well. You can see here this particular spike can be used as an anomaly. What you can do is you can create alarms on these metrics  enabled with anomaly detection, so you don't have to worry about static thresholds, because sometimes the metric can show some seasonal trends. So you don't know actually what is the right threshold. Using anomaly detection, it automatically understands what the expected values are, and then you can set an alarm, and it also helps you to reduce the alert fatigue as well.

So, Matthias, you had a customer that actually used this in a real scenario. That's true. I had a customer a few years back, so what they've done is they managed buildings, and then in the buildings they installed multiple cameras. What happened is when someone goes across those cameras, it just triggered the motion and then sends the files to S3. The customer was like, how can I make that cheap to know if there's a party in that building, like if there's a lot of people going through that camera. So what they've done is they created a metric per camera, because it's uploading files to S3, right? Then they used anomaly detection to actually note if there's a lot of people crossing that specific camera out of normal. So if there's a party in the afternoon that was not supposed to happen, then those files are getting uploaded more often, and that's when the alarm was triggered by using the anomaly detection. Yeah, over to you.

[![Thumbnail 1700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1700.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1700)

Yeah, that was a good use case. Now, let's talk about features that can help you to identify lagging indicators. Again, I want to talk about two features. First is Logs Pattern and Compare.  Using this, you can basically group similar log events into patterns, and then you can also compare whether these patterns are occurring in the past or not. You can maybe select two particular time ranges, let's say from now to last one day, and then you can compare what is the delta of seeing this kind of patterns to understand if something has drastically changed within your logs. Second is Contributor Insights. This is one of my favorites. It is a very simple feature, but it is very effective. What it does is it helps you to find top talkers. Whenever you want to understand what are my instances which are actually degrading the performance, or what are the heaviest network users that are consuming the entire network bandwidth, for example, or what are my API endpoints that are actually facing the highest number of errors, you can use Contributor Insights to derive those information from your logs.

[![Thumbnail 1760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1760.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1760)

Let us try to see them in action. Here is an example of Pattern and Compare. As you can see on the top, I have  around 27 patterns, but let's try to focus on some of them. Here is the highlighted area which we can focus on. One of the patterns that we have derived is showing us that there's an error called database connection timeout. Now what I'm also doing is I'm comparing it with the current time to let's say the last one day or last one week. I can see that the delta is plus 252. That means that these are new events that got generated after, let's say, I made a new deployment. This can exactly tell you what is the difference of this error, like how many times it has occurred, comparing it with the past periods, basically. It can help you to quickly understand whether the change that you've made is actually working or not.

Here's an example of Contributor Insights in action. What I'm doing here is I've created a Contributor Insights rule on my log group, and I'm tracking the payment failures

[![Thumbnail 1810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1810.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1810)

[![Thumbnail 1830](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1830.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1830)

 for my customers using their customer ID. You can see that here there are a total of 12 unique contributors, or 12 unique customers, that are facing the failures, and I'm just showing the top 10 here. You can see that this particular customer with this ID is having the highest number of payment failures.  On the top, you also get the logs getting converted into your time series automatically by creating the rules, so you can exactly see what the error trend is for this particular contributor.

[![Thumbnail 1850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1850.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1850)

[![Thumbnail 1860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1860.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1860)

[![Thumbnail 1870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1870.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1870)

### Amazon CloudWatch Investigation: AI-Powered Root Cause Analysis and Incident Reporting

So now we have our detection mechanism in place that tells you that there is a problem, but then how do we go about  investigating them and understanding what actually caused it? As a support engineer myself, I've been on a lot of incident calls with our customers,  and there is a common pattern that I see. You start with seeing a lot of alerts that are going off. Most of them are noise, which doesn't tell you exactly what is going wrong.  The teams start to dig in between different tools. Let's say they go and check one tool for metrics, maybe another for traces, and then check the logs. They're trying to piece together what is happening. They have all the data, but that is scattered across all these different tools, which takes them a lot of time to come to the final understanding of what is actually happening and why the problem is occurring.

[![Thumbnail 1920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1920.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1920)

But imagine that at 3 a.m. you are on call, and there is someone who is actually going and investigating all this information for you. When you actually go and check, it tells you exactly what happened. Wouldn't that be great? Let me introduce you to Amazon CloudWatch Investigation, which is your AI companion  that is built right into your CloudWatch console. This actually helps you to automatically scan and correlate all your telemetry data that you have. It can be your metrics, logs, traces, your CloudTrail events, changes, for example, and then it generates AI-powered findings and root cause analysis showing exactly what happened and why. What normally would take you around hours for investigating an issue will be able to be completed in just minutes. You're actually going to focus on how to fix the problem rather than finding it.

[![Thumbnail 1960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1960.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1960)

[![Thumbnail 1970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1970.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1970)

[![Thumbnail 1990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/1990.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=1990)

[![Thumbnail 2010](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2010.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2010)

Let me walk you through how this actually works behind the scenes. Let's say  we start the investigation using this feature, and here's your AI buddy right there. What happens is that once the investigation starts,  the agent will start to first form the service topology. What I mean by that is that whatever services are related to this particular issue or investigation, it will try to build a map and see how they're interconnected. Next, it will then go and try to correlate all the telemetry data  for all the services. It can be your applications, your services, or your AWS services. You see that all the input gets scanned by the AI agent, like your metrics, logs, traces, and all the CloudTrail events. For all this telemetry data, it tries to detect the anomalies, like is there a spike or is there a particular trend that it is seeing. 

[![Thumbnail 2020](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2020.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2020)

[![Thumbnail 2030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2030.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2030)

[![Thumbnail 2040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2040.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2040)

[![Thumbnail 2050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2050.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2050)

[![Thumbnail 2060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2060.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2060)

It also does the pattern analysis automatically for you. Let's say there are some error logs that are being generated during the investigation. It will try to understand the pattern  and show it to you once the entire process is completed. You'll start to get the observations or key findings, and then based on that, the AI agent will  create the hypothesis, which is actually the root cause analysis of what happened and why. Then finally, it also gives you suggestions about how to fix that issue.  Once the investigation is completed, generally we go and write down the detailed incident report, which is really  time consuming. It will take a lot of time to generate that kind of report. So it also gives you an option to generate an incident report in standard format. Let's try to see that  in action with a demo.

[![Thumbnail 2070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2070.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2070)

[![Thumbnail 2080](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2080.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2080)

[![Thumbnail 2090](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2090.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2090)

Here is my demo scenario. It's a very simplified e-commerce application that I'm running on an  EKS cluster. Users are actually trying to post the orders through this particular API endpoint, and then they are not able to place the order and are facing some errors.  Now as an on-call, you have started to get paged and you are going to investigate this using CloudWatch Investigation. Let us see how that works. 

So here's a demo for that. I am currently at the SLO page, and you can see that the SLO that I created to track the order processing is currently unhealthy. I'm almost going to exhaust my error budget.

[![Thumbnail 2120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2120.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2120)

So what I can do is click on Actions and click on Investigate. This will open an investigation pane in the same window where you can provide a unique name to your investigation. It's kind of like you create a ticket and ask the agent to work on it. Then when you scroll down, you can just  click on the Start Investigation button that will trigger the AI agent to start the investigation.

[![Thumbnail 2130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2130.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2130)

[![Thumbnail 2140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2140.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2140)

So now let's try to deep dive into what the agent is actually doing.  You can open the investigation that we just created, so I can just open that investigation. If you recall  back the workflow that I showed you, the agent will first go and create a service topology and try to identify what all resources it needs to check. On the top, you can see that it is analyzing, let's say, my Java Order API service or my Java Delivery API service, which we saw in the architecture as well, which are part of the demo.

[![Thumbnail 2160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2160.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2160)

[![Thumbnail 2170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2170.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2170)

[![Thumbnail 2180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2180.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2180)

So what I can do is I can click on  the Agent Queue and you can exactly understand how the agent is going to investigate and thinking about how to proceed. All the resources that it is going to check, you can see that.  And now if you scroll down, you start to get the key findings. So the agent has started to now investigate the telemetry data. It is trying to correlate  it, and here, for example, you can see that it has found that the DynamoDB table is actually getting throttled. So we saw that again in our architecture that the orders are getting stored there.

[![Thumbnail 2190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2190.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2190)

[![Thumbnail 2200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2200.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2200)

[![Thumbnail 2210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2210.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2210)

 And now you can see that it is also trying to understand any anomalies by using the pattern and the anomaly queries to check if there are any anomalies within your logs,  and it has found some of the anomalies as well. And here is a metric that it used to confirm that there are some throttling happening. So it's automatically checking all the kind of data that you have  with these services and then giving you as key findings.

[![Thumbnail 2220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2220.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2220)

[![Thumbnail 2230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2230.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2230)

[![Thumbnail 2240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2240.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2240)

So while this is happening, what you can also do is that you can go and  add your own custom note. So let's say you are a team and you are investigating together. If I find something important, I can share that  context with my team by just adding a custom note which will be part of your investigation. So I can click on Add and it will add the investigation. Anyone in your team can  look into it if there is some important information.

[![Thumbnail 2250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2250.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2250)

[![Thumbnail 2270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2270.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2270)

[![Thumbnail 2280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2280.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2280)

So once this is completed, the AI agent will now generate a hypothesis once it has enough evidence of what caused the issue.  So let us now take a look at the hypothesis that the agent generated for us. What I can do is I can click on this hypothesis and it'll open a detailed hypothesis of information. So you can get all the information like, okay, what was the root cause summary, like what happened. You can see that the problem  actually was the DynamoDB table throttling, and then exactly like the timeline of how the investigation went. And this is the service  topology that I was talking about that the agent creates, a map view as well.

[![Thumbnail 2290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2290.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2290)

[![Thumbnail 2300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2300.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2300)

And then finally you see the suggested actions that how you can basically fix this particular issue. In this case, as our DynamoDB  table was throttling, we can obviously go and increase the write capacity on the table and it will basically mitigate the issue. And you can also see some of the  troubleshooting documents which it can suggest to you, which can help you to further investigate. So what I can do is I can maybe open the runbook that it suggested and I can fill in the input parameters, and then I can try to increase the capacity right from the same console.

[![Thumbnail 2320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2320.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2320)

So this was  the demo that shows you exactly how the investigation works. You can see how drastically it reduces your time to investigate and get to a root cause much faster. So Matthias, as a solution architect, you might be interacting with your customers. Like how they can generate the incident report, is this something that they are always asking? Yeah, it's really important for my customers to be able to generate a report that they can send to the management so they can understand in details what happened to the application. So what can we have?

[![Thumbnail 2350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2350.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2350)

[![Thumbnail 2370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2370.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2370)

Yeah, we also have that option now. So once the investigation is  completed by the AI agent, you can just click on the Incident Report button, as you can see on the top. So once I click there, it will open the incident report console. Now what the agent is doing is actually collecting all the facts about the investigation, like what all details can be used for the investigation purpose. And then you can also review those facts  that the agent collected.

[![Thumbnail 2390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2390.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2390)

[![Thumbnail 2400](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2400.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2400)

So for example, here, what I can do is I can update this fact that how many total customers I have, how many of them got impacted, so you can tell your executive that, okay, this percentage of customers were impacted by this incident. And then once you fill all these facts, I mean you don't have to fill everything, but a few of them you can always edit,  and then it will take a few minutes to generate the incident report. So yeah, you can see here the report is generated for our investigation which says DynamoDB write capacity issue,  and then it will fill it all up with all the information that you generally would add to your incident report like

[![Thumbnail 2410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2410.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2410)

[![Thumbnail 2420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2420.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2420)

what was the customer impact, what went well during the investigation,  what are the next steps that you can use to mitigate the problem, or what are the lessons learned about this investigation, all this information will automatically  fill up in this particular report, which you can then export and share with your executives or stakeholders. So yeah, this is the report which we just created.

[![Thumbnail 2450](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2450.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2450)

[![Thumbnail 2460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2460.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2460)

[![Thumbnail 2470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2470.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2470)

[![Thumbnail 2480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2480.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2480)

[![Thumbnail 2490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2490.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2490)

[![Thumbnail 2500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2500.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2500)

[![Thumbnail 2510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2510.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2510)

[![Thumbnail 2520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2520.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2520)

[![Thumbnail 2530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2530.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2530)

[![Thumbnail 2540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2540.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2540)

[![Thumbnail 2550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2550.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2550)

[![Thumbnail 2560](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2560.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2560)

### Resolving Issues with Kiro CLI: Autonomous Troubleshooting Demo

I'll hand it over to you now, Matheus. Thank you, Jay. Let's now talk about how we resolve a problem. So what I want to do now is jump straight into a demo which uses Kiro CLI. You  heard about Kiro IDE, which is an agentic IDE, but now I want to talk about the Kiro CLI which you can run in your terminal.  So before we jump into the demo and show you the application, I want to explain how the application works. Basically, you have a microphone, and this microphone will send a voice to a page,  and that voice will be processed by a backend, which is an ECS, and then we also have a DynamoDB and a model. So once the voice comes in, it will translate the voice,  will get into a text and translate to a desired language, which will be broadcasted to multiple users. So we have two applications here.  And then if you see, this is how the application works. So I'm going to create a session. So the first web page, it's a test for re:Invent. I'm going to add a description  for that session, and then I'm going to select a language. In that case, it would be Portuguese, because I'm Brazilian, so I speak Portuguese. And you see,  on the next slide, creating the session, and you can start recording. I'll jump into the other page where I can join a session. So I'm then selecting English as the output in the text format,  and then I'll open the page. So if you see now, once it just starts streaming, you're going to see from the original language  to English as the selected language. And then here in that page is where you can see the two boxes in yellow. That's where the audio will go in and  then broadcast the text out. So let's see that working. OlÃ¡, vou testar se essa aplicaÃ§Ã£o funciona e quero ver a traduÃ§Ã£o do portuguÃªs para inglÃªs.  So as you can see, I was speaking in Portuguese and I got that translated in near real time to the other side in English. 

[![Thumbnail 2590](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2590.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2590)

[![Thumbnail 2600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2600.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2600)

[![Thumbnail 2620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2620.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2620)

So I heard from a user complaining that the user cannot create a session. You just saw that we created in the sample, but the user just said, no, I cannot create a session. And then what we're going to do is do an investigation using Kiro CLI. So what I have here is my terminal inside of the folder called Platform, and then that folder contains the CDK. I've used the CDK to deploy the whole infrastructure, and I'm going to run Kiro CLI.  So once I run Kiro CLI, it starts loading. And then as you can see, I'm running multiple MCPs, so it extends the LLM by loading ECS MCP,  the CloudWatch, the documentation, Playwright, which is an important MCP in that troubleshooting, and also Application Signals, as Jay mentioned. So they are also using Claude Sonnet 3.5. And then I'll paste the prompts now. So I'll clear the session,  and then I'll paste a prompt for the LLM. So as you can see, I'm asking the LLM to go and open the page and try to create a session. I'm not providing details where to click, how to click in the HTML, just saying go and simulate a session. I'm also providing details below saying, do not change anything in AWS without my permission. Also below, I'm telling about the infrastructure. So I'm saying there's a CDK in that folder where you will load it. I also am telling there's an AWS profile called RIV which gives access to the AWS infrastructure like Route 53, CloudFormation. And I'm also telling the LLM that's where the backend source code is.

[![Thumbnail 2680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2680.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2680)

[![Thumbnail 2690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2690.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2690)

[![Thumbnail 2700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2700.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2700)

So if you press enter, the LLM, well, the Kiro CLI, will start now thinking and trying to simulate that create session. So despite being recorded, at this  stage, I'm not touching anything. So the LLM or the Kiro CLI is actually going through and trying to figure out how to create the session and trying to simulate the user.  So as you can see on the screen, it's saying you can see the page, and then checking for the console logs. It's also waiting for the browser to finally load and say, oh, actually I  found how to create a session, and now I start populating the session with the details, like just the fake details, you know, test session.

[![Thumbnail 2710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2710.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2710)

[![Thumbnail 2720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2720.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2720)

 I'm going to select a language and try to create a session. At this stage you can see that the session cannot be created, right? So when you saw the first time you could create a session, it could translate, but at this stage it's failing. 

[![Thumbnail 2730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2730.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2730)

[![Thumbnail 2740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2740.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2740)

[![Thumbnail 2750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2750.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2750)

So if I continue processing, now what Kiro CLI is doing is going to dive deep into the AWS infrastructure.  It's going to be querying the AWS CLI to understand about Route 53, where is that domain pointing?  What are the records using that hosted zone? It's listing the resources there. You can see it found the DNS records, and then now it's going to go into  the load balancer. Is there any healthy target there? Is it pointing to anything behind the scenes?

[![Thumbnail 2760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2760.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2760)

[![Thumbnail 2770](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2770.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2770)

[![Thumbnail 2780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2780.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2780)

[![Thumbnail 2790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2790.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2790)

So let's continue, it's going to the listeners.  It will check to see if there's any 443 connections going to the load balancer. It's describing the rules, so just continue.  Yeah, going to the, checking if there's any healthy targets in the backend. Now it's touching  the ECS. As you remember, I had the ECS as my backend. Then what it's saying is, I found an issue with your ECS. So let's continue to debug. 

Then, as you can see, there's a red message there. Jay, as you work in a support team, what does the error mean? So basically, what happened is the LLM tried to use a made-up cluster name in the beginning, but this was not existing, right? We had something else using the name with the cluster. So in the first place, it failed, but then what it automatically understood is that I need to go and grab the cluster names. So what it does is in the next call, you can see, it makes use of the list cluster API call and then automatically tries to list the actual cluster names. So it is doing it by its own and trying to list the right set of clusters that we have, basically. Thank you, Jay.

[![Thumbnail 2840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2840.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2840)

[![Thumbnail 2850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2850.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2850)

[![Thumbnail 2860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2860.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2860)

[![Thumbnail 2870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2870.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2870)

So we'll continue. Now it's listing the service. We have a service and then in the ECS service, we have the tasks, right? So it's describing  the service now. Actually it found the root cause,  and then as you can see, it's highlighting that the desired count in the ECS for that specific service is zero, which means we don't have a backend,  so there's no container running behind the scenes. Then what Kiro CLI is going to do now is going to provide me a root cause and how to go and fix the problem. 

[![Thumbnail 2880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2880.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2880)

[![Thumbnail 2900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2900.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2900)

As you can see, it gives me detailed information of what was the problem. So if you think about what the problem was,  that's a screenshot of the ECS and then the container is stopped, so there's no backend. That's what Kiro CLI found through querying the AWS backend. Now what I'm saying to Kiro CLI is, go and then add another container, right? So change the desired count to zero to one,  and then test it again.

[![Thumbnail 2910](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2910.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2910)

[![Thumbnail 2920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2920.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2920)

[![Thumbnail 2930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2930.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2930)

So Kiro CLI is running commands, adding an extra container to that service.  Then if you see it's waiting for 60 seconds, but I just sped up the video just to avoid us waiting, but it's just waiting for the container to warm up.  Then checking if now the container is healthy, and then starting again the same test we've done before to see if now you can create a session. 

[![Thumbnail 2940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2940.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2940)

[![Thumbnail 2950](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2950.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2950)

Let's see if we can create a session, if it actually solved the problem. So we'll provide the details of the session name similar to what I've done before, select a language.  Then create a session. Here we go. Here we go. So now it's able to create a session. Right, so Kiro CLI was able to go  and then simulate a user, do all the testing, go into AWS, understand the whole environment, because I haven't provided, like, this is my ECS, this is where the task is. So it was able to figure out all the details, find the root cause, and once I provided the command, it just went there and then fixed the problem. So if you see, now we have a running container in the backend. Alright.

[![Thumbnail 2980](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2980.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2980)

[![Thumbnail 2990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/2990.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=2990)

[![Thumbnail 3000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/3000.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=3000)

### Key Takeaways: Working Backwards from Customer Needs

And then,  we're about to finish. I just want you to think for a second, what matters more in our use case? Is it the lights? So if you see for my use case,  the server is down, but my wife could continue to use the lights, is it better? Or maybe the server was working without any problem, but the lights were not  working.

And here's where I wanted you to start to think about working backwards from your customer and understanding how critical the application is and defining with the business how to deal with those situations in case you have them. And then, let's get the key takeaways for the day.

[![Thumbnail 3020](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/3020.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=3020)

[![Thumbnail 3030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/3030.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=3030)

[![Thumbnail 3040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/3040.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=3040)

 So, in the case we talked about backup, right? In my case, I could have provided a candle so my wife would be able to organize her breakfast using a candle.  I also could have organized a game day, and then the family would understand how to proceed in case we had a bad day. Or, as Jay mentioned, we could have dashboards  to understand how the environment's operating. Create also alarms, so if there's an issue, I get alerted.

[![Thumbnail 3050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/3050.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=3050)

Also it's really, really important to define the  SLAs, SLOs, SLIs, and get the business together, right? I've seen a lot of customers where the IT defines all of those numbers, but they don't have the connection with their customers, with the business. And lastly, as we all talked about AI Ops, I could have, for example, Alexa and say, Alexa, go and fix the lights for me.

[![Thumbnail 3090](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/52045329f1568398/3090.jpg)](https://www.youtube.com/watch?v=-P2hll4zioI&t=3090)

So I hope you all have enjoyed the session. One thing that I would ask you to do is, in your app, you should have access to the survey. It's really, really important for us, because I do actually read all of that feedback, because that way we improve our next session. And then here's the call to action,  so you can scan and learn more about what we discussed. Thank you.


----

; This article is entirely auto-generated using Amazon Bedrock.
