---
title: 'AWS re:Invent 2025 - 800GB of AI data: Lessons from a failed project (DEV345)'
published: true
description: 'In this video, Sandeep, a Principal Solutions Architect at AntStack, shares a failure case from a VALORANT hackathon project. His team processed 7,500 game files (100GB compressed, 800GB uncompressed) using Amazon Lightsail and attempted multiple AI approaches to select optimal 5-player teams. Initial vector database attempts with Amazon Bedrock''s Knowledge Base failed due to chunking issues and numerical context loss. Function calling with agents showed promise but suffered from cognitive overload, Lambda''s 25KB response limit, and frozen LLM executions. A multi-stage Step Functions approach also failed. The breakthrough came when simplifying the promptâ€”removing explicit instructions and letting Claude 3.5 use its existing VALORANT knowledge. The key lesson: don''t teach an LLM what it already knows.'
tags: ''
cover_image: https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/0.jpg
series: ''
canonical_url:
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - 800GB of AI data: Lessons from a failed project (DEV345)**

> In this video, Sandeep, a Principal Solutions Architect at AntStack, shares a failure case from a VALORANT hackathon project. His team processed 7,500 game files (100GB compressed, 800GB uncompressed) using Amazon Lightsail and attempted multiple AI approaches to select optimal 5-player teams. Initial vector database attempts with Amazon Bedrock's Knowledge Base failed due to chunking issues and numerical context loss. Function calling with agents showed promise but suffered from cognitive overload, Lambda's 25KB response limit, and frozen LLM executions. A multi-stage Step Functions approach also failed. The breakthrough came when simplifying the promptâ€”removing explicit instructions and letting Claude 3.5 use its existing VALORANT knowledge. The key lesson: don't teach an LLM what it already knows.

{% youtube https://www.youtube.com/watch?v=9Zu1wqWddrE %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/0.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=0)

[![Thumbnail 10](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/10.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=10)

### The VALORANT Hackathon Challenge: Wrestling with 800 GB of Game Data

 Hi, everyone. My name is Sandeep,  and today we're going to talk about a failure case. So let's start. My name is Sandeep. I work as a Principal Solutions Architect at AntStack. At AntStack, we build servers and AI applications, so you can reach out to me on any of these handles.

[![Thumbnail 30](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/30.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=30)

[![Thumbnail 40](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/40.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=40)

So this is how it started. One of my colleagues sent a message in our Slack channel telling us there's a hackathon.  Why don't you give it a shot? So we were like, it's about gaming, so why not give it a shot? And about the game, so VALORANT  is an online multiplayer game, and you have a five-player team. You have 13 rounds to win to win the game, and you have about 28 agents. So these agents are special characters that you can choose. Each character has a different power. So when you create the team, it's about using all these special powers together and providing a strategy.

And we have about 12 maps. Each map varies in the kind of location, the kind of sneak spots that are there, and what kind of tactics you're going to use. So all of it depends on the agent combination and also the kind of map you're playing.

[![Thumbnail 80](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/80.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=80)

So we were given a script  from the VALORANT team. All we had to do was run the script and we get the data into our systems. But when we ran the script, it took a very long time and all our laptops crashed. Luckily it was in an S3 bucket, so we just did an S3 sync to get all the data to our S3 bucket, and this is what we ended up with.

[![Thumbnail 100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/100.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=100)

[![Thumbnail 130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/130.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=130)

 So the data we were given were about 7,500 game files from the VALORANT team, which is spread across three different leagues or three different tournaments, and it is for three different years of gameplay. The total size of this was 100 GB. So we wanted to see what is there in these files. So when we downloaded some of these files into our laptop and tried to extract what is there,  even then our VS Code was crashing because these files varied anywhere from 200 MB to 800 MB of pure JSON data.

[![Thumbnail 170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/170.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=170)

So that's when we started using Amazon Lightsail. Amazon Lightsail is an easy-to-use service where you get all these abstracted resources like a Node.js server or a Django server or anything like that. So what we did is we ran the uncompressed script into the Lightsail and then we connected it through our VS Code through remote SSH, and it gives you a wonderful dev experience. It looks like you're working from your laptop,  but you're actually running the scripts on the server.

[![Thumbnail 180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/180.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=180)

So after the uncompression was done, the total size arrived to 800  GB. Now the question is, what is there in these files? So what we started doing is, it's just a JSON file, right? So we started splitting it up based on what are the keys that are available. And then we found all this information. Everything that a player does in the game is recorded in these files: how much ammunition you have, what speed you're running, if you're jumping, what are your coordinates, where are you landing, whom did you kill, how many times you got killed, and if you have used any special abilities, who won the game.

[![Thumbnail 230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/230.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=230)

Every single thing that is required for this game is available in these files. So once we started segmenting this data, we started recording what is there in these files and what metrics we can use to derive or create a team of five players.  One thing we quickly realized is the volume is not equal to the data. Even though we had 800 GB of data, once we started processing it, there was a lot of unwanted information that was there, and we started deriving these few metrics that are helpful for us to identify the best set of players.

[![Thumbnail 250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/250.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=250)

 What we ended up with is creating six to ten different datasets. These were specific to the characters that were being played, specific to the map that was being played with, and what are the player characteristics or the player statistics. So this had accumulated information on one player: how many games they have played, how many kills they have done, what is their combat score, and all relevant information on these kinds of metrics.

[![Thumbnail 280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/280.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=280)

[![Thumbnail 290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/290.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=290)

[![Thumbnail 300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/300.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=300)

### Why Vector Databases Failed: The Limitations of Amazon Bedrock Knowledge Base

 Now that the data was ready, the question was how do we use it? We cannot put it directly into an LLM because again, it's a large set of data. The LLMs will not be able to process this information.  That's when we thought we would give vectorization a shot, and we started doing that with Amazon Bedrock's Knowledge Base. So Knowledge  Base is a very easy way for us to spin up a vector database and get connected to it.

It also comes with an in-built chatbot, so it's easy for you to see how your vectors are performing, how your queries are performing, and then you can fine-tune it based on that. The main thing about using a vector database is the chunking strategy.

[![Thumbnail 320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/320.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=320)

 So first we started off with default chunking. Default chunking is basically taking the entire JSON file and then splitting them into 300 tokens each and then storing them as a vector record in the database. For the vector database, we used OpenSearch. Again, that's a very easy to create resource from the knowledge base. So these tokens that were stored, each of them is a separate record in the vector database. But when we do it like this, what happened was the JSON file containing all the information is now split up and it did not make sense at all. So one player's information is now overlapping the next player's information, so none of it made any sense. When we ran queries over it, we did not get any output.

[![Thumbnail 370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/370.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=370)

 Then we started to use something called a no chunking strategy. So instead of having one single file containing all the player information, we split up these files. Each player had their own file with their own metrics, and that becomes a vector record in the database. Now with this, we were able to see some good results.

[![Thumbnail 390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/390.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=390)

 This is the kind of responses we got. So we used Claude 3.5 to see what kind of responses we were getting. And when we asked something like create a team of 5 players, it is now calling the vector database and getting the information out. So here we are asking it specifically to get the players based on the combat score, but this data is not correct. All the combat scores, there are players who have had better combat scores, and it just randomly selected 5 players in the lot, and this happened every single time. And if we did not specify combat score and we asked the generic question like create a team of 5 players, it never gave any valuable results to us. That's when we realized that this is not going to work out, and then we got into why this is not working out.

[![Thumbnail 440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/440.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=440)

 So this is a sample of the JSON that we were storing in these databases. Now, all this information is spread across different characteristics of the data, right? So you have assists, you have damage, you have kills, you have the number of games. Each of them are a different dimension or a different characteristic of the data. When you put all of them together into a vector space, all this information is now spread out and there's no relevance between what is happening. We know that assist is something that you do and combat score is something that is generated by the system, but the vectorization process removes all this context from it and just stores it as raw data, which does not make any sense when we are trying to query it back.

[![Thumbnail 490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/490.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=490)

 The other problem that is there with vector databases is the number problem. So we know that 5, 10, and 15 are multiples of 5, but to an LLM or to a vector, these are basically just numbers that are just closer to each other. To a vector, probably 5 and 15 are more closer to each other, and 10 is in a different dimension space altogether. So when you put vectors which are having a lot of numerical value in them, they lose their mathematical value out of it.

[![Thumbnail 520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/520.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=520)

### From Function Calling to Multi-Stage Flows: Learning Not to Over-Prompt the LLM

 So you have to be really careful while doing this part. So the next question is, now that we know vectorization is not working, how do we let an AI decide who are the best players? The simplest thing to do is just to write a Python script which is going to take these 5 metrics, accumulate them, find the average, and so on, right? But that's not something that we wanted to do. We wanted to make sure that the AI is able to understand that 10 metrics are available and then it needs to use all these 10 metrics in its space to get the best information out. That's when we started experimenting or implemented function calling.

[![Thumbnail 560](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/560.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=560)

[![Thumbnail 570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/570.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=570)

 Function calling is nothing but your agentic calling.  So again, Bedrock has builders which are agents. Now this makes it simple for you to create agents. It's just a two-step process. So you start off with giving an instruction to the agent. Here you tell how the agent needs to react based on the kind of question that you're getting in. So what we asked it to do is select the best characters for each map, characters or agents,

[![Thumbnail 590](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/590.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=590)

 and then for each of those characters select the best player who has played them across the league and from this information shortlist 5 players who will be able to work as a team. Now after you get these 5 players, assign them to each map, and when you assign them, also tell what character they have to play as.

So this is all that we asked the LLM to do, and at the end of it, we also asked them to create a strategy. So in each map, how these players need to play, who's going to attack first, who's going to defend, who's going to be a healer, all this information in one single prompt.

[![Thumbnail 630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/630.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=630)

[![Thumbnail 640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/640.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=640)

And the other part that we did is we used  action groups. So we created one action group called ES Query, and what it basically does is we have a Lambda function behind the action  group. This Lambda function then queries an OpenSearch table. All the information or all the data sets that we just discussed about is now stored in the OpenSearch database. The Bedrock is designed in a way that it is going to call the Lambda every time it needs information. It is going to generate an ES query and send it to the Lambda. The Lambda is then going to call the OpenSearch with the actual query, get the data out, and send it back to Bedrock.

[![Thumbnail 670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/670.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=670)

 Now when we did this, we got wonderful results. So in this example you can see that it's not just taking combat score into the picture, it's also taking how many times the inventory was used, how effective that person was, how many times the entry frag was done, basically how aggressive that player is, and many other metrics are taken into consideration. So this is a holistic report on how it works or how beautifully it works, but then this worked only once in 20 or 30 iterations or 20 or 30 times that we tried it. Then we realized the hiccups that were there in this situation.

[![Thumbnail 710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/710.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=710)

So first thing is the cognitive overload.  So basically we're just asking the LLM to do too many things in one single prompt. All the things that you saw in the graph are just too much. It gets a lot of data. It gets confused on what player needs to do or what metrics it needs to take from which player.

[![Thumbnail 730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/730.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=730)

The other problems that we had is  the Lambda that is sending the response back to the LLM had a limitation that it cannot send more than 25 KB of data, and any time that happened, the LLM executions failed. The next problem we had is there were too many function calls. Every time the LLM tried to query the ES, there were sometimes that there were 30 or more executions that happened with the LLM trying to triage into who the players are. Now, the ES queries are primarily dependent on the kind of data set that is there. So if you're running any aggregation queries on top of it, you need to make sure that these follow the kind of data that you have already stored. The last problem that we faced is something called as a frozen LLM. So in these cases, the LLM just got stuck. It just timed out. There were no function calls. There were no log traces of anything happening in the LLM, just that the execution stopped.

[![Thumbnail 790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/790.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=790)

[![Thumbnail 800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/800.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=800)

[![Thumbnail 810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/810.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=810)

 So all this happened and this was just 2 days before the submission of the project, and then we wanted to see  how we can get this done in such a short time. That's when we tried with something called as multi-stage flows. So since we're very fond of Step Functions, we thought we'll just use a Step Function to get all of this  done. So instead of one single LLM doing all these things, we split it up into different LLMs and then orchestrated everything using a Step Function. And then we use Lambdas in between to cache the responses, store them in the DynamoDB. Because at the end of the day, we also had to build a chatbot to which we can ask queries like why this player was chosen or what is the strategy, and it needs to be able to respond to it.

[![Thumbnail 840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/840.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=840)

[![Thumbnail 850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/850.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=850)

It worked until everything had to work together. Each of these pieces  individually were working great, but the final summarization and selecting those five players never worked out.  So finally, since it never selected 5 players, we were not able to submit it. We tried until the last 10 minutes, but then at that point, we just gave up.

[![Thumbnail 860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/860.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=860)

 And then when we were preparing for this presentation, we redid the entire thing to take some screenshots. And that's when I wanted screenshots of things failing, but it never failed. And then we realized one very simple logic is that don't teach an LLM what it already knows. The difference between the prompt that we used before to now is one simple thing. Previously we were telling the LLM how it needs to think, how it needs to select the players per map, per characters. This prompt had none of that information. It just said create a team for the VALORANT team, and that's it. And we gave the schema of the OpenSearch and it understood from all its previous training that VALORANT is a game and it needs to have 5 players and for what map, what kind of aggression style, what kind of characteristics it needs to have, all that information was already available. All we were doing is retraining the LLM to do something out of its thought.

[![Thumbnail 930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f1f8ddc7086fd60f/930.jpg)](https://www.youtube.com/watch?v=9Zu1wqWddrE&t=930)

And last,  when we got the Slack message, we thought it's going to be a simple project. It's going to be like a weekend project where we sit for a week and it's done, and it was not easy at all. That's it from my side. Thank you for joining the session. If you have any questions, do let me know.


----

; This article is entirely auto-generated using Amazon Bedrock.
