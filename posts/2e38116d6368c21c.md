---
title: 'AWS re:Invent 2025 - Building Multi-tenant global ML SaaS platform (ISV306)'
published: true
description: 'In this video, Vin Dahake from AWS and Sean Stauth from Qlik present Qlik Predict, a fully managed machine learning SaaS platform built on AWS. They explain how 70% of forecasting programs fail due to univariate approaches, while real-world forecasting requires multivariate time series analysis with up to 50+ variables. The platform leverages AWS''s GPU clusters, EKS with Karpenter, and scale-to-zero architecture across 38 regions to handle 100,000+ monthly training jobs. Results include 99.99% uptime, 9x faster training versus CPUs, 4,500+ active users generating 1.5 billion predictions, and customer savings like Appalachian Regional Healthcare''s $6 million annual reduction in patient no-shows. Key takeaways emphasize designing for multi-tenancy from day one, integrating observability, and ensuring seamless workflow integration through APIs and event-driven architecture.'
tags: ''
series: ''
canonical_url: null
id: 3085172
date: '2025-12-05T03:35:41Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project enhances multilingual accessibility and discoverability while preserving the original content. Detailed transcriptions and keyframes capture the nuances and technical insights that convey the full value of each session.

**Note**: A comprehensive list of re:Invent 2025 transcribed articles is available in this [Spreadsheet](https://docs.google.com/spreadsheets/d/13fihyGeDoSuheATs_lSmcluvnX3tnffdsh16NX0M2iA/edit?usp=sharing)!

# Overview


ðŸ“– **AWS re:Invent 2025 - Building Multi-tenant global ML SaaS platform (ISV306)**

> In this video, Vin Dahake from AWS and Sean Stauth from Qlik present Qlik Predict, a fully managed machine learning SaaS platform built on AWS. They explain how 70% of forecasting programs fail due to univariate approaches, while real-world forecasting requires multivariate time series analysis with up to 50+ variables. The platform leverages AWS's GPU clusters, EKS with Karpenter, and scale-to-zero architecture across 38 regions to handle 100,000+ monthly training jobs. Results include 99.99% uptime, 9x faster training versus CPUs, 4,500+ active users generating 1.5 billion predictions, and customer savings like Appalachian Regional Healthcare's $6 million annual reduction in patient no-shows. Key takeaways emphasize designing for multi-tenancy from day one, integrating observability, and ensuring seamless workflow integration through APIs and event-driven architecture.

{% youtube https://www.youtube.com/watch?v=flGdaoQsXc4 %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/2e38116d6368c21c/0.jpg)](https://www.youtube.com/watch?v=flGdaoQsXc4&t=0)

### Introduction: The Challenge of Enterprise Machine Learning and the AWS-Qlik Strategic Partnership

 Welcome to re:Invent. I'm excited to see everyone here. We have over 2,000 sessions and workshops lined up this week, so make the most of it. I'd like to give a warm welcome to all first-time attendees. I'm going to recommend that you activate your pedometer on your phone and count the number of steps you'll walk this week. I'm telling you, you're going to be pleasantly surprised by the total.

My name is Vin Dahake. I lead the solutions architect team for ISV Private Equity at AWS. I've been with AWS for five years now and I'm based out of New York City. Let me have my partner introduce himself.

Thank you, Vin. It's a pleasure to be here. My name is Sean Stauth. I'm Global Director of AI and Machine Learning at Qlik, and I have the opportunity to work with our customers worldwide across a variety of different industries on their cutting-edge AI and machine learning solutions.

Before we get started, I'd like to ask a quick question. How many of you have built machine learning applications or analytics applications that worked for the first time in production? That's good. We have a few hands up. It's not easy. I was hoping everybody would raise their hand so I could just walk off the stage and say thank you very much, but this is the reason we are here. Building machine learning platforms that are enterprise-ready and scalable is not easy, and that's why we have Qlik here today.

Let me tell you a little bit about Qlik. Qlik has been a global leader for the last 30 years in the data analytics space. They have helped companies transform by processing data and getting insights from it. Qlik has three core areas of expertise that we are seeing. They've done extensive work in real-time data integration, analytics, business intelligence, and visualization, and third, AI, ML, and AutoML. That's the reason we're here to discuss Qlik Predict. Today, Qlik has over 40,000 customers across 100 different countries. In 2024, AWS and Qlik signed a strategic collaboration agreement, and I'm excited to tell you that the result of this agreement is Qlik Predict. This is a fully managed, multi-tenant, global machine learning SaaS platform that is entirely built on AWS.

[![Thumbnail 190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/2e38116d6368c21c/190.jpg)](https://www.youtube.com/watch?v=flGdaoQsXc4&t=190)

 Let's take a quick look at the agenda. We will talk about what this machine learning predictive analytics platform is. We will do a deep dive into the architecture. We will look at some case studies, and then we'll talk about the challenges that we faced and how we can learn from them.

[![Thumbnail 210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/2e38116d6368c21c/210.jpg)](https://www.youtube.com/watch?v=flGdaoQsXc4&t=210)

 Seventy percent of forecasting programs fail. This is not an academic study. This is real money, real business, and real challenges that people face. Most traditional forecasting programs fail because they look at data in isolation, and that's not how the real world works. When programs are doing sales forecasting, for example, they look at what their sales data was for last month and assume next month will be similar. But that's not how it works in reality. There are multiple variables that need to be taken into consideration when you're doing forecasting. It could be seasonality, your inventory, economic conditions, or your competitor's actions. There are multiple factors, and as a matter of fact, there could be up to 50 different factors that can impact your forecasting.

Simple models can probably look at seasonality and make predictions, but when we have 50 or more different variables that interact with each other, we need complex, advanced algorithms like encoder-decoder, perceptron, or recurrent neural networks to do the forecasting. These models are very computationally intensive.

They require GPUs to perform the calculations. As I mentioned, we've worked with Qlik and formed a strategic collaboration agreement. I'm happy to say that the result of that was building Qlik Predict. Sean, would you like to share a bit more about this story?

### Real-World Impact and the Need for Multivariate Time Series Forecasting

Yeah, thank you. As Vin mentioned, this opportunity is massive. With machine learning, real companies are getting massive results around their supply chains, logistics, HR, and more. I want to share a quick story about a company called Software Logistik Artland, or SLA, in Germany. They have a very complex network of suppliers, distributors, and manufacturing operations that they run on a daily basis, where even small changes in their operations can lead to massive impacts on finances and staffing.

With Qlik Predict, they were able to build a forecasting capability and predict with 90% accuracy the demand they needed to produce every single month. This led to a 50% reduction in annual planning needs. While their business is complex and dynamic, they needed a capability that could match that reality. Today we're talking about taking the next leap with a multivariate forecasting capability that can deliver smarter forecasting at a global scale.

[![Thumbnail 400](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/2e38116d6368c21c/400.jpg)](https://www.youtube.com/watch?v=flGdaoQsXc4&t=400)

To start, I want to talk about what machine learning is, what AutoML is, and why the demands of time series are fundamentally different.  Machine learning is the ability to predict future results based on past occurrences and understand why things are happening so that you can take corrective action. Automated machine learning takes many of the time-consuming tasks, whether data preparation, feature engineering, ML selection, ModelOps, and more, so that you can deploy these at scale where they're needed for the business.

Time series modeling is a subset of machine learning where you're looking at forecasting on a continuous time window. Let me give you an example of why this is needed. If we think about retail, it's a really good example, and we work with retail companies worldwide. In retail, you have products, SKUs, customers, locations, online channels, physical retail locations, and a multitude of different factors impacting your business every day in real time.

[![Thumbnail 470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/2e38116d6368c21c/470.jpg)](https://www.youtube.com/watch?v=flGdaoQsXc4&t=470)

This leads to a web of exponential dependencies where one factor is actually impacting another, resulting in billions of interactions.  Traditionally, a lot of the forecasting has been univariate, which means looking at one historical variable to forecast a future result. But in reality, businesses are complex and dynamic, with thousands of different interactions from channels to products. Even weather has a large impact on business operations, and each added input leads to a multiplying effect of complexity.

This is why we need multivariate time seriesâ€”the ability to capture all these different signals to create an accurate, actionable forecast where you can run your business. But this also leads to a massive compute challenge with billions of potential interactions. Today, we're happy to announce and talk about our multivariate time series capability with an AWS partnership that's based on GPUs and elastic just-in-time compute at scale.

[![Thumbnail 540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/2e38116d6368c21c/540.jpg)](https://www.youtube.com/watch?v=flGdaoQsXc4&t=540)

### Building Qlik Predict: Architecture, AWS Infrastructure, and Technical Implementation

All right, so why AWS?  When Qlik was looking to build this platform, they weren't looking for just any cloud platform. They were looking for someone who could help them scale and build enterprise models serving the 40,000 customers they have today. There were three key things that Qlik was looking at. Number one is global scale with data sovereignty. Today, AWS has 38 regions with three more coming up, and AWS has the global scale to serve Qlik's customers in 100 different countries.

Also, data sovereignty is critical. With GDPR and other compliance requirements, data needs to reside in that country. AWS provides the global scale as well as data sovereignty for building the application. Second, we talked about GPU scaling. GPUs are expensive, so you need to be able to scale as well as control the costs. You need to be able to scale down to zero as required.

Third, we're looking at enterprise-grade reliability. When customers are running these applications, they're mission-critical applications. They need a platform that needs to be up and running 99.9% of the time. Not only that, they also want to have the right high availability and disaster recovery in place for running these mission-critical applications.

[![Thumbnail 640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/2e38116d6368c21c/640.jpg)](https://www.youtube.com/watch?v=flGdaoQsXc4&t=640)

Now let's take a quick look at the architecture for Qlik Predict. Qlik Predict is a completely cloud native application built on AWS. The three core components that we've looked at are GPU clusters, regional training models that we are using, as well as a scale-to-zero architecture to keep the costs low.  Also, we have used several native services like Amazon MQ, Amazon S3, and RDS. For realtime integration, we've leveraged webhooks and AWS Lambda.

What is so amazing is that with AWS, we're able to take this to scale and make it a reality. These complex algorithms are necessary for billions of interactions in real time for our customers. We're talking about deep neural architectures, GPU acceleration, elastic compute at the reliability, the scalability, and the security requirements that our customers need. This is what AWS can deliver, which is forecasting for the real world.

The compute demands are enormous. We're learning relationships across thousands of variables, thousands of signals that impact businesses every day from supply chain to demand, seasonality, temporal patterns, and cross-correlation. We're really looking at things in a systematic way, a holistic way that is more representative of a business. To work with these deep recurrent networks where the combinations explode, we need the GPU power. Working with Amazon to have these GPUs that can really do this at the speed that's necessary for businesses to take action is exciting.

[![Thumbnail 800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/2e38116d6368c21c/800.jpg)](https://www.youtube.com/watch?v=flGdaoQsXc4&t=800)

It all starts with the API gateway where a request is routed to the correct region across the world where it's needed within its boundary so that it can meet the data sovereignty and regulations for each particular region. The heavy lifting with EKS and Karpenter allows for just-in-time scaling of these workloads, being able to scale up to massive demands when needed. The GPU EC2 instances can be tuned for different neural workloads, depending on the use case. Together it's a globally distributed, GPU-accelerated SaaS capability, one SaaS capability for each region worldwide. 

Let's talk about the real impact of building on AWS. Speed to market is key. When Qlik was building this platform, they didn't have to worry about building their infrastructure. Leveraging AWS's managed services, they were training their models where competitors were still trying to figure out how to set up their environment. That's the key difference.

Scale is another major benefit. Today Qlik runs 100,000 plus training jobs on a monthly basis. That's literally 3,300 jobs a day. They have the scale today to process and train the models. Third, let's look at cost efficiency. Using Karpenter along with spot instances, you can control your cost and bring it down 60 to 70 percent, leveraging a scale-to-zero architecture along with spot instances so that it doesn't become very expensive.

Also consider regionality. With the 38 regions that we have today, Qlik could easily expand to any new region to serve their customers and did not have to spend a lot of time building their infrastructure over there. Finally, there is reliability. Leveraging HADR and intelligent workload balancing, you can take care of the availability of your application and ensure it's up and running.

[![Thumbnail 900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/2e38116d6368c21c/900.jpg)](https://www.youtube.com/watch?v=flGdaoQsXc4&t=900)

### Results, Customer Outcomes, and Key Takeaways for Enterprise ML Platforms

The results are amazing.  Just looking at our telemetry, currently we have over 4,500 active users on Qlik Predict.

[![Thumbnail 930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/2e38116d6368c21c/930.jpg)](https://www.youtube.com/watch?v=flGdaoQsXc4&t=930)

They're generating over 167,000 trained models and 1.5 billion predictions to date, all of this with over 99.99% uptime. With our GPUs versus a CPU equivalent, we're able to run our training jobs up to nine times faster. 

I would really like to talk about outcomes because it's the actual tangible business outcomes that matter. We work with industries all across the world, from financial services, healthcare, retail and more. I'd like to share a couple of examples today. One with Appalachian Regional Healthcare, a hospital network based on the East Coast, they're able to reduce their patient no-shows and patient cancellation rates, saving over $6 million a year. With Qlik Predict, what they're able to do is not only predict and understand why a patient is going to cancel, but take the corrective action so that they can get the patient to show up when they need to and also have better patient outcomes.

[![Thumbnail 1010](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/2e38116d6368c21c/1010.jpg)](https://www.youtube.com/watch?v=flGdaoQsXc4&t=1010)

In financial services, Integra Financial is a really good example of integrating this into an external workflow with a real-time API for automated lead scoring, which has led to over $1 million in automated savings. Village Roadshow, which is an entertainment and hospitality group in the Asia-Pacific region, has very complex business operations with staffing, customers and more. They were able to use Qlik Predict to forecast demand and staffing for faster data-driven decisions. 

So what is the key takeaway here? Building enterprise-level machine learning SaaS platform isn't something that is in the future. This is happening today. Qlik has built the Predict platform, which is serving multiple enterprise-level customers doing millions of predictions and saving customers millions of dollars for sales forecasting.

The three core things that I want everybody to learn from this are: number one is scale by design. Multi-tenancy isn't something that you can retrofit. It is expensive and risky. Think about multi-tenancy when you're building the application from day one. Second is telemetry and observability. Integrate observability in your application from day one. When you're running 100,000 jobs, your customers want to have the transparency and see what is under the hood. Leverage CloudWatch, for example, to ensure that customers have full visibility into the application that is running.

[![Thumbnail 1130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/2e38116d6368c21c/1130.jpg)](https://www.youtube.com/watch?v=flGdaoQsXc4&t=1130)

Finally, machine learning applications cannot run in silos. Integration is everything. Ensure that you can integrate your applications along with your workflows so that you can derive the maximum benefits. You can use APIs, webhooks, and Lambda event-driven architecture. AWS has many services that can help you do that. Leverage EventBridge, for example, which will help you integrate your application and not run in silos to get the maximum business value out of it. 

This is an excellent example of how Qlik and AWS work together. We had a strategic collaboration agreement where we leveraged Qlik's domain expertise with AWS's global infrastructure to make Qlik Predict happen, which is saving customers millions of dollars doing sales, financial, and operations predictions. Qlik Predict is also available on AWS Marketplace. I encourage all of you to take a look at it and you can see it actually up and running where you can build a machine learning job with very little code and take maximum use of the machine learning models.

Really thanks for having this conversation today. Please come visit us at our booth, 1727. I'm happy to talk about our journey in building this architecture. We have some engineers here as well to talk about their experiences and also your challenges and aspirations around machine learning and multivariate time series. I'm really happy to be here today. My name is Vin and I'll be around if you have any questions. I'm more than happy to answer them. Thank you and enjoy re:Invent.


----

; This article is entirely auto-generated using Amazon Bedrock.
