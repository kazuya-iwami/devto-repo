---
title: 'AWS re:Invent 2025 - Zoomâ€™s Journey from Conversation to Completion with AI Companion 3.0 (ISV321)'
published: true
description: 'In this video, Shizhen Wang from Zoom and Dmitriy from AWS present AI Companion 3.0, showcasing its evolution from meeting summaries to agentic AI that can plan, reason, and execute tasks autonomously. The demo highlights features like post-meeting follow-up generation, cross-meeting analysis, and intelligent scheduling that rearranges calendars. Built on a modular agentic framework with Federated AI combining small language models with frontier LLMs, the solution leverages AWS microservices, Bedrock, and OpenSearch for scalable, cost-effective deployment while maintaining context through vector stores and personalized user preferences.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/0.jpg'
series: ''
canonical_url: null
id: 3093079
date: '2025-12-08T19:53:32Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Zoomâ€™s Journey from Conversation to Completion with AI Companion 3.0 (ISV321)**

> In this video, Shizhen Wang from Zoom and Dmitriy from AWS present AI Companion 3.0, showcasing its evolution from meeting summaries to agentic AI that can plan, reason, and execute tasks autonomously. The demo highlights features like post-meeting follow-up generation, cross-meeting analysis, and intelligent scheduling that rearranges calendars. Built on a modular agentic framework with Federated AI combining small language models with frontier LLMs, the solution leverages AWS microservices, Bedrock, and OpenSearch for scalable, cost-effective deployment while maintaining context through vector stores and personalized user preferences.

{% youtube https://www.youtube.com/watch?v=XC5olmoITYU %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/0.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=0)

### Introducing AI Companion 3.0: From Meeting Summaries to Cross-Meeting Analysis

 We'll talk about Zoom's journey from conversation to completion with AI Companion 3.0. We'll share how Zoom is leveraging Agentic AI to improve productivity and how our collaboration with AWS is making that happen. I'm Shizhen Wang, Head of AI Infrastructure at Zoom. I lead the development of AI Foundation and also inference optimization to serve Zoom AI capability in a cost-effective way at scale. With me, Dmitriy.

Thanks Shizhen. I'm Dmitriy. I'm a Solutions Architect at AWS, and I'm honored working with Zoom, one of the most innovative customers I've had the pleasure of working with. Today you're going to learn about the journey that we have been going through with Zoom, and we're going to dive a little deeper into what's happening behind the scenes, how Zoom is reimagining productivity, turning just a conversation and going beyond it into what's happening next with action items, with planning, and with coordination that is usually a part of any conversations. Most of us are spending a lot of time on Zoom calls, so hopefully you find the session informative and interesting, and thanks for joining.

[![Thumbnail 80](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/80.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=80)

[![Thumbnail 90](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/90.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=90)

[![Thumbnail 100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/100.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=100)

 Let's get started. We'll start with a short video about AI Companion. This is the new Zoom AI Companion 3.0 web interface that was announced at Zoomtopia 2025.  Our user can select their chat history to be able to view previous conversations with AI Companion and continue the conversation just by simply writing an  additional follow-up message. By selecting new chat, the user can then choose to start anew.

[![Thumbnail 110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/110.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=110)

Let's look first at one of the getting started quick prompts. We'll choose post-meeting  follow-up, where you'll automatically have attached to your prompt the last meeting that was summarized, where we can view the transcript and the summary. By selecting the plus sign, I can easily select additional meetings or swap out for the appropriate meeting. Here we'll run a follow-up notes and emails prompt, which can be edited before submitted.

[![Thumbnail 150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/150.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=150)

[![Thumbnail 160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/160.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=160)

Meeting summaries are sometimes general and as a result may lack personal value, but with AI Companion Web 3.0, it knows your role and can tailor the summary to your specific needs. In this case, we'll get a quick summary, a more detailed summary with key  decisions made, action items, some risks and concerns, next steps, as well as individual participant notes for each attendee, as well as  any specific email communications that can be created for the team, as well as each individual, that can be simply copied and pasted for distribution.

[![Thumbnail 170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/170.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=170)

[![Thumbnail 190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/190.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=190)

[![Thumbnail 200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/200.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=200)

 Selecting show sources allows us to be able to see what context was used to be able to generate the output. Let's try another. This time we'll choose cross-meeting analysis, which will allow us to be able to attach multiple meetings. Here I can select all and choose all my meetings, or I can filter down by a particular meeting series. In  this case, we'll pull the 123 Main Street Project meeting series. I can choose all meetings or just simply select the meetings that are relevant for  this particular prompt in order to be able to analyze and provide the most valuable output.

[![Thumbnail 210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/210.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=210)

[![Thumbnail 220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/220.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=220)

[![Thumbnail 230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/230.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=230)

[![Thumbnail 240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/240.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=240)

Once we run this output, we'll be able to see a quick summary of all of  the meeting information that we want to have extracted. Here you can see a cross-thread analysis that gives us information about each thread.  The first one is the training program. The next thread is the learning management  system. The next thread is the marketing campaign and budget planning.  The fourth thread is the loyalty program development. And finally, the fifth thread is the feedback and assessment mechanisms the team wants to put in place.

[![Thumbnail 250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/250.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=250)

[![Thumbnail 260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/260.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=260)

 And then a cross-cut analysis that addresses topics that were covered over different meeting types. We'll have a list of action items, long-term  monitoring, and a high-level summary of the project, as well as high priority threads. Leveraging AI Companion Web 3.0 to analyze a series of meetings enables you to track the evolution of discussions across several meetings if you need to capture themes, team involvement, or just general progress of the project over time.

[![Thumbnail 290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/290.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=290)

### The Evolution to Agentic AI: How AI Companion 3.0 Plans, Reasons, and Executes

Now let's see how we build it.  This is an evolution of AI Companion. It all began with meeting summaries to capture the key highlights and also the takeaways, and also evolved into the 2.0 where we introduced the interaction, so you can interact with the AI Companion and ask questions.

And the goal there is to help you get more done. Now we move into the usual agentic AI where the companion can really work for you. AI Companion 3.0 is our latest leap forward. It can plan, reason, and also execute on your behalf. The goal is to get you to quality results faster.

I'll share a recent example. The other day I was reviewing a key project and realized the timeline was at risk. The team is distributed across the world, and I didn't know exactly where we stored everything. Diagnosing this and getting everyone into a room would take days of admin work. Instead, I used AI Companion as an agent.

First, I used agentic retrieval. I didn't do a manual search, so I asked AI Companion to summarize for me. AI Companion connected to Jira, retrieved the related tickets, and summarized where the bottleneck was. Next, I used identity scheduling. I needed to meet with the team immediately to brainstorm and find a way to de-risk the product. Our calendar was a mess because of different time zones, so I asked AI Companion to book a meeting. It told me the next available slot was like a week away. For a key project like this, a week away is too far away.

So I gave AI Companion a really complex command: find the time today and move my other meetings if necessary. AI Companion acted on my behalf, rearranged my calendar, and secured a 30-minute meeting a few hours later. Third, I used prepared meeting. After scheduling the meeting, AI Companion suggested it prepare the meeting for me. It took the Jira summaries and also related previous meeting transcripts and drafted a focused agenda for the meeting.

[![Thumbnail 460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/460.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=460)

The result was that because we prepared and we could jump quickly into the problem solving, we were able to figure out a way to bring the project back on track. What usually took me a day of coordination, AI Companion did in a few minutes.  So from meeting recap to agentic AI, AI Companion evolves from reactive to proactive. We try to connect the conversations to the completed results.

[![Thumbnail 500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/500.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=500)

Our fundamental objectives and needs remain the same. We want to provide the highest quality to our customers. We want to achieve the lowest latency, and also we want to scale in a cost-effective way. How do we really achieve that? First of all, we built AI Companion 3.0 on the agentic framework. 

It's a native multi-agent framework that handles memory, context, prompt history, and so on. There are three key principles we built on. First one is modular, so you can easily extend it to include new capabilities, plug and play. Secondly, it's customizable. You can define your own template and also define your own workflow. You can easily adapt it to different verticals and domains. We have tenancy isolation, bringing in added security.

Next, we have advanced content engineering. What we do is when AI Companion does the work for you, it takes into consideration not just the session information but also the long-term memory and your personal preferences. For example, for me, I prefer short meetings. So when AI Companion schedules the meeting for me, it picks the 30-minute meeting instead of longer ones.

Last but not least is our secret sauce, the Federated AI. At Zoom, we use our own small language model paired with frontier large language models from third parties to provide the highest quality to our customers and also control the cost in a way that we can scale out easily. Next, I'll give it to Dmitriy to talk about our collaboration with AWS.

[![Thumbnail 610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/610.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=610)

### Behind the Scenes: Building Scalable AI Infrastructure with AWS Microservices and Federated AI

Let's dive a little deeper into what's happening  behind the scenes under the hood. For Zoom, serving thousands and millions of customers, scalability is one of the key priorities. When the whole design was happening, the main decision was made to build the solution being modular and based on microservices so that when it's required in different regions, in different locations, or even for different times, the solution is able to scale out to meet the demands. It's also coupled with Bedrock, which gives access to Zoom AI Companion and also allows the solution to access and process the requests by accessing models without the necessity to potentially be concerned about scalability as well.

With that, the next key consideration for Zoom was dealing with index and context, because in Agentic AI, agents would not be as useful without understanding the end user's surroundings. As mentioned earlier, understanding and bringing context into the conversation, into the picture, is a key component. Here, the main component is OpenSearch with index, with vector store, serving conversations and retrieving that information when it's required without any delays.

Another interesting element, and that's where I want to double click, is the federated AI Companion component that Suzanne mentioned. The example here is how SLMs are serving and processing that input before it goes to larger models, to LLMs. What that means is, let's say a user without explicitly mentioning a particular outcome, but implicitly that would mean that the outcome should be, for example, structured as a table or maybe even as some sort of specific list based on the needs. The small language models will understand that intent first, process it, and then pass that information, enriching that prompt from a user. This means through that multi-step process, the outcome for the user, the output, would be really tailored. That's probably when you start using AI Companion 3.0, you will understand the structure and how it happened in this multi-step process.

[![Thumbnail 790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/790.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=790)

So if we start summarizing it a little bit,  for AI Companion, one of the key decisions was using a purposefully built agentic framework which has custom designed workflow so that every agent makes its own decisions and processes outcomes to the needs of the particular user. It's built on top of AWS microservices, and it allows the whole solution to scale out, serving needs when and how it's required. With access to such services as Bedrock, Zoom is able to take advantage of different models so that for a particular task, for a particular, maybe even a particular agent, the model is providing the best tool for the job, serving the purpose of the request.

[![Thumbnail 870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/870.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=870)

The future state is already in view for Zoom. AI Companion 3.0 is a starting point, if you will, where more and more will be built, and we're already exploring what's happening next. Some of the decisions are made around the architecture with exploring of agent core. Thank you, and with Zoom, we have,  I'm not sure if you have already had a chance to visit, but make sure you stop by. There you can dive a little deeper and even play around with AI Companion 3.0, see what's happening, and it's actually going to be released very soon. Thanks for joining.

[![Thumbnail 890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/890.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=890)

[![Thumbnail 910](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/102060a5b1c3541e/910.jpg)](https://www.youtube.com/watch?v=XC5olmoITYU&t=910)

 If you want to know more, then learn specifics and details of Agentic AI,  here is a link, and it has a lot of material so that you can continue or start building and build something similar or something that serves your use cases. And yeah, with that, Suzanne, thank you, and thank you for joining us. Yeah, enjoy the event and take care.


----

; This article is entirely auto-generated using Amazon Bedrock.
