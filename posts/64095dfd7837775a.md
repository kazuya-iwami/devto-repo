---
title: 'AWS re:Invent 2025 - AWS Cloud WAN MCP Server: Transform network operations with GenAI (NET331)'
published: true
description: 'In this video, Andy and Jose demonstrate the AWS Network MCP Server, an open-source tool for troubleshooting complex AWS networks using AI agents. They explain how the Model Context Protocol (MCP) enables AI models to interact with AWS networking services through discrete tools rather than monolithic scripts. The session includes live demonstrations of finding IP addresses, performing path traces across Cloud WAN, Transit Gateway, and Network Firewalls, and visualizing network policies using Mermaid diagrams in markdown reports. Key design decisions include letting the LLM handle decision-making, implementing robust error handling, and using agent files to provide stable personas. They showcase creating a custom MCP server in minutes using Kiro CLI and emphasize testing with real infrastructure. The AWS Network MCP Server, released as open source in AWS Labs, supports multiple regions and accounts, with tools for Cloud WAN, VPC, and Network Firewall analysis.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/0.jpg'
series: ''
canonical_url: null
id: 3085319
date: '2025-12-05T04:55:50Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project enhances multilingual accessibility and discoverability while preserving the original content. Detailed transcriptions and keyframes capture the nuances and technical insights that convey the full value of each session.

**Note**: A comprehensive list of re:Invent 2025 transcribed articles is available in this [Spreadsheet](https://docs.google.com/spreadsheets/d/13fihyGeDoSuheATs_lSmcluvnX3tnffdsh16NX0M2iA/edit?usp=sharing)!

# Overview


ðŸ“– **AWS re:Invent 2025 - AWS Cloud WAN MCP Server: Transform network operations with GenAI (NET331)**

> In this video, Andy and Jose demonstrate the AWS Network MCP Server, an open-source tool for troubleshooting complex AWS networks using AI agents. They explain how the Model Context Protocol (MCP) enables AI models to interact with AWS networking services through discrete tools rather than monolithic scripts. The session includes live demonstrations of finding IP addresses, performing path traces across Cloud WAN, Transit Gateway, and Network Firewalls, and visualizing network policies using Mermaid diagrams in markdown reports. Key design decisions include letting the LLM handle decision-making, implementing robust error handling, and using agent files to provide stable personas. They showcase creating a custom MCP server in minutes using Kiro CLI and emphasize testing with real infrastructure. The AWS Network MCP Server, released as open source in AWS Labs, supports multiple regions and accounts, with tools for Cloud WAN, VPC, and Network Firewall analysis.

{% youtube https://www.youtube.com/watch?v=7e4UeHMMOXo %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/0.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=0)

### Introduction: Tackling Complex AWS Network Troubleshooting

 Good morning. Thank you all for attending NET331: AWS Cloud WAN MCP Server. I'm Andy, and you can probably guess from the photos who is who with Jose. We really want to make this an interactive session rather than just fly through slides. I'd like to take opportunities for you to ask questions, but you're not going to escape. We've got questions too. So just before we get into this, I'd be really interested to know with a quick show of hands from an audience perspective: who is doing core AWS networking? Okay, and then who's doing more DevOps work? Now, obviously my math is terrible trying to gauge it, but he's doing both. Okay, right, so what's really nice to see is over the last couple of re:Invents that who's doing both is really changing. We're getting more and more people now starting to get involved in both sides, which is a massive win.

[![Thumbnail 90](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/90.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=90)

[![Thumbnail 110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/110.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=110)

So how did we get here?  What actually happened is I ended up having a network similar to this, very similar to this, that I was trying to troubleshoot.  As you can tell, it's a complex network with dual Core Networks, multiple regions, inspection VPCs, Network Function Groupsâ€”you name it, it's got it. Going through this meant that it was very time consuming, and going through each element was very error prone just to work out how they connect. What tools did I have to hand? Well, for my sins, I'm far too stubborn not to have an idea about something and then not at least try to get to the end of it and make it work. I had plenty of coffee and maybe a little help from GenAI.

I think the other thing which became really helpful is collaboration. I was very lucky to be able to collaborate with Jose on this rather than doing it all on my own. It's really good to get a different perspective and just have someone else say, "Hey, hang on, have you thought of this?" And I think that made a massive difference. Of course, we've been through what I will call the network from hell. What options did I have initially to try to put all these pieces of the puzzle together?

[![Thumbnail 200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/200.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=200)

 I could quite easily work out paths between A and B using the AWS console. Click ops are fine, but unfortunately I have a really terrible memory, so I never remember where things are. Also, it's very hard to repeat. The console and click ops are great to learn a new service. AWS CLI, if you start scripting the AWS CLI, it can be quite powerful. But again, I ended up having lots of complex AWS CLI commands that I was stitching together with a shell script, and it just became very brittle and not particularly pleasant. Then there's Python using Boto3. I'm certainly no kind of developer, but if you're using an augmented agent to help you with coding, they're very good at coding. One of the things that I have found is that if you make a good attempt at something and then ask your agent of choiceâ€”in this case, Claudeâ€”to say, "Look, why is this not working and why is yours working? Give me some output and provide some markdown explaining it." As you'll see later on in the slides, I'm a massive fan of markdown together with Mermaid diagrams, and it really gives you some good study material.

So the strategic goal was to create something that all of those who put their hands up for being a kind of core network engineer takes for granted, which is traceroute. I just really wanted to see, look, from A to B, how do I get there, what's in the path? Not just from a routing perspective, but also security controls that might stop that connectivity.

Rather than try and eat the proverbial elephant whole, break it down into some smaller tasks. For example, break those out into kind of more manageable tasks. Use Python scripts to try and achieve that. Get some help with an agentic coding agent and then start taking these kind of discrete scripts and then putting them towards an MCP.

[![Thumbnail 370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/370.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=370)

A good example for me was  creating a Python script that essentially found your global networks in your account, your core networks, all of your route tables. I am obsessed with the rich library from Python, it's got to be colorful, and therefore, you know, print out each of those route tables, so I can really easily see, look. In each region, in each core network, these are the roots or the prefixes in each of those route tables.

[![Thumbnail 430](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/430.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=430)

### Understanding AI Agents and the Model Context Protocol (MCP)

So from here, I want to pass over to because they start talking more about kind of agents and the delineation between agents and scripts. Yes, before we get to the actual code demonstrations,  let's take a moment to talk about AI agents and MCPs so that we all understand what those are.

AI agents are applications that can reason and plan and try to accomplish a goal by leveraging an LLM to do that, and they can also act, meaning that they can call, for example, external APIs to get more information to accomplish this particular goal. These applications are something that either you or someone else has created. If you look a little bit deeper, what actually happens in the application is something we call an agentic loop.

This whole process starts when it gets an input, so you invoke the agent and you give it some prompt, and this is the goal that the agent tries to achieve. The agent takes this input or the goal and all of the information that was given to the agent beforehand, so this would be like the persona or any other information and also all of the tool information that it has access to through MCPs for example. The agent sends all of this information to the LLM and then the LLM starts the reasoning process that can it accomplish the goal with this information that it has.

If the goal is something simple like what is an IPv4 address, it most likely can find the information from its training data and answer back immediately. If it is something that it doesn't know, for example, where is this IP address located in my AWS environment, it needs to do something else. It will go to the tool information and try to find a tool that can get this information to it.

The LLM then sends the control back to the agent with a specific syntax, specifying that it wants to use a tool with particular arguments. The agent, the application calls, for example, the MCP and utilizes the tool there with the arguments and gets the results back after it has finished. Then the loop starts again, so all of the information, the previous information, and now the new information is sent back to the LLM and the LLM starts the reasoning again that does it now have enough information to answer?

[![Thumbnail 600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/600.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=600)

If the IP address was not found, it might continue the loop and for example, call the tool again with a different set of arguments like another AWS region. Or if the IP address was found, it can generate the final answer and return back to the user that yes, the IP address was found. 

[![Thumbnail 610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/610.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=610)

The MCP, which is short for Model Context Protocol, is an open source protocol developed  by Anthropic. It provides a standardized way for us to connect AI models to external data sources and tools. It is very widely used at the moment and is used in the network MCP that we are demonstrating today. In the AI agent that you have created, you would have an MCP client running that can then connect to MCP servers that might be running on your laptop or somewhere remote.

[![Thumbnail 650](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/650.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=650)

### Scripts vs. AI: Choosing the Right Tool for Network Management

Let me take another show of hands.  How many of you are currently using scripts to manage your AWS network? How many of you are using AI at the moment to manage the network? There are a few, not that many yet. Hopefully we can change that. Both of these are still perfectly valid approaches. Scripts are very good in scenarios where you already know what you want to get as an output. For example, if you want to find the IP address and you know how your network is built, you can just use a script and get the same answer every time, and it is fast.

[![Thumbnail 710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/710.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=710)

However, if the question is something more complex or you do not exactly know what you are going to be asking, then AI is a really good tool for that. For example, if you want to ask whether the EC2 instance that owns that IP address can reach the internet and you might have a complex network, AI can help. We will see this in the demonstrations.  In the demo today, we will be using a live environment. If you have any questions during the presentation, we can try to do something live as well. Behind the scenes, there is an AWS Cloud WAN network with two AWS transit gateways, some VPCs, and AWS Network Firewalls in the mix.

[![Thumbnail 740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/740.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=740)

[![Thumbnail 780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/780.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=780)

[![Thumbnail 790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/790.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=790)

[![Thumbnail 800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/800.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=800)

Let us go into the code.  Before we go on to the code itself, it is probably a good opportunity to ask if anyone has any questions or any thoughts at the moment that you want to ask. Can you switch over to the terminal? Yes, so today we will be using Kiro CLI as our AI agent.  Let us load that up. It will be initializing two MCP servers. We will be using the AWS Network MCP  server and there is also an AWS Knowledge MCP server available for us. The first thing is I will be switching to a  predefined agent. As I was mentioning at the start, when we are sending the information to the LLM, we can have some information in the AI agent itself. Here we have specified some more detailed information about what the agent should do and some networking examples there.

[![Thumbnail 830](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/830.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=830)

[![Thumbnail 840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/840.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=840)

[![Thumbnail 860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/860.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=860)

### Deep Dive into MCP Tool Architecture: The get_cwan Example

We can also take a look at the tools, so we can see that here is the AWS Network MCP server and the tools  that are available to us at the moment. Before going into the demonstration, let us take a moment and look at the code that is behind the scenes.  This is one tool that is within the network MCP server, and all of this has been built with the FastMCP framework. The first tool that we are looking at is get_cwan, a pretty simple function,  but this gives us the possibility to look at the structure of how it has been built. There are four arguments in this tool, with two of them being mandatory ones: core_network_id and core_network_region.

Core_network_id is the ID that we want to get. Core_network_region is one of the key design choices that we made for this MCP. We wanted to be able to switch between regions and accounts as easily as possible, so all of the tools have this region capability within them. The LLM can decide that it will call, for example, us-west-2, eu-north-1, or any other region that is available.

[![Thumbnail 940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/940.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=940)

The third argument is the next token, which controls pagination for core network attachments. There are basically two design choices we could take. Either we do the pagination internally within the tool and return everything immediately, or we let the LLM control whether it wants to get more information. For this particular tool, we have taken the approach that the LLM can decide when it wants to have more attachments given to it. 

[![Thumbnail 970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/970.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=970)

Lastly, there is the profile name. As mentioned, we want to control or keep the LLM control to go to different accounts so it can use the AWS CLI name profiles to switch accounts. Also important is the description field. We are using Pydantic, and the description field is one of the details that is sent to the LLM when it starts to do the reasoning about which tools to use and how to use those tools. So the description set for the arguments is an important detail. 

[![Thumbnail 1020](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1020.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1020)

Moving on, we have the docstring for the tool. This is again one of the information sets that will be sent to the LLM so that it knows how to use it. We will first give some high-level information that you can use this tool to get the Cloud WAN core network configuration and state. We have also given information about when to use this tool, for example, when the LLM is asked to do troubleshooting or understand network topology. This is part of what we learned when we were testing out these tools. Creating good descriptions really makes a difference in how well the LLM can execute, for example, in complex scenarios when it is doing path tracing and needs to use multiple different tools. 

[![Thumbnail 1050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1050.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1050)

There is also information on workflows. Depending on the tool, there might be a lot more information on the workflows and what the most potential next tools would be after calling this tool to give it good enough information. For example, here it is stating that get Cloud WAN routes or detect Cloud WAN inspection might be good approaches after this one. 

[![Thumbnail 1060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1060.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1060)

Finally, we are specifying what information will be returned, so it is returning a dictionary containing the core network information, live policy, and attachments. 

[![Thumbnail 1070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1070.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1070)

[![Thumbnail 1090](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1090.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1090)

Then we have the actual code itself, which is basic Python code. We are using the Boto3 library for this to get access to the AWS APIs.  We have a helper method to get an AWS client, which we will be using to switch between regions and get the actual network manager client. If there is a next token specified, we will just get the list of attachments and return immediately those attachment details and the potential next token. 

[![Thumbnail 1100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1100.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1100)

However, the core network policy and attachments is also one design choice that we made with this tool. We do not want to create individual tools for individual API calls. There are other AWS MCP servers that you can use for that, so we try to combine and make the abstraction level higher.  For each of the tools, it actually does multiple API calls, gets more information immediately, and keeps that back to the LLM. This makes troubleshooting analysis faster because there are fewer tool calls and also makes it more efficient from a processing perspective because we do not need to send the information back and forth to the LLM all the time.

[![Thumbnail 1150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1150.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1150)

[![Thumbnail 1200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1200.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1200)

For all of these tools, we are capturing all of the exceptions. We are not handling those within the code, but we are raising all of the errors back to the LLM using tool error from the FastMCP framework.  For each error, we are specifying some details. For example, if there was an error getting the AWS core network details, we will also give it some information about what to do next, like validate parameter information. This might depend on the actual tool what information we are giving back. We are also sending the full error back to the LLM so that it can reason about what to do next, for example, if there was an error with signing into AWS or something else. 

Finally, if everything was good, we will return back the core network policy, live policy, and attachments.

[![Thumbnail 1210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1210.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1210)

[![Thumbnail 1230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1230.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1230)

[![Thumbnail 1240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1240.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1240)

### Live Demonstration: Querying Core Networks and Error Handling

Let's do one demonstration.  So we have our agent, and as we saw from the tool, we need to give it the information of the core network ID. We don't know it at the moment, so what we need to do first is, for example, list the current networks that we have. So we can ask  to list the core networks in US West 2, what we might have available. It is using a tool called list_core_networks. And it found out that there is one  core network in the US West 2 with just basic information, so we know the core network ID and state, but nothing else at the moment.

[![Thumbnail 1260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1260.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1260)

[![Thumbnail 1290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1290.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1290)

[![Thumbnail 1300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1300.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1300)

[![Thumbnail 1310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1310.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1310)

We can also ask to get more details. And now hopefully it will use the get_cwan tool.  After this call, we are now actually getting more details of the core network. So it's creating the basic information at the start, which is the name, ID, and its date. It's also starting to pass through the core network policy. So for example, pulling information about what locations we have, what are the ASN numbers, and segment information.  Which segments we have and which regions. And also more details, for example, from network function groups.  And to control and the DPC attachments or all of the attachments that we have specified. And if we would want, we could then go  in and ask more questions, for example, more detailed questions on the attachments, what each of the attachments are, and so forth.

[![Thumbnail 1350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1350.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1350)

But what I want to show here also is the error handling. So what if we ask something that is not there? For example, if you ask to get one core network but we know that is not valid, get detail. OK, that shouldn't be there. It is again calling the tool. And now we get the error back  that the core network ID is invalid and the core network must be following a specific pattern. And this is the reason why we didn't want to handle all of the errors in the code but actually keep those back to the LLM so now the LLM can give us more information that yes, the ID was wrong and for example, do we want to use the valid core network that it already knew or something else, for example, list more networks.

[![Thumbnail 1390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1390.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1390)

### Design Philosophy: Agent Files and the AWS Networking MCP Server

So we're going to move on to MCP and agent files.  But before we move into that, just one thing that I really wanted to emphasize. A design decision was taken really early on. Jose has gone through a couple of the tools that were used, and live demos have been good so far. But this really comes into scripting versus using an MCP. The idea was to use the actual agent and the LLM for the decision making, not turn an MCP into this giant script where all the logic is built within the script. So the tools and any tool training that's done will pass the information back to the agent. The agent will then use the LLM to make decisions as to what to do next. And I think that's something that is a really important paradigm to remember. Otherwise you do end up building out this huge script basically that just happens to be called MCP, and the differences are stark in the results.

Now for the keen-eyed of you, you may have noticed that when Jose went into Kiro, actually there was a small line on there saying AWS network agent. Why are we using an agent as well as an MCP? So what we found through a lot of trial and error, and also trying to build some of the additional logic into the MCP that makes it become huge and quite complex is that using an agent file is quite complex.

It doesn't actually alter the capabilities or functionality of the MCP server, but it does give you several very useful things, not just for this MCP server, but literally for any agent. It will give you a stable persona. In this example with AWS Network MCP, we gave the persona of a network engineer, so the typical kind of rules that a network engineer should follow. We gave a tool usage policy, specifying when to use which tools, and provided more guided prompts to deliver specific outcomes that we wanted.

What we really found from this is that the agent itself has a context-first approach, so it looks at the context before it starts making calls. It orchestrates those workflows and will provide some sort of overrides and specialization in terms of knowledge and prompting. The same queries or prompts that were given to the MCP server would have worked. It's just that by using an agent, we get back exactly what we want in the format we want it. So it gives us a lot more control over how the MCP works and the data that we get back.

[![Thumbnail 1620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1620.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1620)

[![Thumbnail 1680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1680.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1680)

From here we're going to go on to some videos that will do some demonstrations.  The MCP that we're talking about today started life as Cloud WAN MCP because it was very geared towards just the AWS Cloud WAN. But what we found is that if we wanted to do things like trace route, for example, it goes through VPCs, Cloud WAN, Network Firewall, Transit Gateway. It touched on far more technologies than you would find just in Cloud WAN.  So we renamed it as AWS Networking MCP.

Your question, just to paraphrase so everyone can hear it, was whether the core network tool is a specialized tool. Yes, so what you'll find within the MCP server itself is a number of tools, and those tools are written specifically for that MCP server. Get Core Network is a tool specific to the AWS Networking MCP server. The AWS Networking MCP server was released yesterday, so by all means you can go and have a look at it. There will be a link in GitHub AWS Labs, and you can actually walk through and see all of the tools included, plus all the source code. Ultimately this is open source. There's nothing proprietary about this.

The agent is also open source that you have wrapped around the MCP server. The agent that we're actually using here is Kiro for obvious reasons. But we've also tested it with Claude Code, with VS Code, with the usual suspects. The most commonly used agents we've tested it with to make sure it works. So it should work with any standard coding agent. What that coding agent uses in the background, you can choose sometimes. You're limited in choice, but other times you can choose the actual LLM itself that the agent is using.

[![Thumbnail 1830](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1830.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1830)

[![Thumbnail 1840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1840.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1840)

[![Thumbnail 1850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1850.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1850)

### Building and Using MCP Tools: From IP Address Lookup to Path Tracing

For this, we're going to do a demo. Let me quickly work out where we are here. Okay, let's do it.  So what we're going to do here is go through one of the things. If you're using a cloud WAN or any other network service, IP addresses are pretty much common to everything.  Where's my IP? Someone gives you an IP address, where is it? So what we're going to do is live code a find my IP MCP server. 

[![Thumbnail 1860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1860.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1860)

[![Thumbnail 1870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1870.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1870)

[![Thumbnail 1880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1880.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1880)

[![Thumbnail 1890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1890.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1890)

Just like when I started originally doing this, not being from a developer background, I did use Kiro to help me create the initial Python as a proof of concept to make sure I can get what I need.   You can apply the same principle here with putting in what you want that MCP to do. This is very specificâ€”it's finding an IP address. So we've asked Kiro to create an MCP server to find an IP address and given it some parameters around that.  Kiro will now go off and work its magic, and you'll see here what it's actually creating. 

[![Thumbnail 1900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1900.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1900)

[![Thumbnail 1910](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1910.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1910)

[![Thumbnail 1920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1920.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1920)

It will create the find IP address MCP server. Going back to your question earlier, it will create specific tools in the MCP server to find the IP address and there are some additional details that will be found as part of the MCP.  What it will then do is also provide you the JSON that you'll normally end up putting in, like mcp.json, for example, which means that once it's finished building it, we can add it to the MCP JSON and try it live.  I need to get the IP address with tool AWS IP search with a profile network. This shouldn't take too long. 

[![Thumbnail 1950](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/1950.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=1950)

[![Thumbnail 2000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2000.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2000)

Because they didn't provide a region, what the MCP will actually do is look at all of the regions your account is opted into and then use a parallel async function to search all the regions and then stop all of those threads or functions once it finds it. Otherwise, it's going to keep searching all of them.  You can see from here it's found the IP, the region, the ENI that the IP address is associated with, the subnet, the instance that's associated with the ENI, and it's saying that it's a private IP address.  I mean, that literally took three or four minutes to create. Personally, what I think is quite a helpful tool, but that gives you an example that you don't have to be a core Python developer that's built MCPs in the past. There's a really easy way to get started using an agentic coding assistant.

That pool looks like it was built to specifically achieve that goal of finding an IP address. Is that the approach that you would recommend versus like having MCP discover information and then trying to piece together the more generic approach, like buying all your different accounts and things like that? Yes, just to make sure everyone got the question and please correct me if I paraphrase it incorrectly. The tool here that was built was very specific to find an IP address and then provide some information around the IP address. When you're building a larger MCP server.

is that the approach that we would normally take, or would we look at providing building tools that are far more generic? I'll give you my view on this, and then hopefully we've got a similar view, but I'll also pass it over to Jose to give his view on this.

So for MCP servers, if you take a look at the source for example of the AWS networking MCP server, you'll find that there's a lot of tools in there. What we've actually done is there are kind of two ways to do this. There's using a monolithic server approach, which has got everything in it. But that then starts to become really big, really quickly. Or you can create logical groups of tools in the file system and dynamically load and register those, which is what we ended up doing.

So the tools that we've built are to achieve a specific purpose. So find IP address, find all of your core networks in your account, find your global networks, find AWS network firewall and policies. And then by giving the information back to the agent, and of course we've used an agent file to give it some further direction, what we should then do is say to the agent, look, here's all the information that we've got, how should we proceed? And then it will choose the tool training to put in place for specific information.

To almost analyze the hop by hop, if you want to do traceroute for example, or if you've got a much more complex question to ask it, it's how to break that down into subtasks and choose the tools that it should use to build that up to achieve the bigger, more complex picture. If I expand on that, we will see an example of path trace next, but exactly when we were creating this tool, we tried to avoid two specific tools and large tools like path trace. We could just write a script for that, but then it would be a script, so we tried to hit some balance where there is a higher level of abstraction, but still we could get enough information to achieve higher goals or more complex goals.

I think the last thing on this that goes back to something I said earlier is when you're using an MCP server, it's being used by an agent that's got access to it. Use that intelligence, use the intelligence and the capabilities of the language model, which is very good at taking tons of data in, pulling out the data it needs and then doing something with it. We're going to go through path trace in a minute or traceroute, and you'll see that it touches so many different technologies from AWS that if you were to try and build that into one big monolithic tool, you'd have to cater for every use case.

What we're doing is by calling multiple specific tools, getting the agent to make the decision about what to do with that and what to do next. Specifically with the find the IP address example and that tool, is that based on how you build it, is that why we're getting that output? And for example, if I wanted to include something like account ID, would I have to build it into the MCP? Have that context if I were to ask that as well?

So because the find IP address itself has to look through the accounts, look through the regions, if you were to ask it something that by doing the kind of lookups that it's got to do would have the information to hand, it will give you that information back. If it's something that hasn't got anything to do with any of the lookups that it's got, then it wouldn't. Yeah, and that's really why if you build smaller discrete tools and then use the intelligence of the agent and LLM to stitch those together, you can get a lot more flexibility from that.

So you could ask, say, find this IP address and show me the security groups associated with the incidents.

[![Thumbnail 2420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2420.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2420)

[![Thumbnail 2430](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2430.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2430)

[![Thumbnail 2460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2460.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2460)

[![Thumbnail 2470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2470.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2470)

The agent and the LLM would then say "I can find the IP. Now, what tools do I have available to me to find the security groups?" When we go through the videos here, one thing I'm a massive fan of , not just for these MCPs but generally when you're using an agent, is  to get the agent to give you a report in markdown but also provide Mermaid diagrams to make things visual. You'll see why it really does give you a lot of information. For this particular one, do you want to run the path trace first? Yes, so what we'll do is we have a recorded path trace because it takes a long time and we've cut out all the thinking parts. So if we go onto the PowerPoint , we get it from there . I just find the, oh you've got the clicker. I think this really brings it together. Here we go.

[![Thumbnail 2490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2490.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2490)

[![Thumbnail 2500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2500.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2500)

[![Thumbnail 2510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2510.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2510)

Right, so what we've done here is this is the  path trace, and what we're doing from here is we're literally just saying "Can you provide a  path trace between two IP addresses using the AWS Network MCP?" Now, this reiterates what we've said around small specific tools that provide specific output that can then be used to chain tools, and the intelligence is all done by the actual agent and LLM itself.  So what it's doing here is going through hop by hop, how you would do a traceroute normally. It goes through and finds your source destination, then runs through literally hop by hop what your infrastructure is composed of and records all of this information.

[![Thumbnail 2610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2610.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2610)

[![Thumbnail 2630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2630.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2630)

What I've done at the end of this is I've asked it afterwards "Please can you provide me a report in markdown with Mermaid diagrams to explain what that path trace looks like?" This is the path trace report. Now, whenever you're doing a report with  markdown, ask it to include Mermaid diagrams because it'll produce diagrams like this that actually show you a breakdown of the path trace, exactly what path it took, and it even puts a nice little emoji on there to show  an inspection of an EPC with a firewall. It'll literally walk through each component showing what's there, but then it'll go into more detail. It's hard to see from here, but it'll show you each of those hops that it takes and what that's composed of.

[![Thumbnail 2650](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2650.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2650)

[![Thumbnail 2660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2660.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2660)

[![Thumbnail 2670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2670.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2670)

[![Thumbnail 2680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2680.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2680)

[![Thumbnail 2690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2690.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2690)

[![Thumbnail 2700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2700.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2700)

From a network engineer perspective, as we know, the return path is equally as valid because if it's not symmetric ,  you're going to have a problem. Firewalls are not going to play nicely. So once it's done that, if we keep going down, it'll give you an overview of what the cloud architecture itself looks like and where the segments are. I got to use Network Function Groups.  If you keep going down, it then starts showing you your route tables. We can just gradually go through the rest of it if you just scroll down.  If there's anything really pertinent,  it will also show you your security control analysis, that's network ACLs for anyone who uses them,  firewall inspection VPCs, and whether the policy allows that connectivity.

[![Thumbnail 2710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2710.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2710)

[![Thumbnail 2720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2720.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2720)

[![Thumbnail 2730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2730.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2730)

[![Thumbnail 2740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2740.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2740)

[![Thumbnail 2780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2780.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2780)

 Any particular issues that are identified, and it will also show you your security groups. Then the nice thing is it'll give you a connectivity matrix.  Now this is nothing more than saying provide a path trace. Because as we kind of said before the questions,  that causes a lot of discrete tools, and each of those tools provides data. What it's now doing is taking all that data  and creating a markdown report for you, but it's using Mermaid diagrams as well to give you the visualization where that really helps. So I think on this one, what it also does is just provide you some CLI tools if you want to not trust what it says and kind of validate for yourself, you know, each of the parts, each of the hops itself. It'll provide you the AWS CLI tools. 

[![Thumbnail 2790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/2790.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=2790)

### Key Learnings, Network Function Groups, and Community Contributions

The next oneâ€”yeah, go for it. On the side, you know, when you went through this, bringing up this demo here, it said that there's a lot of trial and error.  Any key learnings of what you tried that you learned from and not to do when you're building this? Well, first of all, when I had hair, yes, lots. So I'll give you just a couple of the ones that I found that were really key, and then obviously there are more in there because he's got a much stronger development background than I have.

First of all, if you rely too much on a GenAI coding agent, it ultimately did provide a CloudWare and MCP server that gave me what I wanted, but it was really full of, for want of a better term, bloatware. There was a lot of things in there that weren't needed, it didn't clean up a few things properly, and it didn't give me a lot of control. The standard in the AWS Labs MCP servers, bar this one just because of the size of it, were very much putting everything in server.py so you'd have kind of one monolithic file with all the tools in.

We soon found that once you start touching on CloudWAN, you know, VPCs, firewalls, firewall policies, and so on, that soon becomes huge. And it also means that it's not that extensible. So by breaking that down into logical groups on the file system for CloudWAN tools, network firewall tools, it means that later on, if you wanted to add some tools in specifically for DPC endpoints or VPC Lattice, you know, whatever the case may be, you've got dedicated tools within a directory rather than forever expanding this massive server.py. So I think that was a key learning.

The other one was test with real infrastructure often. What I found is when I used mock infrastructure or mock data to test with, often it would be left in there and then you'd say, is this particular tool working properly? Yeah, it's great, look, it works perfectly. And when you look closely, it's just using mock data. So I try to avoid using mock data when I don't need to. With one of the benefits of doing this in the cloud, we can spin up a test environment, and if it's CloudWAN, please then spin it down afterwards. But you can test it against a known good architecture, just test often against something, making sure you get the responses you want every time. Yeah, I think that's one key learning.

Also was the error handling. So as LLM tries to be as helpful as possible without good error handling and good information giving back that if something failed, that what it needs to do next and for example validate. So we have a lot of information in the tools and there is a specific tool, for example, just for path trace

that gives information on the methodology of what needs to be done and in which order. Without that guidance, it tries to be helpful, but if something fails or it doesn't have access to something, it can just go past and say that everything is good and working even though it didn't actually verify it. So error handling is one of the key details here to make sure that you get that right.

I can add just one last point on this. Even before we started using agent files, we used an MCP resource to provide a persona to the MCP server, literally saying you are a network engineer or network operations, and these are the guidelines. If partial data comes back or a tool returns incomplete data, don't assume everything is okay. Stop, use error handling, and report back. Otherwise, it can just carry on saying everything is good, and you end up with a core decision that leads you down a potentially very dark path when trying to troubleshoot.

The issues identified are actually included as output from the particular tool that found where there was a potential problem. That is further enhanced when you use things like a persona or an agent file to give it very strict direction. Generally, if the tool returns data where it thinks there's a problem, it will get there automatically, so you don't have to go overboard trying to think of every use case or corner case.

We have a couple more questions, but due to time, I think we need to finalize this one. If you have more questions, we will be around here after the presentation. What I would encourage is that we are going to be around. We love talking about this stuff, so if you want to sit down and have a coffee and chat now or anytime during the week, just give us a shout. Both of us would love to sit down and talk with you and connect offline.

[![Thumbnail 3190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/3190.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=3190)

[![Thumbnail 3210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/3210.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=3210)

[![Thumbnail 3220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/3220.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=3220)

One of the tools that I found was very useful because trying to do this manually is hard. I tried to explain this to a customer once, and I wrote some Python to try and do it, and it was very difficult.  The prompt that was given to the MCP server was please explain the core network policies, always plural in case there's more than one. Explain the network function group configuration if it exists,  and please include Mermaid diagrams where that is viable. 

[![Thumbnail 3240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/3240.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=3240)

[![Thumbnail 3250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/3250.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=3250)

[![Thumbnail 3260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/3260.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=3260)

As you can see from here, it breaks down the policy and shows you all of your segments, the segments that are isolated, and the segments that have direct connectivity, which you see here because they have route sharing configured.  It shows you not just which segments have connectivity, but you have arrows on there to show you the direction as well.  It builds out a connectivity matrix, and then the really handy thing is if you go down a bit further, it explains to you, or if you go up a little bit,  it explains to you why certain routes are blocked. So as well as giving you the diagrams and the explanations, it also tells you why things work or why things don't work.

[![Thumbnail 3280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/3280.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=3280)

[![Thumbnail 3290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/3290.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=3290)

[![Thumbnail 3300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/3300.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=3300)

Now the hardest part is the next section,  which is the network function group analysis. It takes the network function group configuration in a policy  and builds out Mermaid diagrams to show you each of the network function groups and their capabilities. As we go down,  you see the attachments and the patterns that each of the attachments have.

[![Thumbnail 3310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/3310.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=3310)

[![Thumbnail 3320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/3320.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=3320)

You'll see the send to and send via patterns,  and if you continue further down, you'll start seeing that for each of the network function groups, you get a visual explanation of how it works.  So if you're troubleshooting something and you're not quite sure if a network function group is doing something specific, you can actually look at the document which will give you a written explanation of how it's configured, but also provide Mermaid diagrams to show you how things are configured, where things are blocked, where connectivity is blocked by design, and where there's isolation.

[![Thumbnail 3380](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/3380.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=3380)

[![Thumbnail 3400](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/3400.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=3400)

Getting that information just from a JSON document that is returned from Cloud One is very difficult to do. If you go down to the last section, it'll show you the configuration of the network function group and give you some of the information in JSON as well. But using  a question asking it to provide the output in a Markdown document with Mermaid diagrams will save you so much time and is incredibly helpful for learning. 

[![Thumbnail 3470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/64095dfd7837775a/3470.jpg)](https://www.youtube.com/watch?v=7e4UeHMMOXo&t=3470)

So as I said before, just to recap quickly, and we have a few minutes for questions, this started off as an AWS Cloud RAN MCP server, but after we realized that it touched so many network services and the fact that we want to make this extensible to any network services, we changed the name to AWS Network MCP server. That's been released and it's available today for folks to use. It's open source, so if you're doing something on path trace or you're looking at something about getting the policy and you think you have a really good idea, do a pull request and add to it. If you're doing something on a service that's not there already, such as one of the services being announced this week or VPC Lattice or one of the services you heavily use, do a pull request. It would be really good to get community involvement.  So that's what we covered today.


----

; This article is entirely auto-generated using Amazon Bedrock.
