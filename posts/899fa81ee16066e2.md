---
title: 'AWS re:Invent 2025 - From Documents to Decisions: Unleashing AI-Powered Business Automation (SMB204)'
published: true
description: 'In this video, David Mefford from AWS and Priya Iragavarapu, VP of Data Science and AI at AArete, discuss how AArete solved the challenge of extracting data from healthcare provider and vendor contracts using their generative AI solution, DOCZY.AI. AArete evolved from manual processing (100 documents per week) through rules-based engines with AWS Textract (50-60% accuracy) to a generative AI approach achieving 99% accuracy and processing 500,000 documents weekly. Built entirely on AWS using Bedrock with Claude models, the solution processed 2.5 million documents and 442 billion tokens in 22 months, delivering $330 million in client savings through overpayment identification and reduced manual effort. The patent-pending platform is launching as a SaaS solution for healthcare payers.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/0.jpg'
series: ''
canonical_url: null
id: 3088413
date: '2025-12-06T08:10:09Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project enhances multilingual accessibility and discoverability while preserving the original content. Detailed transcriptions and keyframes capture the nuances and technical insights that convey the full value of each session.

**Note**: A comprehensive list of re:Invent 2025 transcribed articles is available in this [Spreadsheet](https://docs.google.com/spreadsheets/d/13fihyGeDoSuheATs_lSmcluvnX3tnffdsh16NX0M2iA/edit?usp=sharing)!

# Overview


ðŸ“– **AWS re:Invent 2025 - From Documents to Decisions: Unleashing AI-Powered Business Automation (SMB204)**

> In this video, David Mefford from AWS and Priya Iragavarapu, VP of Data Science and AI at AArete, discuss how AArete solved the challenge of extracting data from healthcare provider and vendor contracts using their generative AI solution, DOCZY.AI. AArete evolved from manual processing (100 documents per week) through rules-based engines with AWS Textract (50-60% accuracy) to a generative AI approach achieving 99% accuracy and processing 500,000 documents weekly. Built entirely on AWS using Bedrock with Claude models, the solution processed 2.5 million documents and 442 billion tokens in 22 months, delivering $330 million in client savings through overpayment identification and reduced manual effort. The patent-pending platform is launching as a SaaS solution for healthcare payers.

{% youtube https://www.youtube.com/watch?v=kzglciudj1I %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/0.jpg)](https://www.youtube.com/watch?v=kzglciudj1I&t=0)

### AArete's Challenge: Unlocking Data Trapped in Healthcare and Financial Documents

 All right. Thank you for joining everyone. I'm David Mefford, AWS Commercial Sales Leader, based out of Chicago. I have the luxury of building teams to help our customers build solutions, and I'm excited to highlight one of those today with Priya here. Today's session is Documents to Decisions. AArete lives in the healthcare and financial services space and serves as a consulting firm, helping customers extract data from documents and make decisions through their consulting firm or through their consultants. They face a unique challenge in getting that data out of the documents, and that's what we're here to discuss today.

Without further ado, I want to introduce the leader of the program, Priya. Thanks for coming to re:Invent. Welcome to your first re:Invent, and we're looking forward to hearing more about AArete and your problem. Absolutely, Dave, thank you so much for having us. This is fantastic. Are you all having fun here? Absolutely, me too. I feel like I'm a kid in a candy store. Exciting things happening everywhere.

[![Thumbnail 80](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/80.jpg)](https://www.youtube.com/watch?v=kzglciudj1I&t=80)

So myself, Priya Iragavarapu, Vice President of Data Science and AI at AArete. AArete is a global management and technology consulting company headquartered in Chicago. We help healthcare payers,  the health insurance companies primarily. We process their claims. We help them understand how to improve their medical and administrative cost reduction. And then also help out with member engagement, improve member retention, and also help them through care coordination and care management. We also have a financial services practice, and I lead the AI practice that serves both the industries. So really excited to be here and share our success story.

[![Thumbnail 140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/140.jpg)](https://www.youtube.com/watch?v=kzglciudj1I&t=140)

Our success story is essentially we found a business problem, a challenge, and then we applied generative AI to solve that problem at scale, and that's really the story that we want to share here today. Awesome, so the challenge that we  have solved for is data is locked up in documents. We have processed a lot of provider contracts, which are contracts between health plans and also the providers, which are the hospitals and physicians. So there's a contract that's written that details all the payment terms, the contractual terms. And also we have seen member or vendor contracts that are processed for organizations through the vendors with various SLAs, KPIs, and other metrics. Data that is in those contract documents is locked.

[![Thumbnail 180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/180.jpg)](https://www.youtube.com/watch?v=kzglciudj1I&t=180)

And in order to get it out,  the current options essentially fall short. You need a lot of institutional knowledge. You have to throw a lot of people at it. Anytime you want information that is needed to be extracted from documents, you need all of those kinds of additional resources. It's not scalable, right? You have more documents, you need more people to do the work. And then also the contract lifecycle management solutions and products that are out there, they're not doing a much effective job because they only cater to the configurations for a few fields. But then a lot more other fields, there's no process now for contract lifecycle management tools to incorporate.

[![Thumbnail 250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/250.jpg)](https://www.youtube.com/watch?v=kzglciudj1I&t=250)

So with that, what happens is really a lot of friction in downstream use cases. If you want to use that data in documents for analytics, aggregated metrics, KPIs, insights, you're out of luck. So that's the challenge that we have solved for using DOCZY.AI. Our DOCZY.AI is a metadata extraction and interpretation  tool that is built on generative AI. So simply put, what it does is it looks at the document, understands it like a human would, extracts the information from it into a structured repository that is then usable for downstream needs.

So the primary perspective or the primary uplift is in terms of removing that subjectivity. You need a lot of people to do all the work, but different people with different experiences would do it differently, right? But by using this technology, we've been able to eliminate that variance and subjectivity within the humans, and every document is processed the same way across the board by a large language model. That's the primary benefit. And the scale, of course.

But the secondary benefit is that now you have extracted that data, and then you can use it. It's aggregable, queryable, searchable, and you can use it for downstream needs. That's the secondary benefit from it.

### The Evolution from Manual Processing to DOCZY.AI: A Journey to 99% Accuracy and $330 Million in Savings

Yeah, and I know, Priya, we're talking about the generative AI portion of it now, but like any good story, there's a start, middle, and end, and you all have been on an evolution of trying to figure out how do we get this data out of the documents. So talk to us a little bit about the journey you all went on at AArÃªte to get to this point.

[![Thumbnail 350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/350.jpg)](https://www.youtube.com/watch?v=kzglciudj1I&t=350)

Definitely, Dave. So that's a perfect segue because our journey did not happen overnight, right? We wanted to definitely start off with prior to 2020,  we were doing this manually. We had, you know, 17 years of ontology experience doing this manually, and obviously our consultants were not too happy with it because it's mundane work. They wanted to be able to do something more effective, something that is more strategic with the clients. But then the scale of that was we were only processing 100 documents per week per person using that manual approach.

And then in 2020, we decided, you know what, we need an accelerator for this because it's not really ideal to just put human resources on this problem, right? So we used AWS Textract as an OCR tool. By the way, that's the best OCR tool out there if you're wondering. We used that to convert PDFs to text, and then using that text, we wrote a rules-based engine on top of it. We basically said go to this page, go to this line, grab these characters, and for this field, put it into this JSON structure. So we created that rules-based engine, which worked for quite a good time, but then we also had a challenge with it. You know, the challenge was not all documents are created equal. If it followed a certain template, the results would be consistent. If the documents had varied levels of information at varied locations, we were out of luck, and then we had to again go back to human resources for solving that problem. And so it was giving us essentially, you know, 50 to 60% accurate results.

[![Thumbnail 450](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/450.jpg)](https://www.youtube.com/watch?v=kzglciudj1I&t=450)

 So with the advent of generative AI in 2024, we did rapid prototyping, and then we said this is the perfect candidate for using generative AI for solving this problem. And then we actually got very positive results, and our impact at that point really was very significant.

Yeah, I think it's great to see the sort of construct and where you were going and the idea of getting the work off the consultant's plate. It was really low value to put them back in front of your customers. This is great. I think the numbers start to speak for themselves in terms of what you were able to deliver. So can you walk us through the numbers and what you saw as a business?

[![Thumbnail 500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/500.jpg)](https://www.youtube.com/watch?v=kzglciudj1I&t=500)

Absolutely. I think, as I mentioned, right, we were processing 100  documents per person per week, and we went up to actually even 500,000 documents per week. This is actually a lowball number, but the scale that we were able to process using our generative DOCZY.AI approach was tremendous, and this is something that we could not have otherwise done if not for the technology, obviously along with the ontology and the domain expertise that we incorporated into it.

[![Thumbnail 540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/540.jpg)](https://www.youtube.com/watch?v=kzglciudj1I&t=540)

[![Thumbnail 560](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/560.jpg)](https://www.youtube.com/watch?v=kzglciudj1I&t=560)

[![Thumbnail 570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/570.jpg)](https://www.youtube.com/watch?v=kzglciudj1I&t=570)

But then who would want a solution or a product that is not accurate, right?  It doesn't matter if you're able to do it at that scale. You need to be accurate, and we were able to get it at 99% accuracy level, which again a lot of our clients and our team members were extremely ecstatic with that. And also this created  a reduction in the manual effort that was going into it from our past experience. So we got a 97% reduction in the manual effort.  All in all, this enabled a lot of savings for our clients, you know, we were able to get $330 million of savings for our clients as a combination of direct and indirect savings.

So the direct savings for our health plans was we got the reimbursement information from the provider contracts out, and then we compared it to the claims and then identified overpayments. And then that's a direct recoupable opportunity for the health plans, and that's the direct savings that they were able to find.

From an indirect savings perspective, it's obviously all of the human resources that they have avoided in order to be able to do that kind of work and the scale at which that was done. So if DOCZY.AI wasn't that accelerator that was used, then they would have to use a lot of manual team members for this. That's really the savings that we have seen.

### Building a Scalable Solution: AWS Architecture, 442 Billion Tokens, and the Future of Business Process Automation

Yeah, I appreciate how you shaped up the business problem and now you're seeing clear returns. Now the business is excited about new generative AI products through your team and what you're capable of delivering. I know this is oftentimes a technical audience, so can you walk us through the solution and how it's architected?

[![Thumbnail 650](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/650.jpg)](https://www.youtube.com/watch?v=kzglciudj1I&t=650)

Absolutely. So by the end  of this year we're also launching a SaaS platform on DOCZY.AI. That's a great achievement for us. And number two, we also submitted for patent, so it's patent pending invention as well. We've put all of our eggs into the AWS basket, so to speak. So we've built our end-to-end solution on the AWS platform.

Our external users would log into a front-end interface that's built on Next.js, authenticated by AWS Cognito. When they upload the documents, that gets stored into an S3 bucket, and from there it invokes a Lambda function that calls Amazon Textract service to then use that to convert PDFs to text. Here what happens is if you have tables, if you have forms and checkboxes, if you have signatures, that identifies signatures, and if you have even handwritten notes, it identifies the handwritten notes and converts it into text. All of this happens within the Amazon Textract process, and then that data, that output, gets ready to be processed.

It runs on ECS as a containerized service using that compute. But then what happens is essentially we strategically chunk the document, the text, and include our prompting that is built on our 17 years of ontology and domain expertise. Together, we make API calls to AWS Bedrock, and then the output gets extracted. So we use Claude, Anthropic's Sonnet models 3.5, 3.7, and even 4.0. So we're very heavily invested into AWS Bedrock, and we were also one of the top consumers of AWS Bedrock until recently. From there, that output gets stored into Snowflake database, which then is again usable by the front-end users from our interface.

Yeah, and I think a couple of things to point out here for the audience. You touched on it a little bit, but you've used four to five models now, and you've been able to swap those out when you found better returns and cost performance. The other thing I'll say is you work in a heavily regulated industry. So you were able to put this in your own VPC in your own environment, and I know for particular clients, high trust was a big issue, and you're able to accomplish all of that in the solution. So again, by the numbers, I think it's interesting to look because everybody now knows what a token is and everyone is familiar with the size. But talk us through what the actual numbers look like and the outputs of how you're leveraging this architecture.

[![Thumbnail 830](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/830.jpg)](https://www.youtube.com/watch?v=kzglciudj1I&t=830)

Absolutely. The numbers really speak for themselves. We've been able to process about 2.5 million documents  using our tool, which amounts to really 442 billion tokens in just the last 22 months. So the scale at which we were able to do this would not have been possible without Dave and his team, Brett and Sanketh and Garish and everybody here. It was not something that we achieved in one go. We would constantly keep hitting the limits like the tokens per minute limit and also the requests per minute limit. We would keep hitting it, and then we would work with Dave and team to help increase those numbers. Finally, we've gotten them to a pretty high level so that we're able to process things at the scale and keep up the delivery that we had to do for our clients.

So absolutely, great success story. We wouldn't have been able to scale without the Bedrock platform that is built by AWS and also for this partnership. There's not like a vendor-customer kind of relationship, but we're together in it to help and deliver. So very thankful to Dave and team.

Well, we appreciate the trust that AArete has put into AWS. And I think what's interesting now is you have a solution that is in a consulting world living and breathing.

And I think when you start to look at maybe your health plan customers, when you look at them and how they can go out and consume DOCZY.AI, how do you see this product changing your business and how you serve those customers?

[![Thumbnail 930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/899fa81ee16066e2/930.jpg)](https://www.youtube.com/watch?v=kzglciudj1I&t=930)

Absolutely. So Dave, you know, our product, we don't want it to be a once and done kind of a thing. Anytime you process documents  through DOCZY.AI, there are contract documents, but then you go back and renegotiate and do amendments on top of it, right? So these documents are living and breathing and changing over time. And what we want to do with DOCZY.AI is make it an integral part of a business process automation so that it lives within the ecosystem of our healthcare payers and their environment.

That way each provider contract or vendor contract, when they are written, when they're signed, it's processed through DOCZY.AI, gets the metadata out of it, and then we proceed towards either claims adjudication, claim accuracy, or even invoice accuracy and pricing at that time. So we want this to be a living and breathing thing within our clients' ecosystem, and that's our goal and that's where we're heading towards through our SaaS platform and subsequent integrations through API that we're going to build within our payer ecosystem.

Yeah, and I think the other thing we've noticed is it's unlocked other opportunities for vendor management and other contract management opportunities that are maybe outside of the core health plan space, and you're able to move quickly now. And you've got the confidence in the business, and your customers now have the confidence in you, so thank you, Priya, for walking us through the solution, the challenge, and how you and Reed and AWS partnered together to go solve this problem. And again, enjoy your first re:Invent.

So we'll be at the end here down to the side. Priya will be signing autographs, and yeah, thank you all for coming. Thanks, Priya. Appreciate it. Thank you so much.


----

; This article is entirely auto-generated using Amazon Bedrock.
