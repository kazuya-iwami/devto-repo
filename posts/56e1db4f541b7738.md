---
title: 'AWS re:Invent 2025 - Breaking 25 years of tech debt using AWS Transform for .NET (MAM410)'
published: true
description: 'In this video, AWS product lead Nits Jeganathan and Idemia''s Srinivas Singaraju discuss AWS Transform for .NET, an agentic AI service that modernizes legacy .NET Framework applications to .NET 8/10 on Linux. Idemia successfully transformed their 25-year-old DMV certification system from .NET Framework 3.5 on Windows to containerized .NET 8 on Linux, achieving 4x faster transformation, 30% cost reduction, and enhanced security. New capabilities include .NET Standard support, Web Forms to Blazor transformation, Entity Framework migration, and editable transformation plans. AWS announces full stack modernization with SQL Server to Aurora PostgreSQL migration, enabling complete application stack transformation through the same agentic workflow, available free to customers.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/0.jpg'
series: ''
canonical_url: null
id: 3085330
date: '2025-12-05T05:01:57Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project enhances multilingual accessibility and discoverability while preserving the original content. Detailed transcriptions and keyframes capture the nuances and technical insights that convey the full value of each session.

**Note**: A comprehensive list of re:Invent 2025 transcribed articles is available in this [Spreadsheet](https://docs.google.com/spreadsheets/d/13fihyGeDoSuheATs_lSmcluvnX3tnffdsh16NX0M2iA/edit?usp=sharing)!

# Overview


ðŸ“– **AWS re:Invent 2025 - Breaking 25 years of tech debt using AWS Transform for .NET (MAM410)**

> In this video, AWS product lead Nits Jeganathan and Idemia's Srinivas Singaraju discuss AWS Transform for .NET, an agentic AI service that modernizes legacy .NET Framework applications to .NET 8/10 on Linux. Idemia successfully transformed their 25-year-old DMV certification system from .NET Framework 3.5 on Windows to containerized .NET 8 on Linux, achieving 4x faster transformation, 30% cost reduction, and enhanced security. New capabilities include .NET Standard support, Web Forms to Blazor transformation, Entity Framework migration, and editable transformation plans. AWS announces full stack modernization with SQL Server to Aurora PostgreSQL migration, enabling complete application stack transformation through the same agentic workflow, available free to customers.

{% youtube https://www.youtube.com/watch?v=JF1KJkSpFeM %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/0.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=0)

### Introduction: Modernizing .NET Applications from Windows to Linux with AWS Transform

 Hello, everyone. Thank you for coming in today. I appreciate all of you being here. My name is Nits Jeganathan and I'm the product lead for AWS Transform. Joining me today is Srinivas Singaraju. Please introduce yourself, Srinivas.

Hello, everyone. I'm Srinivas Singaraju with Idemia, focusing on technology transformation at Idemia. Joining me also is Rahul Chugh, and he's an SA in AWS. Please introduce yourself, Rahul.

Hi everyone. I'm Rahul Chugh. I'm an AI Acceleration SA, so I essentially help partners accelerate migrations and modernization on AWS using AI and Gen AI technologies. Excellent. Thank you. Today we're going to be talking about how our customers at Idemia have used AWS Transform to break down the technical debt that they have built over 25 years. While we're walking through this journey, we'll also explain the new capabilities that we are introducing into AWS Transform for .NET.

[![Thumbnail 80](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/80.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=80)

 Just before we get into this, I want to get a show of hands from all of you. How many of you know about AWS Transform for .NET? This is our agentic AI service we launched. That's a few of you, and some of you are fairly new. So I'll set the context a little bit and then we can dive into some of the new capabilities that we have added.

[![Thumbnail 100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/100.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=100)

 The first thing that I want to talk about is why a customer would want to modernize their .NET applications from Windows to Linux. Many customers have applications written in .NET Framework that are 20 or more years old. These legacy applications can only run on Windows, and that prevents customers from taking advantage of the new technologies and flexibility available to them by moving to Linux. If you move to Linux, you can run it on different instances whether it is x86 or even Graviton instances. You can run them as containers and take advantage of the scalability, or you can run them as Lambdas. Running it only on Windows prevents you from doing that.

There are other significant advantages as well. One is definitely the operating cost reduction because the licensing costs for Windows licenses are no longer applicable. Customers are able to save up to 40 percent on some applications. By moving to the latest versions of .NET, that number increases to 1.5 to 2x, which comes from Microsoft because of the complete performance upgrades across the entire stack, including the SDKs and libraries. By moving from .NET Framework to .NET 8 or .NET 10, you can expect to see up to 2x performance improvement.

The scalability point I mentioned is also significant. Once you can run it on Linux and as a container, you have a world of options for how you want to scale and how you want to build new capabilities. This is one of the reasons we have seen up to 70 percent of our customers who are running Windows on AWS today increasingly adopting Linux for their Windows ecosystem of applications.

[![Thumbnail 230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/230.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=230)

### Challenges of Legacy Application Transformation and AWS Transform's Agentic AI Solution

 That sounds great, but what is preventing customers from actually transforming their applications? It is not exactly straightforward. For example, to port your legacy applications, you want to first analyze the code and identify incompatibilities between the previous version and the current versions. The longer the version gap, for example from Framework 3.5 to .NET 8, many of those libraries are stale and you need to find different libraries and different mechanisms for doing things. Then you have to port the code and finally validate and deploy. Even though this shows as a single streamlined workflow, it is never that straightforward. Each one of these is a loop. Developers make a change and then suddenly there are 200 build errors, and then you have to go back and fix it. Then the libraries are wrong. It is a very cumbersome and undifferentiated heavy lifting for our customers.

Customers would rather spend this time focusing on the core competencies of building new capabilities rather than trying to maintain old code which they may not fully understand because the folks who wrote this code are no longer there or have moved on to something else. It requires collaboration across multiple organizations and progress is just very slow. This is exactly where AWS Transform for .NET comes in. For folks who are not familiar with it, this is the first agentic AI experience for transforming your .NET Framework applications to .NET 8, and we are now supporting .NET 10 at scale.

If you have hundreds or thousands of applications, we support those in an agentic workflow model where we shift the developer's role from executor to reviewer. This is a human-in-the-loop approach where developers review the code being transformed. We have built a .NET domain expert agent using open source projects and our learnings from many years. We use this as a mechanism for a unified web experience where customers can point to their repositories and we handle all the transformation. Developers can review it before deploying to their production environment.

By doing this, customers can offload tedious tasks and achieve acceleration of up to 4X. These are numbers we have seen from working with customers. We launched the service in preview at re:Invent last year and launched it in general availability on May 15, 2025. In the last six months, customers have been using it and transforming at scale, porting hundreds of applications and boosting application performance and scalability.

Let me touch upon what has changed from GA to now over these six months. We have learned from talking to customers and understanding what capabilities they want to build this product further. One of the first things we did was expand support to .NET 10. Microsoft released a new .NET version and customers now want to go to 10, not just 8, so we support that. More importantly, customers want to support .NET Standard because most customers with large legacy application portfolios want to do this incrementally. They do not want to break compatibility with their .NET Framework applications. If you do not want to move everything to .NET 8 at once and want to keep some applications in Standard, that allows you to do it in an incremental fashion using the strangler fig pattern.

That is why we added support for .NET Standard. If you think of your .NET Framework applications as a three-layered cake, at GA we were transforming the middle layer, the business logic. But customers could not get their UI ported. Most framework applications were written on Web Forms and did not have a straightforward way to transform them. What we have done now is enable the same agentic workflow for transforming Web Forms to Blazor. This allows customers to transform many of these legacy applications in one go. Additionally, we added Entity Framework and ADO.NET ORM support. If your code was written for database access in Framework with Entity Framework or ADO.NET, we can apply the corresponding changes to .NET 8. Without this, customers would have to manually make these changes, but with the agentic experience, customers can take advantage of this automation.

Beyond feature capabilities, we have been talking with many developers and they provided feedback that once transformation begins, they want to provide fine-grained inputs, customize it, and nudge it in a specific direction. To support that, we provided an editable transformation plan. The transformation plan is a high-level flow of all the steps the agent will take to modernize your application portfolio. Customers can make choices like going to a specific version instead of another. Those kinds of changes and recommendations will appear in the plan. Developers also want to understand how much time transformation will take rather than it being a black box. We now provide more transparency and feedback on exactly how long it is taking and which builder the agent is stuck on. Finally, customers want to use a coding assistant of their choice. If they are using Copilot, they want to continue the work that AWS Transform has done, take it to Copilot, and finish those changes.

Then try again to fix issues in an iterative format. We are enabling those kinds of functionalities today. There will be a transformation plan with the next steps as a markdown which you can directly feed to Quiro, complete the job, and then run the transformation again. Finally, one of the things that we had was that it's available in two experiences, whether you start in web or whether you use Visual Studio IDE, you can see the work that is happening across both of these together. So now there is no longer the separation of if I'm doing the work in IDE, I cannot see what's happening on the web experience and vice versa. It is now one unified workspace for your teams to collaborate together.

Those are the functionalities that we have added. But enough about the potentials. I want to have one of our customers who have used the service show you how they have used AWS Transform to solve their problems and that would act as guidance for some of the challenges that you yourself may face and how AWS Transform can help you there. I'll invite Srinivas to share those details here, Srinivas.

[![Thumbnail 720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/720.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=720)

### Idemia's Journey: Technical Debt and Modernization Challenges Across 45 DMVs

Thank you, Nits. So we at Idemia, we service 45+ DMVs across the country. Any one of you who has a driver's license in the United States, the chances are that we would have touched your life in some form or another. This particular solution that we took through the transformation process is one of the critical products that we offer as a service. It's for certifying as you enter the DMV you go through a knowledge test and then a skills test and then the whole process of getting your driver's license. As part of that, this product was built some time back.  The legacy state was a typical monolithic application that we have been deploying for a while, with a thick client WPF-based application and then .NET Framework 3.5 with a SQL Server database as the back end. Nothing fancy, but a critical application.

[![Thumbnail 760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/760.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=760)

As we started embarking on the journey of trying to scale it up across multiple customers and multiple types of users that we had to cater to, we started realizing that there were going to be some significant challenges.  These are some of the challenges, not just all encompassing, that we encountered and that we needed some answers for. As we started ramping up, we realized that the technical debt was piling up with outdated infrastructure architecture based on .NET Framework that was no longer scalable and limiting us from being able to containerize and move to the next level.

Additionally, we started encountering higher cost of ownership from a performance perspective and the legacy applications that were running on a Windows environment and could not be ported into a Linux setting. We also started seeing some security challenges that we needed to address, particularly in the space that we operate in. Compliance is a big thing that we need to be very careful about because we deal with PII on a continuous basis. We also need to make sure that not only we're compliant with the regulatory standards, but we also need to be ahead of all those nation state actors that we need to worry about.

[![Thumbnail 850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/850.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=850)

So we needed to think about what we need to do. As we started scaling up, we started noticing some customer satisfaction issues were starting to creep up. Customers started complaining that the performance is not at the level that we're looking for or we were hoping for. What can you guys do about that? When we started thinking about it, we realized we need to start transforming what we're doing right now.  So from a technical debt perspective, what are we looking at? The manual deployment process was taking longer than what we were hoping for. The incompatibility with lightweight Linux containers that we needed to address and also the auto scaling were issues. We were setting up the environments for the worst case scenario but not using it on a regular basis, so the cost of ownership was obviously going through the roof.

The restricted integration for the CI/CD pipelines that we wanted to bring to bear was another issue. The cloud native capabilities that the team was hoping to leverage, we were not able to get any of that in place because of the legacy architecture.

[![Thumbnail 910](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/910.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=910)

Additionally, we also started noticing 32-bit versus 64-bit inefficiencies that we needed to address, along with memory management and garbage collection issues.  Those of you who are familiar with .NET applications and who have used the older .NET frameworks would have definitely experienced these pain points on a continuous basis. If you ask me what kept me up at night, there were occasions where I had to jump on calls to figure out what was going on, and our team was not too happy about that.

The end of life of Windows 2012 Server also accelerated the process that we needed to transform our application. Additionally, the overprovisioning of EC2 instances and the amount of storage that we had to overprovision became a significant concern. My colleague here lived that nightmare with me, and we started thinking about what we could do. We realized that 99 percent of the time, the majority of our resources were actually sitting idle, and we needed to address that technical debt.

[![Thumbnail 1000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1000.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1000)

We also needed to handle higher capacity requirements during usage peaks, which were not uniform but showed ebbs and flows that we needed to deal with. As we started looking at these problems, we realized that we needed to tackle them sooner rather than later.  We encountered several security challenges, including limited TLS 1.2 versus TLS 1.3 support in .NET 3.5, obsolete code access security versus the modern .NET 8 framework security, weak authentication schemes, minimal protection for CSRF attacks, poor stack trace visibility in .NET 3.5 versus .NET 8, and insecure token storage practices that we had to deal with as part of our .NET 3.5 architecture.

[![Thumbnail 1050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1050.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1050)

 With all of that in mind, we set some goals for modernizing our application and the service we offer to our customers. We started talking to some partners, Cloud Hedge and Amazon, and realized that we needed to containerize as quickly as possible, moving to a lightweight Linux container model. We needed to improve our security posture, bring down the total cost of ownership, and more importantly, be able to go cross-platform, which was limited in .NET 3.5 that we were experiencing.

[![Thumbnail 1100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1100.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1100)

### Transformation Results: 4X Efficiency Gains and 30% Cost Reduction

How did we achieve that? We started talking to Cloud Hedge and Amazon and realized the ideal application state that we needed to reach.  We started becoming more cloud native, which was not the case previously. We needed to host it in a multi-availability zone model, which was not the case before. We containerized the application using ECR for managing those containers and EKS to store our containers. As part of the journey, before the availability of the SQL Server transformation platform, we started migrating some of that into Amazon Aurora PostgreSQL.

As we started doing that, we realized there had to be a better way. That is when we talked to Amazon about AWS Transform being the right platform for us to take us to the next level. Think of it this way: each area that we are talking about has a code base that is unique to each DMV that we need to deploy, and then we factor that in across 45 DMVs. That is not a simple task for either the development team or the SRE team on our side.

[![Thumbnail 1160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1160.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1160)

[![Thumbnail 1200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1200.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1200)

 With this architecture, what we started noticing was close to 4 times efficiency, as Nits had already pointed out in his presentation. The team started seeing that kind of efficiency as we started transforming to the target state.  The results that we achieved as part of that were significant.

The most important thing for me was to improve resiliency and uptime availability by using EKS containers across multiple availability zones. This has helped us achieve better uptime and improved performance bottlenecks. As we started implementing this approach, we realized we were running into some issues when moving to GovCloud. We successfully overcame those challenges and deployed to GovCloud, which was a huge step forward for us.

The application transformation happened at four times faster pace than previously estimated. The team initially gave me an estimate of close to six months per DMV, which meant we were looking at two to three years overall to transform the entire application. I'm sure everyone here knows that we don't have that luxury because technology keeps changing and we need to cater to our customers' needs on a continuous basis. With AWS Transform, we completed the application layer transformation in less than a quarter of that timeframe. This is huge for us because the longer we remain on the older platform, the more it increases costs and exposes us to security vulnerabilities we need to address continuously.

We achieved reduced total cost of ownership by realizing approximately thirty percent in cost reduction. Previously, we would have needed to provision extra resources, but now with the auto scaling properties that we can set efficiently, we're able to recognize that thirty percent savings in the dollars we're spending. Modern deployment practices have also improved significantly. We now have an efficient CI/CD pipeline that was lacking previously, and we've reduced deployment time by thirty-five percent. More importantly, security has been enhanced. I'm sure all of you have experienced some security challenges while building applications. With .NET 8, we can leverage newer security features, particularly by migrating our application from thirty-two-bit to sixty-four-bit architecture and proactively addressing all the CVEs we previously had to deal with using the .NET 8 framework. This is a huge win for us.

[![Thumbnail 1380](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1380.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1380)

 This is a reaction from our director of software engineering. He dealt with this challenging application for years, and this is verbatim what he said: AWS Transform helped us speed up the full transformation by four times and more efficiently host the software on Linux versus Windows servers. From a business standpoint, this means I can now take this application and move to a true software as a service model, which we could not do previously. In a nutshell, this is what we've experienced as an AWS Transform partner and cloud hedge partner. Raul is going to take us through how he helped us transform our application.

[![Thumbnail 1460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1460.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1460)

### How AWS Transform Works: Analysis, Transformation, and Validation Process

Let's see how that magic actually happens and how AWS Transform works. It's actually quite simple.  It goes through three steps: analysis, followed by transformation, and then validation. As part of the analysis phase, the .NET agent is essentially a deep domain expert with intelligence built on top of Amazon Bedrock models that we have trained. It enables code integration from GitHub, Bitbucket, GitLab, and several other sources wherever your code resides today. The way analysis works is it starts by identifying the .NET version of the project you have.

The .NET Transformation agent determines what different project types are present and analyzes the code and dependencies between different projects and repositories that you provide for analysis. Once the analysis completes, it generates a pre-transformation analysis report where you can review what will be transformed during the entire process and examine the complexity for different projects in your solution.

Based on your codebase, dependencies, and business objectives, the agent delivers a tailored transformation plan. This is where you enter the transformation phase. You can edit this transformation plan by adding your own instructions in plain English. Behind the scenes, an LLM understands what needs to be done and transforms the code for you.

The transformation can handle different project types including WCF projects, web API projects, console applications, and test projects. It allows you to configure repository-level settings and provide third-party package dependencies for the transformation to work and complete successfully. During the transformation process, the agent first transforms the code, attempts to build it, and if it doesn't build, it tries to fix it. This cycle continues repeatedly in the background until the project reaches a state where the AI cannot make further improvements at that moment.

Once transformation completes, the agent generates a transformation report showing what has been transformed and why. It also generates a file called NextSteps.md, a markdown file that indicates what has not been transformed and provides steps on how you can further transform it. Alternatively, you can run the entire transformation again based on your new knowledge. For example, if dependency injection failed in your implementation, you can add a custom step to your next transformation run to handle dependency injection in a specific way, allowing that part of the project to be transformed as well. You can repeat this process as many times as needed.

Once transformation completes, the agent generates a new branch containing all the transformed code that you can merge into your production branch. As part of the transformation completion, AWS Transform automatically runs your unit tests and tells you how much has succeeded, what has failed, and attempts to fix issues as part of your transformation plan itself. It also generates a Linux readiness report that you can review to determine if further code changes are needed.

The agent generates a natural language transformation summary, which is a detailed overview of all the changes made and all build issues identified for your review. You can then further optimize based on this information. Once the transformation completes, the agent also generates an email notification, which means you don't have to wait in front of your screen if the transformation takes several hours.

For example, the transformation process might tell you it will take 3 hours. You don't have to sit in front of your systemâ€”you can leave it once you get the email and work on it. The process is essentially headless, so the transformation happens behind the scenes. You don't have to keep your screen open or keep the project open. It happens for you, and you can load that transformation once you get the email notification.

[![Thumbnail 1840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1840.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1840)

[![Thumbnail 1870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1870.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1870)

[![Thumbnail 1880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1880.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1880)

### Live Demo: AWS Transform in Web Console and Visual Studio IDE

Let's quickly look at a demo. We have two experiences here. The first experience is  in the console. In the AWS Transform web console, when you start AWS Transform, you can create a job for transformation. To create a job, you can click on create job, but at the same time, you can chat with AWS Transform to create these jobs for you. Here, you can either chat with it  or you can click on the guided experience. Let's select Windows modernization because .NET is part of that, and then you select .NET transformation. 

[![Thumbnail 1920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1920.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1920)

Once you select what kind of job it is, you need to supply the code. You can either upload it through an S3 bucket or use AWS code connections. AWS code connection works by allowing you to go to the AWS console and configure your GitHub, GitLab, or Bitbucket. You supply the credentials there, and it integrates. In the web console, you provide details about that connector. Once that connector is  configured, AWS Transform is able to pull all the different repositories that are out there in your GitHub, GitLab, or whichever source code repository you're using.

[![Thumbnail 1940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1940.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1940)

[![Thumbnail 1970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1970.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1970)

All these repositories are pulled, and then you can select  the specific repositories that you want to modernize. For example, I want to modernize Bob's bookstore, and there's a dependent repository called API test. I would select both those repositories so that when transformation happens, it is able to find the correlations between repositories and transform the whole codebase better. 

[![Thumbnail 1980](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1980.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1980)

[![Thumbnail 1990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/1990.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=1990)

[![Thumbnail 2000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2000.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2000)

Once you have supplied these repositories, there is another kind of dependency: NuGet packages.  You can either supply those private NuGet packages through Azure Artifacts store or upload  these packages through the web console itself. This is one of the most requested features we had when we had our product in beta.  Many customers had these private NuGet packages and wanted to ensure that when they're transforming, those dependencies are resolved. Now we are able to do that.

[![Thumbnail 2020](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2020.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2020)

Once you have done that, you can review all the dependent repositories to ensure they are configured correctly. You can ensure all the dependent packages are configured correctly, and then you can approve and start that transformation.  When the transformation starts, it generates a lot of logs for you, and you can see all of that. It is quite verbose and shows you all the things that it is doing. You have the option to sit there or you can close it and come back and start working on the transformation again.

[![Thumbnail 2060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2060.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2060)

When I was doing this transformation,  you can see that one of the projects succeeded and one of the projects failed. The repositories which have succeeded show what all has succeeded, and whatever has failed, you can actually talk to the console itself in natural language, and it can tell you what things you can do. It also generates a next steps markdown file for you, which will have all that information. You can use that information and run the transformation again, fix a few things and run the transformation, or if AWS Transform is not able to transform after a certain point, you can use other code companions like Copilot to continue the work of transformation and complete it.

[![Thumbnail 2130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2130.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2130)

[![Thumbnail 2160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2160.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2160)

We have another experience which is in the IDE, Visual Studio IDE. As a .NET developer, this is the default IDE that all .NET developers use.  You can install AWS Toolkit with Visual Studio 2022 or Visual Studio 2026, and you'll get the option to transform there. I'm starting with a project that is on .NET Framework 4.8, and I've installed AWS Toolkit. Before I can start the transformation, I need  to configure AWS Toolkit for AWS Transform to work. I can go in and set it up the same way I did with the web console earlier using IAM Identity Center. You basically give it Identity Center credentials, it all gets set up, and then you can start the transformation.

[![Thumbnail 2190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2190.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2190)

[![Thumbnail 2200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2200.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2200)

To start the transformation, you can either port a solution or you can port a project.  You can right-click on your solution and then say start the transform. When you do that, it basically gives you two options here.  You can see the workspace here, and the second option that you see is what version you want to get to. Currently, we support .NET 8, we also support .NET 10, and we support .NET Standard as well as the target framework. Workspaces help when you have a team of developers who all eventually want to work on certain things in the transform process. Every transformation job that runs executes in a workspace, and that workspace can be shared with multiple people so multiple people can then work on that transformation.

[![Thumbnail 2250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2250.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2250)

[![Thumbnail 2260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2260.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2260)

[![Thumbnail 2300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2300.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2300)

When the transformation  starts, it begins with analysis and analyzes everything. At the end of analysis,  it generates an assessment report. You can look at this report on the complexity of the transformation. A lot of times it helps with estimation, like when you're estimating how much time it's going to take to eventually do the rest of the work that will be left. It's always helpful to look at all this initial assessment report that is available. Once your transformation  is complete, it also generates a report for you, which is the whole transformation report on what has changed in your transformation, why it has changed, and it also generates a next steps file for you.

[![Thumbnail 2350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2350.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2350)

This file contains all the things about if something has failed, what are the steps that you can take to fix them. Or it might have certain things where it might not be able to suggest to you what you need to change, but then you still need to take some action, so you can analyze them. Then you can change your transformation plan, run that transformation again, and you can keep doing that incrementally. Once  you have completed the whole transformation, at that time, all the files that are available, you can start merging. You can look at them one by one, compare them, and then pull them into your system. You can click on save changes for a particular file, and it will basically merge. Or you can select everything and do a single merge, which is the easier option, but then you can still review each and every file that is available and what is changing.

[![Thumbnail 2390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2390.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2390)

At the end of the transformation, you can see a newer framework, which is our goal.  With that, let me invite the PM for the product.

[![Thumbnail 2410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2410.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2410)

### Full Stack Modernization: New SQL Server to Aurora PostgreSQL Transformation Capability

 Thank you, Raul, and thank you as well. So what we have seen is that for the .NET side, for the .NET transformation, we are moving customers from .NET Framework to .NET 8 or .NET 10. If you look at it from a customer objective point of view, if you want to migrate your legacy applications, think of it as a three-layered cake. We are now supporting Web Forms to Blazor from the UI framework point of view. We are supporting the middle tier for .NET Framework to .NET 8, but that alone doesn't help them complete the whole story.

[![Thumbnail 2450](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2450.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2450)

So what we have launched today in GA is a full stack modernization agent. We are now able to handle .NET Framework to cross-platform, Web Forms to Blazor, but more importantly, we are now supporting if you have a SQL Server, we are using the same agentic experience to actually transform them into Aurora PostgreSQL. The main advantage of this is that customers who have all of these legacy applications can use the same mechanisms they are used to for .NET to start modernizing their SQL servers as well. 

After you have transformed your entire application stack, we are supporting deploying those into a sandbox environment so you can validate the whole thing. This is one of the big pieces of feedback that we have gotten from customers: they want to be able to try, take this application, test it to make sure it's working fine. Now that we have full stack capability of transformation, you can actually put it in an environment and test the functionality. This is going to help accelerate customers modernizing into the newer .NET 8 and .NET 10 world.

[![Thumbnail 2560](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2560.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2560)

One final piece is that this whole service is completely free for you to use. This whole experience in AWS Transform for the Windows ecosystem is free to use today. We are definitely looking forward to seeing more use cases that are coming and how we can assist you on this process. The same sequence that we had for .NET, we have exactly a similar flow here as well. We are going to do an analysis and then identify the database schemas, the tables, the views, and the indexes that you have, and then we are going to start migrating those schemas and all the database-related items. 

More importantly, we are also going to make corresponding changes in the application code as well. This means you do not actually have to go make changes to the application yourself. We identify the dependencies between your .NET applications and your SQL Server, and as we migrate to the PostgreSQL target, we will make the corresponding changes in your application code. You will have a fully transformed stack as part of this, and then we will help you validate and deploy in a new environment. This is the functionality we launched today, and I want to make sure that all of you are able to at least get a sneak peek at this.

[![Thumbnail 2630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2630.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2630)

[![Thumbnail 2640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2640.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2640)

There is a session that we are hosting tomorrow at 1:30, and we have that information on the next slide. We would love to have you there and understand a little bit more and see what you can build and take it from here.  The interactive demo which Rahul showed, you can actually get it from that QR code, and you can see more from our website.  The session that we are talking about tomorrow, the full stack SQL modernization, there is a builder session that you can get. There is also a breakout session where we would be talking about this as well.

[![Thumbnail 2660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/56e1db4f541b7738/2660.jpg)](https://www.youtube.com/watch?v=JF1KJkSpFeM&t=2660)

With that, I am very excited for you to test it and give your feedback and where you would love to take this product next. Thank you all for your time and your patience. I appreciate it. 


----

; This article is entirely auto-generated using Amazon Bedrock.
