---
title: 'AWS re:Invent 2025 - Building reliable operations, feat. Fannie Mae (COP340)'
published: true
description: 'In this video, AWS solution architects and Fannie Mae''s VP of Operations Engineering discuss building reliable operations in the cloud. Bobby Hallahan explains AWS''s operational philosophy including two-pizza teams, Correction of Errors (COE), and SLOs, demonstrating Systems Manager''s Runbook Builder for automated incident remediation. Moiz Halani shares how Fannie Mae achieved 71% reduction in critical incidents and 80% decrease in MTTR through integrated observability, automated regional failover patterns, and implementing COE processes. Steve Rice presents five reliability "cheat codes": three pillars of change (gradual rollout, automatic rollbacks, pre-deployment validation), trunk-based development, feature flags for operational control, Operational Readiness Reviews (ORR), and treating resiliency as the top feature. He demonstrates using AWS AppConfig with CloudWatch alarms to automatically adjust logging verbosity when suspicious activity is detected, showcasing how automation enables faster response than human intervention.'
tags: ''
cover_image: https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/0.jpg
series: ''
canonical_url:
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Building reliable operations, feat. Fannie Mae (COP340)**

> In this video, AWS solution architects and Fannie Mae's VP of Operations Engineering discuss building reliable operations in the cloud. Bobby Hallahan explains AWS's operational philosophy including two-pizza teams, Correction of Errors (COE), and SLOs, demonstrating Systems Manager's Runbook Builder for automated incident remediation. Moiz Halani shares how Fannie Mae achieved 71% reduction in critical incidents and 80% decrease in MTTR through integrated observability, automated regional failover patterns, and implementing COE processes. Steve Rice presents five reliability "cheat codes": three pillars of change (gradual rollout, automatic rollbacks, pre-deployment validation), trunk-based development, feature flags for operational control, Operational Readiness Reviews (ORR), and treating resiliency as the top feature. He demonstrates using AWS AppConfig with CloudWatch alarms to automatically adjust logging verbosity when suspicious activity is detected, showcasing how automation enables faster response than human intervention.

{% youtube https://www.youtube.com/watch?v=q9lfBSHEibo %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/0.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=0)

[![Thumbnail 20](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/20.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=20)

### Introduction: Building Reliable Operations at AWS

 Good. Alright, OK, cool. So welcome to COP 340 Building reliable operations featuring Fannie Mae. My name is Bobby Hallahan and I'm a solution architect here at AWS. So what are we gonna talk about today? What we're gonna focus on mostly is what is reliable operations, like what we mean by that and  at least why I think it's important and hopefully by the time you all leave the room today you'll think it's important too. But to cover that we're gonna talk a little bit about our AWS cloud operations philosophy. So we'll talk about how we do operations here at AWS.

From there we'll go into a little bit of tooling, right? So this is a 300 level session. So I'm assuming that you're gonna know most of this stuff, but we're still gonna cover a little bit of it and hit some advanced topics. We'll pepper in a demo there that I think you all enjoy, and then from there we'll cover Fannie Mae's story, right, because it's easy to talk the talk, right? It's easier said than done. You may have heard that before, right?

So if we come up and say hey you gotta do all these different types of mechanisms, you know, let's bring a customer who's actually done it. And they can, they're gonna tell you about some of the pitfalls they made, some of the value they got out of it, and some of the things they may have tweaked to make it work for their organization. So what we wanna be able to, what you want or what I want you to walk away with today is not just understanding how AWS does ops, but then how you could actually take that and apply it to your own organization as well.

And then just as we wrap up, and just so you also leave with something you can do today, right, because redoing your entire operations model, that can, you know, that's not a one day thing, right? That's not something I can go home and we're doing that next week, right? That's just, it's tough to do, it can take time. So we wanna make sure you're getting something immediately valuable and we're gonna cover 5 advanced reliability cheat codes that you can actually start doing probably tomorrow, next week, so you're getting immediate value from the session, OK, so without further ado.

[![Thumbnail 120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/120.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=120)

[![Thumbnail 140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/140.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=140)

### Why Operations Matter: The Hidden Impact on System Reliability

 This might be a leading question, but when we think of what is one of the most important features of an application, right, some say security and that is important, but since we're in an operations focused session, the name of the title of the session is, you know, focused on reliability. I would say reliability is an important feature of an application, if not one of the most important features of an application.  Also depending on what you do, right? If some applications are, they're zero fail missions, right, like they need to run.

[![Thumbnail 150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/150.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=150)

[![Thumbnail 170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/170.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=170)

So with that said, what do we think of when we think of reliability, right? Like think about that.  You're normally thinking like maybe like HA architectures, DR, multi-region cell-based architectures like that's what I think of when I think of reliability, right? It's all in, you know, it's in well architected too. That's what you normally think of, however.  What do we think of when we think of operations? Right, we think of, you know, operational excellence, operating well, however.

[![Thumbnail 190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/190.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=190)

[![Thumbnail 200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/200.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=200)

Normally, at least when I speak to customers and I would say probably at face value right operations almost seems disconnected from that reliability perspective right where it's normally hey we're thinking hardware and software and resilience.  However, if we take a look at the numbers here, why systems actually fail, if you take a look at it, it's really 42% of system  failures, and we're talking about degradation of service is caused by something that happened in operations.

[![Thumbnail 210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/210.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=210)

[![Thumbnail 230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/230.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=230)

So when we think of reliability, and my contention is  that instead of perceiving just all three of these, right, and what we're gonna talk about today, so just full disclaimer, we're not gonna get into cell-based architectures, we're not gonna necessarily talk about like multi-region type stuff. What we're gonna focus on is how to build reliable operations. And while these can be separate, what  we're specifically what we'll focus on is the operations piece. So that's what we're in for today.

[![Thumbnail 240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/240.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=240)

[![Thumbnail 260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/260.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=260)

### AWS Cloud Operations Philosophy: Good Intentions Don't Work, Mechanisms Do

So let's jump right in. And specifically let's talk about like how AWS does ops  right? So if anyone's seen like a culture of innovation talks where we talk about you know well actually we'll get right into it but some of this may seem familiar to you but if not, hopefully you'll learn some stuff. But I always like starting off with a quote, right, which is, good intentions don't work, mechanisms do, right? A lot of times I like to think it's like, hey,  I'm a nice person. I try to help people out, but if there's no mechanism in there to do it, if you get busy, nothing happens, or it's like, hey, you know, we want the application to run at, you know, to be up all the time, but just feeling about it, trying, you know, having a good intention doesn't actually force it.

[![Thumbnail 290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/290.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=290)

You need mechanisms to force things like innovation, force things like reliability. So let's cover a couple of mechanisms we have at AWS. So the first is our two pizza team, right, and the idea behind the two pizza team is, you know, your team size shouldn't be as big that you wouldn't be able to feed with two  pizzas for lunch. Now what does that get you, right? So generally speaking, right, you don't want very large teams but you don't want too small teams, and really what it gives you is, you know, a team that's owner operator mindset.

A team with an owner-operator mindset serves as the first contact for alarms and manages their own operational environments. They automate as much as possible, driving that decision-making and ownership down to a lower level. This approach ensures that stakes and ownership are baked into those teams. That's something we've embraced here at AWS, and I know that model may not work for everybody, but we feel that it's beneficial and has a lot of advantages.

[![Thumbnail 340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/340.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=340)

The next big mechanism we have is the COE, or Correction of Error,  which is essentially a blameless autopsy to learn from our mistakes. It focuses on who, what, and why, with data to back it up. We have action items to ensure that the exact specific cause of that error doesn't happen again. It's okay if a failure happened, but we need to make sure we have a mechanism put in place to prevent it from happening again.

[![Thumbnail 380](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/380.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=380)

The big key to having a successful COE is being transparent about what went wrong so we can learn from it. COEs need to be transparent, and if you are to implement this, I would say the single biggest thing you need to make sure of is  that a COE is not to blame people and not to punish people. They need to be a learning mechanism, because the second somebody thinks that this is a mechanism to show blame or somehow punish somebody for making a mistake, that requirement for transparency just goes out the window. If I think my job's on the line because something went wrong and I need to write a COE, people may not be as forthcoming with what the real problem was.

My advice is that you should look to adopt some sort of COE mechanism, and if you do that, the thing of most paramount importance is that it's not to blame and it's not to punish people. It's a learning exercise to make sure you can prevent specific errors from happening again.

[![Thumbnail 440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/440.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=440)

[![Thumbnail 460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/460.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=460)

### Key Operational Mechanisms: SLOs, Automation, and Proactive Incident Preparation

A couple of other mechanisms that we find important include SLOs, or Service Level Objectives. If you may ask what an SLO is,  these are measurable service quality targets derived from user perspective metrics that drive continuous improvement in IT service delivery experience and reliability. I know that's kind of a mouthful, so let's look at a specific example of what we mean by an SLO, and in this case we'll take a look at latency. 

We have a latency SLO for maybe a payment processing platform on an e-commerce site, and we would say we want our goal to have 99% of payments process within a certain time. That would be our P99. We would want a certain attainment of that latency, so attainment of a goal, and then we would monitor that using some sort of APM tool. You have attainment of the goal, as well as requests that fall outside of that, which would then factor into something like a burn rate. You can create burn rates on your SLOs knowing that you would be close to breaching something, meaning that you can then take action before you potentially even breach an SLO based on burn rates.

I would say the big takeaway here is probably looking at how you're instrumenting your workloads, ensuring that the telemetry that you're actually sending out or stitching together after the fact gives you something that provides a real, reliable understanding of the health of that application so you can then derive what the SLO is. If you don't have that, then that's maybe something you would want to start thinking about.

[![Thumbnail 530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/530.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=530)

Another neat one, and this is actually something we're going to demo  in a little bit, is leveraging automations to maintain safety while reducing MTTR, or Mean Time to Resolve. This gives us the ability to do some automatic incident remediation. Instead of an alarm firing and having somebody look at it and somebody getting paged, maybe we try some automatic remediation. Maybe we'll try to run some runbooks, and then if that doesn't work, we can start to involve a human. Even better, when we involve a human, we want to give them context. Maybe we'll do some enrichment on that data and then send it down so that alarm is actually actionable to an operator instead of getting paged at 2 a.m. with just some alarm like 400s. 400s for what? For what service? Where did it go? Where's the dashboard? Having all that information could be helpful, so we'll demo a little bit of that today.

[![Thumbnail 580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/580.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=580)

[![Thumbnail 590](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/590.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=590)

 And then, of course, proactively preparing for incidents.  These could be things like tabletop exercises, understanding what would happen if this broke or what would happen if something else failed, or even actually running game days. You could even get right into it and inject actual faults using something like fault injection. I would say, you know, maybe tabletop a couple things before you actually start actively injecting faults.

But the idea of being able to proactively prepare and understand the failure modes of your application is critical. More so from that operations perspective, knowing who gets paged, what's that escalation mechanism, where are those runbooks, what's the dashboard operators, where and how all that stitches together and happens. It's not magic, right? This is hard work and it's practice, and I would much rather say you would want to practice when nothing's wrong than at 2 a.m. or maybe in the middle of a very large event where potentially millions of dollars per minute are on the line, where you're looking at reputational or financial loss.

[![Thumbnail 650](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/650.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=650)

[![Thumbnail 660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/660.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=660)

### AWS Systems Manager: Agents, Automations, and the Runbook Builder

Now, those are a couple mechanisms,  but what I want to focus on now is a quick overview of just how we cover cloud operations. So when we think of the building blocks of cloud operations, we have CloudWatch, Systems Manager, Config, and CloudTrail.  What we're going to focus a lot on today is going to be a little bit of Config, a little bit of Systems Manager, well, a lot of Systems Manager actually because it actually lets us do a lot of really neat stuff. So let's jump in.

[![Thumbnail 700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/700.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=700)

[![Thumbnail 710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/710.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=710)

When we think about how do we put those building blocks together, we would have observe, right? So this is understanding what happened. You can use things like Config for your configuration items, understand compliance there. CloudTrail is a good indication of that as well as CloudWatch. And then be able to decide, right? So when things happen, how do we decide what's that decision logic look like, how do we route things like EventBridge or Step Functions or Systems Manager. And then actually acting would be  taking response and action to something, right? So for example, I would argue or I would say that Systems Manager is a really great way to do that. 

[![Thumbnail 720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/720.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=720)

[![Thumbnail 750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/750.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=750)

Now with that, let's talk a little bit about Systems Manager, right, because there's a lot to it. Systems Manager is a really powerful service. There's a lot of capabilities,  but what I'm going to do is I'm going to try to give you the very high level so you'll just understand Systems Manager essentially without having to know every single feature of it. What it has is essentially you have automations, right? So these are almost kind of like Step Functions, right? There's actions you can take in response to events. You tie them up with EventBridge, and they're step-driven approaches that you can do to execute APIs, run scripts, all this neat stuff outside of the context of an  instance.

[![Thumbnail 760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/760.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=760)

And then you have the agent, right? So this is the actual SSM agent that lives on the instance that allows for things like remote management, patch management, session management,  and then of course node management, right? So the node management could be if I need to do things across many instances, right, that's where I can use automation. But at its core, Systems Manager is agents and automations, right? Agents allow for run command. Run command helps perform and do a lot of things with SSM.

[![Thumbnail 780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/780.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=780)

[![Thumbnail 800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/800.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=800)

[![Thumbnail 820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/820.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=820)

Now, I'll speak a little bit about automations, right? So it lets  us execute critical tasks, operational tasks, or automate operational tasks, that is, streamline some things that are complex, and then gives you more visibility and control, and this is something that we'll be able to show here very quickly. So we launched an automation runbook builder just about last year, this time last year.  There's been quite a few improvements to it which we're going to show off today, but what the Runbook Builder lets you do is it's a low-code visual designer that empowers users. It gives you visualization, you can author effectively and securely, so it's really neat. So instead of just showing you more of that and telling you about  it, let's actually go check it out.

[![Thumbnail 840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/840.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=840)

### Live Demo: Building Automated Alarm Response with Systems Manager Runbook Builder

All right. And okay, so as we can see here we are in the SSM console. And we can see right here, okay, how do we get to the screen? It's right here on automations,  and I can see all the automations that I have been running. I can see some are waiting, some have failed and some are successful. So let's take that scenario right where I have an alarm that I'd like to process, right? So I want to add some sort of automation logic to my alarms. So let's go ahead and actually create a new runbook.

[![Thumbnail 860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/860.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=860)

[![Thumbnail 870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/870.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=870)

And from here, what we're going to get is,  we can see on the left-hand side we have flow control states, so branching, looping, sleeping, pauses, approval states.  We have things like scripting, like running a script within the automation itself. So instead of, let's say, hey, let's run a Lambda function, like trigger a Lambda function to run, I can actually do some scripting within the automation itself without necessarily having to invoke Lambda. And then of course resource management.

[![Thumbnail 890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/890.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=890)

[![Thumbnail 900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/900.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=900)

Now in addition to the flow states we have  AWS APIs. So essentially almost just about any API you can think of, right, you can use with automations. And I would say this is where it gets really  cool is that automations can be used to execute other automations.

[![Thumbnail 920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/920.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=920)

If there are reusable components that you've built in an automation, you can start nesting those together. Let's say I don't necessarily know where to start. What we can do is take a look at some of these samples that are built in, and what we're going to do here right now  is take a look at this Hello World example, and I'll walk us through it right now.

[![Thumbnail 930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/930.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=930)

[![Thumbnail 950](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/950.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=950)

So what we can see is it's a branch decision state that goes to an approval state,  some sort of delay, an execution loop. This is a loop state where we want something to try something several times. Well, that thing we're going to try is actually a script, and then we'll have it repeat and then end. So you know, this could serve us a little bit for that use  case, right? There's something that we have an event in response, we're going to try something a few times and end it.

[![Thumbnail 960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/960.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=960)

[![Thumbnail 970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/970.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=970)

[![Thumbnail 980](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/980.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=980)

[![Thumbnail 990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/990.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=990)

But what is something that we might not necessarily want to have on an alarm automation?  Having a manual approval step, you know, that could slow us down a bit, so maybe we can just get rid of that. Now let's say we want to do, you know, maybe  our automation works, right, or fails. In either case, I'd probably want to know about it, so we can just jump to our AWS APIs and we'll search for Amazon SNS.  And we can say, you know, we'll go ahead and publish, and we'll call this one good. And then maybe we'll add a different one and we'll call it  bad.

[![Thumbnail 1000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1000.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1000)

[![Thumbnail 1020](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1020.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1020)

[![Thumbnail 1030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1030.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1030)

And then from here we can see our inputs where we have our message,  and then I can have additional options where I would target the actual topic ARN. So then I can have a specific message that comes from the output state of the previous states from our automation. However, let's say our automation, our automatic fix just works the first time, right?  In this loop state, it would then apply the same fix two more times, right, because it says run three times, so  it's going to run three times.

[![Thumbnail 1040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1040.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1040)

[![Thumbnail 1050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1050.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1050)

[![Thumbnail 1060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1060.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1060)

[![Thumbnail 1070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1070.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1070)

[![Thumbnail 1080](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1080.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1080)

What we can do here is we can actually use a flow control state and add a branch right here at the bottom. And what this branch is going to let us do is based on the output of our script,  we can determine what to do next. So for example, we can go to our inputs and I can say Rule One. We'll add a condition and we'll say  if the output of our output payload here, right, so this is that script that we're running, what that output payload is, and let's just imagine it can  fix some stuff for us, and maybe it can then set an alarm or look at an alarm state as well. If it's equal to something, and we'll say it's, hey, let's say it's OK, right,  we can then say instead of adding a new step, we'll say just go right to Good. And you see that it just broke out of the loop, so that based on a conditional argument, we can break out of the loop. 

[![Thumbnail 1090](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1090.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1090)

[![Thumbnail 1100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1100.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1100)

[![Thumbnail 1110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1110.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1110)

And then for our default actions, so let's say if it's not good or really anything else,  we would then want to say instead of adding a new step, we can just go right to the end and repeat the loop. And then for this, we'll just change our  loop, and then our output and configuration next step is Bad, and then for Bad  we'll go to our configuration and to End.

[![Thumbnail 1120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1120.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1120)

So that's what it would look like, right? We have our delay, a choice, we'll try some automatic fix.  If it works, break it out, go to Good, and that's the end of it. And if it doesn't after three times and it fails, then we could then send a different notification message, right? So the idea, what I want to demonstrate here is just, you know, in a couple minutes we built that.

[![Thumbnail 1140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1140.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1140)

[![Thumbnail 1160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1160.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1160)

[![Thumbnail 1170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1170.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1170)

And then if you want to gut check it and say, OK, how do we actually string this all together, it's pretty straightforward. All we need is a CloudWatch alarm,  and then given an alarm, and as you can see this alarm state has been changing over time, we just need to create an EventBridge rule. And I'll zoom in a little bit so we can see it. But the EventBridge rule just targets for my CloudWatch alarm. You can have a trigger  for any alarm, right, but you can also have those EventBridge rules focused for a specific alarm. And then for my target, I just point it at the automation, I give it an IAM role, and we're off to the races. 

[![Thumbnail 1180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1180.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1180)

So if we want to take a look at the whole thing, we can see that's what it looks like in practice. And just to prove that I'm not just showing you, you  know, OK, here's something that looks good on paper, we actually did build it and we can take a look where it actually succeeds. And if we check it out, we can then go and see each and every specific action that took place, a success or error state. And if those error states do occur, we can then jump into the logs.

[![Thumbnail 1200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1200.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1200)

So when we talk about an easy way to start building runbooks,  it's not just building a runbook, it's also being able to debug it, because if it breaks, you know exactly what step it broke on and you have the ability to do step by step debugging.



[![Thumbnail 1230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1230.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1230)

### Fannie Mae's Journey: From Good to Great Performance Indicators

So with that said, the very last thing I want to cover here is Config. We talked about Systems Manager. One thing you do want to know about when it comes to Config is essentially we'll create resource items when a resource changes or periodically.  We have configuration recorders which create rules, and rules evaluate compliance, which is a desired state or an undesired state we'd like to have. If a noncompliant rule does happen, we can then remediate that. In that box you'll see it says Systems Manager, but really what that is, not a trick question, but it's an automation. Every remediation within Config is an automation. Think about how, what are other things we could do with automation? It's not just automating some tasks, but we're actually using this within our own services as well.

Without further ado, we'd like to talk about how all this is good, but how can a customer do it? Who I'd like to invite on the stage is Moiz Halani, who's going to walk us through how Fannie Mae has been able to adopt our cloud operating principles and be successful with it. Thank you. Can you guys hear me okay? Good afternoon, everyone. There was some really good information from Bobby on reliability. I am Moiz Halani, Vice President of Operations Engineering at Fannie Mae.

[![Thumbnail 1310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1310.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1310)

[![Thumbnail 1320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1320.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1320)

 Some of you may think, who is Fannie Mae? Fannie Mae was chartered by the U.S. Congress in 1938.  We promote homeownership and make housing available in the U.S. by providing stability and liquidity to the housing market. About one in four mortgages in the U.S. are owned by Fannie Mae, so we finance one in four homes in the U.S. We have more than four trillion dollars in assets. Our balance sheet is the largest in the U.S. and fifth largest in the world.

You can kind of imagine the scope and impact of Fannie Mae. When Fannie Mae sneezes, the mortgage industry catches a cold. There are all sorts of lenders across the U.S., some big lenders who have built their applications around Fannie Mae's systems. You can kind of imagine the importance of reliability, stability, and performance of Fannie Mae's systems. I'm sure you guys also face challenges with your systems when it comes to stability, reliability, performance, and so on and so forth. Today, I'm actually going to share three strategies that we implemented at Fannie Mae, and I'm going to share some of the achievements in terms of performance indicators that we landed.

[![Thumbnail 1410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1410.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1410)

[![Thumbnail 1420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1420.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1420)

[![Thumbnail 1430](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1430.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1430)

[![Thumbnail 1440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1440.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1440)

About six years back when we started  our cloud journey,  we took a value-driven approach, and there were certain outcomes that we were looking for. We wanted to prevent financial impacts. We wanted higher regulatory compliance,  faster time to market, higher customer satisfaction. We wanted to minimize operational disruptions, increased productivity, and so on and so forth. Now, when you kind of fast forward six years,  what I can tell you is that we have some best-in-class performance indicators. It's not like our KPIs were not good, they were pretty good, but we went from good to great.

[![Thumbnail 1460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1460.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1460)

[![Thumbnail 1480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1480.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1480)

[![Thumbnail 1500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1500.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1500)

Here are some of the KPIs.  We reduced our critical incidents by about 71 percent. You can imagine if, let's say over a period of time, if we had ten critical incidents a few years back, today we only have three. Our change failure rate is down by 75 percent. I want you to kind of take a step back and  imagine us pumping in about 10,000 changes in a particular period of time across Fannie Mae's systems, and out of the 10,000, there's only two or three that actually cause business impacts. You can kind of do the math on that.  In terms of mean time to recover, we're down by about 80 percent.

[![Thumbnail 1520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1520.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1520)

What that means is, before our cloud journey, if it took us 2.5 hours to resolve an incident, now it only takes us 30 minutes. The last thing I would share  in terms of KPIs is that when you think about AWS platform-caused incidents, it's about three per year. So, some really good numbers is what I can share with you that we've achieved.

[![Thumbnail 1540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1540.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1540)

[![Thumbnail 1550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1550.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1550)

[![Thumbnail 1560](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1560.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1560)

[![Thumbnail 1570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1570.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1570)

[![Thumbnail 1580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1580.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1580)

[![Thumbnail 1590](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1590.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1590)

### Strategy One: Integrated Observability and Automated Regional Failover at Fannie Mae

Now, how did we achieve this?  I'm going to talk a little bit about that here. The three strategies that I spoke about, the first one is integrated observability and incident management. So we have our  homegrown tool called Sentinus, which provides us with real-time alerting and monitoring, event correlation, and so on and so forth.  Now, we obviously have CloudWatch, EventBridge, AWS Personal Health Dashboard, OpenTelemetry, and so on,  writing to Splunk, and then from Splunk, we're making API calls to write into our Sentinus tool, like I mentioned earlier. And then we have other tools such as Dynatrace  for app monitoring, and then we have some synthetic transaction monitoring tool called Catchpoint and some other tools. They all kind of bring  the data into Sentinus. And then, of course, we use xMatters for paging our support teams and so on and so forth.

[![Thumbnail 1600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1600.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1600)

[![Thumbnail 1630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1630.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1630)

[![Thumbnail 1640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1640.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1640)

Now, what this has done is this provides us with end-to-end  transaction tracking as well as visibility across the board. So we can kind of slice and dice the data in terms of VPCs, accounts, and so on and so forth. So, even before AWS reaches out to us notifying us about an incident, we already know what the incident is, and most of the times, we know the cause of the incident as well.  Now, the other thing I'd like to share is we also build runbooks using Gen AI and  then we enhance them using automation. These are runbooks for standard operating procedures like reaching out to different support teams or reaching out to AWS teams and so on and so forth.

[![Thumbnail 1660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1660.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1660)

[![Thumbnail 1670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1670.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1670)

We also implemented Monitoring as Code. So this is where  we have consistent alerting and monitoring that we've applied across all of our applications. And then, last but not least,  we've implemented chaos engineering as well across many of our applications using AWS Fault Injection Simulator and a few other tools. What chaos engineering helps us do is we learn from those exercises and we're able to kind of take those learnings and apply them to our systems to kind of make them more reliable.

[![Thumbnail 1710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1710.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1710)

[![Thumbnail 1720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1720.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1720)

Now, in terms of outcome, what did we achieve? Much faster detection and recovery, quicker incident resolution, improved operational resilience,  and then, of course, self-reliance of the teams. So this is something  that kind of comes into play before the incident. Now let's talk about another strategy when it comes to what we do during an incident. So, as the AWS CTO Werner Vogels says all the time, everything fails all the time, and that's true because things do fail. I think what is important is how do your systems recover from those failures. What type of tolerance you built in, what type of defensive mechanisms you've built into your applications, and so on and so forth.

[![Thumbnail 1760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1760.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1760)

[![Thumbnail 1790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1790.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1790)

How many of you are using automation to fail over from one region to another? So there's a few hands.  So, some of you may remember the December 2021 event where there was an Amazon outage and there was an issue with the Route 53 control plane. We were impacted by that outage as well. And we took the lessons from that outage and we built automation patterns where we took away the dependency on the Route 53 control plane. We also made those automations independent of the CI/CD pipeline.  Because again, if your pipeline is sitting, let's say in US-EAST-1, and if US-EAST-1 has a failure, you don't want to be dependent on the pipeline to fail over all the other assets.

[![Thumbnail 1810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1810.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1810)

We built all of this using AWS native services like CloudWatch, Step Functions, Lambda, and so on.  The other thing we do is have our teams exercise these failovers on a periodic basis, which builds muscle memory for them. Even during the October 20th event that we just had, we were able to fail over the majority of our critical applications using these automation patterns, so a really good outcome.

[![Thumbnail 1860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1860.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1860)

Just at a high level in terms of outcomes, as you can imagine, we have faster recovery coming out of this, autonomous operations, and it has enhanced our business continuity. The last thing is we've empowered our teams, meaning  if an application onboards a new service from AWS, the teams are independent and they can go in and make updates to those automation patterns so that they can continue to use the failover mechanisms that we've built.

[![Thumbnail 1880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1880.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1880)

### Strategy Two: Implementing AWS Correction of Errors Framework with Fannie Mae Innovations

 Now, I know Bobby touched upon Correction of Errors, right? A few years back, we had a fairly mature postmortem process. How many of you have some type of a postmortem or a root cause analysis? That's a lot of hands, right? We had a pretty good postmortem process, but we wanted to improve upon it and innovate. So we took AWS's Correction of Errors framework, and we applied some Fannie Mae tweaks to it.

[![Thumbnail 1920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1920.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1920)

[![Thumbnail 1940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1940.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1940)

It has the normal  features that any root cause analysis would have, which is your incident summary, impact, timeline, and so on, but the main things that really worked for us were the five whys, the lessons learned, and the action items. What we do is, every week,  we have a call with some very critical stakeholders, and we take the critical incident from the previous week. We invite the root cause CI owner, the impacted CI owners, our business stakeholders, our risk stakeholders, and many other partners across Fannie Mae. We invite them to this meeting and we start out with five to seven minutes of quiet time at the beginning where folks read the COE document. They're able to take their own notes, and then we open up for questions.

[![Thumbnail 1980](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/1980.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=1980)

[![Thumbnail 2010](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2010.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2010)

What we also do is  we ask our junior members to start asking the questions before the senior members, because what we don't want is a VP such as myself starts asking a whole bunch of questions, and then the conversation gets influenced and goes into a particular direction. That's why we encourage our junior members to raise their comments and questions and so on. On top of that, in terms of Fannie Mae tweaks,  what we do is we run a monthly forum where we actually talk about the lessons that we've learned from some of these incidents and how we have implemented those patterns across other applications across the enterprise, which has been fairly instrumental in us achieving some of the reliability results that you saw earlier. We do take those patterns and we convert those into work streams where other teams are able to implement those action items.

In this monthly forum, again, it's the same set of stakeholders plus many more, and we go over some of the critical incidents over the previous month. Again, we don't go into too much detail, just a high-level summary, but we try to focus on the patterns coming out of those incidents and what we're doing with those patterns and what is the outcome of the work streams and so on. In fact, to a point where we've had business teams come over to us and asked us to train some of their team members because they wanted to implement the COE process within their teams, especially when it comes to business process failures and so on.

[![Thumbnail 2100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2100.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2100)

What were the outcomes that we achieved as a result of this? Of course, accelerated learning. 

[![Thumbnail 2120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2120.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2120)

[![Thumbnail 2140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2140.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2140)

As I mentioned, we're able to learn from these incidents and look at the patterns coming out of those. And again, that's improved knowledge sharing and data-driven decision making. Imagine having a few applications running into similar types of issues.  Now we have the data to ensure that we're investing with those applications, and it's not any kind of a biased approach. And then blameless accountability. I know Bobby touched on this.  We're not looking to blame anyone. We're not looking to punish anyone. It's really about an improvement-first kind of mindset, and I'll give you an example.

Let's say there's an incident which was caused by a human error. Now we don't think of that human as being the cause. We try to look at, well, why did that human commit an error, right? So maybe the support engineer was working on four different change tickets, or maybe there were two or three incidents that came in at the same time. It could be so many different factors. So we try to get to the root cause of those. So those are the three strategies.

To wrap it up, we talked about integrated observability and incident management. We talked about how we develop the automation patterns and how we're using them during an actual failover. And then we talked about implementation of the Correction of Errors process across Fannie Mae. Now today, I want to leave you all with a challenge, and that challenge is to take one of these strategies and implement that in your organization, maybe starting as early as next Monday. And again, take baby steps. Small steps lead to big outcomes. So thank you for your time.

[![Thumbnail 2260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2260.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2260)

### Five Advanced Reliability Cheat Codes: From Change Control to Cultural Transformation

And at this point, I'll invite Steve Rice. Steve is going to talk about, he's basically going to give us some critical nuggets on advanced reliability, and he's also going to present a demo. Thank you. All right, thanks everybody. My name is Steve Rice. I'm General Manager for AWS Config and Parameter Store, which are two tools that are used for reliability and moving faster. I'm going to give you the top five cheat codes that we've observed at Amazon when you want to increase your  reliability.

I was talking to somebody who's here from Sony PlayStation. He probably has some different cheat codes that you might want to find them afterwards, but these are sort of operational cheat codes that you can implement. These are things that ideally you can start implementing tomorrow or maybe Monday when you get back. Some of them, depending on where you are on your reliability journey, might be a little bit longer, but again these are things that we use and we use them at scale inside of AWS to make sure that we're delivering high reliability and high availability.

[![Thumbnail 2290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2290.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2290)

 So the first thing is talking about the three pillars of change. And there's a QR code on all these. You can feel free to scan the QR code, but really there's a phrase I like to say that the enemy of reliability is change, but change is a necessary part of developing software and running a business. So of course you have to make changes, but most of the outages that we see are caused by some sort of a change. It could be a change to an application, infrastructure change, or configuration-related change. And if you look back in the past 18 months, there's been a lot of kind of famous changes and outages that were caused by configuration updates.

But you all are probably using some sort of CI/CD tools and they probably have some change control pieces, but you may not have them enabled. And the three core pillars I would say you absolutely have to enable are, one, make sure that you're changing things gradually. You don't want to turn something on everywhere all at once. You want to turn it on slowly for 1% of your fleet or 1% of your customers and then 10% and then 20%. I say at Amazon we always develop very quickly but release very slowly, because if we release something and it only affects 1% of our customers, it's very different than if we release something and instantly it affects all of our customers.

There have been some of those incidents, but ideally everything we do starts very small and you control the blast radius of those changes. So releasing slowly over the course of days or weeks is a must-have. Two, you always want to have rollbacks that are configured to automatically roll back the change if an alarm goes off. If you're using CloudWatch or DataDog, New Relic, any of these kinds of things, they all are going to sound an alarm when something's wrong. If you're in the middle of a change, you should have that alarm actually trigger an automatic rollback.

I would say this is like having automatic braking in a car today. I would never drive a car if you didn't have some sort of collision detection. You want the same thing in your pipelines to be able to say, hey, something's dangerous ahead.

I'm hitting the brakes. I'm rolling everything back. And again, you can respond very quickly if you're only not even out to your first 1% and it gets rolled back. That's a very different type of customer experience than if it's all the way rolled out, it's been out there for three days, and then you realize there's a problem.

The last thing is a pre-deployment validation test. Most people are probably doing integration tests or contract tests, those kinds of things already. In the case of configuration data, you probably want to make sure that you are deploying valid configuration data. If it's JSON, for example, valid using JSON schema, valid JSON, or valid configuration data. So you want to make sure you have some sort of mechanism there to make sure that what you plan to deploy is what will get deployed. So those are sort of the three core pillars we follow at Amazon for any type of configuration update, any type of code deployment.

[![Thumbnail 2460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2460.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2460)

The next cheat code  is moving to trunk-based development. We talked to a lot of customers that are building their software, and these are the application developers more than operational teams, but they're building their software using branches. Branches were a great technique. If you want to improve resiliency, I'd highly recommend moving to trunk-based development. It provides a lot of benefits, especially when you want to roll something back.

So the idea is you don't have these branches that live out there for a month. Something has to be merged in. Sometimes the merge is successful. Sometimes it's semi-successful, and that rolls out to production and can cause some problems. Using trunk-based development, you're developing everything on the trunk. If you're not ready to release the feature, you use something called feature flags. That's the next slide to control the release of that feature, but this really gives you a lot of control about how the software is getting deployed out to your customers.

[![Thumbnail 2520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2520.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2520)

Tied to that trunk-based development is this idea of feature flags.  Can I ask, are there any groups today using feature flags? Okay, great. Yeah, feature flags are a great tool not only for application developers to release features, but there's something we call operational flags. Those are must-have in your toolbox, and I'll talk about that in just a second.

So typically a feature flag, people think of, I have a new feature to gate access to that feature through a little configuration toggle that says is feature enabled? If so, let this code execute. If feature is not enabled, then hide it. And so again, your developers can actually develop on the trunk. They can push the code to production, but nobody can access it. And then when they're ready, they flip that feature flag on for 1% of the fleet or 1% of the users and then 10% and 20%, release that gradually. But that decouples the launch of the feature from the deployment of the code, which again allows you to react much faster if something goes wrong. You can just flip that feature flag back. You don't have to pull the whole deployment back, put something back in your CI/CD pipeline, and depending on what you're building, that could be hours before that thing gets fixed. So again, feature flags are a great technique.

Operational flags are these long-lived feature flags that allow you to control things like maybe the number of background tasks that you're going to allow, and during peak time you might want to actually lower that number because you're at capacity. We didn't invent feature flagging at Amazon, but we use it at scale, and actually this week and last week are huge feature flag weeks for us. This week, every single thing you see that gets announced was hidden behind a feature flag, and no code was pushed. The code has actually been pushed to production for all these new features that were announced at the keynote a couple weeks ago, but the feature flags were flipped today.

On Black Friday on Amazon.com, they use AWS AppConfig in order to control some of the operations. I think you probably all bought something on Amazon that says customers that bought this also bought this, and we might say, oh, let's show them five things. Well, those five things can be an expensive query. So during Black Friday, sometimes that gets down to just showing three things, for example, and that really reduces the CPU on that operation. One final thing, and I'm going to do a demo on this, is flags can be automated to be turned on and off. Bobby showed you some automation. I'm going to sort of riff on that a little bit.

[![Thumbnail 2660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2660.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2660)

Okay, cheat code number four, the ORR.  This is something super easy to implement and it makes a huge difference to how you operate, and it's a really simple concept. The idea of an ORR is it's just a checklist. It's a checklist of things that you think are important for the services that you operate. And what we do at Amazon is we do the ORR, Operational Readiness Review, once a year, so we make sure that, hey, is everything all good? Once a year, we also do it before the release of a major feature, so it happens a couple times a year. But that checklist is managed by the senior developers in our company, and all the things in that checklist are actually ideas that came from some of the COEs that happened before.

Were we prepared to scale? What happens when you have a noisy neighbor? Are you prepared to throttle a single customer so that it doesn't take down the whole service? Those kinds of things.

So we have a checklist of things that we have to do and make sure that we're prepared when we release a new feature and just making sure that our services are healthy. You don't want that checklist to get too big. It can get really onerous, and it shouldn't take months of work for a team to run through the checklist, so you need to have a mechanism to cull that list, the Operational Readiness Review, to make sure it's just the most important things. But again, it's a checklist of best practices, and it makes a huge difference, and that way you can take the knowledge of those very senior engineers that have seen a lot of stuff and put it in the hands of very junior engineers.

[![Thumbnail 2740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2740.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2740)

 The last is a culture change, and my guess is if you're here you probably already feel this is an important thing for your culture, but resiliency is a feature. We say at Amazon the most important feature that we offer to AWS customers is security. The number two feature is availability and resiliency, and the number three thing is whatever your service does. So really, honestly, the idea that you need to make sure that your service is available has got to be the mindset. You might have some product people on your team that are saying, oh, we can gain 5% more customers if we add this feature or that feature, and those features are important, but even more important is resiliency.

Getting back to that car metaphor, you know, would I buy a car that didn't have a heated steering wheel? Yeah, I would. Would I buy a car that didn't have CarPlay or something like that? Yeah. Would I buy a car that didn't start reliably? No. That availability and reliability of that car is the most important feature, and you need to make sure that that is understood at the top and that cascades down. That can't be something that is from the ground up necessarily.

[![Thumbnail 2810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2810.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2810)

### Feature Flags in Action: AWS AppConfig Demo and Closing Takeaways

 Okay, I'm going to do a quick demo here. I'm going to show you AWS AppConfig and a feature flag. I talked a little bit about feature flags. This is going to be an operational flag, and a common use case that we have is that we want to be able to control the logging verbosity with a feature flag. You might have something sort of suspicious happening on production, and instead of pushing out a change to your code that changes the log level, you want to control that through a feature flag and you can get that pushed out in seconds.

[![Thumbnail 2860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2860.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2860)

Okay, so let me go here. What I'm showing you here is the console for AWS AppConfig. Of course all this is available with infrastructure as code and there's a Terraform module, there's CloudFormation as well, but we have a couple different things here.  I'm going to choose a feature flag and I'm going to create what's called a configuration profile. That's a collection of flags that you might want to group together. You can put a single flag in there too, but here I'm going to call this logging verbosity.

And I'm going to create a flag within there that is really going to be the thing that we toggle. This is again the verbosity value. This is how it's referenced in code. You have your code reaching out, reading that configuration value, and it's doing it on a regular basis. It's every five seconds or every minute or whatever makes sense for your use case. We do have the ability in AppConfig to also set a flag as short-term. You don't want to have a lot of clutter of stale flags in your code. That can be onerous and difficult to debug, so we have that ability.

[![Thumbnail 2900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2900.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2900)

 This is an operational flag, and I'm actually not going to set this as a short-term flag, and I'm going to enable that. So now my logging will be controlled by this feature flag. Alright, so here I'm going to actually add what's an attribute. It's not just going to be a toggle, yes or no, should I be debug. I'm actually going to put the log level in here because you may want to have a different log level than you think. So here again I'm going to put the value. I'm going to put type string, and here I'm going to say by default we're going to just log at the info level.

[![Thumbnail 2930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2930.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2930)

[![Thumbnail 2950](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2950.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2950)

[![Thumbnail 2960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2960.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2960)

 Alright, and then with AppConfig we think of configuration like code. It's just as dangerous as code, so you can make an update but it's not available until you deploy it. So I'm going to go and review the changes I made.  Yes, and it's set to info, which is correct, and I'm going to actually deploy the change to my feature flag. I'm going to update the flag. I'm doing a demo here so I'm not going to make you watch paint dry.  I'm just going to do an instant deployment, but again, the idea is unless it's really urgent, I'm going to deploy it slowly over the course of minutes or hours.

[![Thumbnail 2970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2970.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2970)

[![Thumbnail 2990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/2990.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=2990)

 Okay, so I've deployed the change. I'm logging now at the info level. My code is reading this feature flag. I'm going to go over to CloudWatch and set up an alarm here, and this alarm is going to look for suspicious activity.  And in particular, just as a sample idea here, you might want to monitor how often things like IAM roles are listed. And in your workflows that might be something that happens regular times during the day. Of course it's just part of your operations, how many times are you listing all the IAM roles. But if one day you get a spike in those things that seems kind of suspicious, what's going on? What processes are triggering that? You're going to want to have additional logging to understand what's really going on here.

[![Thumbnail 3030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/3030.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=3030)

So this is just using sort of anomaly detection where it's tracking how many times you're listing IAM roles. The alarm, once it's detected, is going to kick off  some automation. The automation it's going to do is it's going to toggle that feature flag to go from info to debug.

[![Thumbnail 3040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/3040.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=3040)

[![Thumbnail 3070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/3070.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=3070)

So I'm going to click on actions here.  Bobby already showed you the visual automation builder. It's super cool. I chose a simpler route here just for demo purposes of just calling a Lambda, and that Lambda in turn is going to call AppConfig and toggle that feature flag. It's also going to do a message because you're going to want to know if this kind of thing happened. So I have set all of this up. The alarm is configured to monitor, look for anomalies, and then do this automation of flipping the feature flag. 

[![Thumbnail 3080](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/3080.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=3080)

[![Thumbnail 3100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/3100.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=3100)

Almost like a cooking show here, I'm going to jump over and wow, it alarmed. You see those red peaks  where something went wrong. So this is where suspicious activity was detected. It might be something normal, we don't know, but I want to start changing my logging level. And you can see that green bar and there's a couple reds. Those reds will trigger that Lambda. So I'm going to jump back over here to AppConfig and I'm going to check that flag. And indeed, when I look at the attributes of the flag, it has been flipped over to debug. 

[![Thumbnail 3120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/3120.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=3120)

Okay, so that's a way that you can react without a human being in the mix. The automation can react much faster than a human being can, and that's a core secret to making sure that your resilience is very high. All right, so to recap what I just showed you, you can control the logging  verbosity with a feature flag. You can set up an alarm to trigger that feature flag, and then you can automate the flipping of that feature flag.

[![Thumbnail 3130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/3130.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=3130)

Okay, key takeaways. We're almost done here.  So there are three of them. Number one, I just covered it a little bit. Resiliency is more important than other features. It is a mindset change for a lot of companies, but Moiz talked about how important resiliency is for Fannie Mae. Every second that Fannie Mae is out is, I don't know the number and he's probably not going to tell me, but it's probably millions and millions of dollars that can be impacted. So that's real. Resiliency has got to be the feature that you focus on.

[![Thumbnail 3160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/3160.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=3160)

[![Thumbnail 3180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/3180.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=3180)

Number two, build for resiliency. I love that Werner quote which says everything fails all  the time. You should be ready that some core piece of your infrastructure is going to go down. You should limit the number of dependencies you have and you should find some sort of a fallback where possible. And the last one is start small and then build on that. Different people are at different parts of their journey. I talked to the people in the crowd a little bit. There are some people  that are looking just to get to that very, you know, getting from five nines to seven nines. There's some people that are just looking to get started on their resiliency journey.

[![Thumbnail 3210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/3210.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=3210)

So start small. We gave you some cheat codes and again you'll be able to watch this video later on YouTube. And we'll also be here for questions, but you know, figure out what's going to work for your organization, adapt accordingly, and then build on top of those successes. Okay, in the Venetian there are kiosks  in the middle in the AWS village. Highly recommend that you go there and there's swag, but you can also get demos of some of this stuff and you can get some literature and those kind of things that you might want to do. We'll be there for some of the time, but there'll be other experts from AWS that can help you and answer more in-depth personal questions.

[![Thumbnail 3250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/e1205ab21af37803/3250.jpg)](https://www.youtube.com/watch?v=q9lfBSHEibo&t=3250)

And if you guys don't mind coming on the stage, this is it. What we're going to do, I really appreciate you all sticking around. I know it's late and there's happy hours going on and it's Las Vegas, so you probably want to get out soon. We're going to be on the side of the stage over here to answer questions. And again, come to the booth in the kiosks in the middle of the Venetian Expo hall, but  thank you very much for your time.


----

; This article is entirely auto-generated using Amazon Bedrock.
