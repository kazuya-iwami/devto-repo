---
title: 'AWS re:Invent 2025 - Data innovation: Amazon S3 Access Points for FSx for NetApp ONTAP (STG219)'
published: true
description: 'In this video, Ben Littman, a Senior Specialist Solutions Architect at AWS, introduces S3 Access Points for FSx for NetApp ONTAP, a feature that enables direct S3-compatible access to file server data without copying or migration. He explains how enterprises can unlock value from petabytes of unstructured data stored in NFS and SMB shares by integrating with AWS analytics and AI services like Athena, QuickSight, and Bedrock. The solution eliminates the need for duplicate data copies and ETL pipelines while maintaining real-time synchronization. A pharmaceutical research use case demonstrates how natural language queries can instantly access decades of file-based reports through AI models, transforming underutilized file data into actionable insights.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/0.jpg'
series: ''
canonical_url: null
id: 3093053
date: '2025-12-08T19:35:28Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Data innovation: Amazon S3 Access Points for FSx for NetApp ONTAP (STG219)**

> In this video, Ben Littman, a Senior Specialist Solutions Architect at AWS, introduces S3 Access Points for FSx for NetApp ONTAP, a feature that enables direct S3-compatible access to file server data without copying or migration. He explains how enterprises can unlock value from petabytes of unstructured data stored in NFS and SMB shares by integrating with AWS analytics and AI services like Athena, QuickSight, and Bedrock. The solution eliminates the need for duplicate data copies and ETL pipelines while maintaining real-time synchronization. A pharmaceutical research use case demonstrates how natural language queries can instantly access decades of file-based reports through AI models, transforming underutilized file data into actionable insights.

{% youtube https://www.youtube.com/watch?v=yg4QclLNOps %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/0.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=0)

### Introduction: Unlocking Value from Enterprise File Server Data

 Hey folks, thanks for joining me here. I am not Luke, by the way. My name is Ben Littman. I'm a Senior Specialist Solutions Architect, filling in and helping out the storage team. I help customers get their workloads from typically VMware platforms into AWS, and a lot of what I end up doing is talking about file servers and storage because that's a big part of our enterprise IT story. So today we're talking about S3 Access Points. It's really exciting.

[![Thumbnail 30](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/30.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=30)

[![Thumbnail 50](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/50.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=50)

 We're going to get into that in just a minute, but let's back up a little bit. Let's zoom out. Why are we talking about data? Data is valuable to your company. This is how we can unlock innovation, especially with AI, machine learning, and analytics, right?  We have lots of data on file servers. Almost everyone has file servers, exabytes of data. It's not uncommon to have hundreds of petabytes of data in SMB and NFS shares. The question is, how do we unlock value in this data that we already have? We could make copies of it, we could put it in S3 and maintain two copies and keep replicating it, but there's got to be a better way.

[![Thumbnail 70](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/70.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=70)

[![Thumbnail 90](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/90.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=90)

[![Thumbnail 100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/100.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=100)

 All this is unstructured data for the most part. It's your reports, your video files, CAD files, all sorts of data. So how do we make decisions based on data? How do we do analytics with this data? That's what we're going to talk about. But when we're using file server data,  we're not really putting it to work. It's just there for teams to access user shares, business processes, pass things back and forth.  We're not really adding a whole lot of value to it.

### FSx for NetApp ONTAP: Fully Managed Storage with Enterprise Capabilities

So let's talk about FSx for NetApp ONTAP. If you're not familiar with it, it's a fully managed AWS service, and it's the only one where it's actually fully feature compatible with your on-premises NetApp. You can deploy FSx for NetApp ONTAP in AWS. It takes about 30 minutes to spin up, and then you've got NFS shares, SMB shares, iSCSI, NVMe over TCP, fully capable NetApp. SnapMirror can replicate it. You can have snapshots, clones, deduplication, compression, all this fun stuff that NetApp users love, all this enterprise power, but it's on AWS. So when we're migrating, I talk about what kind of storage do you have. Let's get you on NetApp so that you don't have to run file servers. Nobody wants to run file servers, right? NetApp can do this for you.

[![Thumbnail 150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/150.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=150)

 We talked about provisioning. In 30 minutes, you can have this thing spun up. You can do all sorts of fun stuff. It could be your data and log volume for your SQL databases, for example. Your deduplication and compression can help optimize that, and it's fully managed. If you have a problem, you call AWS, talk about your EC2 instances. We can help you with your ONTAP. The cost is a big one too. With EC2, often we're using EBS, Elastic Block Store, and there's nothing wrong with that. But FSx for NetApp ONTAP gives you deduplication and compression, for example, thin provisioning. That SQL database we talked about, those can be 80 to 90 percent compressible. So this is also a way to save money and take advantage of some of the space efficiency, compression, compaction, and deduplication.

It can reduce complexity. If you think about your EBS volumes, you could have hundreds or thousands of instances, each with a handful of volumes. With ONTAP, it's one array, essentially. All your volumes are there. Your storage virtual machine can export iSCSI LUNs to these things. It's all in one spot, one thing to manage. This helps you innovate. This gives you the power of NetApp and AWS together.

[![Thumbnail 230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/230.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=230)

 But what we're going to talk about is how do we do this AI and analytics? How do we add value to this data? Because that's what our executives are looking for. That's what our business really wants. Files aren't terribly interesting, but analytics are interesting. Maybe we have decades of reports and briefings, and we want to ask questions from QuickSight. Tell me about this data. Traditionally, maybe we'll lift this up, put it in S3, and then we can use Athena and Glue and some of these services to crawl the data and read it and utilize it. But there's all sorts of use cases here that ONTAP can help you with. Backup and disaster recovery, for example. You can use SnapMirror from one region to another. We're only shipping the data across after it's deduped and compressed, so it's a nice and efficient process.

[![Thumbnail 280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/280.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=280)

So this is what we're talking about today.  This is the portfolio of things that we're talking about, adding value to your data. We have under analytics, EMR, Lake Formation, Athena, so you can crawl these files, maybe use Redshift to query them. And then I'm sure you've heard about our AWS AI services, Bedrock. We talked about QuickSight. We're going to use these tools and surround all this data and add value to it. So that's the name of the game here.

[![Thumbnail 310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/310.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=310)

### S3 Access Points: Real-Time S3 Compatibility for File Data Without Migration

This is what we're announcing: S3 Access Points. So what is  this? You take your file server, and you have a volume in FSX for ONTAP. All we have to do is provision an access point and say, provide access to that volume. There's no copying, there's no moving the data around, and then all of a sudden, this data is fully S3 compatible at the same time as it's still file data. So instead of making a copy and having to refresh it periodically, we access the data where it is in real time with S3 compatibility and with your NFS, SMB, whatever protocol you're using.

[![Thumbnail 350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/350.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=350)

This is really a game changer if you're trying to say, hey, we have all these file servers, how do we get AI to talk to this? How do we add value to this data?  How do we do more with the data? With S3 Access Points, we're taking all this data. It could be SAP HANA datasets for genomics. All this is instantly S3 compatible. Maybe it's trading data and you want to put reports and dashboards up for your executives. It's seamless integration with all of our analytic, AI, and compute services because these things are meant to talk to S3. So we're just plugging in S3 compatibility right to your FSX file systems.

[![Thumbnail 390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/390.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=390)

[![Thumbnail 400](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/400.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=400)

[![Thumbnail 400](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/400.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=400)

[![Thumbnail 410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/410.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=410)

Let's take a deeper look and see what else we can do with this new feature to help us maximize this potential. Here's a little demo.  Here's our QuickSight interface. We can just ask questions about our data.  You've got petabytes of data, maybe documents, research data,  institutional knowledge, and that's the question, right? How do we access this? How do we add value? We're just going to plug S3 Access Points right into this, and then everything can instantly  talk to it just as if it were copied up to S3.

[![Thumbnail 430](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/430.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=430)

[![Thumbnail 450](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/450.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=450)

QuickSight, Bedrock knowledge bases, maybe you're doing a RAG knowledge base so that you can have an AI assistant that knows about all these documents and you ask questions. That can instantly search and query and inform that  AI model to know all about your data, and you can just ask natural language queries about it. We don't want to do data migration. We don't have ETL pipelines to move the stuff back and forth. Now you're paying for it twice. You're always going to be out of sync after that file copy happened. This keeps it in FSX for  ONTAP and then just plugs in S3 compatibility right into it.

[![Thumbnail 470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/470.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=470)

[![Thumbnail 480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/480.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=480)

This is going to add value. It helps transform this underutilized file data. We're using file shares for users to pass documents back and forth. Now we can add AI onto this and instantly do more with that data.  That's one of the biggest use cases. If you're migrating into AWS and you've got file servers, instead of putting them on EC2 with EBS volumes, you're going to just copy  that file data right over to FSX for ONTAP, and then your S3 Access Points can plug right into that.

[![Thumbnail 490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/490.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=490)

[![Thumbnail 500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/dd625269561c66a5/500.jpg)](https://www.youtube.com/watch?v=yg4QclLNOps&t=500)

One of the use cases we talked about, imagine  a pharmaceutical researcher saying, hey, what compounds showed promise in our cardiovascular trials from 2015 to 2020?  That's a great natural language query. And then the AI model is just going to crawl that data and then give you answers in real time for that exact query. No writing dashboards or having to build this manually. That's it. Do we have any questions? This is a pretty amazing feature. You just plug it right in and it works, and it's fairly simple. How many people here use FSX for ONTAP? Do we have a couple? Great, perfect. So you're already used to it. It's better than managing a file server, right?


----

; This article is entirely auto-generated using Amazon Bedrock.
