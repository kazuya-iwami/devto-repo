---
title: 'AWS re:Invent 2025 - Adding agentic AI to legacy apps with Amazon Bedrock AgentCore  (MAM345)'
published: true
description: 'In this video, Deepali Tandale, Franz Stefan, and Jan Thewes demonstrate how to integrate agentic AI into legacy applications using Amazon Bedrock AgentCore and Strands SDK without rewriting code. They explain the agentic loop concept, showing how agents orchestrate LLM calls and use tools for external tasks. The team live-codes an agent using Python, starting with basic queries, adding the request tool for real-time data, and deploying to AWS using BedrockAgentCoreApp. They showcase MCP (Model Context Protocol) for connecting agents to services, implement an AgentCore gateway with OpenAPI specifications to interact with a Java-based unicorn store application, add memory capabilities for session management, and demonstrate streaming responses. The session includes practical examples of tool usage, OAuth authentication, session handling, and observability through CloudWatch and tracing, proving agents can enhance legacy systems without modifying existing code.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/0.jpg'
series: ''
canonical_url: null
id: 3085332
date: '2025-12-05T05:02:06Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Adding agentic AI to legacy apps with Amazon Bedrock AgentCore  (MAM345)**

> In this video, Deepali Tandale, Franz Stefan, and Jan Thewes demonstrate how to integrate agentic AI into legacy applications using Amazon Bedrock AgentCore and Strands SDK without rewriting code. They explain the agentic loop concept, showing how agents orchestrate LLM calls and use tools for external tasks. The team live-codes an agent using Python, starting with basic queries, adding the request tool for real-time data, and deploying to AWS using BedrockAgentCoreApp. They showcase MCP (Model Context Protocol) for connecting agents to services, implement an AgentCore gateway with OpenAPI specifications to interact with a Java-based unicorn store application, add memory capabilities for session management, and demonstrate streaming responses. The session includes practical examples of tool usage, OAuth authentication, session handling, and observability through CloudWatch and tracing, proving agents can enhance legacy systems without modifying existing code.

{% youtube https://www.youtube.com/watch?v=_-X-N0J02UI %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/0.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=0)

### Introduction: Building AI Agents for Legacy Applications Without Rewriting Code

 Let me start with a statement: older applications or legacy applications are reliable, without a doubt. However, when it comes to adaptation or automation, it becomes tricky with legacy applications. It becomes really tough when you are new to that application, you do not understand the code base, and you want to modernize it while still figuring out how it works. If I tell you that you can create an AI agent who will interact with that legacy system and can act and think on its own without rewriting anything, that would be pretty awesome. That would make our life a little bit easier as a developer or architect.

To show you exactly how to do that, I am Deepali Tandale along with my colleagues Franz Stefan and Jan Thewes. Together we will demonstrate how to use Amazon Bedrock AgentCore to create agentic AI into the existing legacy application. Before we dive in, I know you all are here to see us coding and troubleshooting online. But give me a few minutes to go through the core concepts so that it is easy for all of us to follow what we are doing and why we are doing it.

[![Thumbnail 80](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/80.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=80)

 After that, Franz is going to take over and show you how easy it is to create an AI agent using Strands SDK and run it on Agent Core runtime all in an empty project. After that, Jan is going to show you how to do the same thing within an existing legacy system. Let's start by understanding the agentic loop itself or how the LLMs work on a very high level.

[![Thumbnail 120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/120.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=120)

### Understanding the Agentic Loop: How Strands SDK, Agent Core, and MCP Work Together

 You begin with a prompt that you provide to the agent, which could be something like "What's the weather in London today?" This will trigger the initial loop. The agent you can think of as a controller or an orchestrator who knows what to do based on its logic. It will determine when and how to call a model, and the model is the underlying intelligence. These are the foundation models which power your agent and generate responses based on the data that they were trained on.

Sometimes, the model cannot answer you directly. For example, if I ask the model to give me the ten recent Jira tickets for this project, the model doesn't have access to that kind of information. That's why we have tools. Tools are external entities that allow your agent to talk to the outside world other than the model to perform tasks like web searches, database lookups, code execution, calling APIs, anything that your agent wants to do for task completion. In fact, the agent can create a new prompt internally that goes through the same loop again.

[![Thumbnail 220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/220.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=220)

This process of acting, interpreting, and planning is what we call the agentic loop, and it continues until the task is completed. The framework which we are going to use today to build the agent is Strands SDK.  Strands is an open source Python SDK which will let you build the AI agent with just a few lines of code. Compared to other frameworks where developers are required to create complex workflows for their agents, Strands Agent follows a model agnostic or model driven approach, similar to what we saw in the agentic loop.

[![Thumbnail 280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/280.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=280)

[![Thumbnail 290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/290.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=290)

What happens is Strands can run on any infrastructure, and it can call models that are either hosted on Amazon Bedrock or even OpenAI models. Strands will let you define how your agent can think and act on its own. But the next question is, how can you make this agent run in a scalable and production way? The answer is to use Agent Core.  Agent Core is a managed runtime and infrastructure offering from AWS which will let you build, develop, and operate your AI agent at scale.  It provides a lot of out of box components, some of which you can see on the screen. If you're hearing about Agent Core for the first time, do not worry about it. I will go over the components on a very high level.

[![Thumbnail 310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/310.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=310)

[![Thumbnail 340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/340.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=340)

 We have an agent who can think and act, but it needs a runtime which will basically allow us to fulfill the business goals we have, for example, multiple users access, auto scaling, sandboxing sessions, interacting with the tools which we will have in the agent, and most importantly, the performance. For everything like that you will need an Agent Core.  You can think of Strands as providing the intelligence to your agents, and Agent Core will provide the structure, the scalability, the security that your agent needs.

On top of that, if I want my agent to remember the conversation I had in the past, I could use memory capability, which will store the context information across the session and the agents. Along with memory and the runtime, Agent Core does have built-in tool support, and in AWS it provides the native integrations so that your agents can either store your data in S3 buckets or trigger a Lambda function or even write into DynamoDB databases. Other than native integrations, you can also register your APIs as MCP tools so that your agent can access them securely.

[![Thumbnail 430](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/430.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=430)

There is more you can see on top. It's gateways, Agent Core gateways, which will allow you to expose your internal APIs and Lambda functions, if you have any, as MCP tools. Finally, we have identity, which will give you plenty of options for authentication and authorization to basically lock down everything. We have seen Strands,  which will define the agent capabilities, and you will run it on Agent Core runtime for the scalability it requires.

[![Thumbnail 440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/440.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=440)

So what is missing in these two?  Before answering it, let me ask you, how do you think that the context, the memory or the tooling information or any other thing is flowing reliably between the agent and the system it needs to interact with? That missing link is MCP. MCP is the open standard which will let you define how your agents can connect or communicate with the applications and the services. It provides a consistent way to expose the capabilities, and what I mean is like your database queries or APIs or any other services as tools so that your agent can access them securely.

[![Thumbnail 490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/490.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=490)

[![Thumbnail 510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/510.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=510)

Additionally, MCP does not just expose the capabilities as a tool, but it also provides three key capabilities for your agent.  First off, we have tools, and these are the actions that your agent can perform. Essentially, you are telling your agent this is what you can do. For example, you can fetch the weather,  or trigger a workflow, or even retrieve the customer data. Second, we have resources, and these are the external data sources that your agent can access like database lists, documents, files, URLs, basically all the information that your agent can read. Lastly, we have prompts, which is an instruction manual including text and arguments, so it is basically telling the model that this is the given context for the response you will send.

[![Thumbnail 570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/570.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=570)

### Creating Your First Agent with Strands SDK: From Basic Setup to CLI Interaction

To conclude everything, once again, we have Strands that will let you define the agent capabilities. Agent Core will allow you to run in a scalable manner, and MCP will expose the capabilities as a tool so that your agent can access them. Altogether, you will build an AI agent into the existing legacy application. We have the scene now. We know we have gone through the concept.  Now I will ask my colleague Franz, who will demonstrate to you how to create an agent using Strands SDK and run it on Agent Core runtime all in an empty project. To you, Franz. Thank you. Let me switch over to the other screen. Hello everyone. Franz is my name. So next to Jan, we will try for the remaining 15 minutes to do some coding. As we started with the preparation for this code talk today, we had initially much more slides, but this is a code talk.

This is a code talk, so we're not here to go through a lot of concepts and theoretical aspects. However, we had to set the scene to give an understanding of what we want to use and build today. We want to build an agent with Strands Agents as the key, transform it to a Bedrock Agent Core, deploy it to the cloud, and then add some capabilities. We will start at a low level, but the level will increase as we progress.

For the second step, we had to take a trade-off. We could code everything from scratch, but that would not fit within the time constraints. So we will have some parts that we want to go through, and we will copy some code and then try to give an understanding. Feel free to ask questions as well. We are here after the session in case you have questions, but it is encouraged to ask questions in between. I apologize if I sit down, but it makes it much easier than standing while coding.

[![Thumbnail 690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/690.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=690)

What we want to start with first, I think you can see the screen. Let me try to make this a little bit more readable.  So what we're going to start with will be primarily based on Python today. We will use Python as this is the main supported language as of now to get started. There are other options for how to use other languages, which I will come to in a second. But the first thing I want to go through is to make use of these three packages.

I have defined these three packages in my requirements.txt file. Those packages are all we need to transform the agent that we're going to start with now, deploy it to AWS, and extend it. Let me increase this here a bit. In addition, what I'm going to do now is create a virtual environment. The next thing I'm going to do is import the packages. As these packages are getting imported, I need to create a file so that I'm able to use it as my main file for the agent itself, for instance, reinvent_demo_agent_main_345.py.

[![Thumbnail 780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/780.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=780)

[![Thumbnail 800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/800.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=800)

 What is now needed to start with the Strands Agent is pretty easy and straightforward. First, what we want to do is import the Agent class from the Strands package.  As you can see there, there is a class from the Strands package that is needed and that we need to instantiate. This class receives user input, processes the input, and so on. That's the first thing we need to start with when building our first agent or our initial agent.

The remaining three lines to say that we have now built the first agent are those ones. What we are going to do now is instantiate the class. The second thing here is to take an input. Usually we are used to taking an input from a user interface. We have also a user interface that I will show you in a second, but in this case we are taking the user input from the CLI. In Python, that's the input function. I give myself a name, and then I pass the user input to the agent. That's pretty much it to get started.

[![Thumbnail 870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/870.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=870)

[![Thumbnail 900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/900.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=900)

I'm going back to my CLI. Just started, and we can now ask a question like "What is the capital of the USA?" Based on that question,  that's something the LLMs are trained on, so that's nothing very sophisticated. We will get immediately a response. But if I would ask now something, as mentioned by my colleague Deepali before, that requires some real-time information like "What is the weather today in Las Vegas?" I would expect that the LLM cannot return it back. As you can see here, the LLM is not trained on real-time data as we know, so this is something now where we need to  introduce what was mentioned by my colleague before, which is making use of tools. These tools either you can write as part of your agent itself, or you can use an SDK that already includes some tools.

### Extending Agent Capabilities: Adding Tools and System Prompts for Real-Time Data

That's what we're going to do now, or you can use MCP, which we'll see later, to get some tools returned. When talking to agents, the primary question is: what can you do for me? In response, you get some tools that give you understanding so that the loop between the agent and the LLM is about tools and reasoning. This allows the agent to say, "I found a tool that might fit the prompt, so I'll make use of it."

[![Thumbnail 960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/960.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=960)

[![Thumbnail 1000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1000.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1000)

This means we need to add something in addition, which is the second package that we imported. We want to make use of the Strands tool package.  What I'm trying to import here is a tool that already exists as part of the Strands package. You can see here a bunch of tools that we can make use of. We know that LLMs are not great at doing mathematical operations, so we have a calculator tool. We also have an RSS tool, so we can use that tool to import it and get back, for instance, the ten most recent blog posts on the AWS channel in that category. The request tool is more generic but very helpful because it has the capability to  reach out to the internet, invoke other APIs, and give us something in return. That's what we want to make use of.

[![Thumbnail 1020](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1020.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1020)

[![Thumbnail 1040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1040.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1040)

[![Thumbnail 1050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1050.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1050)

Something we need to add on top of that is a system prompt.  A system prompt is like a persona. I want to set some guardrails or pathways and maybe some boundaries so that it's easier to get further. In this case, I'm asking and giving as a prompt that it should only use APIs that are not  requiring any kind of authentication, keys, or authorization. Usually, we want to do that for the sake of simplicity. We're trying to get access to some external endpoints that  are not requiring that.

[![Thumbnail 1060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1060.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1060)

[![Thumbnail 1080](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1080.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1080)

The last remaining part that we need to take care of is to pass the system prompt  to the agent, and in addition, we also need to pass the tool. In this case, we only make use of one tool, but we can have more tools that we can make use of. We're passing the system prompt and the tool to our agent.  Let's try it again to see if there is a change compared to the initial question that we saw. I'm calling my agent again: "What is the weather today in Las Vegas?" As you can see here already, it found a tool that it wants to make use of. I'm not debugging all the information, but we can take a look at that in a second. What it tries to do now is find some APIs with the help of this agentic loop and routing to go somewhere and find out recent information about the weather. It found something, and we got in return something that seems very reliable. It's a difference compared to what we saw before, so we've extended our agent with tools.

[![Thumbnail 1150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1150.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1150)

[![Thumbnail 1180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1180.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1180)

[![Thumbnail 1190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1190.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1190)

[![Thumbnail 1200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1200.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1200)

### Transforming to Bedrock Agent Core: Deploying Your Agent to the Cloud

The next step, as we've seen, is that we have three packages we want to make use of. We use the first one as the base one for creating an agent, the  tools and agents package for making use of existing tools, and the third one is the Bedrock AgentCore package so that we can transform this to a Bedrock AgentCore agent and be able to deploy it into the cloud. There's not much needed to transform this one, but what a surprise, we need to import another class which is coming from the Bedrock AgentCore  package. We need to instantiate the class BedrockAgentCoreApp.   By doing this, when you instantiate this one, it's creating an HTTP server listening on port 8080 and has two endpoints that are important for a Bedrock AgentCore agent.

There is a ping endpoint, which serves as a health endpoint and is especially useful for multi-agent communication. The most important one is the invocations endpoint because it takes the prompt and listens to the input, typically a JSON file, and then proceeds with the further processing.

We also need to add a decorator as part of the agent. This is mandatory for any agent to have an entry point. We have the app.entrypoint decorator and then a function that has the payload that we pass through. It tries to find an adjacent attribute for the prompt. We are passing the user input, which is primarily the same as we did from the CLI, but now passing it as JSON and then returning it back. The last remaining point we need to take care of is adding the code to make the app running.

[![Thumbnail 1260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1260.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1260)



Your agent is now live and listening. This is because we have an HTTP server listening on port 8080 and waiting for requests coming from a client. I will switch over to a second tab and use Curl to make a request. I have a Curl command here trying to ask a question, such as "What is the weather today in New York?" This gets passed to the running agent listening on port 8080.

[![Thumbnail 1300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1300.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1300)



[![Thumbnail 1330](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1330.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1330)



You can already see that it is trying to make use of the tool that is passed through, and we are waiting for the response. This agentic loop, which was introduced on the slides at the beginning, involves iteration. This can take place once or multiple times. I have also seen questions like "I'm using Lambda. Can I now use AgentCore instead?" The answer is probably not in most cases, depending on what the use case is. Usually, Lambda is used to transform something, but you should not forget that this loop might take a couple of seconds, especially when we are trying to find an API we are not aware of because this is a decision taken by the LLM and the cycle between the agent and the LLM.

[![Thumbnail 1350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1350.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1350)



You can see that this took more than one iteration. There was at least a second invocation, but in return we got something that already makes sense. This is the response that we got back from the agent. To answer the question about whether you can get a streaming response from a call: yes, simple answer, yes, in a minute. That is a good question.

[![Thumbnail 1400](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1400.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1400)



[![Thumbnail 1410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1410.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1410)

### Deployment Walkthrough: Using Agent Core Starter Toolkit and Runtime Configuration



We are still running locally, which is not what we want to do. Usually when we start developing, it is locally. The next step we want to achieve is how to deploy it to the cloud. As mentioned before, we have a serverless runtime called Agent Runtime where we can run our agents. The next step is now to deploy it. There are multiple ways to achieve that. For production environments, you would use infrastructure tools called CloudFormation, Terraform, and so on. Something that exists when making use of Python is a toolkit that I have not introduced so far, but it becomes very handy as it gives you some possibilities with the help of the AgentCore CLI to deploy and configure some stuff. When you are doing this with infrastructure as code, you need to pass some attributes and some configuration items, and this is something we will see here in a second by making use of another package that I am trying to install now.

[![Thumbnail 1500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1500.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1500)



[![Thumbnail 1510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1510.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1510)

I'm trying to install this now. This is called the Bedrock Agent Core Starter Toolkit, and this is not mentioned in the requirements.txt because I just want to make use of it in the IDE.  As this is getting downloaded, I can now just say configure agent core configure and pass through my agent class. It's now going to ask me some questions that are mandatory and important to mention or you need to consider when you're using cloud formation or terraform.

The first question is what should we name the agent? If you don't pass a name, it will take the file name. We're good with that and taking this as standard. Do you have a requirements.txt file? Is it named requirements.txt? Yes, we are good. What kind of deployment configuration do you want to make use of? Bedrock Agent Core is GA for a couple of weeks now. It started with container or Docker deployment, and now it's even easier, very comparable to how you would deploy Lambdas. So you can use the first one, which is now the default one.

It would then zip all the assets needed together, upload to S3, and behind all the magic, it's going to get deployed to runtime. Why you should consider Docker as a second option is especially if you have specific requirements or dependencies that you want to adjust in your Docker file. But also one question might be: Python is good and fully supported. What about Java, Go, or other languages? You could theoretically make use of these other languages as well. As long as they are not fully supported like Python in that case, you would build a wrapper so that you have these endpoints that are mandatory: the invocation endpoint and the ping endpoint. That's where you would probably also make use of Docker.

We are good with the default option, which is number one. Which Python environment do we want to make use of? And yes, execution role is very comparable to Lambda. You want a role that has the necessary policies and actions needed to run the agent in your environment. If you don't have one, we are good to go with the default one, so it will take care of this as well. Free bucket where to upload it? I don't have one. I'm good to let one be created. Authorization configuration: you can use OAuth, or in that case I'm good with IAM authorization. Take this one.

You can also define some request headers, especially if you have multi-agent collaboration, which is very handy. We are good to ignore that as well. And last but not least, we have memory, which was mentioned in the slides at the beginning as well. If we are passing and having the communication in the user interface, we don't want to pass 50 or 100 lines of information. We want to memorize it. That's where we have short-term and long-term memory that you can make use of here as well. We will come to that in a minute. I'm going to skip this, and that's primarily it.

[![Thumbnail 1750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1750.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1750)

So what is happening now in addition is we have not skipped it yet. I have not skipped it, yeah, sorry, thanks. Yeah, so one of the advantages is if you're using this data toolkit, it gives you immediately also some best practices on how to proceed. So agent core launch would be the command to deploy the agent, which would be the next step. In addition, what also happened is it's creating a YAML file locally  based on what you have passed through, and for all further communication with this startup toolkit, it will reference to this one. So I will skip this.

[![Thumbnail 1770](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1770.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1770)

[![Thumbnail 1780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1780.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1780)

What we want to do now is invoke Agent Core launch.  And it will show you what is happening next. So it's packaging all assets needed,  all imports that were considered in the requirements.txt file, and it's creating the ZIP file, uploading into S3, creating the execution role, and deploying it to the runtime. To showcase you this in the console, it's going to look like this.

[![Thumbnail 1810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1810.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1810)

[![Thumbnail 1830](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1830.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1830)

[![Thumbnail 1840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1840.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1840)

[![Thumbnail 1880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1880.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1880)

[![Thumbnail 1890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1890.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1890)

[![Thumbnail 1900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1900.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1900)

[![Thumbnail 1910](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1910.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1910)

[![Thumbnail 1920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/1920.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=1920)

Let me increase this a little bit.  So you have this Agent Core service, which you want to start. You have then here some of these capabilities that we introduced at the beginning, and let's start with runtime. You can then see here immediately all the agents that you have deployed and  running in your account in your region. In that case, I'm in US East One, North Virginia, and I have here already my running agent.  If I'm switching back, I also have here a response in a positive way. You will get also here immediately a possibility to tail on your CloudWatch logs. So in case something happens, observability is a very important aspect also of Agent Core. Open telemetry is fully supported. We have all the traces and responses that we might see also in a second. Now we can invoke this from the CLI, or let me switch now to introduce you to a user interface.  Which more or less is listening to all the agents that you have deployed in your account.  That's the one that we have deployed a minute ago. And I can now ask more or less the same questions as we have done before. What is the  capital of something different? Germany. And the initial  invocation of the agent may take one or two seconds longer  as it's starting to spawn up, but will then remain in the session. You can see in a very raw way just the JSON output. It's getting us something back from the LLM. I can do now the same with something we have now seen three times, so I will not bother you with something we have already seen. I'm happy to switch over to my colleague Jan, who will try to make use of the existing agent and extend it with more capabilities and also attach it to the legacy app without touching the legacy app.

[![Thumbnail 2010](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2010.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2010)

Sure, you defer the application to the cloud in the second iteration. Why did it take the agent twice to do it? You can debug the whole cycle and what is going on. So the whole communication and the cycle between agent and the LLM you can for sure trace this. For the sake of simplicity, I have skipped this now, but you would then see it could be because it did not find the API or it found an API that was not able to respond in a given time. You will get all this information out as part of your debug information. In that case, it was not disclosed in this demo, but usually there are reasons why an API is  taking too much time or not responding. I'm not getting it in an exact manner. Everything is disclosed in the output as you define in your debug configuration. But fair question, especially for HTTP requests, this may take longer because it's kind of a black box where it goes. If you then use something that you have more control over, which you will see now in a second, it usually is much faster because we have the expectation on the endpoints we want to take care of. Jan will introduce you to that.

[![Thumbnail 2080](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2080.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2080)

[![Thumbnail 2100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2100.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2100)

### Integrating with Legacy Applications: Building a Unicorn Store Agent Using Gateway and OpenAPI

Also, to add on this one, adding a general tool like HTTP request means the LLM is tempted to use it for everything, right? It might know what the capital of Germany is, but it might ask an HTTP endpoint nonetheless to validate it's really true. So these general tools might tempt the LLM to do stuff which we don't want to do. Looking at your faces, you want to see some legacy applications, right? You're missing it already. So we do have a legacy application, and I have no idea what it  is doing. Of course, I have, but let's assume we just got this on the table and we have to add some agentic AI stuff to it. So it's running on ECS. It's some Java application. It's using some database. Let's check it out what it is doing.  And I heard you all love unicorns, so the great part is it's a unicorn store and we can shop unicorns.

[![Thumbnail 2140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2140.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2140)

So let's go ahead and add an agentic capability for our users to not only use this website, which is quite old, but also use an agent to shop for unicorns. For this, we have the first issue: I don't know the endpoints the application provides. I have no idea which REST endpoints are available. So my first idea would be to use Amazon Q Developer  and ask it to create an OpenAPI specification from my application. That's quite simple. I don't know what's going on inside the application, but let's use Q Developer to figure it out. So I'll ask it to please create an OpenAPI spec from my legacy application and please ignore text/plain endpoints because we don't want those.

[![Thumbnail 2180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2180.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2180)

[![Thumbnail 2190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2190.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2190)

[![Thumbnail 2200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2200.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2200)

[![Thumbnail 2210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2210.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2210)

[![Thumbnail 2220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2220.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2220)

[![Thumbnail 2230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2230.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2230)

[![Thumbnail 2240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2240.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2240)

[![Thumbnail 2260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2260.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2260)

While Q Developer is working, I will show you the result in a second, but I prepared the result already, and I will pick this up  to use. So we do have an OpenAPI spec, and I swear this has been generated by Q Developer. We will just pick this OpenAPI spec  and switch over into the Amazon Bedrock AgentCore console into the gateway. The gateway has been introduced as a way  to host tools basically, and we have provisioned one gateway already. You can add several targets to a gateway.  Targets can be, and we will see that in a second, targets can be MCP servers, which you find on any open source GitHub, for  example. It can be a Lambda function and it can be REST APIs. So we can go ahead and say REST API OpenAPI schema  and inline schema. That's great. We are just pasting the whole API schema that has been generated  by Q Developer in here. For authorization, we are selecting an API key, which we don't need. Our application is accessible from the public internet, but in case you could also configure OAuth or an API key. I will add this as a target to my gateway. That's great. So now we have a second target. We will get to the Lambda target  later on, but now this gateway is able to interact with our application using the OpenAPI schema.

[![Thumbnail 2290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2290.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2290)

[![Thumbnail 2370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2370.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2370)

So what we have to do next is we have to update our agent to make use of this gateway. That's the next step. To show you what we are going to do, I will quickly switch over to this architecture. You can see the legacy application part, right?  And we are going to add the gateway. We are going to use our agent on the left side. We're using the front end that you have seen already, and the goal is that our client, our agent, is using the gateway  and then the OpenAPI specification to invoke endpoints in our legacy application. So we are not touching the legacy application in any way. We are really enhancing it. Just to add a sentence because I had a recent conversation with a customer who had the same challenge. They have a legacy application. There is an OpenAPI schema that you can write or that exists or that you can generate with AI. The question was, okay, but where do I need to write the code? You don't need to write the code. The translation, that's where the gateway comes in and makes it so super easy. It's the OpenAPI schema that translates all the paths into tools that you can run and invoke from your agents. So you don't need to touch your legacy app. You don't need to write code. You're writing code to connect to the gateway, which can have multiple targets, but you can communicate without making any changes or writing any code to make use of your legacy application.

[![Thumbnail 2380](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2380.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2380)

[![Thumbnail 2390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2390.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2390)

Then we are going back to the IDE. I have great news. Q Developer was able to create this OpenAPI  specification file. I will show you, so it was able to create it. We could have used it, but I wanted to speed up things. So what we are going to  do now is we have to enhance our agent like Fran said. We have to add the capability for the agent to invoke the gateway, which means fetching some credentials and configuring the gateway.

[![Thumbnail 2410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2410.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2410)

[![Thumbnail 2420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2420.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2420)

I will guide you through it. I will copy stuff over to make it more quick, but we will get there.  The first thing we have to do is increase the size a bit to make it more visible.  What we are going to do is add some more imports at this point. I will guide you through it. I'm setting up the logging because I want to be able to see what the agent is doing. As I mentioned, we do have to get some parameters or some secrets. We have to authenticate towards the gateway and we also have to get the gateway URL.

[![Thumbnail 2440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2440.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2440)

[![Thumbnail 2460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2460.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2460)

[![Thumbnail 2480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2480.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2480)

 What I'm doing here is defining some variables. The gateway URL is the address where our gateway is reachable. I'm defining the memory, which we will get to later, and I'm also defining the agent core gateway or provider URL. This is used to get an access token. The agent is calling the OAuth provider to get an access token, and with this access token, it's allowed to access the gateway. I'm defining a model ID as well and a system prompt which says you are an agent which is helping with shopping unicorns.  That's it for now. We are getting the parameters.  The next step is we have to get this access token, and the great thing is in the Strands SDK there's a decorator called requires_access_token. We are just passing in the OAuth provider URL, and we are getting back an access token. That's quite nice.

[![Thumbnail 2490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2490.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2490)

[![Thumbnail 2500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2500.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2500)

 Now we have to change the agent initialization a little bit. When we are talking about tool usage and gateway usage, we have to take care of several user sessions. Users do have sessions with an agent, and we have to handle that internally to make sure that a tool is bound to the session context of a user.  For this we will add the init_agent method, and yes, that's a bigger one, but I will guide you through it. In this init_agent, we are trying to get the agent from the context. All the context stuff that you are seeing here is completely related to session management. It's all about separating user sessions and getting an agent for this user session.

[![Thumbnail 2540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2540.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2540)

[![Thumbnail 2590](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2590.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2590)

 If you already have an agent, that's great. We just return it because it has been initialized for this user session already. If not, we want to initialize it and get the gateway access token. As I mentioned, you need to authenticate towards the agent core gateway. We are doing this using the method we just created, which is getting the access token. Then we do some sanity checks, and that's fine.  The next step is we are creating an MCP client. Our agent will now use MCP to communicate with the gateway. The MCP client takes our gateway URL and the gateway access token, and we are setting a timeout. Two minutes timeout for a call is fine for our demo.

[![Thumbnail 2630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2630.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2630)

[![Thumbnail 2640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2640.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2640)

Afterwards, we have the gateway client. We have to start it, and then we save it in the session. That's happening here. For the next request the user does, the session is already started, and we will just pick up the existing agent, including the session.  We are creating the model.  We are selecting a specific model in this case, and then we are initializing the agent like we did before. We are passing in the model and we are passing in the gateway tools. I was jumping over this one, which is quite important. After initializing the MCP client, we have to fetch the tools which are available. Our agent is running in one place and the gateway is running somewhere else, and the agent has to fetch the available tools from the gateway to inject it into the prompt so the LLM can make a decision.

[![Thumbnail 2690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2690.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2690)

[![Thumbnail 2700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2700.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2700)

 That's what's happening here. On the gateway client, we are invoking the list_tools_sync method and we are retrieving all the tools, meaning targets and for the OpenAPI specification target, all the methods available. We are getting back the tools, we are passing this to the agent, and storing the agent in the context so we don't have to do it again in the next session.  We are nearly done. Just a small step left.

[![Thumbnail 2710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2710.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2710)

[![Thumbnail 2730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2730.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2730)

We're now looking at the lifespan manager. You can see that we've been using the  Bedrock Agent Core app before, but now we're passing in the lifespan. This is also completely related to session management. I won't go too deeply into it, but basically it's tying the agent and the gateway client to this session, and the Bedrock Agent Core SDK extension takes care of this. 

[![Thumbnail 2740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2740.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2740)

[![Thumbnail 2750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2750.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2750)

[![Thumbnail 2770](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2770.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2770)

Great, we're nearly done. I just want to make it a little bit more beautiful, and there was a question about streaming. We're doing that now.  Let me go over the agent invocation.  As you've seen in the user interface, we were returning the JSON, and that wasn't really user friendly. If we want to offer an end user experience for shopping unicorns, we have to do some parsing. I'm invoking the agent here and then parsing  the results and just returning the real text.

[![Thumbnail 2790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2790.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2790)

[![Thumbnail 2810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2810.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2810)

I'm also doing some sanity checks to verify that we have a session ID and that we have a user message, so a prompt coming in. Then I'm initializing the agent and invoking it.  That's all we had to change, and this is a one-time change that you have to do. Now it's as easy as Franz mentionedâ€”it's as easy as adding a second target to the gateway and the agent will automatically pick it up. Let's see how that works by updating our agent. 

[![Thumbnail 2820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2820.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2820)

[![Thumbnail 2850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2850.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2850)

I'll just do an agent core launch. Like we've seen before, I've configured this stuff, so I have a YAML file here.  We will now update the agent and see if we can get some information out of our legacy application. Let me switch to the console to take a look. We do have a one-time hereâ€”this is  the session name agent, and it has been last updated at 12:18. That's exactly what happened. Let's switch over to the browser and take a look at our front end. I'll just reload this one. We are creating a shopping session. These are the sessions. Shopping session is the session ID that gets passed to the agent one-time, and based on the session ID it will initialize an agent.

[![Thumbnail 2890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2890.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2890)

[![Thumbnail 2900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2900.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2900)

[![Thumbnail 2910](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2910.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2910)

Which unicorns do we have in store? Let's see. The first request, as Franz mentioned, requires the one-time to spin up and the agent to be initialized.  This includes fetching the access token and fetching the tools from the gateway, so the first request takes some time.  But afterwards, the requests are quite fast.  That's quite nice. We get an answer that we have three types of magical unicorn products: a unicorn float, a unicorn party dress, and the unicorn hip hop. That's great.

[![Thumbnail 2960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2960.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2960)

[![Thumbnail 2970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2970.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2970)

### Adding Memory and Observability: Complete Shopping Experience with Tracing Capabilities

Based on the OpenAPI spec, the agent was now able to figure out the user's intention and give me the products. I would like to shop for a unicorn, so I would like to go ahead and say let's buy a party dress, for example. But for this to work, we have to create a user account and the agent has to remember which unicorn I want to shop. So we will make use of the memory now because memory allows the agent to retrieve previous messages that I have sent and that it has answered. I promise compared to what we  did before, it's a really small change. Let me quickly switch over. The memory one is really quite easy. 

[![Thumbnail 2990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/2990.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=2990)

We're going back into the IDE. When we are initializing the agent right here, we are just adding the agent core memory configuration, so we are passing in the session ID.  As I've shown you in the user interface, we can create a new session, and of course we want the memory to be separated between sessions, right? I don't want user A to retrieve information from user B.

[![Thumbnail 3040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3040.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3040)

[![Thumbnail 3050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3050.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3050)

[![Thumbnail 3060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3060.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3060)

[![Thumbnail 3070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3070.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3070)

[![Thumbnail 3080](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3080.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3080)

[![Thumbnail 3100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3100.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3100)

[![Thumbnail 3110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3110.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3110)

[![Thumbnail 3120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3120.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3120)

[![Thumbnail 3130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3130.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3130)

[![Thumbnail 3170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3170.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3170)

We could add the actor ID, but we're not doing that today. We will separate on the session ID. The next step is that we have the agent core memory config, and we are creating a session manager. In this case, it's an agent core memory session manager, and we are passing this over to the agent. That's the whole thing. The memory has been created by me before, but as you have seen in the CLI, you could use this CLI to create a memory for you, so that's quite convenient.  The change to the agent has been done.  Next step, we have to update the agent. That's a local agent call. So it will now update the agent, and afterwards we are going to shop for a unicorn. Let's go back to the console to check what's happening.  I can quickly show you the memory that has been provisioned here. As you can see, we do have a memory available.  We can also see that events expire after 30 days, so nothing super interesting here, but not to forget about observability.  To showcase this as well, we can take a look at observability in a second. I quickly want to buy one unicorn at least. The agent has been updated, so we will go back to our front end and create a new session, which is the memory shopping session.  I want to buy a unicorn.  I want to show the guided experience that the agent will provide. I was quite unspecific in my intention.  Well, quite unspecific. I expect the agent to deliver the available unicorns to me, and then the agent will guide me through account creation and stuff.  That's great. The agent is offering me the available unicorns. I'm going for a party dress definitely. Let's go with the party dress.  The next question should be whether I have an account or if the agent would like to create one. I want to create an account. It needs my name, first name, last name, and my email address.

[![Thumbnail 3190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3190.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3190)

[![Thumbnail 3200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3200.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3200)

[![Thumbnail 3210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3210.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3210)

[![Thumbnail 3230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3230.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3230)

The agent should figure out all the details, and in the background, this loop will take some time because the agent will create an account and add the unicorn to my basket in this account. This legacy application has no checkout process, but we will look into the application and see that it really worked.  The account has been created, and I do have a unicorn party dress inside my basket. That sounds fantastic. Let's go to the store.  I'm going to log in. The password is not being checked, so I'm just using anything in this case, but we can see I'm logging in and I do have one item in my cart.  By just adding an OpenAPI spec to the gateway, the agent is now really able to interact with my application, which I have not touched in any way for this example. Maybe I should show in the OpenAPI the POST method that was used for that case. 

[![Thumbnail 3260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3260.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3260)

[![Thumbnail 3270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3270.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3270)

[![Thumbnail 3280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3280.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3280)

[![Thumbnail 3290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3290.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3290)

I would like to show you some observability parts for the last one or two seconds because adding all these capabilities to the agent might get quite hard to understand what is happening. For this, we can enable tracing on the agent, one time on the memory, on the gateway, and what this allows us to see is a whole overview of what is going on.  We can have an application map. If we go into the application map and expand that, we can see our agent right here. That's the agent running on Agent Core.  We can see that it is using the Bedrock Agent Core service. Of course, we can see that it is using our gateway.  We can see that it's using the memory and the OAuth, right? We are getting an access token.  We can also see that it is invoking Bedrock and the LLM really did 8 requests to the LLM.

[![Thumbnail 3310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3310.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3310)

[![Thumbnail 3320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3320.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3320)

[![Thumbnail 3340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3340.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3340)

We can also see that we are using Sequences Manager to fetch the OO  secret and the gateway URL. We get real insight into what's happening, and the really cool thing is  that the gateway is invoking our unknown remote service. So we can see that the gateway is invoking our application, and we do see that several requests happened to this one. I think that's a great way to really see what the agent is doing and also how many requests to an LLM it's making  in a great visual way.

[![Thumbnail 3350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3350.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3350)

To wrap this up, these three QR codes, especially the third one, all those demos that  exist. The third one is a large GitHub repository with a lot of tutorials. The second one has a lot of use cases with ready-to-deploy CloudFormation templates that are primarily showcasing what we tried to do now in 60 minutes. We had some stretch tasks that we wanted to show you today as well, but with respect to the time, it's not feasible. We really encourage you to make use of the Tekita repository. Deepali, do you want to wrap up with the last one?

[![Thumbnail 3400](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/5adf4bc85cd25503/3400.jpg)](https://www.youtube.com/watch?v=_-X-N0J02UI&t=3400)

No, I think you did it. I hope you guys enjoyed our code walkthrough. Hopefully you're taking something back home to try out in your personal environments or your company's environment. So enjoy the rest of your day. Thank you for attending, and please provide your feedback if you loved our session. Thank you.  Thanks. Thank you.


----

; This article is entirely auto-generated using Amazon Bedrock.
