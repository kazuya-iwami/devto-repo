---
title: 'AWS re:Invent 2025 - Turn unstructured data in Amazon S3 into AI-ready assets with SageMaker Catalog'
published: true
description: 'In this video, AWS experts and Bayer''s Principal Engineering Lead discuss building AI-ready data foundations for unstructured and multimodal data. Navneet Srivastava explains three key pillars for data readiness: contextual information (metadata, ontologies), tool provisioning (APIs, MCP servers), and data maturity. Shiv Narayanan demonstrates SageMaker Unified Studio and SageMaker Catalog, showing how to catalog unstructured S3 data, create knowledge bases with Bedrock guardrails, and deploy compliant chat applications. Avinash Reddy Erupaka from Bayer shares their real-world implementation using distributed data mesh architecture, migrating 300 terabytes of biomarker data with ALCOA compliance controls, and deploying agentic AI solutions that reduced biomarker data harmonization from one week to automated processing, accelerating clinical trial decisions.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/0.jpg'
series: ''
canonical_url: null
id: 3086755
date: '2025-12-05T15:01:36Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project enhances multilingual accessibility and discoverability while preserving the original content. Detailed transcriptions and keyframes capture the nuances and technical insights that convey the full value of each session.

**Note**: A comprehensive list of re:Invent 2025 transcribed articles is available in this [Spreadsheet](https://docs.google.com/spreadsheets/d/13fihyGeDoSuheATs_lSmcluvnX3tnffdsh16NX0M2iA/edit?usp=sharing)!

# Overview


ðŸ“– **AWS re:Invent 2025 - Turn unstructured data in Amazon S3 into AI-ready assets with SageMaker Catalog**

> In this video, AWS experts and Bayer's Principal Engineering Lead discuss building AI-ready data foundations for unstructured and multimodal data. Navneet Srivastava explains three key pillars for data readiness: contextual information (metadata, ontologies), tool provisioning (APIs, MCP servers), and data maturity. Shiv Narayanan demonstrates SageMaker Unified Studio and SageMaker Catalog, showing how to catalog unstructured S3 data, create knowledge bases with Bedrock guardrails, and deploy compliant chat applications. Avinash Reddy Erupaka from Bayer shares their real-world implementation using distributed data mesh architecture, migrating 300 terabytes of biomarker data with ALCOA compliance controls, and deploying agentic AI solutions that reduced biomarker data harmonization from one week to automated processing, accelerating clinical trial decisions.

{% youtube https://www.youtube.com/watch?v=5pfmkyh3I_c %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/0.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=0)

### Introduction: Unstructured Data and AI Foundations in Life Sciences

 Thank you all for attending a session that talks about unstructured data and different data modalities, and how you can build strong foundations for AI. We're very excited about this session and excited to share some of our experience in the real world as well. We couldn't be more thrilled to be here with you. With me on the stage, I have Avinash Reddy Erupaka, who is our speaker from the customer side and a leading principal engineering lead at Bayer. I also have Shiv Narayanan, who is our product lead for SageMaker Unified Studio. Throughout our session, we're going to be looking at multiple demos as well as some real world examples. So thank you, Avinash and Shiv.

[![Thumbnail 70](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/70.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=70)

I just want to start by asking how's everyone doing? I know it's a virtual setting and I cannot hear you, but that's all good. Thumbs up is good. What we have done today is structured our conversation and story in four different sections.  We're going to talk about a very important topic called data readiness for AI. We are talking about unstructured data today, among other modalities, but it is important for us to align and land on this foundation that talks about how you build your data platform which is ready for agentic and AI workflows and things like that.

We're also going to look at different data modalities. My name is Navneet Srivastava, and I lead the data and analytics for AWS for Life Sciences customers. Most of my examples are coming from the life sciences world. Having said that, a lot of my other partners and colleagues in the organization work with different industries, and I see a lot of similarities that we're going to talk about. Then we're going to look at the demos for Amazon SageMaker Unified Studio and Amazon SageMaker governance to see how you can build a platform that can serve not only structured but unstructured data. Finally, we're going to hear from Avinash on the real world examples and use cases from Bayer.

[![Thumbnail 140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/140.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=140)

### From Data Mesh to Agentic AI: The Evolution of Data Paradigms

I want to start with this slide, which I'm sure you all are very familiar with, or at least the concept.  As you know, a lot of interest and a lot of work is being done in building generative AI and AI applications, agents, and agentic AI applications. This is a 40,000 foot view, and of course we're not drilling down into every detail, but if you look at this pyramid, at the bottom of all this is the data foundations. Data foundation is something which is evolving and changing with the need and the kind of modalities that we have and also the type of agents that we are writing.

[![Thumbnail 190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/190.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=190)

To write an AI application or an agentic application, you need to rely on the data foundations. Today we're going to talk about how you build that, what are some of the best practices, and what you can use on AWS as an example. So we're going to start with this today.  A few years back, there was a paradigm in data called Data Mesh. Have you heard of that? Some of you might have heard of Data Mesh. It was an interesting paradigm, actually very timely at that point, because that was the first time someone was building a paradigm shift on data that involves people, process, and governance.

Governance wasn't new before that. There were Master Data Management systems and data governance leads and things like that, but the distribution of data assets across your organization was something that Data Mesh was targeting along with people, process, and technology. In the last couple of years, we have seen the same paradigm shift on the generative AI side. Keep that Data Mesh concept in mind because I'll try to merge them together here to show how you can leverage your existing platform in actually serving up your agents.

We started from traditional AI and ML. This is an era where you're writing neural nets, deep learning models, machine learning models, statistical analysis, regressions, and you name it. Most of the uses there involved having a notebook or an art studio or something like that, which enables your data scientists to run analysis. This is the typical workflow. Then came generative AI with large language models, building summarization, building notes, and building other sorts of content that can be leveraged for your business.

But with the introduction of generative AI-based workloads, there's another thing that was very much important along with the data, and that is the context. That's where you have technologies like RAG. Lately, we are seeing a lot of interest and a lot of workloads that customers are running, building agents, which is basically in my opinion a unit of work that gets a specific business metric or a specific work done for you. We're looking at multi-agent collaboration now, so it's not only one agent, but a combination of agents with orchestration, with chain of thought reasoning, and all those things that help you build a workload that serves your business. There are several examples in this space.



### Multimodal Data Science: Integrating Structured and Unstructured Healthcare Data

Now, what is important when you think about building data and building these agents is that the one common theme between the two is how you are utilizing your data platform to serve up these agents and how that differs from what you were doing previously. As you see in this slide at the top, we have the foundation modelâ€”the models that you would be utilizing to build these agents. But that alone is not sufficient. You need enterprise knowledge at the bottom, as it says in the bottom of the slide. Think about the shift in the data paradigm with the data mesh, and think about the paradigm shift in generative AI, which in this slide we're calling multi-agent collaboration or a mesh.

[![Thumbnail 350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/350.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=350)

Data is no longer the only product that you're sharing across the organization. You're also sharing agents and other things. AI is only as smart as your data, and data can be a different type. This is a life sciences example. In your organization, you may have your existing dataâ€”your relational databases, your warehouses, your S3 data, your S3 tables, or one of our partner solutions. This data typically is largely structured and also unstructured, but mainly what we have seen is that you have rows, columns, some sort of a Parquet document, all stored raw, but you can query that. 

The new data that you're creating is where we're seeing a lot of data getting created in an unstructured way. In my example, and then Avinash will talk about that later as well, a lot of data is coming from these instrumentsâ€”the lab instruments. A lot of it is coming from your genomics information and gene information, and other verticals too, like social networking, your clinical notes, or images, PDFs, and things like that. All the data that you're creating is largely unstructured. Now you have to work with both. You cannot leave the structured data behind. You have to make sure that your guidance and your implementation has both of those things.

[![Thumbnail 430](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/430.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=430)

Then there is third-party data. This is what you acquire from other partners and other sources. So how you combine these different data assets and spread that in a data mesh-like setting with the right pillars so that you can serve up your agentic platform as well as human usage and things like that is an example of multimodal data science. 

Now, even though you're not from the life sciences healthcare industry, it still is very much relevant for you. At the center of this diagram, we have somebody called a patient. A patient is someone who has certain data records like admissions, discharges, labs, conditions, and procedures. We all have that, right? We've all been to different healthcare facilities and we have this data.

If you note that you have the EHR data, which is largely structured other than the clinical notes and the summaries, but you also have the clinical notes, the dictation in the physician room, vaccination data, or social geographic data. This comprises multimodality in any organization. So you want to make sure that as you look at this example, you identify the modalities in your specific lines of business and identify the different types of modality, and then create a common model that can help you govern the data and help you build the agents and things like that.

[![Thumbnail 510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/510.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=510)

On the right-hand side of the patient, you have the OMICS data. This also has a large volume, like for example microbiome, metabolism, or the proteome. All this data that you have is largely unstructured and requires a great deal of analysis that you need. 

### Building Blocks for AI-Ready Data: Context, Tools, and Maturity

Now, you might ask that you've been building your data agents and your data platform for a number of years now. Your data is very good. You don't have to do anything else. What is it that you need to do to make your unstructured and structured data something like what we've seen in the previous slide ready for AI? This is a very small example. On the left, you see the current state, which is a state of data scientists and data engineers interacting with the data. A researcher investigating drug interaction knows where to startâ€”a database, a molecular databaseâ€”that can then go and understand the significance of specific protein bindings and things like that. They start with a very narrow focus approach, and they know exactly what they're looking for.

You may be having the right quality, the right access, and things like that, and they're good with that. The challenge is that it doesn't scale. If you scale that to hundreds and thousands of data scientists, if you scale it to hundreds and thousands of different data models, chances are you need something that can help you scale. This brings us back to the other side, which is that you can write agents that can go against this data and really scale it further. What is the challenge there? It starts with speculative exploration, because you're pretty much throwing every single data element to those agents, and then they're doing some analysis. For example, in this case, I have an agent tasked with analyzing clinical trial effectiveness that might initially request all the available trial data and then further filter it down.

So what is the right balance? The reason it's important for us to note now more than ever is that when you think about the right balance between how much you want to provide to the agents and how much you don't want to provide to the agents, the data modality plays a big role. For unstructured data, a lot of data is something that an agent can bring value out of.

[![Thumbnail 620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/620.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=620)

For structured data, you may require far more governance control and similar considerations. We have these building blocks that you should think about at a high level. My colleagues will go deeper into some of these  topics, but if you look at this one, we are saying that you build data ready for AI using three building blocks. The first building block is contextual information. You create data ready for AI by bringing the right context to the data. The right context means several things. It could mean your enterprise knowledge, your ontologies, your metadata, your business metadata, and similar elements.

The second thing is that your data platform is the tool provisioning. This is how someone is going to be accessing your data. Remember Data Mesh? They had this concept called data product endpoints. A data product can be called using an API or SQL or something similar. You want to make sure that your data platform is ready to be accessible by different tooling and resources, something like an MCP server or another agent. Finally, there is maturity. This is a bit tricky because data maturity for structured data means different things, and for unstructured data it means different things. However, it does not matter to your data scientists because they want data to be fully matured. As you think about modalities and unstructured data, I would highly recommend that you look through these three different pillars.

[![Thumbnail 710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/710.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=710)

### Metadata as an Intelligent Amplifier: Unified Governance for All Data Types

How many of you are actually utilizing your business metadata as the context information for your data assets? I can tell you that metadata is one of the largest wealth of information outside of your data that can provide a lot of information for your agents to work with for your outcomes.  If you look at metadata from a few years back, it was largely treated as documentation. I remember sitting with my team working on metadata, building data dictionaries that explained what data is. Documentation, pretty much. You go through multiple Word documents and multiple data dictionaries. It was not bad and very useful, but it was largely documentation.

Whereas now in the contextual world, and by the way, data context metadata is just one of the contexts. There are other contexts depending on the industry that you work with. Now in the generative AI era, metadata is actually an intelligent amplifier. You can use metadata for business context, your glossaries or enterprise knowledge, something the data steward can work with, and relationship discovery across domains as an example. Of course, there is real-time trust. Think about your metadata, and it is even more important for your unstructured data because with structured data I can still query and make some sense out of it. I may have at least basic information of the columns that it has, but for unstructured data it is largely unknown to me until I actually look inside the file and see what is going on.

[![Thumbnail 790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/790.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=790)

Therefore, it is more relevant for you to think about contextual information. You build your data platform with those three pillars in the context, starting with business metadata. So how do you get your unstructured data ready for AI?  On this screen you see that you have different types of sources. Some video transcription is coming, some plain documentation is coming. The two things that I would like you to take as an outcome of this talk are, of course, this is a complex topic. As you start working, I am not overly simplifying any of it, but the two areas that we will be focusing a lot today are one, how do you build a unified governance of your data irrespective of its type and modality. Even if it is structured or unstructured, your data needs to be treated the same way, and so do the agents.

The second thing is specifically for unstructured data, how do you use some of the capabilities that we have in Amazon Bedrock and Bedrock Agent Core and Amazon SageMaker that you can utilize to build insights from the data. Remember, governance is first, building insight is second. Those are the two areas that we uniquely focus on today in regards to unstructured data. But as you can see, they could be structured plus unstructured here as well. In most cases, like in my patient example, you have both of them. It is important for you to understand how you can merge the experience there as an example.

[![Thumbnail 860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/860.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=860)

### Data Foundation Layer: AWS Architecture for Healthcare AI Applications

I am going to talk a little bit about the data foundation layer,  which is something very much linked with what I presented earlier on the three topics. Look at the bottom of this layer. We call it data readiness for AI. This is where you have the data foundations, the structured, unstructured interoperability and similar elements. This is how you store your data for best performance and cost modality. If I have data in Iceberg, I would store that in S3 tables as an example. If I have unstructured data, I store that in an S3 general purpose bucket. If I have warehouse data or structured data, I will store that in RDS or a data warehouse or something similar. If I have unstructured data, I will simply store that in my S3 buckets and then utilize it.

However, how we store the data should not guide the architecture upstream. It is just the storage at the end of the day. What guides the architecture upstream is how you interact with the data. That is where the interoperability is very handy. It is something like Iceberg-compatible data as an example.

This is very handy. On top of that, to have your data ready for AI, you have context, tools, and maturity. Remember those three pillars. Context is extremely important for your agents to work with your data. Without that, it's going to be speculative exploration for the most part. Context is not only business metadata. There are things like clinical ontologies in my world, in your world could be other ontologies and enterprise knowledge and things like that.

You have that platform, then you start building agents. In my case, healthcare life sciences agents, but you may be having agents specific to your industry. We have an offering there which you can use with accelerators that our team has built. You have agentic workflow, you have data accelerators, all that you put in there. Then you build a governance layer with FAIR principles. Everybody knows what FAIR is, I'm assuming: findable, accessible, interoperable, reusable. The L is the lineage, which is something that we've added as part of it, and it's interesting to know that even lineage can act as context to your data, how the provenance, the transformation and things like that.

[![Thumbnail 990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/990.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=990)

Then after that you build an experience layer. This is for your end users like you as a developer or as an IT governance lead. You're building all this platform and then you build an experience layer with analytics, visualization, and chat. Those are the typical three that I've seen lately: SQL analysis, notebooks, or the chat agent experience. How do you do that on AWS? You have Amazon SageMaker Lake House. That's how you store the data: structured, unstructured, federated into existing sources and things like that. 

[![Thumbnail 1030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1030.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1030)

You have the context of the ontology, metadata, and knowledge graph. Your tooling is MCP servers and APIs, and of course the maturity is the quality. There are other maturity principles that you can follow. Amazon Bedrock and Agent Core are for running and building your agents and operationalizing production. Amazon SageMaker Catalog is a unified governance model through which you can unify your governance across any type of modalities of data, including unstructured data. Then at the top you have SageMaker Unified Studio for building your experience. 

You have Amazon SageMaker notebooks and data agents to accelerate your development using AI, and then your Amazon Quick Suite for you to build a chat agent experience for your customers. I have a sample use case for digital labs. It is very healthcare specific. The one thing I want to call out here is that on the left hand side you see there are different types of instruments from where the data is coming out. Like I said, every industry has something very specific to how they're collecting data. In my case, it's coming through that. All that part is not that super important.

What is important is that it's getting stored in the storage layer. Remember the previous slide where I showed you the data can be structured or unstructured. Focus on the storage and how you store it best. Don't store your unstructured data in a relational database. It's not a good idea. It's not a cost effective solution. Then we have the lineage, metadata, catalog, and governance built. So just those three pieces: start small, think big. Don't refactor everything. Your environment currently is good enough for you to build these components starting now.

[![Thumbnail 1120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1120.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1120)

Then you have the semantic layer, which is extremely important. The semantic is an extended concept of context. What are the semantics for your own organization? In my case it might be something like what is a brain tumor, what is diabetes, and what is a carcinoma. In your world it could be something else. The point here is that you build a semantic layer and then you build all these consumption models. So in a cloud environment, store your data effectively, build the right context, and then go from there. 

### Addressing Challenges in Processing Unstructured Data

Some of the challenges that I want to call out before I call upon Shiv are the challenges in processing unstructured data. So far we talked about the approach of data foundation and what is important for readiness and why unstructured data needs to be treated in a very similar way. Governance is of course a challenge. The governance of unstructured data is very different at the bottom level, but it shouldn't be different at the top level. The findability and access provisioning are challenges. Model and tool selection is a challenge too, where you have selecting optimal solutions and modality use cases.

There's a lot of manual processing for unstructured data, like data extraction, tuning, and parameters and things like that. Finally, orchestration is a challenge. Managing multiple models for unstructured data is not easy. Output integration is a challenge and things like that. So how do we address these challenges that can span across the governance of data and the usage of it? For that I'll call upon my colleague Shiv to talk about the next portion where we'll see some of the SageMaker capabilities to address these challenges.

### SageMaker Unified Studio: Helping Dr. Smith with Patient Care Through Cataloging

All right, hey folks, hopefully you'll be able to hear me. Great. So my name is Shiv Narayanan. I'm a product manager on the SageMaker team, the NextGen SageMaker. There are two services: SageMaker AI, which is the machine learning and artificial intelligence, and the NextGen SageMaker puts everything together. How many of you use SageMaker today? Awesome.

[![Thumbnail 1210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1210.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1210)

I wanted to put up my picture, but then I figured I might as well just put somebody who's from Adobe.  So today, my goal is to expand upon what Navneet said and show you a bunch of demos on SageMaker Unified Studio. This is Doctor Smith, and we're going to be walking through a journey. Doctor Smith is a neurooncologist treating brain cancer, and we're going to help him prepare for a meeting tomorrow with one of his patients.

One of the patients he's going to be meeting is a 25-year-old female who has been recently diagnosed with a neurological cancer. The meeting tomorrow is super important for Dr. Smith because that's the first time that she's actually meeting with him. The most important thing that Doctor Smith wants to do in that meeting is to instill hope. The way you do that in the most effective way is to tell the patient that I've actually seen patients like you, and you have hope simply because we've actually done this over and over, and there is really light at the end of the tunnel.

But what he's actually doing right now is staring at those documents, the unstructured data. In those documents, one of the couple of things that he's really scared of, like you probably might be also scared of, is the amount of incredibly insightful information that's scattered across this data. This data changes every single document. This is actually the reality of healthcare today. There is demographics data, there is medications, there are procedures and treatments, but there's also sensitive data.

Now it's super important for us to be able to provide Doctor Smith the required tools in order to make sure that he gains access to this data and the capabilities to use the latest generation technologies like large language models to help process and parse this and eventually help him prepare for this meeting. That's what I'm going to do now. We as a team are going to go through that to see how to actually help him prepare for that meeting. In order to do this, the most important thing is that obviously you have to have the right AWS services to do it, and at the end of the day, our goal is to actually build him a chat agent.

[![Thumbnail 1360](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1360.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1360)

[![Thumbnail 1370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1370.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1370)

This chat agent needs to be built with all the right governance controls in place. Traditionally, it was also a little difficult in AWS to do this simply because while we have all the breadth of the services, you have to hop on to different consoles. So what is the innovation that we've done in the past year to simplify these problems?  With that, I wanted to talk a little bit about the team that I'm part of and very proud of the Next Generation SageMaker.  This is actually your center for data analytics and AI. SageMaker is comprised of three important components.

The first one is the lake house architecture where you actually store all these documents that you saw. The next one is a catalog, the ability for you to make sure that you actually take all these unstructured and structured documents, catalog them, annotate them, provide the visibility of data quality metrics, associate glossary terms. And you have a Unified Studio that allows customers to build applications all the way from simple data engineering pipelines to extremely complicated machine learning models and also chat agents with ease, all without you having to switch different consoles.

[![Thumbnail 1430](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1430.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1430)

Before we dive into a demo of how we do this, let's walk through a little bit more details about the catalog first. How many of you use the SageMaker catalog today?  So what's different about the SageMaker catalog is, first of all, it's actually built on Amazon DataZone's business data catalog. That's it, it really is built on a very scalable model to begin with. The second important thing about the catalog is it's not just a catalog for structured data assets. It's a catalog for your unstructured data assets and a catalog for your business intelligence assets, so it's really much more broad.

We continue to enhance the number of types of objects that we support. You can also understand the quality metrics and the data lineage from that catalog. You can also understand the ability for you to search and you can subscribe to these assets and gain permissions to data in an auditable and compliant way. That is very unique about the permissioning model that has been integrated with the SageMaker catalog. In addition to it, there are other components that I'll be talking through my talk in terms of the guardrails and the responsible AI aspects that you'll actually see in a demo also.

The catalog is an extremely important component for Doctor Smith and his team because as a first step, what we want to do is to be able to take all this unstructured data, catalog them, make them discoverable, provide the right guardrails so that he and his team can actually get the right access controls.

[![Thumbnail 1520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1520.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1520)

### Demo: Cataloging Unstructured Medical Records in SageMaker

The next part is how do you build your applications. That's where we have the Unified Studio. So Unified Studio gives you the ability  in a single console to build all required apps that are needed for your data engineering work to the AI work.

For example, if you're a visual person and more into visual ETL development, we have a visual ETL that is available for you. If you're more of a code-based data engineering, you have notebooks that are embedded in it. If you want to build machine learning models, we have foundational models and the SageMaker AI models that are available in a model hub that you can take, train, experiment with using ML Flow, and then deploy. And if you're a generative AI developer, we have the ability for you to build chat applications and prompts with the necessary guardrails, all of them together. So that is the Unified Studio.

[![Thumbnail 1600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1600.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1600)

[![Thumbnail 1610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1610.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1610)

Now what we're going to do is watch a demo and I'm going to walk you through this. As a first step to help Doctor Smith prepare for his meeting, we're going to take all this unstructured data that's already available in S3, catalog them, and make sure that it's actually discoverable. That's step number one. Before that, let me quickly walk you through an important launch that we did a couple of months ago, which is the ability for you to catalog these unstructured assets. With this you can connect to S3  either to a bucket or a folder, take those assets, provide business context, publish those to the data catalog, and then make it discoverable. 

[![Thumbnail 1620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1620.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1620)

[![Thumbnail 1630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1630.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1630)

[![Thumbnail 1640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1640.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1640)

So with that, let's watch this demo. I'm showing you the Unified Studio and here what we're going to do is go to the data tab of that project.  As you can see here I have my lakehouse which is structured assets and then I have buckets. I'm going to connect to my S3 location, provide a name for the data lake, provide a description,  specify the URL where the medication records are stored, provide a role, and then we are going to hit the ability to connect. 

[![Thumbnail 1650](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1650.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1650)

[![Thumbnail 1660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1660.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1660)

[![Thumbnail 1670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1670.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1670)

What this does in the backend is actually going to create a connection to S3, and then it is going to first bring in all the assets that you watched in the previous screen which Doctor Smith was staring at.  These are all the unstructured data that you're seeing, and these are all the medications that you just watched in that. As a next step, what I'm going to do is catalog the entire bucket for brevity of this demo. You can actually catalog individual folders, but what we're going to do is add  some business metadata to the structured assets. 

[![Thumbnail 1680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1680.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1680)

[![Thumbnail 1690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1690.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1690)

This is the screen where you can add a lot of business metadata. To begin with, I'm going to start adding context in terms of the README file, and this is what was talked about regarding the context that is needed for the generative AI purposes.  I've added what exactly these documents are, provided detailed descriptions, the type of diagnosis, the medications that are there. I'm also associating glossary terms so in the catalog you have the ability to create a glossary  in a hierarchical way and then associate terms to these. This allows you to search and it also provides meaningful associations when your other customers who are working on SageMaker can understand and discover these assets pretty easily.

[![Thumbnail 1700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1700.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1700)

[![Thumbnail 1710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1710.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1710)

[![Thumbnail 1720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1720.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1720)

[![Thumbnail 1730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1730.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1730)

I'm going to go through a variety of terms and then select them and associate them  for these assets.   So now that we are happy with adding all those assets, let's go ahead and click yes and you also have the ability to extend this metadata with additional concepts called metadata forms. I'm not going to do that to keep this demo short and let's go ahead and publish this asset. 

[![Thumbnail 1740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1740.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1740)

[![Thumbnail 1750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1750.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1750)

[![Thumbnail 1760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1760.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1760)

[![Thumbnail 1770](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1770.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1770)

When you publish this asset, you've been working in your own local copy, so to speak. When you publish this, it now is discoverable by anybody and everybody, not necessarily the data, but they can actually view the metadata.  So now I just want to go to the catalog, make sure that I've actually published this right, and you can actually browse through the assets and you can see the type of assets, the glossary  terms that I associated, very easy for me now to basically say give me the patient data, give me the cancer diagnosis data. I can go through and look at different asset  types you might have seen like the different types of assets that we support there. We also provide a couple of other capabilities and extensions for this. It looks really great from my perspective  of how I've published metadata. I also have lineage, but this is basic data lineage at this point in time because we just have started to work and as lineage builds up, it's going to be built up pretty well in this.

[![Thumbnail 1780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1780.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1780)

So what I've done so far is taken those assets that were just in S3, that were not discoverable by anybody, and I've made them discoverable at this point in time for people to come in and start working. 

[![Thumbnail 1820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1820.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1820)

### Building Knowledge Bases with Guardrails: From Data Access to Chat Application Deployment

Now we're going to have a generative AI developer come in and do some work with this data. But before that, let's look at a few more concepts. SageMaker Unified Studio is one of the services that brings  all the structured and unstructured data together and allows you to build knowledge bases with ease. We provide the ability in one single place for you to come in and source structured and unstructured data and then easily build knowledge bases for your generative AI applications.

[![Thumbnail 1840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1840.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1840)

How many of you have built a knowledge base in Bedrock? So one of the things that all of us know is that Nani talked adequately about RAGs and their usefulness. These are the concepts or objects that make your foundational model more intelligent and your organization aware. By using a knowledge base, what you can do is enhance your existing large language models to provide more context of your organizational data.  What we do from SageMaker Unified Studio and SageMaker as a whole is allow you to create these knowledge bases with ease without having to navigate through multiple APIs, just simply with a few clicks of buttons. I'm going to show you how you can actually do that.

[![Thumbnail 1920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1920.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1920)

Now it's one thing to have a knowledge base, but the most important aspect is governing to make sure these models are grounded, to make sure that they're not hallucinating, to make sure that they're not being hateful, and to make sure that they're actually providing the right context by looking at the data that you have provided. For this, Bedrock offers guardrails.  With guardrails, what you can do is apply a bunch of filters that come out of the box to make sure that your models are grounded. In addition, you can also extend them with ease using simple natural language to make sure that your prompts and the results of the large language models that you're using are appropriate.

For instance, you could say don't show PII information or you could say I want you to be grounded with facts. You can do a lot with guardrails. What is unique about SageMaker's integration with guardrails is that it allows you to take your data from your catalog, build that knowledge base, and build those guardrails all in one single unified console. Then you're able to deploy these to your business users with ease. That's exactly what we're going to do next.

[![Thumbnail 1980](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1980.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1980)

[![Thumbnail 1990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/1990.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=1990)

We have a generative AI developer. Remember, we just cataloged as a data producer all these assets in our catalog.  As a generative AI developer, John comes in and just searches for a term: diagnosis. This is a very common term that occurs for many people. They just come and search and  immediately they're able to discover that asset. When they discover it, they're able to see the metadata and the glossary terms that have been associated with it. With a lot of confidence and discussions with their colleagues, they determine this is the right dataset that they need to build their knowledge base.

[![Thumbnail 2010](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2010.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2010)

[![Thumbnail 2020](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2020.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2020)

[![Thumbnail 2030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2030.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2030)

So one thing that John does here is ask for access to that data. This is the unstructured data access that he is requesting.  He has requested that access and he can actually view that he's requested access. Now the data producer gets this as a notification that a generative AI developer has asked for access.  At this point in time, they can click and talk to the legal teams to make sure that they understand what the use case is for this particular asset.  Then they can approve or reject this particular access.

[![Thumbnail 2040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2040.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2040)

[![Thumbnail 2050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2050.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2050)

In this case, after discussions with legal and other compliance organizations, they are approving to make sure that they can go ahead and build a chat application or feed this into a knowledge base.  So now we've gotten John access to that data. This is great. John goes into his project, goes to the data tab, and now confirms that he has access to that S3 buckets.  He now has access. So the next natural step is to go ahead and start building the chat application. I remember I talked about two concepts: the knowledge base and guardrails. That's exactly what we're going to build.

[![Thumbnail 2070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2070.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2070)

[![Thumbnail 2080](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2080.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2080)

Look at how easy it is to build that with Unified Studio.  You just go in there and create a knowledge base. It provides the name of the knowledge base. What differentiates things here is the fact that you can now use the data sources that you have gotten access to directly from here.  I just got access to my S3 locations. I just provide that. I'm selecting the embeddings I need.

[![Thumbnail 2110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2110.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2110)

[![Thumbnail 2120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2120.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2120)

SageMaker Unified Studio takes care of all the other required components, such as creating a vector database in Amazon OpenSearch,  which is a serverless offering. It ensures that it indexes all the data and creates that knowledge base for you without you having to do that heavy lifting. It's just a few simple clicks. 

[![Thumbnail 2140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2140.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2140)

[![Thumbnail 2150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2150.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2150)

Once the knowledge base is created, the next step is to create the guardrails because this is the governance application that we need to make sure we're applying the right governance controls. As you can see, out of the box there is a whole bunch of filters that allow you to  control the responses of the knowledge base, but you can also add your custom messages or custom prompts to make sure that you're applying your own governance controls. In this case, I don't want anyone here to prompt for address information or demographic information. 

[![Thumbnail 2160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2160.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2160)

[![Thumbnail 2170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2170.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2170)

So I'm going to create a deny address and I'm going to create a definition for it.  I'm basically saying don't respond if there's patient address information. You can provide some sample phrases, which is optional for you. We're just going to go ahead and create this guardrail. 

[![Thumbnail 2180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2180.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2180)

[![Thumbnail 2190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2190.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2190)

[![Thumbnail 2200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2200.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2200)

[![Thumbnail 2210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2210.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2210)

Once the guardrail is created and the knowledge base is created, it's now time to create the chat app. Again, it's not too difficult.  You simply go to my apps and create a chat app.  Here we provide a name for the chat app. In this case, we'll call it Patient 360. We select the foundational model, and now we provide the knowledge base that we want to augment this foundation model, which is pretty straightforward because we created the knowledge base in the previous step.  We basically select that. We can apply multiple guardrails, so we'll go ahead and apply that specific guardrail here. 

[![Thumbnail 2220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2220.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2220)

[![Thumbnail 2230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2230.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2230)

[![Thumbnail 2250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2250.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2250)

What we're going to do is save this chat app.  Now that I've been working on my local copy in my project, the most important step is to actually deploy it so that it's visible to others and I'm in a position to start sharing this with others.  We'll provide a name for it or the alias name that represents that certain version or any changes to that version. Because it's the first time I'm deploying it, I'm just going to provide the right description for this app. We simply deploy that app. It is pretty straightforward. 

[![Thumbnail 2260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2260.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2260)

[![Thumbnail 2270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2270.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2270)

In a few steps, we basically took the data, got access, and built a knowledge base.  Next, we can actually start sharing this. We're going to share this with Doctor Smith. However, you can also share it with a group of individuals, which is pretty straightforward in terms of how you can share this. We then went ahead and published this app. 

[![Thumbnail 2300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2300.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2300)

[![Thumbnail 2310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2310.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2310)

[![Thumbnail 2320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2320.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2320)

### Testing the Compliant Chat Application: Dr. Smith Prepares for His Patient Meeting

In this demo, we've shown you how easy it is for a GenAI developer to take assets in a very secure, compliant manner in an auditable way and create a knowledge base out of it, apply the right governance and guardrails, and then deploy it using SageMaker Unified Studio. Now is the time when Doctor Smith comes in after his rounds.  He got an email saying the app is ready to share and he can start asking questions. Instead of clicking on the link, he goes and discovers that app, and the app is there. The first thing that always prompts us is to test the app, right?  Like, are you compliant? So let's go ahead and say, "Give me the address of a patient I know, Owen Anderson. Can I get the address?"  The guardrails kick in. It says, "Sorry, I can't give you that information," enforcing that governance control.

[![Thumbnail 2340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2340.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2340)

[![Thumbnail 2350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2350.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2350)

The next thing is I'm happy as Dr. Smith to see that it's actually a chat application that's compliant. But I know of a patient. Let me make sure that I can see if that patient actually has that information that I can validate, right? Like, is the data right?  So he basically asks, "Tell me something about Owen Anderson." The chat app is able to use the knowledge base we created and rightly summarize that information in a very clean way. 

[![Thumbnail 2370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2370.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2370)

[![Thumbnail 2380](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2380.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2380)

The next thing, getting more confident, he asks another question: "How many patients are there with brain cancer?" He uses just a very simple term, not even anything like oligodendroglioma, just a simple brain cancer.  The chat app with the help of the large language model is intelligent enough to understand the context with all the metadata that we have provided and provide really solid responses interacting with a physician, a neuro-oncologist, which I think is pretty cool. 

[![Thumbnail 2390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2390.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2390)

Now he basically says, "I have a meeting tomorrow with a 24-year-old patient. She's a female. Find me patients like her and tell me the number of comparable patients. What is the histology of those patients? Tell me what kind of treatments they've gone through and just be grounded with facts. Don't hallucinate, right?"  He's kind of prompting the system. The model really behaves well. It basically gets that data and provides the necessary information.

[![Thumbnail 2410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2410.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2410)

[![Thumbnail 2420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2420.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2420)

It says, "Look, I found a patient similar to her. She's on this protocol,"  and all kinds of information. Again, all of this is synthetic data that we manufactured. I can only imagine if you start using it on your real data, I'm sure you'll get pretty good results.  At this point, Dr. Smith is able to get the required responses that he wanted, and he's ready to prepare for his meeting and ready to go for tomorrow.

I know we took a healthcare example. You may all be from different industries, but in every part of your journey, SageMaker is there to help you accelerate through that journey. I'm hoping that after this talk, you will go and try out SageMaker Unified Studio, our catalog, and we just can't wait to hear what you do with that.

### Bayer's Real-World Implementation: Breaking Down Data Silos in Drug Discovery

With that, I wanted to invite our customer speaker Avinash from Bayer to tell you how they're actually doing these things in the real world at Bayer. Thank you very much. Good afternoon, everyone. Can you guys hear me? Wonderful. I'm Avinash Reddy Erupaka, a Principal Engineering Lead at Bayer Pharmaceuticals. Bayer is a 150-year-old life sciences organization that is driven by the mission of health for all, hunger for none. We operate across different life science verticals, combining crop science, consumer health, and pharmaceuticals.

[![Thumbnail 2500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2500.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2500)

[![Thumbnail 2510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2510.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2510)

Today, I'm here to  talk about one of the biggest challenges that we have in modern-day drug discovery: data fragmentation and contextualization.  For decades, the search for new therapies has been a race against time, with massive investments pouring into research and development. However, one of the biggest non-scientific challenges that we have is not the complexity of biology, but our ability to leverage existing data and accelerate AI. Data that's trapped in silos slows down our scientists and hampers critical decision-making.

[![Thumbnail 2570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2570.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2570)

Our team's mission is very straightforward. We are here to break down the silos, unlock speed, trust, and scale. When data is locked in silos, we lose speed. When compliance, lineage, and consent are not clear, we lose trust. Without platform-level patterns, we cannot scale. The vision that we have for our biodata science ecosystem  is a platform built on the principles of distributed data mesh, along with analytical and AI workbenches, plus a central governance spine and a central catalog.

[![Thumbnail 2620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2620.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2620)

We operate across vital data domains like omics, clinical, and chemistry, and we operate in a distributed data mesh architecture. Think of a data mesh as a supply chain fabric that connects data and AI across research and development. In a data mesh architecture, the ownership of these data domains is federated to the data owners. For example, the biomarker team owns the biomarker data, and the omics team owns the sequencing data, and so on and so forth, while the central platform manages the  interoperability and scalability of the platform.

[![Thumbnail 2660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2660.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2660)

Our team solves these cross-cutting concerns by providing turnkey solutions around data ops, cost hygiene, observability, monitoring, and also validated reusable templates. By removing all the infrastructural concerns that bog down our scientists, our practitioners like machine learning researchers, bioinformaticians, and biostatisticians can focus 100 percent of their time on science and not on service. The glue that brings all of this  together is SageMaker Unified Studio. SageMaker Unified Studio acts as a central governance control plane and a front door where it enables all of the capabilities and enables these data domain owners to engineer and publish these assets into the catalog.

These assets are unstructured S3 tables, structured S3 assets, analytical assets like machine learning features, machine learning models, inference endpoints, agents, and so on and so forth. The seamless integration where these distributed data domains merge into a unified catalog is what enables the holy grail of R&D, which is multimodal analytics.

[![Thumbnail 2730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2730.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2730)

Just to quickly raise of hands, how many of you are dealing with multimodal data at your organizations? Great. The search for new therapies is fundamentally a multimodal challenge. In order for us to understand a disease,  drug mechanism of action, and how a patient is responding, we cannot look at this data in isolation.

If you look at a critical domain like oncology, approximately 80% of the data across key therapeutic areas is multimodal in nature. None of this would be possible if we have our data in silos. Our internal biomarker archive, a terabyte scale of valuable study-specific data, is a clear example. We're strapped in silos, hard to access, barely findable, and generally slowing down the process.

[![Thumbnail 2800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2800.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2800)

The challenge we had at hand was to handle the scale while still maintaining regulatory compliance and dealing with the multimodal capabilities that we are planning to deliver. The solution is a three-step process. The first step is where we start by ingesting our on-premises biomarker data into S3 study-specific buckets. Then we enable the trust layer because this data is GXP in nature.  We enable automated ALCOA data controls, making this data attributable, legible, contemporaneous, original, and accurate, and we achieve this entirely by AWS native controls.

Trust is achieved by using S3 object locking mechanism in compliance mode, ensuring immutability of this data, which is critical for regulatory compliance. Security is ensured with S3 server-side encryption with KMS. We ensure our data is addressed by leveraging S3 Access Grants to make sure there is a tight boundary of authentication and authorization controls in place. Auditability is achieved by leveraging versioning and CloudTrail, ensuring the technical lineage of data and how the data is accessed is captured, which is critical for GXP data.

[![Thumbnail 2850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2850.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2850)

[![Thumbnail 2870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2870.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2870)

The second  step is where our automation engine picks up. Our automation engine gets into action by provisioning all the infrastructure peripherals and components like SageMaker Unified Studio and its underlying components for the study projects. Then it starts off by creating an authentication and  authorization boundary by leveraging the S3 Access Grants and directly mapping them to these projects.

The third step is where we register the study-specific unstructured S3 locations as assets into the catalog, immediately making it findable and self-describing. Through this process, we also capture multifaceted metadata, including administrative metadata in terms of data ownership and data access, licensing needs of the data, and domain and asset-specific metadata with rich business contextual metadata tags, creating a control layer and making this data ready for AI.

[![Thumbnail 2920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2920.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2920)

[![Thumbnail 2930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2930.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2930)

The third phase is where the closed-loop execution comes into the picture.  Now users start acting on this secured, governed data. The AI consumers now consume this  data from the central catalog in a secured, governed manner, and they start engineering additional assets by leveraging this data. These assets can be cross-study fact tables by exploring dimensional data, which is critical for future concern management.

AI consumers can also produce additional analytical assets like machine learning models, machine learning features, and agents. In turn, all of these assets are published back into the catalog. This powerful phenomenon of closed-loop execution, where you consume and produce back into the same catalog, really creates a lineage-driven closed-loop execution which helps us answer questions not only about who has access to this data, but what is part of this data packet.

[![Thumbnail 2990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/2990.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=2990)

It helps us track the journey of the data from a raw unstructured file to a model really solving the provenance concerns of a model.  None of this would be possible if we were operating in a siloed environment. This truly unleashes the capability of AI and agentic AI in the space of R&D.

[![Thumbnail 3020](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/3020.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=3020)

I want to showcase a real-time, high-value agentic AI use case that we are pursuing in the space of biomarker data engineering.  One of the challenges in early clinical trials is the time required to harmonize data. The ability for us to get data from our laboratory information management systems and from our clinical systems, running it through data engineering pipelines and QCing data is a week-long effort involving manual work that critically impacts our go/no-go decisions.

So we deployed an agentic AI solution that is deployed on Bedrock, which automates this biomarker data ETL process. First, the agent starts off by gathering information from our laboratory information management system, our clinical systems, and our study-specific data. Next, it starts to parse this information. The agent leverages an LLM that is fine-tuned and vector-indexed on internal protocols and SOPs, and it starts to parse this data and identify the patterns.

Second, the agent not only acts but orchestrates the whole flow where it picks the right data engineering pipeline, the biomarker data engineering pipeline, and engineers the product and QCs the metrics. The final step is a result of a strategic asset where we have a multi-dimensional biomarker DataCube that is further published into the catalog, which is very valuable for further analysis.

As an outcome, we are able to remove a week's worth of manual effort. We are able to accelerate the time to harmonize data for pharmacokinetic and pharmacodynamic analysis, in turn accelerating our proof of mechanism and go/no-go decisions, which is critical for clinical trial success. We are also leveraging patient data in real time, understanding drug response and improving the success of clinical trials. This closed-loop architecture really provides us the much-needed value unlocking that we do in terms of trust, speed, and scale.

[![Thumbnail 3180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/3180.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=3180)

Beyond the quantitative benefits, this architectural shift also delivers  quantifiable business value in terms of capturing multifaceted metadata. Technical metadata is guaranteed by S3 versioning and CloudTrail logs, and closed-loop execution allows us to exactly track the journey of the data and answer who has access to this data. With rich business metadata tags and contextual information that we are capturing, plus the cross-study fact tables, we are able to answer which data is actually used for this analysis.

Let's say in the case of a consent-based study where a patient pulls consent. The system is able to determine exactly which part of the analysis is impacted, which is critical for consent-based reusability. Our roadmap is very clear. We intend to expand our ecosystem by onboarding more data domains, industrialize our AI use cases, and truly explore the potential of multimodal analytics by impacting our pipeline, optimizing the cost and time that it takes for bringing critical life-saving therapies to our patients.

In closing, our journey of migrating 300 terabytes of unstructured data that was stuck in an on-premises environment and turning it into an AI-ready strategic asset is not just a technology story. It is a story about empowering science. We have turned an asset that was barely accessible, barely findable, and accessible only through friction into a strategic AI asset which could streamline our pipeline activities, improve efficiency of our R&D decision-making, and overall lay a solid foundation for our future precision medicine activities.

[![Thumbnail 3320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/05adf810ea6c43cb/3320.jpg)](https://www.youtube.com/watch?v=5pfmkyh3I_c&t=3320)

So with this, I thank you all for tuning in. Feel free to let us know your feedback  so we can improve and deliver more talks of this sort. Thank you very much.


----

; This article is entirely auto-generated using Amazon Bedrock.
