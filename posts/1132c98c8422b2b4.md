---
title: 'AWS re:Invent 2025 - Unlocking GenAI potential with automated modernization to AWS (ANT313)'
published: true
description: 'In this video, Sachneet Singh Bains from Impetus Technologies explains how their LeapLogic solution accelerates enterprise legacy system modernization to AWS with 90-95% automation. The presentation covers their four-step methodology (assess, transform, validate, operationalize) for migrating EDW, ETL, BI, and Hadoop systems. Key differentiators include pattern-based transformation, end-to-end lineage mapping, and cell-by-cell validation. Case studies demonstrate 70% effort savings for United Airlines'' Teradata-to-Redshift migration and 50% time reduction for Bank United''s reporting. The session also introduces PRISM, an AI-enabled unified observability solution for multi-cloud cost optimization and governance.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/0.jpg'
series: ''
canonical_url: null
id: 3088004
date: '2025-12-06T02:51:13Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project enhances multilingual accessibility and discoverability while preserving the original content. Detailed transcriptions and keyframes capture the nuances and technical insights that convey the full value of each session.

**Note**: A comprehensive list of re:Invent 2025 transcribed articles is available in this [Spreadsheet](https://docs.google.com/spreadsheets/d/13fihyGeDoSuheATs_lSmcluvnX3tnffdsh16NX0M2iA/edit?usp=sharing)!

# Overview


ðŸ“– **AWS re:Invent 2025 - Unlocking GenAI potential with automated modernization to AWS (ANT313)**

> In this video, Sachneet Singh Bains from Impetus Technologies explains how their LeapLogic solution accelerates enterprise legacy system modernization to AWS with 90-95% automation. The presentation covers their four-step methodology (assess, transform, validate, operationalize) for migrating EDW, ETL, BI, and Hadoop systems. Key differentiators include pattern-based transformation, end-to-end lineage mapping, and cell-by-cell validation. Case studies demonstrate 70% effort savings for United Airlines' Teradata-to-Redshift migration and 50% time reduction for Bank United's reporting. The session also introduces PRISM, an AI-enabled unified observability solution for multi-cloud cost optimization and governance.

{% youtube https://www.youtube.com/watch?v=idJNwNALAhQ %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/0.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=0)

### Impetus Technologies: Empowering the Intelligent Enterprise Through Data, Cloud, and GenAI Solutions

 Good afternoon everyone, and welcome to the session. My name is Sachneet Singh Bains, and I lead the solutions architecture team at Impetus Technologies. Today I'll be talking about how we are helping enterprises unlock GenAI potential with automated modernization of their legacy systems and the data that they have accumulated over decades to the AWS platform.

[![Thumbnail 30](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/30.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=30)

First, let me tell you about Impetus Technologies. We are empowering the intelligent enterprise. We focus on data, cloud, and GenAI thought leadership globally with over 3,600 engineering staff. We are serving more than 30 Fortune 100 customers and are among the top AWS services and solution partners. We have established an AWS Center of Excellence at Impetus and are a premier tier services partner.  We are number one in the ETL migration space and have migrated a number of customers from their legacy systems to AWS Glue. We have more than 10 services and solutions listed on AWS Marketplace, and we are G2E certified as well.

[![Thumbnail 60](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/60.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=60)

Now, talking about the intelligent enterprise, this is a portfolio of Impetus solutions and services. Starting with data and cloud engineering, we begin by defining and designing data strategies, cloud strategies, and AI strategies for our customers. We have built solutions and accelerators, including a data platform accelerator that helps jumpstart and create data platforms, as well as a solution accelerator called Pres which brings unified observability. We also have solutions around data workloads and app modernization.  We start from creating those strategies, whether that's cloud, data, or AI strategy, and then move to implementation and successfully productionizing them. We have a dedicated DevOps practice covering everything from CI/CD to AI and MLOps. We have been delivering that to our customers, including services around GenAI. We also have something called GenAI Labs where we help accelerate the design of ideas and solutions for our customers and assist them in developing any agentic AI frameworks that they want to create or anything they want to build around agentic AI, as well as taking care of any AI-based governance that needs to be in place.

[![Thumbnail 90](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/90.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=90)

 Now talking about GenAI BI services, we have been helping our customers in the modernization space and otherwise to help put their legacy BI systems to these modern platforms, leveraging GenAI BI. For example, if you have thousands of reports, you don't really have to rewrite or redesign all of them. GenAI BI can take care of most of those reports for you, especially the ad hoc reports. Summarizing all this, this is how we have been helping deliver an intelligent enterprise, an enterprise that can make very informed decisions using the insights from the data that they have accumulated over all these decades.

[![Thumbnail 210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/210.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=210)

[![Thumbnail 220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/220.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=220)

### LeapLogic: Automated Legacy System Modernization with 90-95% Transformation Efficiency

Now let's talk about how we are helping transform the data ecosystem for it to be ready for the GenAI era.  I'll first start with a survey that shows that 90 percent of the leaders who are looking at the GenAI space and the AI space first want to prioritize the modernization of the legacy systems that they have because they may be running an EDW and ETL for decades. There is a lot of business logic accumulated there, so they want to prioritize that. A similar number of leaders feel that modernizing all this data and using it in the GenAI era is the key to success.  At the same time, there is a certain percentage that feels that there are certain impediments and challenges to modernization. We are aligned to all these surveys that are out there, and we have solved this problem with our tool solution accelerator called LeapLogic that really helps accelerate such modernizations.

[![Thumbnail 270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/270.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=270)

Before we talk about modernization, the first question is: how should we strategize?  What should be our approach for modernization? Should we take everything as is, the decades of investments that you have on your warehouse, on your ETL, on your BI side, but that was architected for those legacy frameworks? You cannot retrofit that to a modern platform. But then, do you throw that away, or is there a way to reuse that business logic? Once you have made that decision, there is another very important question: how big is this effort? Are you looking at six months of effort, one year, or two years of effort? Now, given that it's six months or eight...

[![Thumbnail 320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/320.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=320)

These are important questions we help answer for our customers as part of our strategy for modernizing their data estates. As part of our modernization methodology and approach, the first thing we start with is creating and proposing a balanced approach.  This means that if you have a lot of legacy systems around EDW, ETL, BI, and analytics, we feel that a balanced approach involves taking 80% of that as-is but modernizing it to the target platform, which is pattern-based transformation. There could be 20% of it that represents technical debt and may need rewrite or re-engineering, but we have seen this 80/20 rule work very well for most of the legacy systems out there.

[![Thumbnail 360](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/360.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=360)

Then comes the methodology part.  What you see on the screen is the methodology we use. On the left-hand side are some of the popular legacy systems we support today, such as EDWs, ETLs, analytics, and Hadoop. On the right-hand side, you'll see some of the services on the AWS side where we are able to migrate all these legacy systems to in an automated fashion. In the center, you will see our four-step methodology.

The first step is assess. This is the most critical part because this is where we strategize the modernization. We look at your legacy systems, assess them, and extract key insights. First, we determine the overall score and volume metrics. Second, we evaluate how complex the business logic is that's contained within your systems. Third, we identify the technical debt. If an EDW has been running for 20 years, there must be a lot of technical debt. This technical debt could be in the business logic, the data itself, or the complexity of the business logic. We are able to extract that information.

Fourth, we perform a lineage and dependency analysis of everything you're running on your legacy ecosystem today. This essentially means we create a mapping from your orchestration to ETL to your EDW and then to the BI, providing end-to-end lineage and dependency analysis. Using all this information, we are able to come up with the right strategy for you, the right timelines, the right target architecture, and the right recommendations as part of the modernization.

[![Thumbnail 550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/550.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=550)

Once we have defined the right strategy and approach, the second step is the transformation itself.  This is where the magic happens because the tool is able to auto-transform 90 to 95% of your legacy code into the modern AWS platform. This essentially means if you're running Informatica, DataStage, Teradata, or Oracle and you want to move that to a Glue and Redshift combination, the tool will do that 90 to 95% in an automated fashion. There is minimal manual effort, only 5 to 10%, which is taken care of by Impetus SMEs. What we deliver to you is a successful modernization within fixed timelines.

The transformation step is where most of the acceleration happens, and at the same time, we take care of standardization and optimizations that must be implicit. The third step is the validation part, where we take care of everything from cell-to-cell-based data validation as well as validating each and every piece of business logic that has been transformed. The last part is the operationalization. When I say we deliver you a successful migration, what I mean is that we don't just transform the code and hand it over. We make sure that we are productionizing it for you.

[![Thumbnail 570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/570.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=570)

This is where the operationalization comes into the picture. We make sure we are building the right CI/CD processes for you and the security governance processes for you, so you're able to productionize your legacy code transformed to the AWS target platform.  This slide talks about some of the automation levels we have. You'll see that for most of the EDW and ETLs, we have very good automation available, up to 90 to 95%. This is the four-step methodology in more detail, which I've already spoken about.

Now, let's compare Impetus LeapLogic to some of the tools out there. If you're thinking of modernization or you're already in the modernization phase, you may have seen a plethora of tools out there. This is a comparison of how Impetus LeapLogic is way ahead of those tools. Let's talk about some of those parameters. The first one is end-to-end automation. You'll find tools in the industry that may do ETL or EDW or Hadoop or BI, but in your ecosystem you have all four of those. Now, do you choose one tool for each, or do you use a tool that does everything for you? Impetus LeapLogic does everything.

This is the first. Leap Logic does everything end to end. The second one is, how does the transformation actually happen? Is the tool just doing a line by line conversion, or is it really understanding the business logic behind it and then transforming it based on pattern-based transformation? Leap Logic really differentiates itself because it does pattern-based modernization and covers all the workload types.

The third one is, how do you do interdependency and lineage? If you have an EDW that's running for two decades, you cannot really transform that in one go. You cannot boil the ocean altogether. You have to break it down. But how do you break it down? You cannot break it down without any intelligence. You need to figure out how the dependency is mapped. This is where Leap Logic differentiates because it has all that end to end mapping to plan a phase-wise migration plan versus a very dumb chunking of your scope of work for modernization.

Then the fourth one is the kind of automation it brings. With 90 to 95% of automation, it really accelerates the modernization. Then what kind of validation do we support? Cell by cell validation ensures that we are doing validation to the most granular level. The tools out there do not go to that granularity. Then is it customizable for the enterprise level? Let's say you're using some custom frameworks. Can we output? Can we generate the code according to those frameworks or not? Yes, Leap Logic can, but do all the tools out there do that? No.

[![Thumbnail 740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/740.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=740)

Then how do we make sure that we are adhering to all the SLAs and delivering the performance to you on the target platform? Leap Logic ensures that because while it does the transformation, it ensures that all the optimizations are implicit. And finally, ensuring a risk-free migration with zero disruption to your business as usual because it has all that linear dependency mapping and it is very well planned. This is what differentiates Leap Logic from all the tools out there, ensuring that you have a successful migration. 

Now, how does that really help in the Gen AI space as well? I spoke about the other EDW ETL you are running. We also support BI tools. You may be running Tableau, you may be running some other BI tools, and you want to modernize that, but you want to leverage Gen AI. The tool will really assess and tell you what kind of patterns you run today or what kind of reports you run today on your legacy and how that can be transformed to the modern platform and what Gen AI can do for you.

[![Thumbnail 800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/800.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=800)

For example, a lot of self-serve reports do not really need the reports to be converted from Tableau to, let's say, the AWS platform. QuickSight along with Amazon Q could really build those self-serve dashboards for you. This means if you have, let's say, 5000 self-serve reports, you don't really have to rebuild all of them. That's the kind of Gen AI readiness the Leap Logic tool is able to bring because it is able to assess and tell you how Gen AI can really help in your reporting landscape. 

[![Thumbnail 820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/820.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=820)

[![Thumbnail 850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/850.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=850)

Now, finally, what's the advantage of using Leap Logic for any of those modernizations? 4X faster transformations, 2X lower cost, 1.5X faster validation, and overall compared to any manual migration, 2X less effort.  We have done this time and again. We have done more than 200 migrations, all successfully delivered. We have transformed over 100 million lines of code, and the grammar engine today that backs Leap Logic is so robust that it has seen most of the patterns out there in EDW, analytics, and big data space. With up to 95% of automation, it ensures that you have at least 50 to 75% of reduction in your migration and modernization cycle. 

### Customer Success Stories and PRISM: AI-Enabled Unified Observability for Cloud Optimization

Some of the case studies talking about United Airlines, they had an application running on legacy today which really helped provide customers with real-time information. But since it was running on legacy, it was really slow. We modernized that using Leap Logic to the AWS platform and ultimately delivered 70% effort and 22% time savings for them. It was a Teradata migration to Redshift that we really accelerated through Leap Logic. And ultimately, for that application itself, United Airlines was actually able to reduce 50% wait time for their passengers and 50% increase in the bookings as well. We did not really just deliver an accelerated migration but also brought a lot of business value for United Airlines.



[![Thumbnail 910](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/910.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=910)

[![Thumbnail 960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/960.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=960)

Similarly, for American Express, we transformed their Teradata, Ab Initio, and SAS migration application with over 70% automation.  I'd like to also talk about how we help Bank United with their reporting challenges. The challenge was that the data they were bringing was taking more than 12 hours to be ready for reporting, which was defeating the purpose of making informed and timely decisions. With LeapLogic, we did the assessment and came up with a modernization approach. We not only delivered the transformation and modernization with 85% automation and acceleration, but we also delivered efficiencies that reduced the time from more than 12 hours on legacy systems by almost more than 50%. This enabled them to make informed decisions in a timely fashion. This is the kind of transformational impact we have been able to bring to our customers. 

We have also come up with a new accelerator and product. LeapLogic does the transformation and modernization and really accelerates that process. But once you have moved to the cloud, how do you make sure that you are continuously optimizing your cost at the same time you're getting a unified view of your cloud spend as well as observability? This is where we have come up with PRISM, which is the industry's first AI-enabled solution for unified observability. It does a number of things. First, it will give you a unified view of multi-cloud and data platforms. If you're using AWS and also using some data platforms like Databricks or Snowflake, or maybe you're also using multi-cloud, you don't have to go to different dashboards to see what you're running and what costs you are incurring. You will get one unified view through PRISM.

Second, it is AI-powered and has predictive analytic insights. This means the observability insights that it will bring to you will also make some predictive recommendations. It will tell you that there are certain anomalies that should be sorted out and how they should be sorted. It will also come up with recommendations around your spend. It will tell you where you are spending and why you are spending that, and what approach you should take to optimize that. All of this is AI-based.

The last capability is the intelligent automation and governance that it brings. This means it has ML-driven forecasting for you. You may be anticipating some good growth on your cloud data platforms, but how do you really quantify that based on historical data or what you're doing today? PRISM can come up with that AI-based, very informed forecasting for you. It also has the ability of smart tagging, which means you may be running hundreds of applications on a cloud. How do you know which application is consuming what kind of resources? You can do smart tagging through PRISM, and the single dashboard that you will have will tell you that this particular business group or this application is actually running these services and this is the kind of cost that you're incurring.

[![Thumbnail 1150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/1132c98c8422b2b4/1150.jpg)](https://www.youtube.com/watch?v=idJNwNALAhQ&t=1150)

Finally, it also has the ability of making recommendations for you across applications with intelligence. This means you may be running an EC2 instance that is costing you too much, but rather than in a simplistic way coming and saying reduce the size of this EC2, the tool is aware that you are running a very mission-critical application on this EC2. You cannot just bring it down or reduce the size. So the recommendations that you get are very application-aware and intelligent. This is the kind of value that PRISM also brings. If you've already modernized or you're modernizing to cloud, PRISM is a tool that you really need because this is what will ensure unified observability and dashboarding for you. 

With that, I'd like to invite you to visit our booth 1553. We're happy to speak about PRISM in detail or LeapLogic in detail or GenAI. We'd love to discuss where you are on your modernization journey or what you are doing in the GenAI space. At the same time, we'd love for you to join us. We are hosting an event today, and we'd like to invite you. Please do visit our booth. We'd love to have a chat over some drinks with you and speak about modernization and other topics. We also have some swag, so we'd love to distribute it and have you come along to the party and have some conversation around modernization and GenAI with you all. With that, I thank you for your time. Thank you.


----

; This article is entirely auto-generated using Amazon Bedrock.
