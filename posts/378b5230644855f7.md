---
title: 'AWS re:Invent 2025 - Manage multicloud Kubernetes at scale feat. Adobe (HMC322)'
published: true
description: 'In this video, Gaurav Dhamija from AWS and John from Adobe discuss managing multicloud Kubernetes at scale. Gaurav explains AWS''s multicloud perspective and the CNOE initiative, emphasizing GitOps-based fleet management for cluster and add-on lifecycle management. John presents Adobe''s Ethos platform, which orchestrates 4 million containers daily across 450 clusters in 30 regions. He demonstrates a GitOps workflow using Argo CD, AWS Controllers for Kubernetes (ACK), and Cluster API to provision and manage EKS clusters declaratively without console interaction. Adobe achieved 3x faster fleet-wide deployments, 2x faster Kubernetes upgrades, and 25% reduced provisioning time. Key takeaways include investing in Kubernetes expertise, embracing automation and open source tools, treating platforms as products, and maintaining standardized yet flexible configurations across cloud providers.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/20.jpg'
series: ''
canonical_url: null
id: 3085246
date: '2025-12-05T04:21:47Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project enhances multilingual accessibility and discoverability while preserving the original content. Detailed transcriptions and keyframes capture the nuances and technical insights that convey the full value of each session.

**Note**: A comprehensive list of re:Invent 2025 transcribed articles is available in this [Spreadsheet](https://docs.google.com/spreadsheets/d/13fihyGeDoSuheATs_lSmcluvnX3tnffdsh16NX0M2iA/edit?usp=sharing)!

# Overview


ðŸ“– **AWS re:Invent 2025 - Manage multicloud Kubernetes at scale feat. Adobe (HMC322)**

> In this video, Gaurav Dhamija from AWS and John from Adobe discuss managing multicloud Kubernetes at scale. Gaurav explains AWS's multicloud perspective and the CNOE initiative, emphasizing GitOps-based fleet management for cluster and add-on lifecycle management. John presents Adobe's Ethos platform, which orchestrates 4 million containers daily across 450 clusters in 30 regions. He demonstrates a GitOps workflow using Argo CD, AWS Controllers for Kubernetes (ACK), and Cluster API to provision and manage EKS clusters declaratively without console interaction. Adobe achieved 3x faster fleet-wide deployments, 2x faster Kubernetes upgrades, and 25% reduced provisioning time. Key takeaways include investing in Kubernetes expertise, embracing automation and open source tools, treating platforms as products, and maintaining standardized yet flexible configurations across cloud providers.

{% youtube https://www.youtube.com/watch?v=_hj3eOVGCJw %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 20](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/20.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=20)

### AWS Perspective on Multicloud Kubernetes: GitOps-Based Fleet Management

Thank you everyone for coming to this talk on managing multicloud Kubernetes at scale. My name is Gaurav Dhamija, and I'm a principal solutions architect here at AWS. I have with me John from Adobe. I'm pretty sure most of you, if not all of you, must be using Kubernetes in some capacity in your organization.  But just a quick show of hands if you do it across multiple cloud service providers. Okay, we have a few brave and adventurous folks here. So in our talk today, I'll be sharing the AWS perspective on multicloud, and then we will be talking about some of the considerations related to multicloud Kubernetes fleet management. Then I will be handing it over to John, who will be talking about Adobe's experience in this space and will share some of the learnings and best practices from Adobe's experience.

[![Thumbnail 50](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/50.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=50)

 So from the AWS perspective, what do we mean by multicloud? It means that our customers are running an IT solution or a workload across at least two cloud service providers. When we talk to our customers, they cite multiple reasons for this strategy. It could be their business strategy, it could be mergers and acquisitions, or they might be using a differentiated capability in a specific cloud service provider. From the AWS perspective, we work with them and partner with them to make sure that they're successful. We help them build technical and non-technical capabilities across all process and technology pillars.

[![Thumbnail 80](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/80.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=80)

 Specifically from a technology perspective, what we noticed is that many of our large multicloud customers, including Adobe, have been investing in platform engineering and building internal developer platforms to streamline their experience across multiple cloud service providers. This is why AWS, in partnership with some of these customers including Adobe, launched CNOE, the Cloud Native Operational Excellence initiative. As part of this initiative, we have not only defined composable capability metrics for defining internal developer platforms, but we also offer tools, guidance, and reference implementations that you can use today as part of your multicloud journey.

[![Thumbnail 90](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/90.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=90)

[![Thumbnail 150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/150.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=150)

 It is also not surprising that as part of CNOE initiatives and discussions with our customers, Kubernetes and containers have emerged as a fundamental abstraction used by our multicloud customers to streamline the experience. Now, today our focus is on fleet management,  but there are also other considerations like multi-tenancy and developer experience that you need to think about. From a fleet management perspective, you not only need to think about cluster lifecycle management, but also add-ons lifecycle management. You may have add-ons related to networking, security, and observability on your cluster, and you need to think through their lifecycle. Additionally, clusters in practice typically have different configurations based on the workloads that you're supporting on those clusters. For example, for AI/ML workloads, your cluster may have specific GPU drivers or specific hardware that you need to support. When we talk about multicloud, you may also end up supporting multiple distributions of Kubernetes itself.

[![Thumbnail 200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/200.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=200)

[![Thumbnail 210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/210.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=210)

 One approach that we have seen work well for our multicloud customers, including Adobe, is using a GitOps-based approach for fleet management where we see our customers storing both the cluster and add-on configuration, as well as all the security, audit, and compliance policies themselves in Git as a source of truth.  They then leverage GitOps operators like Argo CD and cloud provider-specific controllers to continuously provision and reconcile the state of their multicloud Kubernetes fleet. Now with that context, let me hand it over to John to share how Adobe has implemented some of these patterns at scale in their organization.

[![Thumbnail 240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/240.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=240)

### Adobe's Ethos Platform: Declarative Infrastructure and GitOps in Action

Thanks so much, Gaurav.  Hi everyone, welcome to AWS re:Invent. I'm John. I'm with the Adobe developer platforms team, and our mission is simple: help developers write better software faster. So when Adobe's landscape looks like this, and I assume a lot of other folks' landscapes look as complex as this, how do you actually do that? I'm also a fan of abstraction and platforms where you need to simplify, and in many cases oversimplify, for your developers. So in this cake of complexity, what happens when you add yet another layer called multicloud?

[![Thumbnail 280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/280.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=280)

[![Thumbnail 300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/300.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=300)

Adobe has been on a multicloud journey for over 15 years, and as part of that, we've had to iterate on our own approach. Fit for purpose is essential.  Where you deploy applications in a multicloud environment must be an intentional choice. Yes, perhaps you have data residency requirements, security attestations, or integrations with a strategic partner. Likewise, we still live in a world with physics after all. Replicating state within one cloud provider,  let alone two, is inherently difficult. Do not approach multicloud as an HA construct on its own.

[![Thumbnail 320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/320.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=320)

We still have the speed of light to deal with. Our emphasis is really on platform engineering at Adobe, which means we treat all cloud providers, including our own data center, as a first-class citizen.  By doing that, it enables you to meet diverse business needs along with specific technology challenges and enables developers to do what they want to do: ship code as fast as possible.

[![Thumbnail 340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/340.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=340)

[![Thumbnail 380](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/380.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=380)

So how do you get this type of consistency and uniformity in a really complex environment like multi-cloud?  At Adobe, we built Ethos. Ethos was built to simplify the developer experience with a consistent interface for developers, regardless of the underlying cloud provider. Likewise, we want our developers to integrate and manage cloud-native infrastructure not with SDKs or proprietary APIs. We want them to interface with infrastructure using uniform CI/CD pipelines regardless of the cloud provider. Finally, we want our developers to focus on delivering business value, not necessarily figuring out how to apply specific security or compliance attestations,  which are unique to each specific region or cloud provider. Developers just want to ship code.

[![Thumbnail 420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/420.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=420)

At Adobe, Ethos is a pretty big deal. We're the dial tone for the entire fabric of the company. On a typical day, we orchestrate around 4 million containers. 90% of Adobe's containerized footprint runs on Ethos. That equates to around 4,000 distinct services across our three clouds: Digital Experience, Creative, and Document. That footprint manifests itself into 450 independent Ethos  clusters globally, which spans around 30 regions, multiple public cloud providers, and multiple private data centers.

[![Thumbnail 440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/440.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=440)

So when you approach this type of complex environment and challenge, how do you engineer your way around this? We had our own operating principles that we pointed to.  Our approach is rooted in one key aspect: declarative infrastructure. We use declarative infrastructure to define cluster configurations, network policies, versions, and resource definitions, which are all managed as code, typically YAML manifests that live in Git. In light of what was said earlier, Adobe has really embraced GitOps and our entire workflow is GitOps-driven, using tools like Argo CD and Helm. All changes to both application state and infrastructure are made as pull requests to specific Git repositories. That enables you to have a single source of truth that allows for automated rollbacks, continuous pipelines, and eventually automated tests to get eventual consistency with what should be in production, referencing what's in source.

We also built Ethos as a modular codebase. We use Helm as a package manager to deploy each of those components and each of those security configurations, which allows for rapid updates, easier maintenance, and customization for different business needs or perhaps technology challenges like multi-cloud. Finally, we really embrace open source. Cert Manager for certificate management, Cluster API for managing Kubernetes components on cluster, OpenTelemetry for our observability stack. Using open source also enables our own teams within Adobe, like Adobe Firefly, to contribute to the platform. What Firefly did was contribute their own custom pod autoscaler for their own business needs.

[![Thumbnail 550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/550.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=550)

[![Thumbnail 580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/580.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=580)

[![Thumbnail 590](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/590.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=590)

So how did we do this? Well, there are two important aspects. The first one is the human or the operator.  What does the human need to do? The human goes ahead and populates a specific manifest file with important key attributes: what the cluster name should be, what region it should be deployed in, what organization, and more importantly, which cloud providers should we deploy this cluster to. Taking that input from the human, what's the machinery that actually executes this? It's a Kubernetes cluster running Argo. Argo listens to signals from Git and wants to take the configuration from Git and get that eventually to production.  The two key aspects that signal from Argo to what's actually in production are ACK,  or AWS Controllers for Kubernetes, and Cluster API, or CAPI. ACK manages specific AWS primitives like EKS. CAPI manages specific Kubernetes components, such as your favorite cluster autoscaler or Karpenter.

[![Thumbnail 610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/610.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=610)

[![Thumbnail 620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/620.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=620)

[![Thumbnail 630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/630.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=630)

[![Thumbnail 640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/640.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=640)

 This setup is not specific to AWS. You can use whatever cloud provider you use, and as long as you adopt their own Kubernetes controller, this system will work.  So what are we going to see here? Actually, this is probably the most challenging pieceâ€”just making sure the video runs. Let's make sure it does. Yes, it does.  So multi-cloud is easy, but playing videos is super hard. We're actually going to go from zero to a fully functional deployable target within AWS for our developers. 

[![Thumbnail 650](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/650.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=650)

[![Thumbnail 660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/660.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=660)

[![Thumbnail 670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/670.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=670)

[![Thumbnail 680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/680.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=680)

[![Thumbnail 690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/690.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=690)

[![Thumbnail 700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/700.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=700)

[![Thumbnail 710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/710.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=710)

[![Thumbnail 720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/720.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=720)

[![Thumbnail 730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/730.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=730)

What are you going to see? It's a GitOps-driven workflow. What is GitOps? It's implementing things like standard software development practices such as testing, automation,  and approval mechanisms. In that manifest, we're going to have non-overlapping IP ranges, specific security configurations,  observability, and a deployment pipeline. Most importantly, a deployment pipeline not only for our developers to deploy to that target, but actually to the cluster itself.  Remember, declarative infrastructure. Every cluster has its own configuration,  and eventually Argo CD wants to get what's in Git into production. You probably saw in Argo that things are in a degraded state.  That's fine, don't worry about it. The beauty of GitOps is its eventual consistency. As we ping pong back and forth  between the Argo UI, kubectl, and the actual AWS console, I want to show you in quasi real time how we build this system.  VPC, EKS, pods, and cluster componentsâ€”all in that type of layer. In this case, we're just checking on the health  of two specific important components: the Cilium operator and CoreDNS. As you can see, those came up all without having to interact with a proprietary cloud vendor console. 

[![Thumbnail 740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/740.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=740)

[![Thumbnail 750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/750.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=750)

[![Thumbnail 760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/760.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=760)

[![Thumbnail 780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/780.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=780)

[![Thumbnail 790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/790.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=790)

[![Thumbnail 800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/800.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=800)

So let's go ahead and update our clusters. Again, lifecycle management. In this case, Adobe has updated our own tagging policy  to make sure we properly attribute all of the resources to a specific Ethos cluster. Again, this starts with Git.  I want to show you and call out what's not being shown to you in this type of standard software development workflow. You're not going to see an AWS CLI.  You're not going to see us grab IAM roles or access keys and secret keys. You're not going to see us go ahead and update CloudFormation templates because those don't exist in other types of cloud providers. You need to put an abstraction on top of that so you can actually drive machinery  to manage the environment in a multi-cloud world. As you can see, as we ping pong back and forth between Argo, what's most important is we want to get that tag  applied to this specific cluster because in this case, I want to make sure I create the demo in this video for you before something nefarious happens to it. 

[![Thumbnail 810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/810.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=810)

[![Thumbnail 820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/820.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=820)

[![Thumbnail 830](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/830.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=830)

[![Thumbnail 840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/840.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=840)

[![Thumbnail 850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/850.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=850)

[![Thumbnail 860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/860.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=860)

[![Thumbnail 870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/870.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=870)

[![Thumbnail 880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/880.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=880)

[![Thumbnail 890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/890.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=890)

[![Thumbnail 900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/900.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=900)

So as you can see, Argo goes ahead and picks up theseâ€”the config eventâ€”eventual consistency. In this case, what's the tag?  This is a re:Invent or demo re:Invent cluster in AWS. As Argo goes ahead and processes this, we'll go back to the AWS console  and show you the VPC ID with a specific AWS tag applied. All right, let's talk about decommissioning.  Before everybody gets out and freaks out and says, wait a minute, you can actually delete infrastructure via pull requests? Yes, you can,  but it took us many, many, many quarters to get to this level of maturity. Just like any software lifecycle that you manage through a Git-based workflow, you need to have safeguards  to prevent hard deletes and accidental or error-prone type of steps. So what do we do? We run tests, right? Tests are good for software.  Linting, we do input validation. I also want to make sure that there are no PDBs to enforce on this cluster. I also want to check my ingress controller to make sure  that there are no routes there. But again, that's all driven through software and observability, not driven by a human going ahead and clicking through consoles to say,  hey, can I go ahead and delete this cluster? Many organizations forget about this most important piece of the lifecycle, which is deletion.  Because if you don't delete, you're going to run into sprawl, waste, and security issues. As you can see, again, no consolesâ€”it was all driven through Git. 

### Lessons Learned and Key Takeaways from Adobe's Multicloud Journey

This is a typical executive scoreboard, but it's about more than just numbers. It's about how the work we do transforms our own development culture and leads to positive business outcomes. We deal on an enormous scale at Adobe. When you're dealing with a fleet of 300 to 450 clusters, you need automation. With this type of system, we're able to deploy changes across this fleet three times faster. We're also able to do full Kubernetes cluster upgrades two times faster. We're also reducing our own provisioning time by 25%. Adobe is a fast-moving business. We have new markets that we need to go into, and building Ethos clusters is essential. Finally, you should be treating this like any other product that you manage. You should talk to your developers to say, "How is this working out?" The response from our own developers around our fleet management system has been overwhelmingly positive.

[![Thumbnail 970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/970.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=970)



So let's wrap up and I'd love to share all of the things that we learned so you don't necessarily have to go through the pain and trials that we did. Kubernetes is your friend. With any friendship, you need to invest. If you don't invest, you're probably not going to have a friend anymore. So how you invest is in your own team. Grow your team's own knowledge of Kubernetes and get them to a place in terms of platform engineering where you need them to be. You also need to automate. It is impossible at scale to have human signal between events to say, "I'm ready for the next step." You need to have GitOps-based workloads that reduce manual errors and accelerate your own delivery.

There's a vibrant culture and community out there that you can adopt. You don't have to go and build all of this on your own. Adobe has gone all in and really embraced the Cloud Native Computing Foundation, or CNCF, where I'm really happy to say that last year in 2024, we were honored with our highest end-user award recognizing our own contributions back to the community. Like I said earlier, platform is product.

[![Thumbnail 1030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/1030.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=1030)



Your end users are never going to use a system like this, and they shouldn't be exposing it. But you should be treating it not only by doing regular sustaining engineering and keeping it up to date, but you should be talking to your own developers and saying, "Do you like this system? Is it meeting the mark? How do you iterate on that?" Finally, cookie cutters scale. But when I go to a bakery, I see lots of different cookies that I want to eat. That's fine because just like multi-cloud, every system has its own unique challenge and business requirements. You need to be ready to have repeatable standardized setups regardless of the deployment target or the cloud provider. This type of system enables your developers to be happier. Happier developers lead to happier and more productive teams, and more productive teams lead to better business outcomes and happier customers, which is what we're all interested in at the end of the day. Thanks for listening. With that, we'll hand it back to Gaurav to take us home.

[![Thumbnail 1090](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/1090.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=1090)



Thank you, John. And before we wrap up, I would also like to highlight some of the other re:Invent sessions in the multi-cloud track that I would encourage you to go and attend.

[![Thumbnail 1100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/1100.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=1100)



I also would like to highlight that we have a multi-cloud kiosk at the AWS Village. You can go there for live demos of what we just saw here and also talk to some of our cloud experts around your use cases. Here are some of the QR codes with links to curated resources that you can reference for your multi-cloud journey.

[![Thumbnail 1120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/378b5230644855f7/1120.jpg)](https://www.youtube.com/watch?v=_hj3eOVGCJw&t=1120)



And last but not least, please do complete the session survey and give us your valuable feedback. Thank you again for joining this talk today. And myself and John are also available off stage to answer any questions that you may have. Thank you again.


----

; This article is entirely auto-generated using Amazon Bedrock.
