---
title: 'AWS re:Invent 2025 - Amazon''s finops: Cloud cost lessons from a global e-commerce giant (AMZ308)'
published: false
description: 'In this video, Nathan Perry, Senior Cloud FinOps Architect at AWS, shares three key lessons from Amazon''s FinOps modernization journey: building on AWS billing and cost management services as foundation, driving efficiency through business-aligned mechanisms, and scaling through intelligent automation. He explains Amazon''s transition from custom monthly reporting to AWS Cost and Usage Reports with hourly and ARN-level granularity, democratizing cost data across teams. Perry introduces Amazon''s "credit score" metric for measuring resource efficiency and discusses the Cloud Intelligence Dashboard for connecting cloud costs to business outcomes. He emphasizes the importance of transparency, automation, and integrating business metrics with AWS cost data to enable teams to make strategic decisions rather than manual analysis.'
tags: ''
series: ''
canonical_url: null
id: 3083201
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Amazon's finops: Cloud cost lessons from a global e-commerce giant (AMZ308)**

> In this video, Nathan Perry, Senior Cloud FinOps Architect at AWS, shares three key lessons from Amazon's FinOps modernization journey: building on AWS billing and cost management services as foundation, driving efficiency through business-aligned mechanisms, and scaling through intelligent automation. He explains Amazon's transition from custom monthly reporting to AWS Cost and Usage Reports with hourly and ARN-level granularity, democratizing cost data across teams. Perry introduces Amazon's "credit score" metric for measuring resource efficiency and discusses the Cloud Intelligence Dashboard for connecting cloud costs to business outcomes. He emphasizes the importance of transparency, automation, and integrating business metrics with AWS cost data to enable teams to make strategic decisions rather than manual analysis.

{% youtube https://www.youtube.com/watch?v=tPYmvdc5oE0 %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/0.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=0)

### Building a Modern FinOps Foundation with AWS Billing and Cost Management Services

 My name is Nathan Perry. I'm a Senior Cloud FinOps Architect on the AWS FinOps team. I've spent the last 11 years at Amazon helping some of our largest AWS customers build modern and scalable approaches to FinOps on the AWS cloud. For the last 5 years, I've worked with Amazon and all the Amazon lines of business as an AWS customer. If anyone's ever had a challenge explaining what they do to their friends or family, double that for me because I work for Amazon, but my customer is Amazon as well. So it kind of breaks my parents' brain. The idea is that I help Amazon understand how to operate effectively in the FinOps space, lower cost, work on cost visibility, and cost allocation.

I'm here today to share some of the lessons that I've learned in the last 5 years working with Amazon on this. I want to share three key lessons from our modernization journey that can help you accelerate your FinOps practices. First, building on AWS billing and cost management services for your foundation. Second, driving efficiency through business-aligned mechanisms. And third, scaling your FinOps practice through intelligent automation. Whether you're just starting your FinOps journey or you're scaling up, these insights are intended to help you move faster as you integrate your financial management systems with AWS billing and cost management.

[![Thumbnail 100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/100.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=100)

 Let's start at the beginning to set the stage. Amazon and all of our lines of business operate on AWS. Just like many customers, Amazon had to learn to operate in the cloud and more specifically how to build a really comprehensive FinOps stance, with the only caveat being enormous scale. We started with a data foundation. Our FinOps journey started with custom financial reporting that provided monthly views of our cloud costs.

[![Thumbnail 130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/130.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=130)

 Today we're working on transforming that foundation using AWS data exports, AWS Cost and Usage Reports, or CUR, and other AWS billing and cost management services. We're moving away from visualizing cost at a monthly grain or an account grain in favor of ARN grain and hourly grain. We're democratizing our cost data, and what I mean by that is that very often cost visibility can be siloed. It can be owned by FinOps teams or finance teams or operations teams. We're putting this in front of all of our teams: our builders, our leaders, our finance, our FinOps teams.

[![Thumbnail 160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/160.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=160)

 Building on this CUR foundation, we're enabling Cost Explorer across the organization to allow self-service cost analysis and enable more real-time decision making. We're deploying organization-wide tagging strategies that track investment and provide better fine-grain cost controls organization-wide. We're integrating this with AWS features like Compute Optimizer and AWS Cost Optimization Hub to vend efficiency opportunities at scale. This represents a bit of a shift for us from some of the centralized reporting to a more distributed model of cost intelligence. We're also leveraging AWS Organizations to help establish consistent controls, and it provides an aggregated tool set across all of our account footprints like a unified framework for our entire AWS footprint.

[![Thumbnail 220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/220.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=220)

### Driving Efficiency Through Business-Aligned Mechanisms and Cost Intelligence

 Remember that building on AWS services allows our teams to focus on driving business value rather than simply having to work on analysis. With this foundation in place, let's look at how we approach efficiency and how the integration of business-specific data helps play a part. The next challenge that we encountered was in driving widespread adoption of our cost management practices and in integrating these to run more efficiently in the cloud. Our key insight that we discovered was to make it as simple as possible to connect cloud costs to business outcomes at the team level.

[![Thumbnail 270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/270.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=270)

[![Thumbnail 300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/300.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=300)

We started by taking data and trying to make it more insightful. We combined two critical elements: granular costs from Cost and Usage Reports, or CUR, and business metrics that teams actually care about. This allowed Amazon and it will allow you to see not just how much you're spending, but what you're getting for each dollar spent. The key for us to driving adoption was connecting costs to business outcomes for our teams. We've included accounts and tag-based   cost allocation to business context, investment tracking, and we're automating return on investment analysis with AWS cost management services as this foundation.

[![Thumbnail 320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/320.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=320)

[![Thumbnail 340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/340.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=340)

We're working to simplify cost visibility.  For instances where the democratization or availability of Cost Explorer by itself is not enough for a team, we're leveraging the AWS Cloud Intelligence Dashboard. If anyone is not familiar with the Cloud Intelligence Dashboard or the CID, it's an open source framework  that was built to provide AWS customers very actionable insight and optimization opportunities at any scale.

An example is Amazon's budget data. We nest AWS service-specific budget data against actual AWS usage. This allows teams to see budgetary variances. Finance teams or operational efficiency teams can step in if an individual builder team or a larger part of the organization is having challenges, if they need to work on cost reduction initiatives, or if they need to revisit their budgets or their forecasts due to changes in business needs. We use the CID to integrate that contextualized business data alongside AWS infrastructure usage and create role-specific views that enable even more in-depth service analysis by our teams.

They can now answer their own questions much more strongly. I found having conversations with builders very challenging because without that visibility, everyone is expected to be a FinOps expert. We just cannot expect that of our engineering teams. We want them to build, and we want the monotony of FinOps to land on our shoulders because we're the FinOps practitioners in the room.

Here's a real world example. When a team sees a cost spike today, they can identify the accounts, the services, and the resources where it originated. They can visualize the business impact by looking at that alongside metrics like revenue or budget. They can tie it to an individual or initiative so that they can take immediate action. Now that we have teams engaged with this cost data, let's look at how we're incorporating efficiency into that mix.

[![Thumbnail 480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/480.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=480)

While cost visibility is crucial and honestly it's probably the thing I'm most passionate about, driving efficiency really requires mechanisms that can measure, monitor, and improve resource utilization at full scale. Here's how we evolved our approach to efficiency. The first thing was realizing that efficiency is not one size fits all. In the early days of our AWS adoption,  we recognized the need to provide efficiency reporting to Amazon teams. Amazon has a pretty well-known culture of efficiency with our frugality mindset, and that's really baked into how our builders operate, but that alone wasn't enough to really enable efficient usage of the cloud.

[![Thumbnail 540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/540.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=540)

We started by measuring the basic resource utilization metrics: CPU utilization, memory usage patterns, and network throughput across all of our teams. We quickly learned that efficiency was not one size fits all. Different workloads required different approaches, and the version of good that translated very well for a team like Amazon Retail wasn't necessarily the same version of good that translated to teams with very different workloads like Alexa or Prime Video. We needed to build central efficiency mechanisms and we needed a line on how we  could get as close to perfect in terms of these centralized efficiency metrics as we could.

We built mechanisms to track business-specific efficiency and monitor resource utilization against this centrally agreed upon ideal. Again, this wasn't universal, but for the lines of business that it held mostly true, we saw very significant gains in efficiency and cost reduction right out of the gate. We created a metric called the credit score. Our credit score essentially measured resource efficiency across many different services, and it was an iterative way to basically continue honing this ideal of a central baseline while continuing to build on what that version of good should look like and what the North Star is.

Our teams using Graviton: is usage aligned with central efficiency campaigns around capacity utilization or storage class optimization?

You know, is it aligned with how the business data that you're pulling in, like revenue or your budget data, correlates to that? All of these were included in this formula that allowed us to measure essentially the FinOps maturity of all of our lines of business. It allowed the mechanisms to really help teams optimize and save big dollars and large dollar amounts. Here's an example of how it would work in practice. Teams would receive a weekly efficiency score and it would provide cost recommendations that could be reviewed and prioritized by their level of impact. Teams were able to group these recommendations by things like technology category: storage, compute, generative AI, database, network. They could see them on accounts and on teams, and they could associate them with owners.

[![Thumbnail 690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/690.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=690)

[![Thumbnail 700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/700.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=700)

### Scaling FinOps Through Intelligent Automation and Creating Your Acceleration Path

All stakeholders in the cloud cost life cycle could see the opportunity and where it sits. Finance teams, leadership, technology owners, and operational efficiency teams could all view this data through the lens of their own respective disciplines, so they could see it in a way that made the most sense to them. Now that we've established our efficiency mechanisms, I want to talk about how automation  has been helping us scale these practices. At Amazon, we've learned that true cloud financial management is not a series of isolated tasks.  It's a continuous intelligent cycle. By integrating AWS services with automated workflows, we're working to transform what was once a very manual and reactive process into more of a self-improving system.

[![Thumbnail 720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/720.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=720)

Starting with this  concept of an intelligence cycle, our journey, which is still in progress, towards automating FinOps started with a really simple goal: just give the teams better visibility into their cloud costs. Through continuous iteration, we're working to create systems that have deeper insights into infrastructure spending patterns. Where teams once spent hours on manual analysis and spreadsheets, we're introducing automation into key processes like financial planning. Each improvement works to feed back into this learning cycle and it's helping us enhance our capabilities and move closer to our vision of intelligent cloud financial management.

[![Thumbnail 770](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/770.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=770)

Effective FinOps automation  starts with really comprehensive usage trends, budget variance, and capacity requirements. When optimization opportunities are identified, teams receive notifications through their own preferred channels. For well understood scenarios, teams can define policies and thresholds that trigger automated responses while maintaining appropriate controls over more complex decisions. This balance between automation and oversight is super important and it's crucial to building trust and driving adoption.

[![Thumbnail 810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/810.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=810)

On the topic of trust, the key for us to scaling FinOps wasn't just technology.  It's building trust through very consistent transparency. Every action, whether it's automated or manual, has to be logged and tracked in detail. Teams need to see exactly what's happening with their infrastructure costs and why. This transparency first approach has been really crucial in driving adoption of all the automation and the planning capabilities that we use across Amazon and all the Amazon lines of business, particularly in retail, where we've seen the impact of combining human insight with automated analysis.

Starting a FinOps automation journey doesn't require building everything at once. Begin with AWS services as your foundation and focus first on gaining visibility into your costs. Then gradually automate very well understood processes, like in our case, our financial planning and our OP one cycle. Planning and capacity management were big for us. As you build trust through transparency and you have results that can back that trust up, you can expand both the scope and the sophistication of your automation. Our goal, and it's important to remember this, wasn't to remove humans from the mix. It was essentially to elevate their role from routine analysis to more strategic decision making.

Now that I've talked about how these three pieces fit togetherâ€”visibility, efficiency, and automationâ€”I want to take a look at how you can build your own FinOps roadmap.

[![Thumbnail 910](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/910.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=910)

[![Thumbnail 930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/930.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=930)

 Throughout this section I've covered various aspects of cloud financial management. Let me share something that I find powerful: specifically how these pieces fit together to accelerate FinOps journeys for organizations of different sizes. Every successful transformation starts with  a solid foundation. We begin our journey with everything customâ€”our own tools, our own mechanisms, our own processes. What we discovered was that AWS billing and cost management services now provide better visibility than our custom solutions ever did. The AWS Cost and Usage Report gives the granular data that our engineers and leaders never knew they needed until they saw it. They didn't understand the power of that fine-grain cost control until they experienced it firsthand.

[![Thumbnail 980](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/980.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=980)

Cost Explorer puts analysis capabilities directly into our team's hands, and AWS Organizations lets us implement governance at massive scale, whether we're managing dozens, thousands, or tens of thousands of  accounts. But data alone is not enough. We learned that lesson the hard way. Real transformation for us happened when we connected business outcomes to our cloud cost. Think about it: knowing you spent $100,000 on compute or storage is important and a helpful metric, but understanding that $100,000 can be attributed to a million dollars in revenueâ€”that's something actionable. That's where the AWS Cost Intelligence Dashboards come in for us. They don't just show costs; they show team-level value. Everybody is able to see the metrics that matter to them in their language, aligned with their goals.

[![Thumbnail 1040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/1040.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=1040)

What began as an internal efficiency mechanism has evolved into features that can be implemented by anyone today. Automation is transformative.  Imagine moving from monthly cost reviews to daily optimization actions. We're not talking about just alerts; we're talking about intelligent systems that detect anomalies, recommend optimization, and even implement improvements automatically. Teams that once spent hours analyzing spreadsheets now focus on strategic decisions while automation handles the routine work. This isn't just about saving time; it's about operating at scale. Let me make this concrete. Three years ago, we were where so many AWS customers were or still are today. We were juggling multiple tools, wrestling with manual processes, and struggling to get clear cost visibility.

[![Thumbnail 1130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/1130.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=1130)

Today, we're integrating AWS services and automating insights. Looking ahead to 2026 and into 2027, we're enabling AI-enhanced optimization, predictive actions, and automating capacity planning. The coolest part to me is that this evolution is not years away for anybody trying to embrace it today. The capabilities are available right now. So the acceleration path starts with three clear layers. First, lay your data foundation.  Enable the Cost and Usage Report, implement a solid tag strategy, and get comfortable with tools like Cost Explorer and Cost Optimization Hub. This gives you the visibility you need to move forward confidently.

Next, build your integration layer. Deploy tools like Cost Intelligence Dashboards to connect your business metrics and enable automated recommendations. This helps turn data into business intelligence. Finally, activate your optimization layer. Implement efficiency recommendations, enable controls for transparency, and automate response actions. This is where FinOps practices become truly scalable. Remember how we started talking about the Dunning-Kruger effect? When Amazon started our FinOps journey, we really thought that our expertise in building custom solutions and tools was our greatest asset. It gave us a false sense of confidence in terms of how successful we were going to be right out of the gate.

What we learned, and what I hope you all take away from this, is that often the fastest path isn't necessarily the obvious one. It requires that we challenge our assumptions. While Amazon's scale can seem daunting, and it still does to me at times, the principles that we've learned work for organizations of any size. Start with AWS billing and cost management services. Build mechanisms that matter to your business units and automate intelligently. What we found is that the smartest choice was really the simplest one, and it's not what we started with. That choice is something you can use today to scale your own organization's approach to cloud financial management.

[![Thumbnail 1240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/903bb04b2cab62a1/1240.jpg)](https://www.youtube.com/watch?v=tPYmvdc5oE0&t=1240)

So thanks everybody.  Before I leave, I want to give a quick plug for One Amazon Lane. If you haven't been to it in the Caesar's Forum, it's in the southeast corner, but it's a very cool interactive exhibit where you can get hands-on with a bunch of really cool Amazon tech. Thank you all for your time today and enjoy Green Bay.


----

; This article is entirely auto-generated using Amazon Bedrock.
