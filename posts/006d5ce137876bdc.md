---
title: 'AWS re:Invent 2025 - Scaling support, compliance, & productivity with conversational AI at Coinbase'
published: true
description: 'In this video, Joshua Smith from AWS and Varsha Mahadevan from Coinbase discuss how Coinbase scaled their operations using generative AI on AWS. The session covers Amazon Bedrock and Bedrock Agent Core for building production-ready AI agents. Varsha details three key use cases: customer support (achieving 65% automation, saving 5 million employee hours annually), compliance (using AI for KYC, KYB, and TMS investigations), and developer productivity (40% of code is AI-generated, saving 75,000 hours in PR reviews, with 86% cost reduction in QA testing). The presentation emphasizes their GenAI platform using standardized MCP interfaces, agentic architectures with RAG, and tools like Claude through Bedrock for scaling AI across the organization.'
tags: ''
cover_image: https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/0.jpg
series: ''
canonical_url:
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Scaling support, compliance, & productivity with conversational AI at Coinbase**

> In this video, Joshua Smith from AWS and Varsha Mahadevan from Coinbase discuss how Coinbase scaled their operations using generative AI on AWS. The session covers Amazon Bedrock and Bedrock Agent Core for building production-ready AI agents. Varsha details three key use cases: customer support (achieving 65% automation, saving 5 million employee hours annually), compliance (using AI for KYC, KYB, and TMS investigations), and developer productivity (40% of code is AI-generated, saving 75,000 hours in PR reviews, with 86% cost reduction in QA testing). The presentation emphasizes their GenAI platform using standardized MCP interfaces, agentic architectures with RAG, and tools like Claude through Bedrock for scaling AI across the organization.

{% youtube https://www.youtube.com/watch?v=IkK6dSsC5fU %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/0.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=0)

### Introduction: Coinbase's Journey with Generative AI on AWS

 Hello and welcome to Reinvent session Industry 3312. We are proud to share with you today a story about how Coinbase scaled their support, compliance, and developer productivity workflows using generative AI on AWS. I'm Joshua Smith, a senior solutions architect here at AWS in Financial Services. I'll be joined by Varsha Mahadevan, who is the director of Machine Learning and Artificial Intelligence at Coinbase. Let's get started.

[![Thumbnail 40](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/40.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=40)

Today we're going to start with a quick introduction, followed by an overview of some of the key AWS services we'll be talking about.  These services are crucial for our customers to build scalable, secure, and resilient AI solutions. After that, I'm going to hand it over to Varsha from Coinbase, and she's going to go over their vision for AI, then she'll break everything down by use cases. She's going to cover customer support, and then she'll cover how Coinbase uses generative AI additionally for compliance and to enhance the developer experience. And then lastly, we'll close on how Coinbase sees their path forward.

[![Thumbnail 70](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/70.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=70)

### The Evolution of Generative AI in Financial Services: From 2023 to 2025

Taking a step back, when we talk about generative AI for financial services  specifically, it's important to look at where we came from and where we're going and the goals and challenges that drove us there. Back in 2023, what we were seeing is that large language models for customer and enterprise had just started to hit the market, and we were starting to get questions around trust and security of data. These were basic questions: how can we trust it with our data? Retrieval augmented generation, or RAG, was critical to businesses, and financial services customers had a treasure trove of data that they could use, but they weren't sure how to get it and make it useful in a way that was safe for them.

[![Thumbnail 110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/110.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=110)

Throughout 2024, after the release of Amazon Bedrock and other solutions  to manage secure data access, guardrails, and more, we saw customers start to use AI across a few key areas like customer support. The questions then started to be more around scale, capacity, and deeper questions around data access, streamlining it, granular security, and specific data storage or specific tools. Customers were exploring at this point how to apply the same well-architected frameworks that they were using for their traditional applications, but apply them to AI to architect them for future growth.

[![Thumbnail 150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/150.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=150)

But now finally in 2025, with the rise of more agentic patterns and more tools,  we're starting to see customers build fully multi-agent autonomous applications, and we're seeing customers start to ask how to completely transform their core business, entire departments of their business. The question isn't anymore how can we build this AI chat or something that is a singular tool. It's how do we revolutionize the way that our customers and our employees interact with that workflow? The goal here shifts into measurable impact and business KPIs.

[![Thumbnail 180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/180.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=180)

[![Thumbnail 190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/190.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=190)

### AWS Infrastructure for Agentic AI: Amazon Bedrock and Foundation Models

So how do we go and build this? It sounds great.  I'm going to briefly talk through a few key ways this is done with AWS services for agentic AI.  Whether you're looking to quickly pre-deploy pre-built agents to boost productivity, you're looking to experiment with open source tools, or you want to build a fleet of sophisticated custom agents, AWS provides the models, tools, infrastructure, and expertise that will help you succeed. We offer robust AI infrastructure, custom silicon, and data foundation tools to help ensure the longevity of those efforts. This is based on decades of experience that Amazon has building secure, resilient, and globally scaled infrastructure and advanced controls we have for data privacy, access management, monitoring, and observability to help customers confidently deploy these agents in every workflow.

We have Q Developer, Quiro, and Q Business for prototyping and building agents and taking advantage of your data. AWS Transform is used to automate modernization of legacy workloads like .NET frameworks and VMware, and we also have agents in Amazon Connect and agents and tools in the marketplace. If you look at this stack, all of this is surrounded by this investment into interfaces, protocols, security, and network enhancements for AI.

[![Thumbnail 260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/260.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=260)

We'll start in the middle here where we're focusing today. Amazon Bedrock is a fully managed service to help build, deploy, and operate generative AI applications, including agents. It provides access to leading foundation models like Anthropic, Meta, Mistral, and Amazon through a single API, and it consistently adds new models. We have tools to privately customize models, some of which we launched this week, and applications with your data, and apply safety guardrails, optimize for cost and latency, and rapidly iterate. Bedrock also newly includes Agent Core, which is a set of services to deploy and operate agents securely at scale. Because Bedrock is serverless, you don't have to manage infrastructure for all of this, and again, it's based on this proven infrastructure. 

[![Thumbnail 310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/310.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=310)

So Bedrock makes it easy  to build and prototype agents. However, Gartner predicted in their most recent report that over 40% of agentic AI projects will be canceled by 2027. The reasons they cited were growing costs, unclear business value, and insufficient security. So getting agents to production is still really hard.

### Overcoming Production Challenges: Introducing Bedrock Agent Core

The first challenge you have to overcome is deployment. In order to deploy AI agents, you need a specialized runtime. Unlike typical applications that follow predictable paths and user journeys, agents can operate over very long time horizons, and they process multiple different types of modalities. They can call different tools and services and make different pathways. The second reason is that as the underlying LLMs are stateless, the agents still need memory to retain context, learn from their past interactions, and provide personalized experiences.

Thirdly, you need fine-tuned identity and access control to ensure that agents can access only the systems and data sources they should. Who is this agent and what can they access? Fourth, you need to ensure that your AI agents can discover and interact with custom tools and data sources with the appropriate identity controls. You also need to execute multi-step workflows autonomously, and you need common tools in those workflows that are shared or restricted. Lastly, you need specialized monitoring that is specifically designed for agentic systems.

[![Thumbnail 420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/420.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=420)

Overall, I talked about a lot of different problems here, but the real message is that operating them in production is very different than prototyping with agents in Bedrock. These challenges are the reason that Amazon built Bedrock Agent Core.  Agent Core is a modular, fast iteration approach to building scalable production agents. If we look at the top, Agent Core is designed to simplify operations and tools for agents.

Agent Core runtime is a secure, serverless runtime that is purpose-built for deploying and scaling dynamic agents and tools, regardless of framework, protocol, or model choice. Developers can reliably run any type of agent, including multimodal, real-time, long-running agents, workloads up to 8 hours running with agents. It has checkpointing and recovery capabilities, and it supports graceful recovery in the event of unexpected interruption or failure. Agent Core Gateway allows you to easily integrate your MCP servers and your APIs with your agents, and provide an easy way to empower them with an array of tools. Agent Core browser and code interpreter allow your agent to act autonomously in the browser or to execute code on your own terms and your own rules.

[![Thumbnail 480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/480.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=480)

If we look at the bottom, I think of these as supporting tools  that help your agents act more effectively as they carry out these tasks. We have Agent Core identity, which helps you build enterprise-ready AI agents from a security perspective and an identity perspective. This has standards-based authentication, compatibility with existing identity providers, and native support for OAuth-enabled services. It has a secure token vault to enable authentication to have more frictionless user experiences for all your agent-powered interactions.

[![Thumbnail 540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/540.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=540)

Agent Core memory, as I mentioned before, is going to allow your agent to store and retrieve short and long-term memory for those complex workflows. How do you continuously use user input, continuously history, build on top of a shared memory? And then lastly, observability is going to help you centralize your observability stack for AI, combining logs, traces, and metrics to measure performance and accuracy at scale. Now that you have a foundation of AWS services for agentic AI, you are set up.  I am going to pass it over to Varsha, who is going to dive deeper into Coinbase's use cases. Thank you.

### Coinbase's Mission and AI Strategy: Building Trust Through Machine Learning

Thank you, Joshua, and thank you all for being here. I know it is the lunch hour, and I appreciate you being here. My name is Varsha, and Joshua already introduced me. I am the director for machine learning and AI at Coinbase, and today I am excited to share how we are leveraging generative AI to elevate both our customer experience and our internal productivity.

[![Thumbnail 580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/580.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=580)

Let us start with the bigger picture. Coinbase is a crypto exchange, but what is crypto and why does it matter? Crypto empowers economic freedom. It ensures fair participation in a global economy.  At Coinbase, our mission is to expand economic freedom to over a billion people.

[![Thumbnail 630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/630.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=630)

[![Thumbnail 650](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/650.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=650)

[![Thumbnail 670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/670.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=670)

We provide a secure and trusted platform for both individuals and institutions to trade and transact crypto assets safely and globally. To truly deliver on this mission, we have to concentrate on  three key pillars. First is building trust, which means we need to safeguard our users' assets with top-tier security and put in place strong protections against fraud and account takeovers.  Second is making crypto accessible. We do this by designing experiences that are intuitive and personalized with the power of AI and machine learning, and we simplify what can otherwise be very complicated financial products. The third is scaling globally,  so we operate efficiently and move quickly, supporting millions of users across 100+ countries and managing billions of dollars in trading volume. These pillars are really the foundation of everything that we do.

[![Thumbnail 690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/690.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=690)

At Coinbase, AI and machine learning are not just buzzwords.  They are fundamental to how we operate our platform. Let's take a look at how this works. Consider the user's journey on the platform. When a user comes in and wants to log in, ML models are at play defending against account takeovers. Second, once the user is logged in and wants to move some fiat currency into the crypto exchange, ML models evaluate the legitimacy of the user and the risk of any credit defaults. Third, when the user wants to move some funds from the centralized exchange onto the blockchain, ML models play a pivotal role assessing risks of any reversals before the funds are released onto the blockchain.

[![Thumbnail 760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/760.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=760)

That covers safety and security, but there is more.  We use ML to personalize every part of the user experience through personalized search results, tailored news feeds, intuitive recommendations, and real-time price alerts. All of these ML-powered experiences, whether for security or personalization, use advanced deep learning models trained on massive datasets. The training and inference for these run on a platform called AnyScale, a cloud platform based on an open-source framework called Ray, which we operate on an AWS EKS cluster.

[![Thumbnail 820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/820.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=820)

[![Thumbnail 860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/860.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=860)

[![Thumbnail 890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/890.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=890)

Having discussed traditional uses of machine learning for safety and personalization,  let's talk about innovations at the intersection of blockchain and AI. The first innovation is an adaptive and highly scalable risk scoring system for blockchain addresses based on graph neural networks. This powerful tool has been instrumental in detecting and blocking malicious blockchain addresses, protecting our customers from transacting with them.  Another exciting innovation is ERC20 scam token detection, which brings together smart contract auditing and machine learning. This solution helps us review assets before they are listed on an exchange, providing our customers more protection. The third innovation is a predictive  machine learning model.

We all know how volatile the crypto market can be, but despite this volatility, we still want to run a very reliable infrastructure. To do this, we have predictive models that allow us to scale our backend databases before a surge can occur. Altogether, these innovations are a great example of how we are using machine learning actively to shape the crypto landscape.

[![Thumbnail 940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/940.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=940)

Now let's shift gears.  We've talked about all of these traditional usages and some innovations, but now let's discuss a new generation of AI investments that we've been doing lately. No surpriseâ€”LLMs. LLMs have transformed the landscape ever since November 2022. It's a historic moment. We all talk about the pre and post ChatGPT era.

[![Thumbnail 1000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1000.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1000)

[![Thumbnail 1020](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1020.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1020)

[![Thumbnail 1030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1030.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1030)

There are three key areas where we are applying generative AI.  The first is customer support. We leverage AI-powered virtual assistants and build advanced tools to support our human agents. Together, these two capabilities enable smarter and more scalable customer interactions. The second area I would like to discuss is compliance. GenAI is helping us streamline complex investigations and navigate the regulatory landscape.  The third is developer productivity. I mean, all technologists in the room, I presume. We're improving developer productivity at Coinbase. Let's dive a little deeper into each one of these. 

[![Thumbnail 1040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1040.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1040)

[![Thumbnail 1070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1070.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1070)

### Transforming Customer Support with GenAI: From Chatbots to Agent Assist

Starting with GenAI transforming customer support at Coinbase.  Let's take a moment to understand the unique challenges of delivering exceptional customer support in the world of crypto. The first challenge is that crypto is incredibly volatile. User activity can swing up and down by a good 50 percent within a month. This kind of unpredictability puts a lot of pressure on our support systems. We simply cannot scale human support quickly enough to match these rapidly expanding user base. 

[![Thumbnail 1090](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1090.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1090)

[![Thumbnail 1110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1110.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1110)

The second challenge is trust. Trust is everything. Our customers need to feel safe and supported, no matter what's happening in the market. The third challenge is that we operate globally.  This means we have to support users across different languages, regulations, and expectations, requiring solutions that are flexible and adaptable. This is where GenAI enters the arena. GenAI helps us overcome these challenges and deliver great customer support, no matter the market conditions. 

We've crafted a strategy that focuses on both breadth and depth. These are important aspects. On the breadth side, we have an internal GenAI platform that integrates multiple LLMs and taps into a wide range of data sources. All of these access points are through standard interfaces. We use OpenAI's API standards when accessing LLMs, and we also use Model Context Protocol, or MCP, standards when accessing any of our data endpoints. This GenAI platform allows every team at Coinbase to easily leverage and extend our AI capabilities for their use cases.

[![Thumbnail 1170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1170.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1170)

When it comes to depth, we are making targeted investments in a few high-impact areas within customer support.  The first is automating customer-facing workflows with conversational chatbots. The second is providing our human support agents with intelligent tools to improve their effectiveness. The third is using GenAI to extract valuable insights from support tickets to help us continually improve our products and services.

[![Thumbnail 1210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1210.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1210)

The use cases I just discussed form a cycle and a continuum.  Let me walk you through how this works. First, a customer comes in and requires some kind of help. They interface with the AI-powered chatbot and receive instant assistance if possible. For more complex cases, they get escalated to a human agent, and those human agents are equipped with real-time AI assistive tools. Then, post-contact AI extracts patterns so that we glean insights and improve our products. Finally, once the product updates, we reduce the need for support and create more knowledge to automate the support. It's a complete cycle with feedback that works together.

[![Thumbnail 1270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1270.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1270)

Now let's dive into each of these use cases.  We'll start with the customer support chatbot. Chat has quickly become the go-to support channel for more than 50% of our customers. Trained on Coinbase's extensive knowledge base, our AI-powered chatbot is able to provide instant, accurate assistance around the clock while adapting to any kind of market volatility.

[![Thumbnail 1300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1300.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1300)

 Let me show you the layers in which we built the chatbot. We built it iteratively, starting very simple. The first layer you see highlighted here is a very simple FAQ-style RAG responses layer. We started simple so that we could focus on accuracy and build a strong foundation for more capabilities we wanted to add to the chatbot. This layer is able to automate simple queries such as sign-in issues, two-factor authentication problems, or other how-to questions.

[![Thumbnail 1350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1350.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1350)

Let's look at the agentic architecture that underpins this.  As shown in the picture, we start with the user input and any prior conversation history that is stored. We store it in a vector database, which serves as the memory layer for us. The RAG retriever is the fulcrum of this design. It uses Bedrock Knowledge Bases, where we vectorize and store all of the Coinbase help articles, and we also use Cohere's re-rank models to get high accuracy from the retrieved RAG articles.

[![Thumbnail 1390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1390.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1390)

[![Thumbnail 1420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1420.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1420)

 Another important component is the response generation. This is a mixture of LLMs, including the cloud models served through Bedrock, to generate a very precise response. Response generation is an important step that involves a sub-agent developed in an actor-critic architecture. Then come the guard rails.  You can see 22 gatekeepers here. You have input guardrails and output guardrails. These guard rails are powered with Bedrock Guardrails, which help protect us against harmful content and leakage of any sensitive PII. Additionally, we have custom domain-specific filters that participate in the input and output guard rails. These help us minimize any chances of prompt injection. We also have custom rules which help keep our responses grounded and reduce the propensity for any hallucination.

[![Thumbnail 1460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1460.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1460)

Now let's look at the next layer that gets added to it.  As things moved on, all of what I'm speaking about happened about 18 to 24 months ago, when we started. As we were building the chatbot and launching it into production, we also saw a lot of movement in the industry and the capabilities of the LLMs. We definitely knew that we could achieve more out of the chatbot than just the RAG layer we had introduced. That's where this next layer comes in. As these model capabilities got better, we enhanced our chatbot to directly follow what are called business procedures. From conversationally collecting information to actually taking direct actions on behalf of the user,

this second layer autonomously operates on business procedures and achieves all of that. The best part here is that these business procedures form what we call a single source of truth. This is very powerful. You have these business procedures that both humans and AI agents use alike, so it becomes a single source of truth, and this is indeed exceptionally powerful. It gives us a lot of adaptability to how we train both our humans and AI systems.

[![Thumbnail 1550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1550.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1550)

Queries about the user's account or specific queries about a transaction that may have been pending all get automated through the second layer now.  Looking at the same agentic architecture that I was showing you earlier, this is now a little expanded with added business procedure capabilities. We introduced what we call the Business Procedure Classifier. This is an important component that allows a query to be routed to the correct sub-agent. As you can see, there is a sub-agent that is emulating every business procedure in our system. The Business Procedure Classifier is a router that directs queries appropriately.

[![Thumbnail 1590](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1590.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1590)

[![Thumbnail 1610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1610.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1610)

The RAG agent that we saw earlier is actually one of the specialized sub-agents executing a specialized procedure which involves looking up the RAG knowledge base.   Now let's talk about the third and final layer that we added. This is the capability to actually do proactive issue resolution. By tapping into things like the user's signals and active incidents that may be happening in the platform, our AI agents are now able to anticipate common problems that users might be facing even before they need to ask us explicitly, hence the term proactive resolution.

[![Thumbnail 1650](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1650.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1650)

[![Thumbnail 1680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1680.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1680)

We've powered our chatbot with this capability, and you can see that layer also augmented in this agentic design.  The proactive issue resolution layer is another ReAct agent. If the bot is not able to find a proactive resolution for the user, then it does fall back to the Business Procedure Classifier layer that I mentioned earlier. As you'd expect, the proactive agent is also powered for all of its data access through standardized MCP servers. 

You've seen the iterative design that I talked about. Now there are a few factors that were very central and important as we made all of our design decisions. Model selection is a key aspect of it. Model selection wasn't just about finding the most accurate model that works. We needed a solution that struck the right balance between accuracy, latency, and scalability. It also wasn't a one-time decision. As the model capabilities were growing, we needed to reevaluate these choices time and again. That was a pretty central aspect to how we decided to operate on things.

The next is the tool standardization part. We specifically chose to standardize all of our tools access through MCPs, or Model Context Protocol, and it gave us a really strong foundation, not just for customer support, but for many other domains that we were operating in. We also focused on business adaptability. Like I was mentioning about the single source of truth, the single source of truth of business procedures was able to power both humans and AI, so that gave us the business adaptability that we wanted. Above all, we also made sure that the bot's responses were grounded. The factual correctness of what the bot was saying was an important factor. All of these were important principles that we always kept in mind as we were building the solution out.

[![Thumbnail 1790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1790.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1790)

We've seen all of these careful considerations, but despite all of this, it is paramount that we are able to observe and monitor how our chatbot is performing in production.  To make sure we're consistently delivering high quality responses,

[![Thumbnail 1830](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1830.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1830)

we made sure that we were using LLM as a judge evaluations. So every chatbot response is assessed for things like relevancy, accuracy, potential bias, hallucinations, and more. We actively track all of these quality metrics and monitor trends, and that allows us to quickly spot any anomalies and step in as needed. 

Now, having talked a lot about the chatbot, let's look at one other use case that I had mentioned earlier. This is called Agent Assist. What you're looking at here is a picture of our AI-powered Agent Assist tool, which is designed to help our human customer support agents. As you can see, the middle pane is that of the human chatting with the customer. On the right side is where you see this Agent Assist tool, and it provides suggestions to the human agent to respond to the customer.

As we've established, it's the complex issues that actually come to the human agent, so the human agent is actually dealing with a stressful, highly complex situation. In that environment, the Agent Assist tool provides real-time assistance to diagnose the customer's issue and also mitigate it. The Agent Assist tool also draws from account signals, ongoing incident data, and past customer support tickets. Agent Assist provides personalized guidance and generates very precise responses in many different languages. That's another important aspect because Coinbase serves customers across 100+ geographies globally. So this is an important aspect that Agent Assist provides.

[![Thumbnail 1940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/1940.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=1940)

The end result of all of this is faster resolutions, happier customers, and great efficiency across the board for our support teams. 

Let's draw some attention to the actual numbers here. What did the impact look like? It's pretty impressive actually. Today, close to 65% of our customer contacts are handled automatically by our AI systems. That's a big number. This automation consequently saves us nearly 5 million employee hours every year. That's an annualized number, which is significant cost savings to the business and a productivity boost as well.

[![Thumbnail 2030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2030.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2030)

Most importantly, these 65% automated cases are now resolved in a single interaction. This is a very important aspect. When cases are handled by automation, they get resolved in less than 10 minutes. But when cases go to a human agent, they can be long drawn and take up to 40 minutes. So these systems, as much as they are a productivity boost, they actually enhance the user experience substantially. That's an important takeaway. These results are showing us how powerful AI can be when it's operating at scale and the difference that it is making both to the business and to the customers. 

### AI-Powered Compliance: Automating AML, KYC, and Complex Investigations

We've talked a lot about customer support. Now let's move on to another sphere: compliance. It's super important for a fintech entity like Coinbase. When it comes to compliance, you've probably heard about terms such as AML, which stands for anti-money laundering, CFT stands for counter financing of terrorism, and ABC stands for anti-bribery and corruption. As a regulated financial entity, Coinbase as a company is committed to upholding the highest standards of these practices, and you do not want anybody using the platform for any such malpractices.

[![Thumbnail 2050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2050.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2050)

In order to uphold these standards, we implement several processes such as KYC, which stands for Know Your Customer, KYB stands for Know Your Business, and TMS stands for Transaction Monitoring Systems. All of these processes, while they are super important, are a very heavy lift for the company and highly human intensive. 

On top of that, we have the market volatility that we've been discussing, which means that scaling the human workforce is not easy. The second challenge is that regulatory bodies expect a very thorough investigation of all compliance cases. They need absolute detailed, full explainability of all cases that go through our system. This is a very important aspect to keep in mind. The third challenge is that because we operate in so many different countries, we have to adapt our compliance processes to meet those diverse regulatory requirements across the board. One size definitely does not fit all in this case.

[![Thumbnail 2160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2160.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2160)

So, what was our strategy?  We look at the breadth and then we look at the depth. I talked about this earlier. On the breadth, we leverage the same internal GENEI platform that I mentioned earlier. The GENEI platform gives you fluid access to LLMs and the data through MCP interfaces. There is something that is a little different about compliance compared to customer support. The compliance solution also entails a traditional machine learning model that detects high-risk compliance cases. For these, we rely on any scale, which is based on the Ray framework. We use our any scale-based ML platform to build these traditional machine learning models that detect the high-risk compliance cases for us.

[![Thumbnail 2220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2220.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2220)

On the depth aspect, with compliance, we built several different solutions.  We've made some intentional investments. For example, we've built advanced deep learning models that are able to detect high-risk cases in multiple different compliance processes, including KYC, KYB, and TMS. I talked about these earlier. Beyond the detection, we also use AI to automate and accelerate complex investigations. These investigations involve gathering and synthesizing data from a variety of different sources, and we apply rigorous approaches of investigations across all of these compliance workflows like KYC, KYB, TMS, and so on.

[![Thumbnail 2270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2270.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2270)

What you see here  is a screenshot of another tool called the Compliance Assist tool. Earlier, I showed you the customer support agent assist tool. This is sort of analogous, but this is for the compliance agents. This is an assistive tool. You can see that this is AI powered and the AI system has automatically gathered and synthesized information from a wide range of different sources. It has pulled data from our internal systems as well as open source intelligence. The AI then composes a narrative summary and gathers a set of clear risk review signals. Our compliance agents, the human agents, are now handed a fully documented, explainable investigation that equips them to make well-informed decisions quickly and with a lot of confidence. This is a great example of where AI is empowering our teams and elevating the standards of our compliance operations.

[![Thumbnail 2340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2340.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2340)

[![Thumbnail 2370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2370.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2370)

This is a quick walkthrough of the block diagram that illustrates the agentic  architecture that we follow. Starting on the left, our process begins where the compliance risk models that I talked about earlier, these are the deep learning models, trigger alerts on high-risk cases. That's where it all begins, and this initiates what's called a holistic review. A holistic review is a comprehensive investigation of a high-risk compliance case. At the center of this solution is our compliance auto resolution  engine, or CAR for short, which acts as the orchestrator for the entire holistic review process. This is where the agentic AI-driven workflow comes into play. It mobilizes both automation and human expertise.

[![Thumbnail 2390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2390.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2390)

The orchestration engine coordinates  a human-in-the-loop process, interacting with two different human personas. The first is our own compliance operations agents. They review the findings of this AI system and they provide essential feedback to keep improving it.

[![Thumbnail 2420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2420.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2420)

[![Thumbnail 2440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2440.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2440)

Additionally, wherever necessary, the system reaches out to our end customers for additional information through RFIs, or requests for information.  Throughout this process, the engine aggregates and synthesizes data from a wide variety of sources. We discussed internal, external, and open source intelligence, all of which is accessed through standardized MCP 5 data connectors. 

The end result is a robust AI-generated report which we call the narrative summary. It is important to note that the final decision always rests with our human compliance operations agent. After reviewing the AI's reasoning and all of the compliance evidence that the AI system has gathered, this individual determines whether a case warrants filing what is called a suspicious activity report that needs to be filed with the government authorities, because the company is liable and responsible for reporting it to the government should a particular high-risk case be proven.

[![Thumbnail 2500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2500.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2500)

### Revolutionizing Developer Productivity: Code Authoring, Review, and Quality Assurance

This approach brings together the best of both worlds: the speed and depth of AI combined with human oversight. We have talked about customer support and compliance. Now, how can we not talk about developer productivity? We would be doing a disservice if we did not address this. This is a hot favorite topic. Let me talk about how we are making a real difference and how AI is radically transforming our software development life cycle, or SDLC, at Coinbase. 

[![Thumbnail 2520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2520.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2520)

[![Thumbnail 2570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2570.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2570)

Today, AI agents help our engineering teams at different stages. They help consolidate tasks like coding, ticketing, documenting, pull request creation, reviewing pull requests, and more. In short, what we have is an AI-powered SDLC that is accelerating productivity across the board.  Today, I will specifically talk about three aspects of this SDLC process: code-authoring, code reviewing, and quality assurance. 

[![Thumbnail 2600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2600.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2600)

Let us talk about code-authoring. The visual you see is probably very familiar to many of you. This is Claude, a state-of-the-art coding assistant that integrates directly into your IDE or can also be used from the command line. Coinbase developers definitely love it. This other visual is that of Cursor, yet another intelligent, context-aware IDE designed to make software development faster, more collaborative, and more efficient. 

[![Thumbnail 2640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2640.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2640)

Developers are a passionate and opinionated lot. That is why what we do at Coinbase is offer a few of these best-in-class coding tools as paved path options to our developers, and our engineers have the freedom to choose whatever works best for them. All of these tools are powered with Anthropic models that are served through Bedrock. 

Now that we have talked about code-authoring, the next step in the development process is pull request and code reviewing. The tool you see here is a homegrown tool adapted from an open source tool and enhanced with Claude models from Bedrock. This agent is implemented as an AI-powered GitHub action that automates PR reviews. It summarizes the pull request and the underlying code changes that have occurred.

As a developer, you often receive a PR review with several tens of files of changes, and you do not know the context because not all developers are diligent about explaining what the change is and why they made that change. Tools like these automatically summarize that change for you, which is very informative for the person trying to review it.

[![Thumbnail 2710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2710.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2710)

They also generate clear natural language review comments wherever applicable, just like a senior engineer would.  Beyond that, this tool also enforces coding conventions, which is an important aspect. Many times, human reviewers spend their time explaining to junior developers what the coding conventions are and how they should write code better for maintainability and other considerations. This tool highlights any gaps in unit testing coverage, which is another important aspect. As an added benefit, if there are any failures in the continuous integration system, it also provides useful tips on how to debug those issues.

[![Thumbnail 2760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2760.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2760)

[![Thumbnail 2770](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2770.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2770)

We've seen great results from this tool. Now, this doesn't mean that developers don't have to review code manually. What we do here  is ensure that all of these routine aspects of code review are handled by this AI-powered automated system.  This allows human developers to focus on the nuanced aspects of the code and deliver higher value. Regarding quality assurance, coding assistants like Claude and Cursor already allow you to automate unit test generation. However, we're taking things a step further with another homegrown AI-powered tool for automated UI testing.

[![Thumbnail 2870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2870.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2870)

This tool brings end-to-end quality assurance automation for our web and mobile UI. It converts natural language test descriptions directly into autonomous browser actions, which is very powerful. It allows us to test the UI the way a human would. The browser actions are performed across a variety of different form factors using services like BrowserStack, which gives us access to different devices where we can test these browser actions. The browser actions are also emulated through frameworks like Playwright. This brings us incredible scale and agility to UI testing. When issues are found, this system captures screenshots and generates structured reports,  making it easy for our development teams to address those bugs and problems.

[![Thumbnail 2880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/2880.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=2880)

Let's talk about the impact and what the numbers show.  Developer productivity is showing very positive results, and we're confident this will continue to grow. Today, nearly 40% of all code written daily at Coinbase is AI-generated or AI-influenced. Our goal is to surpass 50% very soon. Of course, we understand that every line of code still needs to be reviewed and understood by a human developer, and we know that AI-generated code isn't suitable for every part of the business. Nonetheless, wherever it makes sense, we want our teams to harness this superpower responsibly and as often as possible.

Our investment in the PR reviewer is also paying off significantly. We estimate saving about 75,000 hours annually through these automated PR reviews. Beyond that, it's also raising the overall code quality by enforcing coding conventions. Regarding quality assurance, the results are particularly impressive. It's achieving accuracy on par with our human testers and is able to detect three times as many bugs as a human would in the same amount of time. It dramatically speeds up the process of introducing new tests, sometimes in as little as 15 minutes. Consider how that compares with the hours needed to train a human tester to test UI functionality.

When you look at cost efficiency, we're seeing about 86% cost reductions compared to traditional manual testing.

[![Thumbnail 3030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/3030.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=3030)

### Looking Ahead: Democratizing AI Across Coinbase with Agent Core

All in all, we're really excited about the results, and we're looking to go places with it. Now that we've talked about these three dominant domainsâ€”our investments, our impact, and what we're seeing from themâ€”let's discuss what's next for Coinbase. Through all of these use cases that I've shared today, we can see that we are unlocking a lot of power.  But truly, our mission is to put AI agents and the ability to build agents in the hands of every employee. We truly believe we have many miles to go towards that goal.

[![Thumbnail 3050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/3050.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=3050)

We want to empower both individuals and teams to create, experiment, and innovate.  This will not only bring benefits in terms of everyday productivity but also reimagine how we offer our products to our customers. As we look into the future, our focus is on scaling these capabilities for even bigger enterprise-wide impact. We are working to modernize and upgrade many of the tools and technologies that we've developed over the past two years.

This is somewhat ironic. All of us have talked about software that has been built over many years, and there are sessions about upgrades from .NET to new frameworks. These are systems that have lasted a decade. But now we're talking about modernizing what has been built in the last couple of years. That's the nature of this landscape. AI is moving at breakneck speed, so yes, we do need to keep thinking about how we're going to modernize these AI systems and keep up with the innovation in the industry.

[![Thumbnail 3120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/006d5ce137876bdc/3120.jpg)](https://www.youtube.com/watch?v=IkK6dSsC5fU&t=3120)

That's where platforms like Bedrock Agent Core truly come in, and we're really excited about using Agent Core for this next wave of expansion in our AI investments.  We have talked about Agent Core in many different regards. One is secure agent deployment and the robust identity and authentication management that it offers across both agents and MCP tools. Features like powerful memory and advanced interoperability are very exciting for us and hold many possibilities.

Summing it up once again, our goal is to democratize AI across Coinbase so that every employee at Coinbase can leverage this technology, solve problems, and create value for our customers while keeping us at the forefront of our industry. Thank you so much for listening.


----

; This article is entirely auto-generated using Amazon Bedrock.
