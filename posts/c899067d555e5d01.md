---
title: 'AWS re:Invent 2025 - LSEG: Modernizing critical financial systems with multicloud and hybrid cloud'
published: true
description: 'In this video, Richard Chester from AWS and Dean Bryen from London Stock Exchange Group discuss LSEG''s multi-cloud strategy across 1,300+ AWS accounts plus Azure and Google Cloud. Dean explains their multi-cloud product framework built on a cloud capability framework, standardizing on Terraform and native services where possible. Two use cases demonstrate AWS ultra-low latency Outposts: FX PriceStream achieved 6x latency improvement (181 microseconds median vs 1.1ms on-premise), and London Clearing House met Bank of England''s 5-day disconnect requirement for critical national infrastructure using Outposts with EKS, Oracle, and NetApp replication across regions.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/60.jpg'
series: ''
canonical_url: null
id: 3085232
date: '2025-12-05T04:15:38Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project enhances multilingual accessibility and discoverability while preserving the original content. Detailed transcriptions and keyframes capture the nuances and technical insights that convey the full value of each session.

**Note**: A comprehensive list of re:Invent 2025 transcribed articles is available in this [Spreadsheet](https://docs.google.com/spreadsheets/d/13fihyGeDoSuheATs_lSmcluvnX3tnffdsh16NX0M2iA/edit?usp=sharing)!

# Overview


ðŸ“– **AWS re:Invent 2025 - LSEG: Modernizing critical financial systems with multicloud and hybrid cloud**

> In this video, Richard Chester from AWS and Dean Bryen from London Stock Exchange Group discuss LSEG's multi-cloud strategy across 1,300+ AWS accounts plus Azure and Google Cloud. Dean explains their multi-cloud product framework built on a cloud capability framework, standardizing on Terraform and native services where possible. Two use cases demonstrate AWS ultra-low latency Outposts: FX PriceStream achieved 6x latency improvement (181 microseconds median vs 1.1ms on-premise), and London Clearing House met Bank of England's 5-day disconnect requirement for critical national infrastructure using Outposts with EKS, Oracle, and NetApp replication across regions.

{% youtube https://www.youtube.com/watch?v=_pvkfhA7nks %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
### Introduction: LSEG's Multi-Cloud Journey with Over 1,300 AWS Accounts

Good afternoon, everyone. I hope you're enjoying Reinvent, and thank you for joining us today. My name is Richard Chester. I work in financial services for AWS as a principal solution architect, and I'm based in London. I'm delighted to be joined on stage today by Dean Bryen, head of cloud engineering for the London Stock Exchange Group.

[![Thumbnail 60](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/60.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=60)

For the purposes of everybody here, London Stock Exchange Group, or LSEG, is what we use for short. LSEG is well advanced in its journey in public cloud, with over 1,300 AWS accounts. In addition to a significant presence on Azure and Google Cloud, and a sizable on-premises footprint. So like many AWS customers, LSEG is a multi-cloud organization. 

[![Thumbnail 80](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/80.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=80)

Today we'd like to start by giving you a little bit of background about LSEG, what it is and what it does.  Then Dean will take over and talk you through the multi-cloud strategy. After that, we'll conclude with a couple of interesting and quite different use cases that show the placement strategy of workloads at LSEG. We've been collaborating on these for the past 18 months.

[![Thumbnail 120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/120.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=120)

LSEG was founded as a regulated exchange in 1801, with a rich history stretching back through coffee houses and the Royal Exchange.  LSEG is a global provider of market data and financial infrastructure headquartered in London. Among a number of trading platforms it operates, it manages the London Stock Exchange, as the name would suggest, and oversees international equity, fixed income, and derivative markets. The group has more than exchanges in its portfolio.

[![Thumbnail 140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/140.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=140)

[![Thumbnail 150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/150.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=150)

It also offers real-time and reference data products.  Through FTSE Russell, it curates category-defining indices. It develops capital market software used by other exchanges, provides extensive post-trade services, and helps fight financial crime through the risk intelligence business. 

[![Thumbnail 160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/160.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=160)

Now, executing a business transformation through a single cloud provider would be an interesting challenge.  To avoid making this an overwhelming prospect, LSEG has implemented a structure which Dean will now explain. Dean, over to you.

### Building a Deliberate Multi-Cloud Framework: LSEG's Cloud Capability Strategy

When people talk about multi-cloud, you might often think that it's a deliberate strategy that they're taking. But the reality is, and you may or may not agree with me, that most organizations end up there by accident sometimes, through acquisitions, commercial agreements, or maybe there's some regulatory requirement around exit strategy and things like that. When you start doing this, you start realizing that running multiple cloud providers isn't just more of the same; it introduces a whole load of additional complexity.

[![Thumbnail 210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/210.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=210)

[![Thumbnail 230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/230.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=230)

So what challenges do we have with multi-cloud?  In regulated industries, we often have a requirement to meet regulations around exit strategy, concentration risk, and diversity. Using multi-cloud can help us meet some of those requirements. On the technology side, without clear direction, teams build unique identity and access management, logging, monitoring, and golden images across different cloud providers, which causes some constraints as well. 

[![Thumbnail 250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/250.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=250)

From an operational side, running one well-secured, governed, and regulated cloud provider is pretty difficult. Doing that operationally across multiple cloud service providers introduces a whole load of operational complexity.  And then there's people. Generally, people are either an AWS engineer or an Azure engineer. It's quite rare to get people that understand both cloud providers or Google Cloud. You've got a unicorn if you've got someone who understands those to the depth that you need to run a regulated cloud platform. And inertia is real as well. People generally stay with what they know.

[![Thumbnail 290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/290.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=290)

So at LSEG, instead of fighting these challenges, we took a step back and thought about how we can make multi-cloud seem deliberate. How can we build a framework that helps us have multi-cloud in a way where we can leverage the multiple cloud providers where it makes sense, but we can still get the best out of the benefits that each of the cloud providers has for us? 

So what does that look like? At LSEG, we've built a multi-cloud product framework. It starts at the bottom with our cloud capability framework. This is a common foundation of capabilities that we define that says what a good cloud environment should look like. It sets standards and principles for things like identity and access management, networking, policy, and so on. This means that when we build on top of this with multiple clouds, we can ensure consistency and alignment across all our cloud environments.

[![Thumbnail 330](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/330.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=330)

[![Thumbnail 350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/350.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=350)

They can be built on a set of common primitives and features, and our developers in the business know that they get feature parity across the cloud providers. We store this in Git, it's version controlled, it's constantly updated, it's a living framework that we build our cloud platform on top of. Sitting on top of that are our core cloud public cloud platforms. These are our landing zones.  We have one in AWS, one in Azure, and one in GCP. These give us standard APIs for things like IAM, networking, account vending, and typical landing zone operations you would have in a core platform.  When workloads need to remain on premises, we've decided to use AWS Outposts for distributed or hybrid cloud. This gives us the ability to have a consistent set of APIs and interface that our developers are familiar with to deploy on premises when the need is there.

[![Thumbnail 370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/370.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=370)

What we quickly found was that building cross CSP capabilities, there were lots of common things, and as I said earlier, we were starting to build things that were independently different across the cloud providers.  Some examples here are things like policy. We've decided to standardize on a standard policy engine that is uniform across all our cloud providers. We do golden images centrally, some integration, some of our security tooling, things like FinOps, service management, incident management are things that are common and make sense to do across cloud providers, and we're starting to do some AI tooling in this space as well.

This is really the crux of some of the decisions that we have to make in our organization, and I have to make as the head of cloud engineering. One of the most difficult decisions is when we stay with the native services in the cloud provider and when we decide to go agnostic. The principle that we stand by is that where possible, we will always go native as much as possible for application teams, unless there's a reason for us to go cross-platform. There are a few examples of that, things like some of our unified observability across platforms where we need a single view across these core platforms. It makes sense for us to use some agnostic tooling for that. But if you're an application team that solely runs on AWS, it might make sense to use more native services for observability there for the application team. We only really make those decisions to go across CSP when it makes a ton of sense and it's really obvious, or there's regulatory or compliance reasons for us to do so.

On top of that, we've built unified orchestration and management. From an infrastructure as code perspective, we've standardized on Terraform as our tool of choice for provisioning our cloud resources and our platform resources. We build our platforms with this as well. We don't really treat Terraform just as a provisioning tool. We see it as an extendable, extensible API for our developers to consume our services. As a regulated organization, we build verified modules that comply to our security frameworks, to our policies, and they have opinionated defaults built in to make it easy for our developers to deploy. We standardize in a product we call the Cloud Product Framework, which is those modules that we provide out to our developers across all of our underlying cloud platforms.

[![Thumbnail 530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/530.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=530)

When you build landing zones, you have privileged operations, things that you wouldn't want your developers to do, but you'd still like them to self-service. This includes things like account vending, maybe IAM access packages and role provisioning, maybe some networking operations. To do that we've built a custom orchestrator, a provider-based orchestrator that's extensible for doing those privileged operations in a self-service API-driven way for our developers.  At the top level is where we really meet the developers in our organization. We've adopted the term from Werner from last year of simplexity, and we like to use that internally quite a lot. Building these landing zones in cloud platforms is quite complex, so we abstract the essential complexity behind clean APIs and interfaces for our developers.

[![Thumbnail 560](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/560.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=560)

[![Thumbnail 570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/570.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=570)

[![Thumbnail 580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/580.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=580)

What benefits have we got from this? Our developers are more productive.  We can now get applications to cloud within the last year of doing some of this stuff almost 80 percent faster in some cases.  We've bolstered our security and compliance because we've got a standardized framework. It's a lot easier for us to be consistent and have a better security posture across all of our cloud providers.  We've got enhanced collaboration. My platform engineering team is collaborating more, there's reuse, they're working together in some of those cross-cloud capabilities, and we've saved costs, both in resource costs, but also license costs and operational costs as well. There are a number of benefits that we've got from doing this.

[![Thumbnail 600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/600.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=600)

### FX Price Stream Modernization: Achieving Sixfold Performance Improvement with Ultra-Low Latency Outposts

I'm going to hand back to Rich who's going to talk about some specific use cases here at LSEG that we've been doing that are utilizing multi and hybrid cloud.  So we've come to the first of our use cases. This is the uplift of FX Price Stream system. FX Price Stream is a global dealer to client streaming court service.

It offers disclosed liquidity across more than 150 currency pairs by linking liquidity providers, the makers, with taker clients in foreign exchange trading. Globally, it serves over 100 liquidity providers and more than 1,200 taker clients, and while it's not a regulatory requirement, all are served using fair and equal access.

[![Thumbnail 640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/640.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=640)

Let me walk you through the challenges of the existing system. The existing challenges fall into three main categories. First, we have modernization.  While LSEG FX trading infrastructure requires periodic modernization, it does create opportunities to look at new technologies and different ways of doing things. For example, they might use kernel bypass to offload some of the high-performance capabilities so they can use high-performance network interface cards.

[![Thumbnail 670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/670.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=670)

Next comes latency and performance.  The venues have two different kinds of latency. There's macro latency performance, which means that the venue needs to be close to the liquidity providers geographically. But there's also micro latency performance as well, which means the traffic needs to flow from front to back as quickly as possible. The thinking is that if you can improve performance, you can reduce trade rejection rates, drive your volumes up, narrow margins, increase market share, and essentially make more money.

[![Thumbnail 700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/700.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=700)

Finally, we have infrastructure and cost.  As currency trading shifts from primary markets to secondary markets, this causes fragmentation and increases competition. What that means is there's a high upfront cost with capital expenditure, so it's going to be difficult to keep setting up the same infrastructure globally because you're essentially starting from scratch as technology moves on. If you're unable to use a cloud provider in region due to macro latency and you're unwilling to endlessly cycle through ubiquitous hardware, we chose a different route: using ultra-low latency outposts.

[![Thumbnail 750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/750.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=750)

The solution leverages AWS ultra-low latency outposts.  These have optimized bare metal compute with deterministic performance. They have a physically separate network that features ultra-low latency network interface cards. The racks come with equal distance cables and layer two multicast, which isn't available in region, to ensure fair and equal access. The description I'm giving essentially shows the data flow from left to right in the diagram. The top-to-bottom direction is another AWS differentiator.

[![Thumbnail 800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/800.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=800)

[![Thumbnail 810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/810.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=810)

AWS's proprietary Nitro technology provides superior performance through dedicated hardware. You can maintain your security through encrypted connections and built-in tamper detection. Because it's a service-based approach, LSEG doesn't need to manage things like firmware upgrades. So let's look at the results. The PriceStream application on ultra-low latency outposts operates at the 49th percentile for one millisecond versus two milliseconds on premise, so a twofold increase.   The median is 181 microseconds at a peak rate of 165,000 messages per second, compared with 1.1 milliseconds on premise in production. That's a sixfold improvement, and also at 3.3 times the production peak on premise.

[![Thumbnail 840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/840.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=840)

[![Thumbnail 860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/860.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=860)

If we look at the fanout across sustained, where we're looking at double the peak for longer periods, it's twice as quick.  All told, it's faster across all percentiles, it's faster at a much higher peak, and when it fans out sustained, it's also much faster. So it's faster by every measure that we've tried.  I'm going to hand back to Dean. We're going to discuss one more use case which looks at a different feature of ultra-low latency outposts.

### London Clearing House Resilience: Meeting Bank of England's Five-Day Disconnect Requirement

LSEG is a group of companies with lots of different organizations within the group. I've talked about some of the FX work that we've been doing on outposts. I'll talk about a slightly different use case now about our London Clearing House. The London Clearing House is majority owned by LSEG. It's a global financial markets infrastructure organization. It acts as a central counterparty to clear and settle a wide range of financial transactions, including swaps, equities, and repos. It reduces risk for its members by acting as an intermediary between buyers and sellers in a trade, giving them confidence and ensuring that trades are completed successfully, even if one of the parties in the trade defaults.

[![Thumbnail 930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/930.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=930)

The clearing workloads that run inside LCH, the London Clearing House, are in the AWS region, but they are mostly migrated from on-premises rather than developed in the cloud in AWS. 

[![Thumbnail 940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/940.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=940)

[![Thumbnail 950](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/950.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=950)

As with many on-premises workloads, the LCH services have challenges that are well suited to the public cloud.  They need scalability and elasticity. They need innovation and experimentation. We need to move fast and keep up with the market, and we need to reduce the time to market.  What is really important, the single most important factor, is that our LCH workloads are built for resilience.

[![Thumbnail 1030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/1030.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=1030)

The London Clearing House workloads are considered critical national infrastructure in the UK. This means they are under the highest scrutiny from our regulators from a resiliency perspective. Meeting changing regulatory requirements can be difficult, but in our case, there have been some interesting requirements, specifically around critical national infrastructure that make this more interesting.  The Bank of England in March 2023 announced a new directive requiring us to explore options for a total cloud service provider outage. We had to be able to operate completely independently of the cloud service provider going down.

We looked at this as a team and considered a couple of options. We could have stayed on-premises or replicated to another cloud provider, but when we took a step back and looked at it, we thought that did not really make sense because it introduces operational complexity. The last thing you want in a major cloud service provider outage is more operational complexity. That is the kind of thing we want to avoid. Resiliency is really the key thing for us here.

[![Thumbnail 1040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/1040.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=1040)

[![Thumbnail 1060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/1060.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=1060)

The solution that the LCH team built runs predominantly in region.  In the primary region, we are running Amazon EKS, using Oracle and Amazon RDS, and Amazon S3 for storage, and Amazon FSx for NetApp ONTAP, which is our storage solution. Being involved in a NetApp ecosystem gives us flexibility that you will see in a moment.  To first address resilience, we replicate into a secondary region, which is standard multi-region cloud architecture, and the NetApp solution gives us the ability to replicate our data between regions.

[![Thumbnail 1080](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/1080.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=1080)

To meet the Bank of England requirement, we have built a tertiary solution sitting on AWS ultra-low latency outposts, which gives us the ability to meet  the five-day disconnected requirement that the Bank of England has mandated for us. On the outposts, we go via AWS Direct Connect to a local gateway, and we run Amazon EKS on outposts, Oracle on EC2 on outposts, and because we do not have Amazon RDS on the low-latency outposts, we also use a NetApp device on-premises so we can replicate the data to on-premises as well. For some final resiliency and in an absolute worst-case scenario, we replicate the data to Azure as well.

We have actually proven this. We have tested the five-day disconnect with the outposts. We have disconnected and proven to the Bank of England that we can meet their requirements for five-day disconnect successfully. We have done the failover and the failback, including migrating our database to the outposts solution as well. This really proves that we are able to meet these requirements while reducing operational complexities and staying within the AWS ecosystem, apart from the Azure NetApp environment, which makes it really easy for our developers.

[![Thumbnail 1180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/1180.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=1180)

We have a common API within AWS Outposts, and it is a familiar environment for them to work with. This is groundbreaking in the way that regulators treat critical national infrastructure and financial markets infrastructure, and it has given us the ability to sell to them the benefits of running this critical national infrastructure in a cloud ecosystem like we have demonstrated in this architecture here.  With that, I am going to pass back to Rich, who is going to sum up.

[![Thumbnail 1200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/1200.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=1200)

Unfortunately, we are out of time because we had problems with the clicker, so I will have to go very quickly. Take a structured approach to multicloud, balancing cloud native and cloud agnostic.  Ultra-low latency outposts can be used for low-latency requirements, things like low-latency trading, but also extreme resilience. As a call to action, we will be participating in the multicloud village on Thursday morning at 10 o'clock, Dean and I. If you want to learn more about ultra-low latency outposts, we would recommend session HMC 4002, which is a really great session.

[![Thumbnail 1220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/c899067d555e5d01/1220.jpg)](https://www.youtube.com/watch?v=_pvkfhA7nks&t=1220)

All that really remains is to say thank you very much for bearing with us during the clicking problem.  We appreciate it very much, and thanks for your time.


----

; This article is entirely auto-generated using Amazon Bedrock.
