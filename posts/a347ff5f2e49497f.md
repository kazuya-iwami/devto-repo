---
title: 'AWS re:Invent 2025 - AWS Graviton: The best price performance for your AWS workloads (CMP360)'
published: true
description: 'In this video, AWS presents Graviton5, their fifth-generation custom chip with 192 cores built on 3nm process, delivering 25% better performance per vCPU than Graviton4. The session covers the evolution of AWS Silicon portfolio, highlighting how over 90,000 customers use Graviton for best price-performance in EC2. Key innovations include 192MB L3 cache (5.3x increase), DDR5-8800 support, PCIe Gen 6, and single-socket architecture reducing latency by 33%. The new Nitro Isolation Engine, written in Rust with formal verification, provides mathematically proven security. Customer results show 30-60% performance improvements. The presentation includes detailed migration guidance, tools like AWS Transform Custom for Java applications, and the Graviton Savings Dashboard. Workload-specific optimizations for Spark, Python, C++, containers, and machine learning are discussed, with M9G instances now available in preview.'
tags: ''
cover_image: https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/0.jpg
series: ''
canonical_url:
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - AWS Graviton: The best price performance for your AWS workloads (CMP360)**

> In this video, AWS presents Graviton5, their fifth-generation custom chip with 192 cores built on 3nm process, delivering 25% better performance per vCPU than Graviton4. The session covers the evolution of AWS Silicon portfolio, highlighting how over 90,000 customers use Graviton for best price-performance in EC2. Key innovations include 192MB L3 cache (5.3x increase), DDR5-8800 support, PCIe Gen 6, and single-socket architecture reducing latency by 33%. The new Nitro Isolation Engine, written in Rust with formal verification, provides mathematically proven security. Customer results show 30-60% performance improvements. The presentation includes detailed migration guidance, tools like AWS Transform Custom for Java applications, and the Graviton Savings Dashboard. Workload-specific optimizations for Spark, Python, C++, containers, and machine learning are discussed, with M9G instances now available in preview.

{% youtube https://www.youtube.com/watch?v=haSHl2BLhm8 %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/0.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=0)

[![Thumbnail 10](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/10.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=10)

[![Thumbnail 50](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/50.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=50)

### Introduction: AWS Silicon Innovation and the Graviton Advantage

 Good morning everyone. Thank you for making it to the final day. At every conference, there's a group  that makes it to the finish line, and that group is usually the most curious and the most committed. Today, we hope we can reward that commitment by sharing some insights about Graviton and the latest generation, Graviton5. We'll look at how the AWS Silicon portfolio has evolved over the years, and then we'll deep dive into Graviton and Graviton5, which we launched earlier this week. Finally,  we'll share with you some best practices, tips, and tricks that can help you in your migration to Graviton.

[![Thumbnail 60](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/60.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=60)

[![Thumbnail 70](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/70.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=70)

 AWS has over 10 years of innovation in its silicon. In more than 10 years, we have launched 6 generations  of Nitro cards, 5 generations of our own custom Graviton chips, and Trainium and Inferentia for machine learning. We have shipped millions of chips across these three platforms and seen remarkable success. The question that we get asked is why Graviton.

[![Thumbnail 100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/100.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=100)

 The main reason is that Graviton delivers the best price performance in EC2. These instances are based on the Graviton chip, which has AWS innovation not only on the chip but across the entire stack. That helps us to deliver performance, reliability, and efficiency. There are over 300 Graviton-based instances available in 38 regions worldwide, and that's led over 90,000 customers to use Graviton across a wide array of workloads. These customers range from small to medium businesses as well as large enterprises, with verticals ranging from software to financial services and even media and entertainment.

[![Thumbnail 170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/170.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=170)

### Evolution of Graviton: From Generation 1 to Graviton4's Broad Instance Portfolio

With the launch this week,  we now have 5 generations of Graviton that are available. The first generation was Graviton1. We launched that in 2018 with 16 cores. It was great for scale-out microservices, and it introduced for the first time a low-cost, efficient, and performing chip in EC2. In 2019, we launched Graviton2, which was a major leap, going to 64 cores with big boosts in memory bandwidth. It enabled mainstream workloads with up to 40% better price performance compared to other EC2 instances.

In 2021, we launched Graviton3, which was even faster and more efficient. Compute performance increased generation over generation, and we are now seeing customers run compute-bound workloads, memory-bound workloads, containers, Java, and machine learning on Graviton. In 2023, Graviton4 increased performance even more for scale-up workloads, where you could bring your large databases and electronic design automation applications over to the Graviton ecosystem. Now we've launched Graviton5. We'll dive much deeper into Graviton5 in a few minutes.

[![Thumbnail 270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/270.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=270)

What's available widely  in the latest generation, generally available, is Graviton4. It's got a huge breadth of instances for compute-intensive workloads, for memory-intensive workloads, and storage-intensive workloads. We have instances that offer 384 gigabytes to 3 terabytes of memory. These instances also have local storage for your caching workloads and for scratch space. The I instances include local storage ranging from 45 terabytes to 120 terabytes.

If you have workloads that need high performance network bandwidth, the network optimized instances offer up to 600 gigabits per second of network bandwidth. And for high EBS performance, we have EBS optimized instances that give you 720,000 IOPS and 150 gigabits per second of EBS bandwidth. There are lots of choices on Graviton 4 available to you today.

[![Thumbnail 350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/350.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=350)

### Graviton's Full-Stack Design and Real-World Customer Success Stories

Let's dive a little bit deeper into what the Graviton server looks like.  AWS not only designs the chip, we also design the Nitro SSDs, the Nitro cards, the firmware, and the hypervisor that goes into the server. This full ownership across the stack helps us optimize and give you the predictable performance that you expect with reliability, with security, and cost and power efficiency.

[![Thumbnail 390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/390.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=390)

As a result, what we're seeing is Graviton can now run any workload.  Whether it's web servers, high performance computing, or electronic design automation, the high core counts that we have, the memory bandwidth, and the custom stack enable all of these applications to run on Graviton and give you the best price performance overall. It's widely adopted for multiple workloads, including data processing like Spark and EMR, any C applications, and workloads like containerized microservices. We are seeing a lot of our 90,000 customers deploying all of these applications on Graviton today.

[![Thumbnail 440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/440.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=440)

[![Thumbnail 460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/460.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=460)

And here are some of our customers that are really pushing Graviton  by running all of their workloads on it and delivering a better experience for their users. For example, on Graviton 4, ClickHouse saw up to a 76%  improvement in performance on certain queries. Freshworks experienced 23% improvement in average response time, and Quora saw 20% faster performance on their web servers. And this is just a small set of customers that are running their applications on Graviton 4 today.

[![Thumbnail 490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/490.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=490)

Another reason that customers select Graviton  is to lower their carbon footprint while also getting the benefit of performance and cost. Adobe saw a 41% reduction in CO2 emissions. JFrog reduced their carbon footprint by 60%, and Snowflake lowered by 57% their carbon emissions per Snowflake virtual warehouse credit. And all of this combined with performance improvements as well as cost efficiencies.

[![Thumbnail 530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/530.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=530)

 We're also seeing customers running machine learning applications on Graviton. Mobileye, for example, experienced a 2x improvement in throughput while driving down cost. And Sprinklr, for their inference and search workload, saw a 30% latency reduction.

[![Thumbnail 550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/550.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=550)

[![Thumbnail 560](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/560.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=560)

 It's not just our external customers. Our own internal customers, which are AWS services,  are also rapidly growing their usage on Graviton. For example, over 90% of Redshift Serverless runs on Graviton. Managed Streaming for Kafka, MSK, Amazon Aurora, and RDS, over 60% of all of these services run on Graviton. And overall across EC2, over 50% of EC2's CPU capacity is Graviton over the last two years.

### Graviton5 Deep Dive: Doubling Core Count and Architectural Innovations

Let's now deep dive into Graviton5.

[![Thumbnail 620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/620.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=620)

And for that, I'll hand over the mic to Ali. Thank you, Gohan. So let's talk about Graviton5. With Graviton5, we've kind of gone  beyond Moore's Law. In a single generation, we've doubled the core count, going from 96 cores in Graviton4 up to 192 cores in Graviton5. This is a device that's the same size. You put them side by side as Graviton4, but now with twice the cores. It's built in a 3 nanometer process, and each core has about 25% higher performance than the previous generation.

[![Thumbnail 650](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/650.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=650)

Let's talk about how we did this. And we're going to start with the cores.  We've talked a lot about big workloads and designing for big workloads and how micro benchmarks aren't at all like big workloads. With Graviton5, we're using ARM's Neoverse V3 core. It's got bigger branch predictors, it can process more instructions every cycle, it can resolve more branches every cycle, and it has larger structures to handle big workloads. It also has more advanced prefetchers, and it's generally a higher performing core.

[![Thumbnail 680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/680.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=680)

We've coupled that core to our memory  system. Deciding what a memory system looks like is always an optimization problem. You'd love to have as much cache as you can, as close to the processors as possible, but that isn't always feasible. You can't make an L1 cache much bigger, just physics means you can't access a huge cache in the couple of cycles that you have. With Graviton4, we increased the size of our L2 caches from 1 megabyte to 2 megabytes, and we saw lots of customers find that it fit their workloads much better and they got higher performance. With Graviton5, we evaluated where we were going to modify the cache hierarchy and we decided that it was time to increase the L3 size. So with Graviton5, we increased the L3 cache by 5.3x. It's now 192 megabytes. Combined with the L2 caches and the other caches in the system, we have over 600 megabytes of cache in total.

[![Thumbnail 740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/740.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=740)

 With Graviton over the years, we've also led with DDR. Graviton2 was the first system we had in our fleet with DDR4 3200. Graviton4 was one of the first servers with DDR5. With Graviton4, we pushed DDR frequencies, and we're doing that again with Graviton5. The Graviton5 CPU supports up to DDR5 8800, and we're working with DRAM vendors to help them qualify DIMMs at those frequencies so that we can use them. In addition, we've worked to reduce memory latency. We've reduced it by about 15% to less than 100 nanoseconds versus Graviton4.

[![Thumbnail 790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/790.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=790)

[![Thumbnail 810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/810.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=810)

Speaking of IO, Graviton5 supports PCIe Gen 6. This is the first CPU  in our data centers to support Gen 6, and with it we have 0.5 terabytes of IO connectivity. It's going to let us build all the instance shapes and sizes that we've seen with our other compute offerings. With Graviton4, we had two sockets of 96 cores each.  Now we put all those cores on one socket. Having 192 cores led us to see use cases with scale up applications like databases, EDA workloads. But the fact that we had 2 sockets and we had the latency between them and we had the limited bandwidth between them meant that some of these workloads couldn't scale as well as we wanted.

As we put those 192 cores together on one chip, we've seen up to a 33% reduction in latency. We've seen a massive increase in bandwidth between cores and we've seen much better scalability for some of these big workloads. We're not getting rid of NUMA though. We're still affinitizing 96 cores to the local cache and local memory controllers to provide better latency and performance.

[![Thumbnail 870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/870.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=870)

So with Graviton5, we are announcing our 9th generation of EC2 instances, starting with the M9G instance.  They have industry leading performance, up to 25% better than Graviton4. Graviton5 is the most energy efficient CPU we've built. And it provides the best price performance in EC2, with the same scale up capabilities but with lower latency and higher bandwidth than Graviton4.

[![Thumbnail 890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/890.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=890)

[![Thumbnail 900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/900.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=900)

### Advancing Security with the Nitro Isolation Engine and Formal Verification

Now  let's spend a little bit of time talking about security. There are many things that a hypervisor has to do. It has to do scheduling, it has to do resource allocation,  it has to do IO.

When virtualization started, it was all about packing multiple workloads together on a server you owned. We've talked over the years at re:Invent about how Nitro is different. With Nitro, we moved networking, storage, and management to dedicated silicon with our Nitro cards. Now Nitro has many jobs to do, but the most important one is keeping customers isolated, isolated from each other and isolated from us. With the Nitro system, there's no operator access, and we enforce that with mechanisms, not with just policies.

[![Thumbnail 940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/940.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=940)

With Graviton, we've been raising the bar on  our system security. Graviton 2 was the first system to support DDR encryption. Graviton 4 was the first system we had to support PCIe encryption. We took the attestation process that we have in our Nitro cards, and in Graviton 4 we added it to our Graviton CPUs so that we know every chip in our data center is a known production quality device and running the firmware that we expect. And we can continuously measure this through the lifetime of the server.

[![Thumbnail 970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/970.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=970)

[![Thumbnail 1000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1000.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1000)

 Now the Nitro hypervisor is purpose-built for one job, and it's an amazing hypervisor, but we constantly ask ourselves, are there opportunities for us to do better? Coupled with Graviton 5, we've also been building another layer of technology to increase the transparency in our virtualization stack, which we call the Nitro Isolation Engine. The Nitro Isolation Engine sits between the Graviton CPU and the Nitro hypervisor. So what is this thing? We're compartmentalizing the most critical  elements and interactions between instance memory devices and access control into a new layer.

There's a couple of really interesting things about this code. First, it's written in Rust, which eliminates a whole class of issues around memory safety and concurrency. But the most innovative and interesting part about the Nitro Isolation Engine is that formal verification was a first-class consideration from the very start of the project through today. When we sat down to start working on the Nitro Isolation Engine, we had software engineers sitting with applied scientists trying to figure out how to formally specify all the interactions within the Nitro system and how we could formally prove those interactions.

[![Thumbnail 1060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1060.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1060)

But you just keep saying formal verification. What does that mean? This is a really simple function. It takes three inputs and it produces  one output. Now how can you always make sure it does what you expect? Well, you can try different test cases. You can try X is zero, Y is zero, Z is zero, you can try a few others. But can you exhaustively test this function? It's really simple. It seems like you should be able to, but you can't. Even if you had a processor that could evaluate the result of this function a billion times a second, and you had a billion such processors, to exhaustively test this simple three-input function would take more time than the age of the universe.

[![Thumbnail 1120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1120.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1120)

[![Thumbnail 1130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1130.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1130)

Formal verification instead lets you mathematically show that a function matches the specification that it was intended to implement. And so with this, we can use the application of mathematical logic to reason about systems,  particularly what the system can do, what it must do, and what it must never do for all possible inputs in all reachable states. For a hypervisor,  this means we can create and manage VMs. We must preserve guest confidentiality and integrity. We must never do things like null pointer references or buffer overflows, but critically, for all possible inputs across all hypervisor and guest actions in all reachable states.

[![Thumbnail 1150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1150.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1150)

 And so with the Nitro Isolation Engine, we're proving properties that every hypervisor should have, but few can prove that they do have. We're proving memory safety, not just because we're using Rust, but also we can prove unsafe code is also sound, that there aren't any reachable panics that just unwrap on nones, that there aren't logical errors, and the specification and the implementation are matching. And that there's confidentiality and integrity of our virtual machines, that there isn't any unauthorized information leakage of VM state. And we're doing this across the core features required to manage the VM lifecycle. We'll only expand this as time goes on.

[![Thumbnail 1210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1210.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1210)

So the Nitro Isolation Engine is embracing formal verification and pioneering a new standard for mathematically proven cloud-based  security, and it's the default in our M9G instances.

[![Thumbnail 1220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1220.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1220)

[![Thumbnail 1250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1250.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1250)

### Designing Graviton: Pre-Silicon Development and EDA Tool Support

So let's talk now a little bit about designing and building Graviton.  When we're looking at building a new version of Graviton, we're bringing lots of workloads to the design process, and one of the ways that we visualize that is these polar plots like this. On the left-hand side are features that tend to be on the front end of the processor, things like branch prediction and instruction misses. And on the right-hand side are things on the back end, things like execution and data cache misses. If you look at a workload,  for example, this is MongoDB running on a Graviton 4, you can see there's lots of instruction misses, there's lots of branch prediction misses and front-end stalls. There's also lots of L2 misses.

[![Thumbnail 1270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1270.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1270)

And so during the design process, we could take a workload like this and we can ask ourselves, well, how is it going to perform as we're making decisions. But  the pre-silicon design process is actually really challenging. There's over a 10,000x slowdown before you have a chip, when you're trying to simulate a chip. So running a second of simulation takes hours, and running minutes of simulation can take a month. So what can you do? Over the years we've developed mechanisms to run workloads in our lab and take state from that and run it in our pre-silicon environment. This is one of the ways we've been collaborating with companies like SAP on HANA and improving performance of the HANA database on new versions of Graviton.

[![Thumbnail 1310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1310.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1310)

[![Thumbnail 1320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1320.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1320)

[![Thumbnail 1330](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1330.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1330)

But if we go back to MongoDB, we can take that shape of what looks like a Graviton 4,  and we can look at what it's going to look like on Graviton 5.  You can see we've reduced many of the parameters here, and we're going to have a lot higher performance.  Now, one of the things silicon designers get the most excited about is designing the next version of silicon on the current version of silicon. When we started Graviton, that wasn't an option. But over the years, Graviton has become a big part of the design process, not just for Graviton, but for our Nitro chips and our Trainium chips, with thousands of servers worth of capacity, all being used to develop the next generation.

[![Thumbnail 1360](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1360.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1360)

So I'm really excited  to announce today that Siemens, which is the maker of one of the most important industry sign-off tools and is used to check that a design is ready for manufacturing, is announcing support of Caliber on Graviton-based processors. This tool is used by the majority of silicon design companies as one of the most critical tools to run fast. Because as fast as you can run it, it means you can iterate faster and you can get to the place where you can tape it out faster. And in their early testing of Graviton 5, they show an additional 30% performance boost on top of the 20% that they saw compared to the other systems that they tested previously.

[![Thumbnail 1410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1410.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1410)

For over a decade since the inception of Annapurna Labs, Synopsys and AWS have also been collaborating  to enable Amazon's custom silicon development. And Synopsys is also expanding tools to support Graviton, including VCS, PrimeTime, Fusion Compiler, and they've seen substantial improvements in performance here. Up to 35% improvements in Fusion Compiler and PrimeTime, and up to 40% performance improvements in VCS going from one generation.

[![Thumbnail 1440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1440.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1440)

[![Thumbnail 1450](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1450.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1450)

### Graviton5 Performance Results: Benchmarks and Customer Validation

So while we're on the subject of performance, at the top of this talk, I said 25% performance per vCPU.  Let's dive into some of these. Many customers have been doing CPU-based machine learning on Graviton.  Gautham shared some information about Snowflake and Airbnb. And so one of the workloads that we've been looking at with Graviton 5 is, well, how does performance improve with Graviton 5. So we've taken AWS's deep learning containers and run a mix of CPU-based workloads of BERT, RoBERTa, some image analysis as well, and we see a 35% improvement in performance on PyTorch.

[![Thumbnail 1480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1480.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1480)

We also have many customers who are running  Java-based web applications on Graviton, and here too we're seeing impressive gains. Grails is an open-source web framework that uses the Groovy language, and we took a Grails application and fixed a load generator and tried running it on a Graviton 4-based M8G and a Graviton 5-based M9G. And here we see a 32% increase in requests per second.

[![Thumbnail 1510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1510.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1510)

Now, while microservices are great, we also find that monoliths still  exist. We don't have a really good open source example of this, but we took an internal workload that's used for delivery planning and measured it on Graviton 4 versus Graviton 5. This is a really big workload with a JAR that's 100 megabytes or so, and you can see a great 47% performance increase in this case.

[![Thumbnail 1540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1540.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1540)

 NGINX is a popular web server. We see it used as a web server and also a load balancer. Here too, we're fixing a load generator, we're fixing a set of web servers, and in the middle we're either putting a Graviton 4-based M8G or a Graviton 5-based M9G and measuring performance. Here you can see a 27% improvement in performance generation over generation.

[![Thumbnail 1560](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1560.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1560)

 Lastly, we've seen lots of customers running databases, SQL and NoSQL. We took HammerDB, which is an open source load generator meant to mimic a company that has warehouses, keeps inventory, and sells items. It ultimately produces a score in terms of orders per minute that are fulfilled. We took HammerDB and tried again a Graviton 4-based M8G or a Graviton 5-based M9G to see how they performed, and we saw a 40% increase going to M9G.

[![Thumbnail 1600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1600.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1600)

Now, these are workloads that we've run, but over the last few weeks we've also had customers  running workloads on Graviton themselves. Snowflake has been running their virtual data warehouse on Graviton since Graviton 2, and they recently tried an M9G-based Graviton 5 instance. They saw more than 30% performance boost on the representative workloads for the virtual data warehouse.

[![Thumbnail 1620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1620.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1620)

 Similarly, Honeycomb provides an end-to-end observability platform, and they've also been using Graviton since the M6G was launched in 2020. Out of the box, they see a 20 to 25% improvement in latency. When they tried reducing the amount of compute they needed to keep the latency the same, they saw a 36% better throughput per core.

[![Thumbnail 1650](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1650.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1650)

[![Thumbnail 1670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1670.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1670)

[![Thumbnail 1690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1690.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1690)

Airbnb has also adopted Graviton,  and they tested our M9G instances and said they are some of the fastest instances that they've ever tested, finding it to be 25% higher performance than other system architectures. Finally, SAPâ€”we've been collaborating with SAP to support SAP HANA Cloud  now for a couple of generations. HANA Cloud can do many things, but one of them is online transaction processing. In measuring online transaction processing queries, they saw a stunning 35 to 60% performance increase  generation over generation.

So with this, we have benchmarks we've run that have 27 to 47% better performance improvement. We have benchmarks that customers have run that are 20 to even up to 60% better performance. Now I'm going to hand it back to Gautham to talk about how you can transition to using Graviton.

### Migration Best Practices: Tools, Resources, and Workload-Specific Guidance

Thanks, Ali. That was really exciting. Graviton 5 isâ€”we're really excited about what it brings in terms of performance, and it would be great to get your feedback as well once you test it in preview. But now that we know a lot more about Graviton and learned about Graviton 5, I want to take this opportunity to share with you some tips and tricks on how you can simplify your migration to Graviton.

[![Thumbnail 1750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1750.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1750)

Our goal is to make your journey to Graviton  as simple and as low risk as possible. For that, we've learned a lot from our customers running their workloads on Graviton, and we've made available best-in-class guides, tools, and resources to help you in your journey. 90% of applications should work on Graviton without code changes, but for the ones that need some work, we have a lot of resources that we can share with you.

[![Thumbnail 1790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1790.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1790)

Let's start with software. If you look at the operating systems that are available in the market today,  the majority of mainstream Linux operating systems run on Graviton, whether it's commercially available ones like Amazon Linux 2023, Red Hat, SUSE, Ubuntu, or even community Linux operating systems like AlmaLinux and Alpine.

These ARM64 builds receive regular patches and security updates, which means the OS ecosystem for Graviton is very mature and stable. This allows you to bring your applications to Graviton without any major OS-level changes.

[![Thumbnail 1840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1840.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1840)

As I mentioned earlier, customers run their containerized microservices on Graviton.  For orchestration of these containers, services like Amazon ECS and Amazon EKS support Graviton. Docker Hub also allows you to publish multi-architecture images, so you can publish x86 and ARM64 images using these services. You can use Docker BuildX, for example. Graviton also works smoothly with container-optimized Linux distributions like Bottlerocket.

[![Thumbnail 1900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1900.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1900)

For serverless compute, our services like AWS Lambda and AWS Fargate also support Graviton today. Together, all of these container and serverless products make it really straightforward for you to adopt Graviton across your entire deployment pipeline.  You can also use the same CI/CD and automation tools that you rely on today on Graviton.

On the fully managed side, for example, services like AWS CodeBuild, CircleCI, and GitHub all offer ARM64 environments. Now you can build, test, and deploy applications which are ARM native without managing your own infrastructure. For hybrid models, tools like GitHub Actions and GitLab runners support Graviton. For self-managed environments, teams can deploy their preferred DevOps stacks, like Jenkins agents, on Graviton as well.

[![Thumbnail 1960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1960.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1960)

We also have partners that have certified their software on Graviton.  These applications range from observability, databases, security, analytics, and DevOps. Here's a list of some of these key partners, and what this means is that you can run the same commercial software that you run today on Graviton with no functional gaps.

[![Thumbnail 1990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/1990.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=1990)

We talked about a few of the managed services in AWS.  All of these servicesâ€”DocumentDB, Aurora, RDS, ElastiCache, and MemoryDBâ€”support Graviton today, so they offer you Graviton instances for these services. They manage the infrastructure themselves, so you don't need to worry about that. Using an AWS managed service with Graviton is probably the easiest and most seamless way for you to start using Graviton and deriving those price performance benefits.

On the compute side, we talked about Amazon ECS and Amazon EKS, and serverless options like AWS Lambda and AWS Fargate, which also support Graviton. EMR, a big data service, gives you the ability to run your analytics workloads like Spark on Graviton and derive those price performance benefits there as well. Even for machine learning, Amazon SageMaker today supports Graviton, and we have customers running SageMaker with Graviton for their inferencing workloads, for example.

[![Thumbnail 2060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2060.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2060)

[![Thumbnail 2070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2070.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2070)

If you start thinking about what's  involved in your transition, there are a few things to keep in mind. I just want to quickly walk you through what those things are.  The first thing is you want to learn about Graviton. We've talked to you about Graviton today, but there's so much more, and we have a great AWS Graviton Technical Guide on GitHub. It's got a ton of information about what Graviton is, what the instances are, what the architecture is like, and it's got very specific recommendations for each type of workload. I strongly recommend checking that out.

Also, if you want to do a free trial, if you want to try Graviton for free, we have a free trial with an EC2 instance called T4G, which will allow you to experience the benefits of Graviton.

[![Thumbnail 2110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2110.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2110)

The second step is to inventory your software stack.  You want to make sure that you identify all the open source and commercial libraries, all the agents that you're using for monitoring, logging, and security, and make sure that they have ARM64 binaries or architecture agnostic code so that you can run it on Graviton as well. If they don't, then you should reach out to the vendor of that software and ask them for a roadmap for when they can support the ARM64 version of that, or you can reach out to your AWS account team who can then escalate it to us and we can try to help.

[![Thumbnail 2160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2160.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2160)

There's also tools like Amazon Q Developer, which automates some of this for you, so it helps with version upgrades of Java, for example.  Look into some of those tools as well. The third step is to plan your workload transition. When it comes to planning, there's a few things. One is you want to obtain your AMI, or you want to create a new ARM64 AMI. You can build or create an image, and we talked about some of the containers support that we have as well as the image registries.

[![Thumbnail 2200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2200.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2200)

AWS Transform is another great tool which can help you with that, and then you want to test. You want to do some unit and functional testing.  Make sure that you have the right software versions. AWS Transform is a great resource. We just launched a custom version of AWS Transform on Monday, which has a module which can help with Graviton migrations. It's in early access, but what it does is it can identify incompatible libraries. It can even recompile or upgrade to compatible versions. It has a lot of powerful capabilities. It's currently in early access, and we're looking to make more enhancements to it. It's powered by an AI agent behind the scenes, so it learns as you use it and gets better.

[![Thumbnail 2250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2250.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2250)

[![Thumbnail 2270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2270.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2270)

And  then you want to measure performance as well. We have a tool for that called AWS APEV, which is also available through the GitHub page, the Graviton technical guide that I talked about earlier. And finally, you can deploy. When we talk about deployment, the first thing you want to do is update your infrastructure  as code, and then you can use the blue-green deployment method where you can create a parallel Graviton stack next to your existing stack and use weighted routing to send some requests over. And then you can monitor performance and monitor your response times to make sure that the application that's running in production on Graviton is meeting your expectations.

[![Thumbnail 2300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2300.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2300)

 Another way to think about the migration to Graviton is you can start with the low hanging fruit. The easiest and most seamless way, as I mentioned earlier, is to use an AWS managed service like RDS or Aurora, MemoryDB, or EMR is another good one. All of these already support Graviton and they manage the Graviton infrastructure, so all you have to do is upgrade to the version that supports it and derive the price performance benefits that Graviton offers.

And then there's interpreted languages like Java and PHP and Node.js which are also relatively easy. All you have to do is select an ARM64 AMI and install it and containerize the workload to make it even easier, but just make sure you check for certain native modules so that you can upgrade those as well to make sure that it runs smoothly. Compiled languages like C and C++ and Python, make sure that those are a little bit more involved, and so you'll have to recompile those and port any intrinsics, assembly, or native modules.

[![Thumbnail 2400](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2400.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2400)

And if you have a Microsoft .NET workload based on Windows, you can move that over to Linux with .NET Core, and then once it's on Linux, you can then migrate it over to Graviton. So there's a spectrum of workloads that you can start with, some a little bit more involved than others.  I talked about AWS Transform Custom. This is in early access, the Graviton module, which allows and simplifies the migration to Graviton, particularly for Java applications.

Many Java applications can already run on Graviton because Java bytecode is architecture independent. However, if you still have concerns or if you have native libraries or architecture-specific code, this agent can help you. For example, if there are some shared libraries which have no ARM64 variant or JNI bindings compiled for x86, this agent will recompile from source code if that's available, or it will prompt you to ask for an ARM64 compatible version.

[![Thumbnail 2470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2470.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2470)

There's a great dashboard called the Graviton Savings Dashboard. What this helps you with is to calculate the savings that you're getting today from using Graviton, or you can even simulate  a workload that's not running on Graviton today and calculate the savings that you might get from migrating that to Graviton. So this is another great dashboard that you can use to justify the migration.

[![Thumbnail 2490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2490.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2490)

### Optimizing Specific Workloads and Getting Started with Graviton Today

Let's look at some very specific  workloads, and I just wanted to call out a few key points here. We talked about Spark, which is a popular data processing framework, but sometimes it can suffer from straggler issues where a long-running task can slow down the entire cluster. This is often caused by uneven data distribution, and so we have some key recommendations. For example, set the shuffle partition size to less than 200 megabytes. Also make sure to benchmark and optimize settings, because we've seen up to 80% performance improvement if you do that.

EMR, which is an Amazon service where you can run your Spark workloads, is an option, but make sure to use the default settings that EMR provides. As I mentioned earlier, with the versions, it's always the best practice to make sure that your versions are the most up-to-date, because we've seen in the case of Spark you can get up to 40% better performance with Spark 3 and Java 17 compared to Spark 2 with Java 8. So just upgrading the versions can really benefit performance.

[![Thumbnail 2570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2570.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2570)

C++ and C perform really well on Graviton  as long as you compile natively for ARM64 and also make sure to use ARM-specific flags that I've called out here on the slide. Rebuilding native libraries, avoiding x86-specific code, and leveraging vectorization like SVE will greatly help you in running these kinds of applications on Graviton.

[![Thumbnail 2600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2600.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2600)

[![Thumbnail 2630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2630.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2630)

 Python, a high-level interpreted language, runs really well on Graviton when you use ARM64 native Python libraries. Also make sure that your Python math libraries are ARM optimized. We talked about containers earlier. They can help you  build and publish multi-architecture container images. The key is to build ARM64 native images. You can also use Docker Buildx to build those multi-architecture builds, and here again verify all the dependencies and make sure that they support ARM64.

[![Thumbnail 2660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2660.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2660)

Java runs very efficiently on Graviton.  Just make sure to rebuild any native libraries for ARM and use the latest JDK. The one thing to keep in mind is Graviton gives you very good performance even at high CPU utilization, and so make sure to run Graviton hotter than you normally do with other architectures.

[![Thumbnail 2690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2690.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2690)

 Machine learning is an area where we're seeing a lot of customers use Graviton, specifically for use cases like automated speech recognition, sentiment analysis, recommendation systems, and chatbots.

For recommendation systems and chatbots, just make sure to use the right ARM64 native machine learning frameworks. The versions that we've called out here are important to follow. We also have software abstractions to make it simpler, like AWS Deep Learning Containers.

[![Thumbnail 2730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2730.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2730)

And finally,  we just wanted to give you a list of all of the resources that are available to you. The first one I mentioned is the AWS Graviton Technical Guide. The link is on here, and it's got a wealth of information to help you with migrating any workload over to Graviton, and it's continuously updated. We also have migration resources if you want to do a free trial. The T4G instance offers you a free trial of Graviton. Tools like AWS Q Developer and AWS Transform are available today, so definitely take advantage of that. And the Graviton Savings Dashboard as well to calculate your savings. APR, which is a tool built by us, collects performance metrics during your migration and helps you to analyze those metrics to optimize performance on Graviton.

[![Thumbnail 2800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2800.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2800)

So get started today. And the biggest thing to keep in mind here is the reason that you're looking at Graviton is because it delivers the best price performance  across any EC2 instance. Also, the Graviton5-based M9G instance is available today. It's in preview. There's a preview form on our website where you can go and sign up for the preview. And as our VP Dave Brown said, all it takes is one week, one application, and one engineer, and you'll be surprised by what you can do in migrating your applications to Graviton.

[![Thumbnail 2840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a347ff5f2e49497f/2840.jpg)](https://www.youtube.com/watch?v=haSHl2BLhm8&t=2840)

Thank you for your time. Appreciate you all being here. 


----

; This article is entirely auto-generated using Amazon Bedrock.
