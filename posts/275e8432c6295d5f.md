---
title: 'AWS re:Invent 2025 - Designing Agent-Native Dev Teams: Coding Agents in Real Workflows (DVT226)'
published: true
description: 'In this video, Kyle and Ben from the Kiro team present their newly launched Kiro Autonomous Agents and discuss building AI-first development workflows. Kyle demonstrates how Kiro IDE uses spec-driven development, hooks, and steering files for context management, while the Kiro CLI enables lightweight terminal-based agent interactions. The Kiro Autonomous Agent works in sandboxed environments, handles multi-repo changes, maintains persistent context, and integrates with GitHub for autonomous PR creation. Ben shares NVISIONx''s experience using these tools, highlighting an Angular 16 to 20 migration that achieved 80% completion autonomously. He emphasizes the importance of data quality, intent classification, and ontologies for scaling agentic systems to petabyte-level data, explaining how graph-based orchestration and context disambiguation enable effective agent collaboration beyond linear workflows.'
tags: ''
cover_image: https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/0.jpg
series: ''
canonical_url:
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Designing Agent-Native Dev Teams: Coding Agents in Real Workflows (DVT226)**

> In this video, Kyle and Ben from the Kiro team present their newly launched Kiro Autonomous Agents and discuss building AI-first development workflows. Kyle demonstrates how Kiro IDE uses spec-driven development, hooks, and steering files for context management, while the Kiro CLI enables lightweight terminal-based agent interactions. The Kiro Autonomous Agent works in sandboxed environments, handles multi-repo changes, maintains persistent context, and integrates with GitHub for autonomous PR creation. Ben shares NVISIONx's experience using these tools, highlighting an Angular 16 to 20 migration that achieved 80% completion autonomously. He emphasizes the importance of data quality, intent classification, and ontologies for scaling agentic systems to petabyte-level data, explaining how graph-based orchestration and context disambiguation enable effective agent collaboration beyond linear workflows.

{% youtube https://www.youtube.com/watch?v=FAbm2MXYaqc %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/0.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=0)

### Introduction: The Evolution of AI Development Tools in Two Years

 Everyone, thanks for coming out. It's 5:30 on a Wednesday. Appreciate it. I'm excited to talk to you for a bit. I'm Kyle. I'm a product lead on the Kiro team, and I'm joined here with Ben. Hey, how's it going, guys? You guys having a good conference so far? So we're hard to see you, but you know, we'll get there. Yeah, so we're excited. We're going to talk a lot about one of the products we launched this week that I'm super excited about, the Kiro Autonomous Agents, which is what I've been working on for the last eight plus months.

We're going to cover a range of things. I'm sure there's folks in here who are trying to figure out what this world is. I'm sure there's others trying to figure out how to bring tools into your development flow, and then the other group is building with these tools. So we're going to try to hit on all of those topics. We're going to talk a bit about how we're building these agents, the autonomous agent and such, what Kiro is, how you can use it for developers, and then Ben's going to do a great deep dive into how at his startup they're thinking about being AI first and what that matters. So we'll jump right in.

[![Thumbnail 70](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/70.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=70)

I think this is probably the cheesiest slide that you'll see, which everyone says, but it's been pretty neat if you realize it's only been two years.  I still remember how magic autocomplete felt, you know, a command line interface or the function autofill was cool, but the fact that they could write a whole code block was pretty amazing. But when in 2024 assistants arrived and the fact that you could start chatting with context of your system and not going to Stack Overflow or not going to Google as much, it's like, oh alright, there's something here. And then my whole life, and I'm sure most of your lives, have been agentic workflows which entered the scene really in this last year around Sonnet 4. It's like, oh, this thing can follow instructions and call tools. It's kind of neat.

[![Thumbnail 120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/120.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=120)

[![Thumbnail 130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/130.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=130)

So you think about the agentic flows, and that's where we're going to spend a lot of our time today. It's running beside me, it's making dozens of file changes, it's running a compiler, it's auto fixing as well as running remotely. It's a pretty neat time to see that. So I'm sure some of you have heard of this, but earlier this year we launched  a new brand, Kiro, with the intention of building a product that is from the ground up AI native. So what would it mean to build with AI tools? What would it mean to have a system  that assumes there's an agent in the presence? And that's really what we were setting out to do.

[![Thumbnail 140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/140.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=140)

### Building Kiro IDE: Addressing the Limitations of Vibe Coding

We started looking at a couple of problems that I think a lot of these are getting addressed both with  model changes but also these client updates. The first is just vibe coding became a thing. I think we also learned how limiting it was if you wanted to do more than just fix the string, fix this icon, or just have fun and write a side app. But the reality was there wasn't enough structure around that, and we heard this from a lot of customers: great for Greenfield project, not great for existing, needs a little bit more structure. Basically, that was the theme I would hear.

The other one was limited control, both on the models doing model things. It's random by design. It's actually a feature, but basically what we learned where we're at now in a great way is it's faster, so it's actually cheaper to experiment. You can throw it away. The other limiting control was a lot of these experiences were bolted on, you know, an extension or something like that, and it didn't have access to the whole environment that the agent was running in. So those are some of the problems we've been thinking about.

[![Thumbnail 210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/210.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=210)

And then you move to code quality, which spans more than just the code. It's the docs. How do you keep them in sync? How does everything kind of meld as six months ago you vibe coded something? What's the state of that world? How are you maintaining it? So those were the things we had in mind when we launched the Kiro IDE earlier this year. It was from the ground up built for, of course, doing vibe coding, whatever you might want to  do, quick interactions and things like that. But also we introduced a concept around specs, which I'll talk about here in a sec. And the idea was can we bring some structure, can we bring some workflow using systems we already know about into the agentic system.

[![Thumbnail 230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/230.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=230)

So I hear this feedback a lot, which is a lot of our time is spent on the implementation part,  and that's the vibe code part. But one of the top themes in my meeting with customers this week is, yeah, stuff happens before that. There's some planning, there's some requirement gathering, there's some intentional thinking going on. What are we all doing there? And so when we think about that, that's where the spec driven concept comes in. During the planning session, it might be as simple as, hey, I have an existing database schema. I'd like to move from here to there. I have a UI framework and I'd like to shift it, or here's a Jira ticket, help me break it down and build it.

The idea is before you're even writing code, there's real opportunity to be working with these agents. And you'll see this throughout this, it is unapologetically for developers. So as a product manager, I use it for my coding, less for my product planning. But the planning and the designing for the engineers is what we're really focused on with the spec concept. And we want to be able to take it through this loop where you can still vibe, you can still write code with it, but get all the way to the point where you're confident about it and you have a history of what got changed.

[![Thumbnail 290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/290.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=290)

### Spec-Driven Development: Bringing Structure to Agentic Workflows

 So I'll show you some of what this looks like. Inside of the IDE, you can describe a thing. I think in this case the example is an event category for your website. This is a Jira ticket that got pulled in.

[![Thumbnail 310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/310.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=310)

[![Thumbnail 320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/320.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=320)

[![Thumbnail 330](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/330.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=330)

You talk with the agent, and before you're even writing code, you're actually in a session where you're having the agent go through and ask you questions. It'll actually start generating a spec,  and the spec is multiple parts. First, it's requirements, then it's the design, and then it's actually a task list. What the agent does is it works through  this kind of gathering of context, building out the design of what you want. Everything's done in markdown, so you can hop in and edit it and change it however you see fit and keep proceeding at your own pace. So you're in the loop  with the agent in this case, and then you get to the point where you have the task list that's pulling in the requirements.

[![Thumbnail 350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/350.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=350)

But what's really cool is it's building a graph and it's understanding that it has to do one thing before it can do a unit test, or it has to implement the backend API before it can implement the frontend for it. So that's how the task is broken down, and then you can just start the  task and the agent will start working for you. Specs have been a really interesting way to introduce structure to what you're doing, and it's an area that we're still exploring. I think there's a lot of potential there. You're seeing plans in other frameworks, so it's a fun space to see how you can help put rails around the agent.

[![Thumbnail 370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/370.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=370)

The other feature in the IDE that came native was hooks, so  there's always things happening. It could be save localization requirements or API documentation. You can write hooks that take events for file changes. You describe prompts, so you're making a mini agent here, but the agent's just listening. It's listening to your file system, it's listening to what's happening, and it will go and execute these changes asynchronously and put it on your system so that you can keep whatever it is you're trying to do up to sync. So we love the flexibility of that.

[![Thumbnail 400](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/400.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=400)

And the last part is  a theme that you'll hear today, which is context. So how do you do context management? The concept we have in Kiro is steering files. You also see Agent MD and things like that. What's really cool is you bring a new project into Kiro and you click generate steering file, and it's going to come out with a tech stack, a product stack, and an architecture. That's a really nice intro for any agent that follows up to start doing work, and that's stored in your source code. You can always refresh it. It's part of the project, so that's a powerful part of helping these agents really do what they're aiming for.

The other part is MCP. I'm sure most of you are playing with versions of that, whether that's hooking into code analyzers or documentation or your Jira backlog. Bringing that natively into the IDE is super important. And then putting that all together in a place where you can also just bring in architecture diagrams, you can bring in a photo, whatever that is, whatever context you want to do for this task at hand, you can enrich it, and it's designed kind of from the ground up with that in mind. So that's the IDE.

[![Thumbnail 470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/470.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=470)

[![Thumbnail 480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/480.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=480)

[![Thumbnail 490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/490.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=490)

[![Thumbnail 500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/500.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=500)

[![Thumbnail 510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/510.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=510)

### Kiro CLI and Terminal: Lightweight Agents for Everyday Tasks

We also, about two or three weeks ago, announced that Kiro is now in the terminal,  and I don't know if anyone has played with AI agents in the terminal. It's a little weird at first, and then it's really cool. Everything from  I downloaded a bunch of CSV files, I was doing a report, and I just told the agent, hey, in my download folder there's a bunch of CSV files, can you merge them, to actually doing coding tasks like, hey, can you bootstrap a React app inside of my development folder and make it look like this.  What's needed though, and what this CLI experience gives you, is tools that you trust. You can opt in to always allow or per call.  You can actually create custom agents, which has been a really great workflow for me personally. I have an evaluator agent that will take changes that are getting made by other agents and gives me a rank, and it's always  updating the same markdown file. You can have code review agents and things like that.

[![Thumbnail 520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/520.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=520)

[![Thumbnail 540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/540.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=540)

So the terminal, what's really powerful about it, and we're talking about this earlier, is  it's just lightweight. You can open up five terminals and have five different things running at the same time. So we end up moving between the IDE and the terminal a lot as we think through the different goals that we have at the task at hand. Myself personally, I mentioned some of this, but I'm seeing every customer meeting I have goes into a file that has an MCP server attached to it. I use Obsidian,  and Kiro has that as context. It summarizes stuff automatically for me, of course. I'm writing some code with that, but the idea of having these systems running around your personal context in your machine, that's been really a game changer for me.

[![Thumbnail 560](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/560.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=560)

We have customers like N42 who have been one of the earliest adopters for this product. They're sharing with me this morning  they're running basically 40% on planning, 40% is just on getting the system tested, and they're down to like 20% of time spent on coding, and that's actually a feature in their opinion. They're getting more code produced in that amount of time, and they're trusting it more because they put more time into the planning and they put more time into the actual test systems that are running it. So it's been pretty neat to see how this is changing the workflow. Of course, I'm sure we'll talk about this after, but how do you get people adopting, how are they trying it out? But it's pretty neat to see when it starts to stick.

[![Thumbnail 590](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/590.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=590)

So Kiro, kind of broadly  speaking, is we want to put this in a familiar environment. Everyone knows VS Code. We have your extensions. You have access to that, but make it AI first. We want to bring in the cutting edge models running on Bedrock, specifically a lot of the great Sonnet models that are out there, as well as

an auto mode where we automatically select models for you to have the most cost effective tasks. And then what's resonated well is these are backed by Bedrock and AWS from a security standpoint and everything like that. But that's the Kiro sort of CLI and IDE.

[![Thumbnail 620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/620.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=620)

### Launching Kiro Autonomous Agent: Working Beyond the Developer Loop

But earlier this year,  probably February, I got asked the question which is, well, great, we have these highly interactive clients. You have the IDE, you have the CLI, and they're designed with really quick feedback loops, really great for working with the agent, but that still has the developer in the loop, which is a good thing. But there's still more work to be done. There's still other tasks that get thrown to the side. There's other stuff you're not always at your computer. And so what would it take to have an agent that's working alongside you or with you? What would that mean? And it's gotta be more than just a session. It's gotta have context and tools and things like that. And so that's what we've been working on.

[![Thumbnail 660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/660.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=660)

[![Thumbnail 670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/670.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=670)

And yesterday Matt announced it as the Kiro Autonomous Agent, which is now I spent some time on,  it's one of these frontier agents, and the way we're defining that is massively scalable, autonomous with context that it can work in. But specifically for the Kiro Autonomous Agent,  when I sort of wrote the original thinking around it, it was first was autonomy, and what did that mean? It meant there's a sandbox that it can work in that looks just like the developer's environment, so Dockerfiles, dev files, your own custom build systems, pull them in, make the agent work like it's one of the developers. Now it's gotta have guard rails and everything around that, so the sandbox has, I'll get into a little bit more of that, has proxy controls and things like that.

We also noticed, and a lot of customers shared this, is a lot of code changes are not a single repo. You might have your API spec in one repo, your lambda function in another, and logging somewhere. It's got to be able to make changes everywhere. It's got to be able to work across multiple repos in its environment at the same time. The other really important thing for me was persistent context. So this agent can't forget. Context should not be something you're managing. It's something that agent should be managing for you, and that was one of our key requirements. And then the last part was learning. We're just getting started on this one, but it should learn what you like, what you don't like, so that it gets more personal as you use it.

[![Thumbnail 730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/730.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=730)

[![Thumbnail 740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/740.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=740)

[![Thumbnail 750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/750.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=750)

So that's what we launched. I'll give you a quick tour of it. So from Kiro.dev,  in this case I'm using the Hydro app, which is a Rust framework. And the team there asked, hey, we wanna refactor the benchmarks out of the main repo and move  it into a dependency repo. So I put this in the Kiro Autonomous Agent, gave it the description, loaded up the two repos, and basically set it to work. The first thing it does,  of course it spins this up, it takes a look. It's basically loading up a sandbox. It's actually cloning in that code, and then it's gonna start analyzing what it's looking at.

[![Thumbnail 760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/760.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=760)

It'll come back in a few  minutes with a plan. And it'll be a pretty detailed plan and we're continually iterating on this, but very similar to spec, just designed for this agent to kind of self-manage. The mental model when you think of the autonomous agent is it's handling it. It has access to sub agents. It has access to context. It has access to tools, and the idea is it sort of like you in front of the CLI working across things. That's our goal with it. So it'll build out this plan you can review it if you want, or you can just fire and forget and it'll start working on it.

[![Thumbnail 790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/790.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=790)

[![Thumbnail 810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/810.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=810)

So it'll come back with the plan and then  10 to 30 minutes later, depending on the size of the task or longer if it's a really big task like refactoring 20 repos, it'll show you two PRs and you can click into them. It'll have built and validated it. You can see the sort of history that it's done and that autonomy of it to work is pretty neat, especially for these tasks that you might not otherwise  get to. This was considered a chore task. And then we move to the task list. We can run up to 10 tasks in parallel, and then it has a queue, so you can just keep throwing stuff at it and it'll get to the work when it gets to the work. Those are the ideas you have primary work you wanna be getting done? Well, hand the rest off. Don't let it slip, just let it go.

[![Thumbnail 830](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/830.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=830)

[![Thumbnail 840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/840.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=840)

[![Thumbnail 850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/850.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=850)

And then the other thing I wanna hit on is it's an agent,  it's not a task thing, it's the same agent, so you can come in and chat like, hey, what are you working on? What have you done recently? And in this case you can see the first task he comes  back with was the Hydro refactoring and then you can start to talk about it. It's like, well, why did you make those changes or tell me more about that and it has memory. It's remembering what it's done in the past. And it  becomes really handy because it's your agent doing work you might wanna check in on it.

[![Thumbnail 860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/860.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=860)

[![Thumbnail 870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/870.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=870)

[![Thumbnail 880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/880.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=880)

[![Thumbnail 890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/890.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=890)

The other area is it has access to web search. It can ground itself. So let's take if you wanna build an AWS Strands  agent. Claude thinks it's still in preview. It did GA, but this grounds it, lets you know what it's doing, and what's really neat is you can kind of chat. You can go further than this and talk about different designs  and at some point just say I just wanna build this. And from chat you just throw that off and it will go and actually, I think in this case it's like yeah build me a Strands for my to do list.  It'll go and it'll take a look and then it's basically gonna come back, understand your intent, suggest repos for you to pick from and you're on your way kind of creating this task. 

[![Thumbnail 900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/900.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=900)

### GitHub Integration and Agent Architecture: The Brain and Sub-Agents

So the idea is that these agents are yours, you can work with it, you can talk with it, you can give it tasks and only you can kind of control it. The  next area is we realized this has to be inside of tools you're using, so we're starting with GitHub.

[![Thumbnail 910](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/910.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=910)

[![Thumbnail 920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/920.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=920)

Let me show you how this works with the tools you're using, starting with GitHub. From a GitHub issue, it'll also open GitHub PRs as I showed, but from a GitHub issue you can add the Kiro label.  In a few seconds it'll come back with the eyes emoji showing that it's checking it out, and then it'll start getting to work in a very similar pattern that you saw. But we don't want to make you go to the website if you prefer to be on GitHub. This also gives you a system of record of what's been done, which  is nice.

[![Thumbnail 940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/940.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=940)

[![Thumbnail 950](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/950.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=950)

[![Thumbnail 960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/960.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=960)

So it'll come back, and this task probably took about 20 minutes, and it'll eventually open up a PR. You can see the commit is actually Kiro Agent plus you. Everything is done on your behalf, but it's still attributable to the agent, which is the goal. And so we have the PR that got written. It'll actually  learn how you like to write PRs, or if you have PR templates, it'll pick those up, but this is just the generic. I thought this would be useful to have with no prompt. But what's really cool was  I had given it a learning before, or actually I'll show you this. Yeah, this was SQLite. You can just leave comments on the PR which was use Postgres instead. A brand new agent didn't know my preferences.  Give it to Postgres, and it'll start revving on that PR again.

[![Thumbnail 970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/970.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=970)

[![Thumbnail 980](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/980.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=980)

[![Thumbnail 990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/990.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=990)

And then if you look at the change log, you'll notice this agent folder. It's one of the patterns I like to use. I have a change log that  the agents are kind of always updating against. And the way I got there was I actually gave, well I can ask here, hey, what learnings do you have, which is probably the simplest way to  interact with this most directly. And it'll come back and it has two right now. The first one is the Postgres one that got learned on that last PR change, and  the second one is this documentation standard where I said, hey, if the agent folder doesn't exist, make it, do this. And the way it works is the main agent is actually sitting there pulling in learnings and orchestrating writing prompts for all the sub agents, so it's always running kind of that context through.

[![Thumbnail 1020](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1020.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1020)

[![Thumbnail 1030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1030.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1030)

[![Thumbnail 1040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1040.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1040)

And why I think, one of our tenets is play well with others, meaning like integrations and partners and things. If you take a look at like Dynatrace, which is obviously a really popular and critical part of like observability for a lot of our customers,  we did an integration with them which is the simplest integration where we use GitHub issues to hand off between each other, so there's not like a heavy lift there, but it matters, you know. I'm sure if you go into the  Dynatrace view and check your vulnerabilities, I'm sure lots of folks are used to seeing a lot of things that you should do. Might get to it. It's hard to do, and this is an area where I really want to help with this product.  Let's create issues, let's auto assign it to Kiro, and let's get PRs ready. At least you're reviewing the PR now, and you're not, because if that's spanning 10 or 20 projects, you're loading that locally, you're pulling down the latest. Let the agent handle it for you. Let it clone it into its sandbox, let it test it and pull it back up. So in this case, it went through, took the assigned issue and ultimately was, yeah, it opened the PR with the fix.

[![Thumbnail 1070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1070.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1070)

So I've been talking about this agent. I'll show you sort of how I'm  thinking about it, which is a rough illustration, but basically the purple box is your agent. Within that we have this context layer we talk about. We have the chat which is this like high interactivity side we call it internally the brain. The brain is responsible for clarification questions, building the plan, figuring out if this task is for an existing task or a new task. And then we have an event journal. So every time you send it in there, you're chatting with it. At some point chat will be like, hey brain, I think you need to step in, and it'll start to spawn these subtasks or just tasks which are filled with sub agents. We have a code build verifier, we have a dev agent to write code, we have a pull request writer, and we'll be expanding those more and more as we go and making it extensible for yourself.

But the sub agents get to work. The brain's responsible for the delivery. It's all done in the sandbox, and what's really cool is it writes to the event journal so even when those tasks are torn down, the agent still knows what's going on. And then the equally important part is it's wrapped in this proxy where it only goes to the network that you're allowing. So in some cases we have a proxy to GitHub where we don't allow merging and pull requests, for example. Even if you gave it the app access, we restrict things further, and you'll see this pattern as we bring in more and more integrations. So the idea is that you can trust this agent to just go and kind of mess around in its own environment.

[![Thumbnail 1170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1170.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1170)

### Team Agents: Multiplayer Collaboration with Context Awareness

What gets really cool though is what I've been showing you is the Kiro Autonomous Agent which everyone with Pro, Pro Plus and Power subscriptions get their own agent at Kiro.dev. It'll be rolling out this month basically. That's your agent. No one else can work with it, but we've been playing with a version too which is a team agent. So imagine that system that I showed you where you could make dozens  of them, one for every team, one for projects and things like that. And we're doing really interesting work around and still learning. So this is on a waitlist. Happy to, if you want to sign up to get early access, but it hooks into GitHub, GitLab for source control, Slack and Teams for communication, Jira and Confluence and such. And what's really cool about it is it's a multiplayer agent, so Ben and I can both have one agent that we're both talking to. It's, you know, attributes work back to whoever requested it, but it's its own agent working in its space, and that autonomy is something I'm super excited about. We were just talking earlier, I think one of the next challenges to solve is the authorization policies and how we think about deploying these at scale.

But we're really focused right now on making this agent awesome as a collaborator. Chat with it in Slack, have a big long thread on an idea, fire it off and have it go work on it. Ask it, you know, hey, didn't we fix this bug last week from Jira, have it pull in, and again it's a single agent. It knows all about your tools in your world, and the context layer becomes really powerful. And I'll show you just a quick example of that.

[![Thumbnail 1230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1230.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1230)

[![Thumbnail 1240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1240.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1240)

[![Thumbnail 1250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1250.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1250)

[![Thumbnail 1260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1260.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1260)

[![Thumbnail 1270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1270.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1270)

In the team's version  we're building up this context layer. It knows all about your packages. It has tools like get relevant learnings and search code. I can assign it an issue to update a votes route.  I never told it where to make the change. The agent knows all the packages I have, and it will make its best guess on where the change should probably go. If it doesn't know, it'll ask me a clarification question  on the issue, but in this case, yeah, it was a voting app. Let's make the change in there, and it's a little nuance that is super unique for the product because  usually you're directing everything this agent's doing, and our goal here is let's just tell the agent what you want and it's going to go achieve that goal working within boundaries that you trust.  And that becomes super powerful.

### Ben's Perspective: Experimenting with AI Tools at Scale

So that's a lot on Kiro Autonomous agent. I want to hand it over to Ben now who's going to talk a little bit more about how he's building these systems at his startup. Thank you, Kyle. Round of applause for Kyle. Yeah, alright, thank you. So really quick, I've never been to AWS before. This is my first AWS. How many of you here are actually looking for tools, you're leaders, you're trying to empower your developers to do more with less? Show of hands. About 50%. The lights are a bit bright, so I can't see everything. How many of you are here to actually use these tools? Deep use these tools, get in, a lot of similar hands up. That's good, you're hands-on leaders, that's what we need more of. And then finally, how many of you are responsible for embedding these agentic flows that are starting to come out into your products that your companies make? Yeah, some hands, alright, okay, cool, that's really, really good.

[![Thumbnail 1330](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1330.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1330)

So I'm going to start a little bit, it's the Green Book. I want to talk  about sort of foundationally where we started, and then we can move a little bit deeper into some of the things that I've been working with Carl and his team. So we are running experiments everywhere, I'm sure every single one of you are. We probably use 30, 50, 100 AI tools in a day. It's a bit of a minefield out there right now, right? Cursor, Codex, Copilot, all of them under the sun. We're also not just using them for code. We're using them for marketing, we're using them for documents, we're using them for AI BDRs. If you look out there, there's so many different options now that are really helping streamline some of these processes. And it's ultimately bringing, it's not even bringing, it's opening a new world, especially for us as a startup. We can do so much more with less, and it allows us to move even faster, pivot faster. It's really an exciting world right now.

So why did we start looking at this from a company? One of the biggest things as a startup, we're actually quite an old startup. And so we've got sort of five to eight years' worth of tech debt that we've picked up along the way, as we've pivoted, as we've moved forward. And the size and complexity of some of the things that we're doing, right here, for a really good example, right? So we used Angular as a really good example. We asked it a very simple question. Go from Angular 16 to Angular 20. Now, that would probably normally take a dev team months, right? Months and months and months, not just sort of days and hours, right? And this was a really interesting experiment for us, because this wasn't really fathomable without the additional context that the Kiro Autonomous agent, sorry, it was, I've been using the code name. I've been using the internal code name.

So okay, actually, let's back it up a little bit. We actually connected about six months ago on this product, and we've been testing it for the last six months, and it's been amazing to watch the evolution of it. And we've been using it more and more, we've been integrating it more and more into teams, so just kind of a little bit of background. And so with this Kiro agent, we've been able to, where before you'd only be able to take small chunks, think like core code on your local IDE process, we've been able to give these really large chunks and get this all separated up. It does not scroll. It's all good. And so these large chunks now become easier to process, easier to be able to get through the task management, right? What the agent is doing is it's kind of listing out all these tasks, it's trying to split it up into micro chunks and then it's sending them off to the agent, or agents, right? You've got lots of sub-agents, they're kind of disseminating what they should be doing and how they should be doing it. It's automatically creating the PRs as it goes through, and you know, it was interesting.

So the question was pretty basic. It's still not there yet, is where I'm going to say.

So it was phenomenal. It planned it out perfectly, what it told us what it was going to do. The plan was almost perfect. If it had executed on it, it would have been perfect. Bearing in mind that we tried this probably a month ago, and everything I'm speaking now about AI, you know, tomorrow will be complete garbage. Everything's moving so fast, right? If I tried this again, it could probably nail it.

But it was interesting the pieces that it did miss, right? So one of the biggest problems we had was Angular 20 was too new at the time, and it didn't have the knowledge in the LLM that was running to understand some of those deeper things. And so it hallucinated some things, did some funny things, but it still got us 80% of the way there. 80% of the way there, that five month, four month window to do that transition, and you managed to cut out four months, it's huge, right? So this is really like we're living and breathing this weird future.

It's almost like we're moving, we were talking about this a little bit earlier as well, right? This is like the cloud native calling of AI, right? We're kind of making that shift now where we've gone from being able to deploy a single container into these sort of networks of containers or networks of AI that are going to enable this next generation of processing effectively. Alright, so that was our Angular experience.

[![Thumbnail 1590](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1590.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1590)

### The Data Challenge: From Gigabytes to Petabytes in Enterprise AI

 Now, this is another experience we had. We asked a really simple question, this probably comes up in many of your organizations. So our sales engineers had a need to get better, more up-to-date information on our codebases, how to deploy, how to make sure that they could hold a really good conversation with our end users, right? And our codebase is changing quickly, we iterate on it daily.

Ultimately, it nailed the intent when we asked it, nailed the intent. But not only did it nail the intent, it found all of the relevant repos. We threw it 150 repositories. It went and ran through all of those repositories, and it was like, this, this, this, this, we're going to condense that. Okay, this is interesting here. It generated architecture documents, it generated mermaid diagrams, it created all the markdown files so that we could import those into Confluence. And it did a pretty good job, it nailed it.

That would have been multiple days of work for an engineer, right? Silly question, what do you want your engineers to be doing? Right? Is it engineering work, or is it documentation? The whole evolution that we're now experiencing is around how do I empower my developers to actually be true engineers and work on the hard stuff, so that they're not really stuck in the mud. I think that's one of the biggest empowerments that we can provide today, and it's really, really, you know, it's shown itself at this point.

[![Thumbnail 1680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1680.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1680)

 So real quick, I'm going to pause. I'm going to talk about myself a little bit in the company. So we are NVISIONx. We basically look at everyone's data. That's what we're actually doing. And so data is actually your most valuable asset, whether you realize it or not. All of your businesses run on data. Many of you do not know what's inside of those data pieces. We find this time and time again as we introduce and talk to new companies.

And our goal is to democratize data within organizations. We want to reach out to your SharePoint, your OneDrive, your S3 buckets. We will literally snort it all in, and we'll try and help you add some context to it, right, and enrich that data so that you can start to use it. We actually use business records, that's actually our line of thing, right, we convert it into a record schedule. Most companies have a record schedule if they're large enough. And everything is a record item, and then we can enrich it even further from beyond that process.

Ultimately the goal here, and sort of where we're pivoting is we're going to become sort of the gateway to data. That's what we're hoping for, because data is very unstructured. How do we structure it in a way that LLMs can better understand, how do we pull it together? How do you get the right level of context? Right, context is the biggest problem, and we'll talk a little bit more about that in a minute. So how can we sort of have an agentic pattern that supports massive petabyte scale systems? How do we keep moving forward, right?

And how do we discover and answer these ambiguous questions? All of your customers, like internal customers, external customers, they ask questions that you can't really answer, right? They have objectives, they have goals, but they don't normally answer the straightforward question, and we'll talk a little bit more about that in a bit. So a quick warning, again, everything is moving at light speed. Everything that I'm going to say today has been very heavily lifted up, high level. We're moving so fast, if Elon Musk and all these other guys are right, we'll be using Imperial credits by the end of next week.

So the goal here is to make sure that you take everything with a pinch of salt. This is everything that we've discovered and found as we've gone on our agentic journey, and hopefully this will resonate with you and your internal organizations as well.

[![Thumbnail 1830](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1830.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1830)

Quality,  quality of data. How many people have experienced this problem? As you put data into LLMs, what has it generated? Has it always generated the perfect result? Has it always known exactly what the context of your data is? Has it ever hallucinated on your data? These are all problems that you have to look at. It's really interesting. If you feed it enough data, we ran some experiments around this. We fed some really big legal documents. We fed it 1,000 characters, we fed it 10,000 characters, 150,000 characters. It best understood it with only 1,000 characters, not the full document, because it was just that nugget. As it processes that data and it's non-deterministic, the most repeatable way was to give it smaller chunks of information to make sure that we got the same repeatable answer. So interesting tidbit. Ultimately, quality is really important. Garbage in, garbage out. We've got to make sure that that data is clean on the way in. How do you do that? It's not by connecting all of your data and throwing it and brute forcing it through an LLM. It's just not going to work.

[![Thumbnail 1900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/1900.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=1900)

 So this is kind of interesting. How many gigabytes of data do you have? Who operates on the gigabyte scale? Who operates in the terabyte scale, 10, hundreds of terabytes? Who operates in the petabyte scale? Yeah, I love you guys. Unstructured data today accounts for 80 to 90% of enterprise data, and it's increasing 50 to 65% annually. That's a lot of data, and then you look at the LLMs and what tokens relate to size. Now today, I believe some of the best models out there can take around 2 million tokens. That's 200 megabytes of data. I can't even put 1 gigabyte of files in there, let alone 1 petabyte at the enterprise scale. So we've got a clear gap here that we need to address.

Agentic flows enable the activation of these domain experts across multiple documents. How do we split them up? Do I have an agent specific to PDFs? Do I have an agent specific to these kinds of documents, or maybe if I've enriched some additional data, I know these set of documents are this type of record. Okay, now I have a smaller subset. That context is now shrinking as we move forward. The usage of tooling, different types of intents, RAG, all those kinds of things can be massaged in a way that allows your agentic brain, I think you called it earlier, to enable you to be able to understand these documents at a deeper level and with way more intelligence. And it's unlocking the ability for us to be able to understand the data at a very different level.

[![Thumbnail 2000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/2000.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=2000)

### Understanding Intent and Context: The Red Car Problem

And here's a really simple diagram  of agentic flow. We have a request that comes in. We have intent. I'm going to talk about intent in a minute. Intent, I feel, is one of the most under-talked topics in the world. An orchestration graph, this is the brain. This is where everything's happening. This is where the business really happens, and then you have an output. I want to talk about requests a minute. How many people, someone tell me what a request is. Come on. No. All right, fail. We're good.

So a request is not just a human requester. It's not just show me the red car, or it's not just, I don't know, show me all the documents that are related to Ben or Kyle. That's not enough context to be able to do anything with. And when we break down that, that becomes a really big problem. We need to humanize it. We need to humanize how we're thinking about the process and what we're doing to really deeply understand what's going on. Language is really hard. All those English majors now have an amazing job because categorizing all this information with everything that's going to go on, language is just one of the most insane things to be able to understand.

And then with the orchestration graph, can we replicate those kinds of features of humans? When you go to a sales event, you have your sales manager, you have your salespeople, you have your senior, your juniors. All of them, it's that collaboration between these people. And so this is why agentic AI makes so much sense, because it maps back to how we actually operate as humans. And so it's easier to understand, easier with circuit breakers in the middle. Oh, the junior engineer gave me the wrong information, or oh, the senior engineer gave me the wrong information. You can kind of see it, and you can see it in the flow as it happens.

[![Thumbnail 2110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/2110.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=2110)

Okay, intent.  I've kind of messed with this quite heavily. Ultimately, you actually have five core types of intent. You can Wikipedia this. It's assertives, directives, commissives, expressives, and declarations. And then I kind of started removing out the rest of it because I was a bit worried I was going to go way too deep on a topic that maybe didn't make a lot of sense. But what I'm going to try and do is bring that back down to sort of Earth, right?

I have a really good example. At my last company, I worked for a VMS provider. And we had thousands of security cameras across multiple time zones, and we were going to bolt them into it. And so we were going through, it was like, what questions would you ask? The question was, show me the red cars. Okay, what does the LLM or what does the agentic flow have to do to really understand that? You can't brute force that through a single LLM. I can't provide it the 200 million hits I had for the last seven years on red cars, right?

And then it's like, okay, so does the AI need to decide, okay, I should ask a couple of questions, maybe narrow my field of view, narrow my context. That's a little slow, right? What else is intent? It's not just a user question. What have they done in the past? What page are they on in my product? Oh, they've already selected a camera. They're in a camera page that's dedicated to the camera. That needs to be fed in as well. It's all context.

Many people see context a little bit flat, and context is actually very broad, very wide, and it covers so many different parts. And so I think it's really cool to see, like, I've now found a million cars. How do I narrow? Should I ask a question? What, where, when, right? Is it a time-bound problem? How do we make agentic AI understand that, and how do we really figure out how to narrow that context window? That is key to getting to petabyte scale, because you can't force all of it into a context window.

[![Thumbnail 2230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/2230.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=2230)

 What is context? All right, so it's not always a user, it's not always a question. It could be an action, it could be a string of actions with questions in between. It could almost be a declarative list of things that you want it to do. You need to pick these apart, right? And so that's why intent's really important in some of these sections. Organization data, like that's really obvious, but how it's structured is really important. I can't just throw unstructured data. It has to be structured to a degree.

I have to be able to understand potentially what's inside of it. How do you search for it, right, with tooling, with some clever graph logic and things like that, you can kind of get there. And ultimately, how you feed the borg, right, how do you get there? And so again with the red car concept, do I have the context needed to be able to pull off the question? Can I add context? Who is the user?

If we step back again outside of just the VMS context and we become now that organization, where show me the red cars, am I a finance user? Am I looking for the red cars that I sold this year? Am I looking for the red cars that are in the video? Am I looking for the red cars in another system that may track whatever that is, right? So it's a very high level example, but how we propose or get additional context, it could be the current state, it could be the user session. All of that has to feed in. It can't just be linear, hey, here's my question, here's my data. That's quite typically how AI is used today.

[![Thumbnail 2330](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/2330.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=2330)

Ontologies, who knows what an ontology is? Hands up.  Yeah, okay, who knows what taxonomy is? Who knows what a schema is? Everyone, handle, come on. So there's actually differences between these, right? They give different layers of data. And so an ontology is a fun one, right? So ontologies vary per organization. You can't just be like, hey, you're at a financial institution, here's an ontology for your business. It does not work that way. Ontology is absolutely unique to the business.

But it's these relationships and how we look at them, that's what connects the data together. And so being able to provide shape-shifting ontologies into your data pool, that is money to LLMs. Because now I know how many hops it is, right, it's just a DAG, effectively. And so you're looking at these and it's like, okay, show me a customer that has a credit card with this number. All of a sudden, or, hey, here's a number, go find this number. Okay, this number is related to these three things, right?

You can go up and down the graph, you can traverse it in any way you want, and you get to the data much quicker, and you also typically have a much smaller window. And this is very similar to graph RAG, right, that's kind of what it's doing.

But this is a little bit beyond that because you're not just looking at vector search at this point. You may actually be doing a cross between some level of semantic search and vector search to be able to narrow and get to exactly where you need to be, just to reduce this. And so now with the red car example, show me all the red cars, I can now see that I have relations in finance, I have relations in my video management system, I also have relations in HR because I have a parking permit for a red car. Which one do you want? I can now be way more crystal clear with my response, in my actioning, my questioning from an agent perspective.

Also, I can be intelligent. If I've got enough context and I know it's a finance person, I just provide the finance answer. They don't care about HR unless it's their car, but then I'd know that as well because it would all be linked. It would all be in that understanding and how systems ultimately work. This is just basically allowing us to really try and pull apart the disambiguation in all of our data sets at the petabyte level and the gigabyte level. It doesn't matter what level you are, you need that disambiguation, you need to pull it apart, you need to simplify.

[![Thumbnail 2490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/2490.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=2490)

### Agent Architecture and Key Takeaways: Quality, Autonomy, and Ontology

It's not even simplification, it's getting more structure around your data so that you can act upon it and turn that data from a piece of data into an asset for your business so that you can actually operationalize stuff on it. That's the really big key here. That's what we need to  do. Here's a little quick sort of deep dive into the brain. Ultimately you're trying to go from intent to some kind of task management. You then kind of have your agent selector graph. It's also a graph. I want to be super clear, a lot of people use workflows, they're linear. Hey, do this, A, B, C, D, okay, I've now done my task. Not at all.

Sub-agents need to be able to make decisions that may change the entire path as they move forward. As that happens, this is really kind of pivoting from sort of more basic understanding to this understanding where now, if the agents have more control over how they act, we should get better results. At the end of the day also, another really key thing here is they're not necessarily all AI agents. Some of these are policy driven items. As you're going through, you need to add restrictions. I know there was a policy agent thing, I think AWS released to make sure that your LLMs don't go off the rails.

[![Thumbnail 2600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/2600.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=2600)

Things like that, they're more algorithmic, they're rules-based. You don't want bad things happening ultimately as you go through this process. So this kind of ultimately finalizes things, it sucks it all up, and then it spits it out in an output, and hopefully it's the answer you wanted. Non-deterministic system, it could be clowns, but we never know. So yeah, basically what was funny, we met, you said six months ago and we're working on the Kiro Autonomous Agent. We had this architecture in mind of blowing up the workflow to a graph so the brain could run sub-agents, and then starts talking about his thinking and more generic. I was like, oh cool, so there's a pattern here and it's been really neat sort of working with  customers seeing these patterns come out and a couple of themes.

The first is the context and it's such an interesting problem because I mean we have, no one has solved this yet, but do you want it at the repo level? That's helpful, but maybe it's your context. What about cross repos? What about legacy projects to data to everything backing it up? So that's a theme that we're just coming back and forth on is just how do you manage this context, how do you run this context layer? Models are going to keep getting better. You might even start training your own models, but it's going to be context of your data and your systems and there's really interesting opportunities there.

For the Kiro Autonomous Agent, we're making a bet that we can be experts at your code base at the team level to start and growing from there, but just be really great at building embeddings and graphs and just structure around your code, your documents and things like that. And see what Ben and the team are helping other customers enable for is really neat. The other thing is hopefully clear is this autonomy, this idea that an agent's going to fire off other agents and it's going to run for a bit. It's going to reflect. It's going to come back. The advantage is the fact that there's multiple agents though. There's groundings in there. There's a judge. There's a step. There's a plan.

And one thing that we hit on is the sort of the graph that gets built. We saw it right away. One of the earliest agents we had built for doing development workflows, it would make a plan and everyone would be like that looks like a good plan. And the second it started, the plan had nothing to do with what it actually did because the agent just made up a plan. It was cool. So what we're trying to do is ground the plan a little bit more, but also acknowledging that that plan by the time it's done will probably evolve.

That's why it's a little bit different than like even a spec because the agent's going to get in there and start working and be like, oh wait, we missed this step just like we would and we want to have flexibility. So we've built the system, yeah, the graph evolves, that plan evolves. I think it's good, we actually call them internally acceptance criteria.

The goal is to do this. How the agent gets there is actually open to the agent's interpretation. So I think the autonomy part is going to be really neat. Whether it's building with an agent core, using different sandboxing tools on your local machine, giving the autonomy for the agent to just let loose but trust it is going to be the real powerful spot to be at. So those are two things I'm seeing clearly.

[![Thumbnail 2740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/2740.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=2740)

For me, quality of data, and I see this all the time, it really is garbage in, garbage out. You've really got to  understand your data before you start feeding it in, otherwise you will get spurious results. I've seen it time and time again. I've built agents for different companies. It's really down to the quality of data on what you feed it. Because all the LLMs, they are trained on a huge corpus of data that may or may not have any relevance to what you're doing, so you need to narrow that blast radius as you're feeding it, otherwise it will become very hallucinogenic potentially.

[![Thumbnail 2770](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/2770.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=2770)

Sometimes it gets it, sometimes it's not. If you're trying to narrow that non-deterministic to what you  want, that repeatable workflow, this is where quality of data really, really helps, so you can get to that repeatable workflow. And then finally ontology. For me, ontology is a map of your data architecture internally. That is money right there. If you can figure that out, if you can map that to all of your data, whatever that is, whether it's in a database, whether it's in documents, unstructured, structured data, it doesn't matter. If you have an ontology around it, you're able to query and narrow faster than anything else out there. That's the way to do it.

Because if you understand the relationships between your data, not only can you figure out what is relevant, you can also figure out what is not relevant, what is adjacent. All of that comes in. It also enables some other really amazing features such as reasoning, because now it understands how it got there. It can see the reason of why it even picked those items, and it will tell you why it did that. It's honestly mind blowing everything.

[![Thumbnail 2870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/275e8432c6295d5f/2870.jpg)](https://www.youtube.com/watch?v=FAbm2MXYaqc&t=2870)

So I guess I'll close out. I've always, we've been joking, I'm very lucky that we're working in development tools which for years has had compilers and CI systems and truths and grounding in the world of free form, open ended data, but the themes are there. So for Kiro specifically, if anyone's curious  about it, check it out, kiro.dev. The CLI is fun. The IDE is pretty cool. If you got questions, of course, come find me. We've got the booth up, but I appreciate everyone taking the time today to listen to us talk about what we've been spending a lot of time on. Yeah, thanks everybody. That's it.


----

; This article is entirely auto-generated using Amazon Bedrock.
