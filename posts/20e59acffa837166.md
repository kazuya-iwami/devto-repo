---
title: 'AWS re:Invent 2025 - Digital sovereignty and data residency w/ AWS Hybrid and Edge services (HMC310)'
published: true
description: 'In this video, Ben Lavasani and Mallory Gershenfeld explore AWS''s approach to digital sovereignty through hybrid and edge services. They discuss data and operational sovereignty pillars, regulatory compliance challenges, and AWS''s continuum of services including AWS Local Zones, Dedicated Local Zones, and AWS Outposts built on the Nitro system. A case study features Geidea, a Saudi Arabian payment solutions provider achieving 75% POS market share while meeting SAMA regulations using Outposts. The session covers practical implementation using AWS Control Tower for governance at scale, Service Control Policies for data perimeter controls, and S3 on Outposts with separate IAM namespaces. Technical demonstrations include local replication, CloudTrail auditing, CloudWatch monitoring, EMR on Outposts for analytics, and Mountpoint for Amazon S3 integration, all managed through a unified AWS Management Console experience.'
tags: ''
series: ''
canonical_url:
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Digital sovereignty and data residency w/ AWS Hybrid and Edge services (HMC310)**

> In this video, Ben Lavasani and Mallory Gershenfeld explore AWS's approach to digital sovereignty through hybrid and edge services. They discuss data and operational sovereignty pillars, regulatory compliance challenges, and AWS's continuum of services including AWS Local Zones, Dedicated Local Zones, and AWS Outposts built on the Nitro system. A case study features Geidea, a Saudi Arabian payment solutions provider achieving 75% POS market share while meeting SAMA regulations using Outposts. The session covers practical implementation using AWS Control Tower for governance at scale, Service Control Policies for data perimeter controls, and S3 on Outposts with separate IAM namespaces. Technical demonstrations include local replication, CloudTrail auditing, CloudWatch monitoring, EMR on Outposts for analytics, and Mountpoint for Amazon S3 integration, all managed through a unified AWS Management Console experience.

{% youtube https://www.youtube.com/watch?v=CxkRvW42Hgc %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/0.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=0)

### Introduction: The Critical Importance of Digital Sovereignty in Cloud Computing

 Hello and good afternoon everyone. Headsets on please so you can hear me. Can I get a thumbs up if you can hear me? Loud and clear, brilliant. Thank you all for joining and welcome to this session. I'm really excited to see you all here today.

Imagine waking up tomorrow and discovering that your organization's critical data is suddenly subject to laws that you never agreed to. This isn't hypothetical; it's a reality many organizations face today in our interconnected digital world. That's why digital sovereignty has become one of the most crucial conversations in cloud computing.

[![Thumbnail 50](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/50.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=50)

 So much so that 82% of companies are considering sovereign solutions. They're responding to a fundamental truth that organizations need both the transformative power of the cloud and the ability to maintain complete control over their data. But digital sovereignty is not just about where your data resides. It's about who has access to it, how it's processed, and maintaining operational autonomy while still innovating at the pace of the cloud.

From the European GDPR standard to industry-specific regulations, the requirements are intensifying daily. So today, along with my friend Mallory, we will show you how AWS Hybrid and Edge services can help you maintain sovereignty without sacrificing innovation. We're going to explore practical solutions that let you harness the full power of AWS whilst keeping absolute control over your data's location, access, and processing.

### Understanding Digital Sovereignty: Data and Operational Control Pillars

My name is Ben Lavasani. I'm a Senior Go-To-Market Specialist with AWS Hybrid Cloud. Let's get to it. I'm going to start off by talking a little bit more about digital sovereignty and some of the regulatory challenges, and then I'll introduce some hybrid and edge services to you.

[![Thumbnail 120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/120.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=120)

 I'll be speaking on a customer's behalf today, representing Geidea, who are based in Saudi Arabia. Then I'm going to hand over to Mallory Gershenfeld, who's going to go into another layer of detail about specific implementation best practices and controls and building at the edge.

Digital sovereignty represents an organization's ability to maintain complete control over their digital footprint, data operations, and their technology stack. There are two concepts within the broader topic. First of all, data sovereignty, the pillar on the left. Within that we need to consider data residency, which is geographic control of where data is stored and processed, and compliance with local data protection laws and regulations within that jurisdiction where you're deploying.

[![Thumbnail 150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/150.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=150)

 We also need to think about operator access restrictions. This would be things like having granular control of who has access to data and systems, as well as implementation of role-based access control policies, audit trails, and encryption. All of that needs to be considered in this pillar. On the right side, thinking about operational sovereignty, we need systems to be resilient and survive disruptions and disasters, redundancy of critical systems, as well as disaster recovery solutions to make sure that you're protected against any single points of failure in your deployment.

Finally, there's independence and transparency. Clear visibility into your technology stack and dependencies within it are really important to understand. The ability to maintain and modify systems independently is all very important. At AWS, we've been working closely with customers to understand more about some of the digital sovereignty challenges that they're seeing trying to be compliant in their markets.

[![Thumbnail 240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/240.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=240)

### Navigating Compliance, Security, and Operational Challenges in Regulated Markets

 For compliance specifically, the regulatory landscape is constantly evolving. There are new laws and requirements emerging globally, and organizations must navigate complex cross-border data transfer restrictions such as GDPR in Europe. On top of that, there are also many industry-specific regulations that need to be considered. Whether you're in a regulated industry like telecom, healthcare, or financial services, there's often a very complex landscape about how you can be compliant with that specific regulation in that market, and that creates a lot of complexity.

Secondly, security is another challenge we see with customers who have to balance implementing robust security and data access controls while still maintaining usability. It's all good building a very secure system, but if no one's able to utilize it and be productive with it, it's potentially a waste of time.

Additionally, encryption standards are becoming increasingly more complex, and there are challenges around that as well. Audit trails and monitoring also fall into this category. How do you check access and monitor what's happening within your environments? Finally, we see operational challenges as well. Maintaining consistent management across IT environments can be very difficult, whether you're on premises, running in the cloud, or somewhere at the near edge. This can be especially challenging if your workloads are highly distributed around the world in different markets.

[![Thumbnail 380](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/380.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=380)

Of course, you must ensure that you have business continuity while also preserving sovereignty. We see situations in some markets where all data must be stored locally. We see it sometimes when the primary copy needs to be local and backup can be in a region outside of the country. Or where there's no policy and it's much more freedom. Trying to figure out that landscape operationally can be very challenging for our customers. So at AWS, we've been striving to build a continuum of services where we can bring the cloud to where you need it. 

[![Thumbnail 440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/440.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=440)

### AWS Hybrid and Edge Services: From Local Zones to Outposts

The idea is that we offer the same infrastructure, services, APIs, and tools so you can have that consistent developer experience, whether you're running in our regions or all the way out to the far edge. It all starts with regions, and we will continue to innovate and build regions and also new regions such as the European Sovereign Cloud that have been announced. But some customers need to get close and need their workloads to be running closer. So we're expanding with our local zones as well as CloudFront to bring edge locations and new metros around the world. And then we can bring AWS services on premises with services such as Outposts, and then in the far edge with IoT services and EKS and ECS Anywhere. The idea is that we want to do that in a very consistent way so you can leverage the productivity of AWS whether you're running in the cloud or at the edge. 

[![Thumbnail 470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/470.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=470)

This approach has been commended by third parties. I'm really pleased to share that in Gartner's 2025 Magic Quadrant report, AWS has been recognized as a leader in distributed hybrid infrastructure across critical use cases for edge computing, as well as container deployments and AI workloads. This recognition from Gartner really validates our commitment to providing comprehensive hybrid infrastructure that meets our customers' evolving needs. 

[![Thumbnail 480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/480.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=480)

Let's take a look at some of the specific services. I've touched on a few of them, but I'm going to dive into a few for you today. AWS Local Zones are AWS-deployed and operated infrastructure that we're building in large metro areas. For example, there's one right here in Las Vegas that's extending the Oregon region to the city.  With local zones, you're able to access on-demand elastic services on a pay-as-you-go basis, and you can do this in the same way and with the same developer experience that you're already used to using in the cloud today. Services like EC2 are available, and if you're running workloads in a region on EC2, the experience is exactly the same when you're deploying here in Las Vegas.

[![Thumbnail 530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/530.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=530)

It's integrated with the regional services through our backbone, so you can also run hybrid workloads where you might want to push certain parts of your workload to one of the regions. We have many customers that are doing that. Here's a layout of what's happening with the local zones launch.  We started in the US, and all of the locations on the map in purple are already generally available today. Everything in white is announced and planned. We've also expanded into Europe, the Middle East and Africa, as well as Asia Pacific, Australia, New Zealand, and South America. Now we're really interested to hear back from you with any feedback. If there are any specific locations that are of interest from a data sovereignty point of view or a digital sovereignty point of view, we're really excited to learn about this and see whether we can help support you in those locations.

[![Thumbnail 570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/570.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=570)

Dedicated Local Zones are another service I touched on.  These are for organizations with more stringent sovereignty requirements. We are able to offer a Dedicated Local Zone, or DLZ. They are built for the exclusive use of a customer or a community of customers and are placed in customer-specified data centers. That could be your own location or an AWS data center that we have local to you. It's dedicated for that customer's specific use. It can even be operated by AWS personnel that are located in that specific sovereign territory.

We have multi-tenancy features built into Dedicated Local Zones, so some customers mightâ€”for example, a local government might have multiple agencies or entities within itâ€”and they want to share the same common dedicated infrastructure but have a level of multi-tenancy and segmentation between them. This type of thing is possible in a DLZ environment. With Dedicated Local Zones, we can isolate sensitive workloads on dedicated cloud infrastructure. It's possible to build fault tolerance and have multiple locations, and ultimately reduce operational complexity and increase the speed of your innovation. We take care of managing this infrastructure on your behalf, and you can deploy sovereign workloads locally.

The third service I want to touch on is AWS Outposts, which are an extension of AWS Cloud on premises. In this situation, we're able to run this in your data center or a local co-location environment where we're able to extend our cloud into the on-premises environment with that consistent experience. You have a single pane of management, whether you're operating in a region, local zone, Dedicated Local Zone, or Outpost. With Outposts, you effectively see a pool of capacity in a region that's dedicated to you with a different identifier.

Within the family of Outposts, we have both racks as well as Outpost servers. The Outpost rack is a 42U data center rack, bringing those same services and APIs on premises. We have a number of core servicesâ€”EC2, EKS, EBS, S3, and RDS are all available locally in the Outpost. You might see one rack there, but don't think of it as being limited to just one rack. We can have logical Outposts that span across multiple racks, and we handle the intra and inter-rack networking on your behalf. You just see this as a pool of capacity in the console where you can push your workloads, which makes it very simple and abstract for you.

For smaller deployments, we can do Outpost servers in both 2U and 1U form factors. These can extend a subset of AWS Cloud into smaller locations. We run both Intel-backed instances on these as well as Graviton in the 1U. I want to spend a few minutes talking about the Nitro system because in my section of the presentation we're talking a lot about the underlying infrastructure, and this is really a foundational element to how we build in the cloud.

### The Nitro System: Security Architecture and Cryptographic Innovation

The Nitro system has been available in all modern EC2 instances since 2018, and it underpins everything we're doing in our hybrid edge. Everything I've talked aboutâ€”from local zones, Dedicated Local Zones, and Outpostsâ€”is all built foundationally on top of Nitro. The Nitro system reimagines how we deliver cloud infrastructure and offers unprecedented benefits across security, performance, and innovation. At the bottom of the stack, we have the Nitro hardware layer, which offloads the virtualization functions that you would normally run on a software hypervisor into dedicated hardware. These are custom chips designed by AWS, and the system contains security chips that offer continuous verification of hardware integrity, as well as specific Nitro cards for networking, storage, and security functions.

Above this sits the Nitro Hypervisor software layer, which is a very lightweight virtualization layer that delivers near bare metal performance. Many customers will see discernible performance from running in bare metal with all of the benefits of virtualization, and the reason for this is because we offload core hypervisor functions to the Nitro hardware layer. Above that, we have the instance OS layer and application layer where you'll be deploying. The Nitro system is really a prime example of how we continue to innovate at the infrastructure level to deliver better outcomes for our customers. It's able to offer the highest security standards in the industry and performance that's discernible from running in bare metal.

The other thing it brings is that we can very quickly iterate on new instance families with Nitro. You will see this week there are going to be more and more instances launched, and they're all built on top of Nitro with the latest generation hardware from AWS as well as our partners. Looking at more detail within security,

[![Thumbnail 910](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/910.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=910)

encryption is really foundational  to the Nitro system. Every single communication channel within Nitro is encrypted, which means data flowing between the components is all protected from potential threats. Second, there's a secure boot process in Nitro that during the boot sequence will cryptographically validate all of the security keys of the entire system with the hardware. Third, we can continuously patch the Nitro security at runtime, so we don't disrupt any of your workloads while we're maintaining our EC2 fleet on Nitro, whether it be on-premises in your Outpost or another location. You don't get any downtime when we're maintaining our Nitro security layer.

The final point is we have no remote access to this. It's crucially important that this is the case, and it's an underlying design principle of how Nitro has been built. We cannot see inside your environment. There is no operator access from AWS or anyone else outside of your organization to your environment that runs in the cloud. Security really is our number one priority, and these four pillars of Nitro security demonstrate our commitment to providing the most secure cloud infrastructure for our customers.

[![Thumbnail 990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/990.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=990)

[![Thumbnail 1010](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1010.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1010)

Third parties have validated the Nitro system. The global cybersecurity consulting firm NCC has published an independent report on the security design of Nitro and have confirmed that there is no operator access to Nitro as a matter of design.   Let me show you the inside of what's happening on some of these. This is one of the EC2 servers that would be potentially running in an Outpost. One of the things that was really interesting about how we do operations in the field for these on-premises environments is we have a concept called the Nitro Security Key, or NSK. It's in the top right corner up there. I talked about everything in Nitro being encrypted in transit. We also encrypt at rest. The Nitro Security Key is the root of trust for anything that's at rest on the Outpost.

If you pull the security key, the Outpost is cryptographically shredded. You can't access anything that's on the Outpost. So in situations when customers are doing maintenance and upgrading or replacing components, we can hand the customer the security key. If they break that key, everything is sanitized on the Nitro server. We can take that away with us and leave you with the key. This is compliant with the NIST media sanitization standard 800-88. Historically, you would have to physically shred this hardware, but we can do it cryptographically, which is really neat operationally.

[![Thumbnail 1090](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1090.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1090)

[![Thumbnail 1120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1120.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1120)

I've been working on hybrid with AWS now for over five years, and what I've learned engaging with customers is they want that same experience. It's really important, and our goal, which we continue to offer, is to bring you the same reliable infrastructure, same performance, same operational consistency, APIs and tools, and ultimately let you leverage the same pace of innovation of the cloud, whether you're running in our regions all the way out to the edge.  

[![Thumbnail 1150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1150.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1150)

### Geidea Case Study: Payment Solutions and Sovereign Compliance in Saudi Arabia

Speaking of innovation, I want to touch on a customer story. This is a customer I've worked very closely with. I'm based in the UK and I'm covering the Emir region, and Geidea is based in Saudi Arabia. Unfortunately, they were not able to make it, so I'm going to present on their behalf as well as I can. I really hope that at the coming re:Invent we can get them on stage. They really are an incredible team and have been a great partner for us in the region. 

Geidea are offering payment solutions in the cloud, built on AWS. They have 75 percent market share of the POS business in Saudi Arabia, and they're also expanding into Egypt and the United Arab Emirates. They serve over 150,000 merchants and also provide more than 700,000 payment terminals. One of Geidea's missions is to basically empower businesses of any size with the tools to start, manage, and grow their business. That could be a startup restaurant that just wants a simple booking system or EPOS system. They're able to deliver this. One of the challenges we have in the region is the financial regulations are particularly strict.

[![Thumbnail 1230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1230.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1230)

[![Thumbnail 1240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1240.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1240)

In Saudi Arabia, for example, there's the Saudi Arabian Monetary Authority, or SAMA, which everyone just calls the Central Bank. They're strict about what data can leave Saudi Arabia, and Geidea had to innovate in order to launch ahead. We've announced a region there, but they wanted to move quickly. We've been supporting them with building a common stack across different  environments that they're building in. This is a mix of the UAE region as well as outposts in Saudi and in Egypt where they are able to build and deploy a common stack.  They're in a phased approach where right now they've moved some of the backend of the systems into the region, and then they're now starting to scale and move to more cloud-native architectures across that whole fleet. It's been a great partner for us in the region, and we're really thankful for the team. Hopefully you'll get to see them at an upcoming re:Invent.

I'm going to hand over to Mallory at this stage, but thanks for your attention. I'll be around at the end and look forward to meeting you all. It's great to see how Geidea is innovating with AWS Outposts. So far today we've learned how AWS is designed to help meet customers at the edge. Next we'll dive into practical ways you can use these tools and services to help meet your security objectives.

[![Thumbnail 1310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1310.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1310)

[![Thumbnail 1330](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1330.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1330)

[![Thumbnail 1350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1350.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1350)

### AWS Digital Sovereignty Pledge and Implementing Data Perimeters with Control Tower

So what are the security objectives? Let me briefly recap those. We hear how customers in regulated industries  need complete control over their networking and data encryption requirements. Ultimately they want to store data in a specific sovereign location. Oftentimes that's in a location without an AWS region nearby. At AWS we always work backwards from customers, and that's exactly what we've done with the AWS Digital Sovereignty Pledge.  This pledge represents our commitment to offering customers the most advanced set of different digital sovereign controls in the cloud. We fully believe you don't need to make the choice between having the full power of AWS or a sovereign limited  solution. With the pledge we're committed to innovating with new tools and services to help protect customers' data.

This is a four-part pledge, and it starts with giving you the ability to control the location of your data. At AWS you've always been able to do this. You have the choice of running your applications in a specific region, in a single availability zone, in metro areas with local zones, or on-premises with AWS Outposts. Second is giving you verifiable control over data access. We designed and delivered the first of its kind, the AWS Nitro system that Ben spoke about earlier as the foundation for our computing service. It's designed with specialized hardware and software to enforce data standards. As Ben mentioned, there's no administrator access, so this removes the ability for human error and tampering.

[![Thumbnail 1470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1470.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1470)

Third is giving you the ability to encrypt everything everywhere, whether you want to encrypt at rest, in transit, or in memory. We offer tools and services to do that. All AWS services already support encryption today. And finally, our commitment to the resilience of the cloud. Digital sovereignty simply cannot be met without having resilience. Customers need control over their networking, and that becomes table stakes during events like natural disasters and connection interruption. That's why all AWS regions are built with multiple availability zones that are fully isolated. Customers can partition their applications across multiple availability zones and across regions, and at the edge you can actually home your AWS Outpost to different availability zones in the same parent region, or you can home them to different regions altogether. 

[![Thumbnail 1500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1500.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1500)

Building to meet your security objectives often starts with understanding what is your data perimeter. Now it wouldn't be a re:Invent session unless I pulled the audience, so I'm curious, who knows what a data perimeter is? A data perimeter is a set of permission guardrails in your AWS environment to ensure that only your trusted identities access your trusted resources from your expected networks. 

Data perimeters serve as always-on boundaries to help protect your data across a broad set of AWS accounts and resources. They don't replace your existing fine-grained access controls. Rather, they work to ensure that all your IAM users, roles, and resources meet your defined security standards. They also work alongside the AWS Well-Architected Framework design principles to strengthen your overall security posture.

[![Thumbnail 1560](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1560.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1560)

You implement a data perimeter through a combination of three policies: your VPC endpoint policy, resource control policies (RCPs), and service control policies (SCPs), which I'll be speaking about today. Let's talk about a fully automated way that you can implement your data perimeter and your governance objectives at scale. That's AWS Control Tower, a fully managed AWS service  to govern and establish your multi-AWS account environment.

You can think of Control Tower like your command center to implement your security guardrails and governance at scale, whether that's in the cloud or on-premises in your own environment. Control Tower establishes secure landing zones that set up the identity governance and logging of all your accounts based on AWS best practices. It enables governance using pre-built controls that you select from a control catalog.

[![Thumbnail 1600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1600.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1600)

Let's explore what's inside that catalog. The control catalog is a centralized inventory  of over 1,000 AWS-authored controls based on common use cases across availability, cost, security, and other application operations. These controls are preset governance rules written in plain text that you can apply either enterprise-wide or to select accounts within your groups. Each control is also written in plain text and enforces a policy that is either preventative, detective, or proactive, and you can make these either mandatory or optional.

[![Thumbnail 1640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1640.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1640)

Let's dive deeper into that concept. Preventative controls block noncompliant actions before they  happen using IAM service and resource control policies. For example, say that you want to prevent CloudTrail logs from being turned off. When a user attempts to turn off CloudTrail logs, it's automatically blocked by the IAM SCP policy. This is a good choice when enabling logging is table stakes and a non-negotiable compliance requirement that you can't risk turning off for even a moment.

Detective controls identify actions after they have occurred that are noncompliant using AWS Config rules. This is a good choice when you need visibility into the compliance status, but you want to offer more flexibility in how that resource gets created. In this case, if you wanted to detect whether all your EC2 capacity reservations had tags on them, AWS Config rules would identify reservations without tags, flag them, and notify and alert you.

Finally, proactive controls validate compliance during resource deployment time using AWS CloudFormation hooks. This can help shift compliance left in your CI/CD pipelines, so this helps you identify issues before detective controls, but it's less restrictive than a preventative control. In this case, if you wanted to proactively require that tags are applied during EC2 capacity reservations, if you have a developer that's deploying a CloudFormation template, it would fail if it was missing a tag during deployment time.

[![Thumbnail 1750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1750.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1750)

Let's take a look at what that would look like on an Outposts rack. On the left-hand side you have your parent region that your Outposts rack is home to,  and your landing zone is deployed across both any assets you have in the region as well as your on-premises data center. If you have a client that attempts to turn off a service control policy, it is automatically blocked by Control Tower.

[![Thumbnail 1780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1780.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1780)

Let's take a look at what that control is doing. Here we see a governance that's been selected  from the control catalog. This preventative control ensures that CloudTrail logs cannot be altered. What's powerful and easy about Control Tower is how it's written in plain text. This means every user can understand exactly what's being enforced without having to read complicated syntax or know the underlying structure of the policy.

[![Thumbnail 1810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1810.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1810)

However, we always believe in the power of choice, so the policy is also available from the artifacts section of Control Tower. Let's take a look at that.  This is the Service Control Policy that has been applied to your organizational unit across your landing zone both on-premises and in the cloud. We have talked about how Control Tower is a fully managed approach to governance, and you get to select from an inventory of over 1,000 policies. However, many customers also want to implement their own custom rules.

[![Thumbnail 1840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1840.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1840)

[![Thumbnail 1860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1860.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1860)

Let's take a look at an example of a custom Service Control Policy for another specific governance objective.  Let's go back to that Outpost and say that it is located in country one and is home to an AWS parent region that is in a different physical location in a different country. You want to prevent copies from the Outpost back to the parent region. Here is a snippet  of the Service Control Policy to deny that regional copy. I have a QR code in the upper right-hand corner that links to the full blog post and full Service Control Policy on this.

[![Thumbnail 1900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1900.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1900)

We see in the first part of the statement that there is a variety of denies based on each service name. In the beginning, we see how images, volumes, and snapshots are denied from being copied back to the region. As the policy goes on, it repeats this pattern for every service name. Now let's zoom in on the S3 section.  Once we zoom in, we see that all S3 puts are denied. You might be thinking, well, I actually do not want to deny all my S3 puts since my local puts to S3 on Outposts are okay. I only want to deny the regional ones. How would I do that?

[![Thumbnail 1920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1920.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1920)

[![Thumbnail 1930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1930.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1930)

That is exactly why we designed S3 on Outposts to have a separate IAM namespace from regional S3.  Let's talk about the benefits of that. By having separate IAM namespaces, it creates a clear service boundary between what is your cloud-based S3 and what is your on-premises S3.  When you see S3 on Outposts, you instantly know this is my permissions for S3 on Outposts and vice versa. This gives you the benefit of writing modular policies that are least privileged, and you do not have to worry about managing a complex lower-level relationship like splitting out your bucket names.

[![Thumbnail 1960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1960.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1960)

[![Thumbnail 1980](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1980.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1980)

[![Thumbnail 1990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/1990.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=1990)

### Building at the Edge: Compute, Storage, and S3 Replication on Outposts

EC2 also has a similar design pattern to this with a separate action name for EC2 Outposts.  Now we have covered how you will establish your guardrails and create your data perimeter for your trusted identities. Next, we are going to shift gears and talk about how you will build and run those applications. Earlier, Ben talked about how customers want the same experience building at the edge.  Let's dive into how we are delivering on that promise. On Outposts, we have 14 services running locally across compute,  storage, and networking. Additionally, given that Outposts are home to an AWS parent region through an AWS service link, this adds flexibility so you can easily connect back to all AWS services in the parent region.

[![Thumbnail 2010](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2010.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2010)

[![Thumbnail 2030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2030.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2030)

Starting with compute, you can run your compute workloads locally  using the same EC2 instances you know and love back in region, whether you need general purpose instances, compute intensive, or memory intensive. They are available for you on your Outpost rack so that you can process data right where it lives. You also have Amazon EBS, which  gives you the volumes that you need for persistent storage for those EC2 instances. You can use GP2 volumes on all Outpost types, and you can use GP3 volumes on the second generation instance rack of Outposts that was launched earlier this year.

Just like in regions, you can attach and detach volumes to your instances, and you can even copy your AMI, your Amazon Machine Images, from the region to your Outposts so you can launch local instances using the same configurations that you have perfected back in region. This way, you can build your AMI once and deploy it where you need it. This ensures consistency across your deployment. These EBS volumes work as both boot and data volumes, and you can increase the volume size on the fly with no performance impact. You can also take snapshots locally and use local snapshots or AMIs backed by local snapshots to quickly provision new volumes.

This means you can create, manage, and restore snapshots entirely locally without leaving the Outpost. Security is built in by default, so all these volumes and snapshots are encrypted by default.

[![Thumbnail 2110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2110.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2110)

Let's talk about where we're storing these snapshots. Those are in S3 on Outposts, which brings local object storage to your on-premises environment. With S3 on Outposts using S3 APIs, we make it easy to store, retrieve, version, tag, and control access to the objects on your Outpost. 

[![Thumbnail 2130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2130.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2130)

When we designed S3 on Outposts, we focused on delivering key security and management features that we knew would be important to our digital sovereignty customers on premises. For controlling access to your data, that starts with a separate IAM namespace that we just spoke about. We also have encryption enabled by default, so every object on your Outpost is encrypted. You can choose from encryption types of SSE-S3 or SSE-KMS, which gives you flexibility based on your security requirements. 

All these objects on your Outpost are only accessible through VPC-based endpoints, so access is contained to your network perimeter. They're either accessible from your VPC or through your on-premises network endpoints, but nowhere else. Blocked public access is always enabled by default and cannot be changed. For audit and compliance, you have visibility into all S3 APIs using CloudTrail at both the object and bucket level, which we'll dive deeper into later. We're also integrated with CloudFormation, which I'll show in just a bit.

[![Thumbnail 2210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2210.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2210)

Let's talk about how we separate what's back in the parent region versus what stays locally to meet your data perimeter objectives.  Back in the parent region, we store all of your non-object data. That's creating and managing your buckets, your bucket metadata, and all of your policies, including your IAM policies, access point policies, and bucket policies. This also includes telemetry data like your CloudWatch metrics and your CloudTrail logs. Locally, we always keep the object data and object tag information. By default, an object will never leave an Outpost unless you explicitly move it. Optionally, you can choose to copy it locally, copy it back to the region, or move it to another Outpost yourself.

[![Thumbnail 2260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2260.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2260)

Let's talk about how we differentiate between how you route requests back to the parent region and how requests stay locally.  We see a view here where there's a client on an instance on an Outpost subnet in your VPC in your on-premises environment. When you want to create a new bucket in turquoise, that create bucket request is automatically routed back to the S3 Outposts control plane in the parent region to create your bucket and store your bucket metadata. Now let's take that same client. Whenever they do a put operation, a put, get, or any other object operation, that always stays local in orange and is automatically routed locally using the access point ARN or alias. This endpoint routing is done automatically for you by the AWS SDK and CLI, so there's no need to manage or even be aware of this endpoint routing. This is also used across all S3 bucket types, whether that's a general purpose bucket type, a directory bucket type, and so on. The endpoint routing is done for you, so it's automatically routing it in this case to the access point Outpost ID endpoint.

[![Thumbnail 2340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2340.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2340)

[![Thumbnail 2350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2350.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2350)

[![Thumbnail 2360](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2360.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2360)

This is a single Outpost view, and we know that resilience and high availability are top of mind for digital sovereignty customers, which is why we support S3 replication on Outposts. This brings our fully managed S3 replication in-region to your on-premises environment to help you meet your data redundancy and resiliency requirements in your sovereign location.   When you set up replication, objects are automatically replicated to another Outpost or to a different bucket on the same Outpost.  Most importantly, all replication traffic stays local through the customer-owned local gateway, or LGW, without traveling back to the region. This gives you flexible disaster recovery within your defined data perimeter.

[![Thumbnail 2380](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2380.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2380)

We designed local replication to have a similar and flexible experience as regional replication, so you control what's replicated. You can replicate all the items in your bucket, or you can filter based on prefix, tag, or a combination of both. You can also replicate your objects to one destination bucket, multiple destination buckets, and you can do this on the same Outpost, different Outposts from the same account, or from cross-account. 

[![Thumbnail 2420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2420.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2420)

[![Thumbnail 2450](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2450.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2450)

We've also built comprehensive monitoring. You can track the replication progress with AWS CloudWatch metrics, and you can triage failures in Amazon EventBridge. Let me dive into both of those.  In CloudWatch, we publish the same metrics as regional replication, including the amount of replication bytes pending, total operations pending, and replication latency. We publish these alongside other storage capacity metrics so that Outpost owners can understand which accounts and buckets are consuming storage. We recommend setting up AWS CloudTrail alerts and alarms on these metrics so you can take action. 

[![Thumbnail 2470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2470.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2470)

You can also set up Amazon EventBridge to receive failure events to quickly diagnose and correct any replication issues you might have. By default, when you enable metrics from your replication configuration, they go to your default Amazon EventBridge bus, which is a serverless event bus system. However,  you can create a new event rule to automatically filter out just the S3 on Outposts events. Rules in EventBridge enable you to automatically send events to a target destination, and Amazon EventBridge supports over 25 different services where you can send these events for built-in awareness and corrective action.

[![Thumbnail 2510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2510.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2510)

[![Thumbnail 2520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2520.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2520)

Some of the most popular services that customers choose to take action on are Amazon SNS, SQS, Lambda, Glue, and more. Each rule that you create in Amazon EventBridge also comes with built-in monitoring. This way you can automatically see how many times your replication rule has been triggered and whether it has failed.  

[![Thumbnail 2570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2570.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2570)

Each failure in a replication configuration also comes with a failure reason for you to understand what went wrong in your replication configuration. For example, one of the most common failure scenarios we see is where the destination bucket is unversioned. Both the source and destination bucket must have versioning turned on. However, one failure reason that you won't see listed here is service link connection down. 

[![Thumbnail 2610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2610.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2610)

### Operational Excellence: Monitoring, Analytics, and Unified Management Console Experience

During an intermittent network connection issue in your on-premises environment, replication will not fail. Objects that are eligible for replication will queue up with a status of pending, and once your service link connection to the parent region resumes, replication will resume as well. This provides you with built-in networking resiliency. Services on Outposts are also integrated with CloudTrail to enable governance and operational auditing of all your AWS accounts. Any action taken by a user, role, or an AWS service is recorded as events in CloudTrail. 

[![Thumbnail 2640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2640.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2640)

For example, in this CloudTrail entry, you see a put operation for an S3 on Outposts bucket. A trail contains all the logged context for you, so you get to see the identity of the caller, the time of the call, the source IP address, the request parameters, and the response elements returned by the service. Additionally, as we saw a few minutes ago with replication, services on Outposts emit metrics to CloudWatch so you can observe and optimize your workloads. We see a consistent operational experience by emitting the same CloudWatch metrics for services whether they're at the edge or in the cloud. 

[![Thumbnail 2670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2670.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2670)

Given that Outposts are provisioned, this can help you manage your capacity. EC2 emits metrics so that you can see for every instance type that you have what's available, what its utilization rate is, any capacity reservations you have, as well as the connected status of your Outpost device. We talked earlier about service link, so you can track and monitor when your service link connection goes down and automatically notify your networking team through a CloudWatch alarm. Similarly, EBS emits metrics by volume type and the available capacity and utilization. 

[![Thumbnail 2680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2680.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2680)

[![Thumbnail 2690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2690.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2690)

Additionally, S3 on Outposts provides visibility into both the bucket and the account to see who is consuming your capacity.  Now that we've covered your compute, block, and object storage needs, what about your analytical use cases on premises? That's why we support Amazon EMR on Outposts so you can run big data analytics locally with EMR on Outposts. EMR is a managed cluster platform that simplifies running big data frameworks like Apache Hadoop and Apache Spark. 

[![Thumbnail 2720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2720.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2720)

You can use this for analytics use cases, business intelligence, machine learning, and much more.  You can run EMR on EKS as well as on EC2 on Outposts. Let's take a look at how we would deploy a cluster and have that reach our local S3 on Outposts. When you deploy EMR on your EC2 instances on your Outpost rack, that means you're running your entire processing pipeline, both your compute and storage, in your particular sovereign location on premises.

EMR clusters run in a VPC subnet on your Outpost and they access S3 on Outposts using a VPC access point through the S3A connector, just like they do in region. It's the same setup. Similar to CloudTrail and CloudWatch, your EMR logs are located back in the parent region. With EMR you can run Apache Spark for your ETL pipelines, interactive analytics, and more. You can choose from other frameworks like Apache Hive as well as Apache Flink.

[![Thumbnail 2790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2790.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2790)

[![Thumbnail 2800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2800.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2800)

Also, Mountpoint for Amazon S3 is integrated with Outposts buckets.  Mountpoint is an open-source file client that you can mount an S3 bucket on your compute instance and access it like a local file system.  It automatically translates local file system API calls into REST API calls on your S3 objects. Mountpoint is optimized for high throughput performance and is based on the Amazon Common Runtime Library, or CRT, for performance best practices.

[![Thumbnail 2840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2840.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2840)

[![Thumbnail 2850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2850.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2850)

Although Mountpoint is open source, you can use it with confidence for your production workloads because it comes with AWS support and is fully maintained by AWS. Let's take a look at how you would mount a bucket, whether you're mounting an Outposts bucket or a directory or general purpose bucket. It's the same way. You provide the access point alias or ARN, which can always be used in place of bucket name.  No other action is required. You can start accessing your bucket with Mountpoint. 

[![Thumbnail 2880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2880.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2880)

[![Thumbnail 2890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2890.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2890)

Services on Outposts are also integrated with AWS CloudFormation, which is our infrastructure as code service that enables you to model, provision, and manage resources across your entire environment. With CloudFormation, you define your infrastructure in templates in either JSON or YAML, and we handle the provisioning automatically. This eliminates manual configuration and ensures consistency across your environments.  As we spoke about earlier, you were creating an Outposts bucket. You can do that in CloudFormation as well as a capacity reservation on EC2. 

[![Thumbnail 2920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2920.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2920)

Finally, everything we reviewed today is available for you in the AWS Management Console, which delivers a consistent operational experience whether you're managing your assets in the cloud or on premises. When you open services like EC2 or EBS in the console, you see all of them in one location in a unified view. The key differentiator is the Outposts ARN column. This simple but powerful element lets you easily understand  where the asset is physically located, whether in the cloud or on premises. So whether you're provisioning an EC2 instance in US-C1 or thousands of miles away, it's going to show up in the same place.

[![Thumbnail 2940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2940.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2940)

[![Thumbnail 2950](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2950.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2950)

[![Thumbnail 2960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/20e59acffa837166/2960.jpg)](https://www.youtube.com/watch?v=CxkRvW42Hgc&t=2960)

You see this design pattern repeated for your EBS volumes with the same Outposts ARN column.  Additionally, when you look at different S3 bucket types, you see them all on the left-hand side of the navigation.  That has been our session today. I want to thank you for joining us to explore how AWS is committed to meeting your sovereignty goals on premises, and we are excited to see what you'll build with these capabilities. Thank you for your time today. 


----

; This article is entirely auto-generated using Amazon Bedrock.
