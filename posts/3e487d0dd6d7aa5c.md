---
title: 'AWS re:Invent 2025 - Unpredictable by Design: Finding Innovation with Generative AI (AIM223)'
published: true
description: 'In this video, the speaker argues that most businesses are misusing Gen AI by focusing on the first two levelsâ€”summarizing data and repacking insightsâ€”while neglecting the third level of finding new insights and collaborations. Drawing parallels to electricity''s evolution beyond light bulbs, she emphasizes that 95% of organizations are stuck in pilot purgatory because they''re built for linear thinking, while Gen AI requires nonlinear, unpredictable thinking. She challenges audiences to restructure organizations, unlearn assumptions, embrace productive unpredictability, and rethink metrics like "speed" without knowing baselines. The speaker advocates for spotting talent at the edges, creating functional sandboxes, viewing competitors as partners, and embedding breakthroughs through constant feedback loops rather than traditional development cycles.'
tags: ''
cover_image: https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/3e487d0dd6d7aa5c/0.jpg
series: ''
canonical_url:
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Unpredictable by Design: Finding Innovation with Generative AI (AIM223)**

> In this video, the speaker argues that most businesses are misusing Gen AI by focusing on the first two levelsâ€”summarizing data and repacking insightsâ€”while neglecting the third level of finding new insights and collaborations. Drawing parallels to electricity's evolution beyond light bulbs, she emphasizes that 95% of organizations are stuck in pilot purgatory because they're built for linear thinking, while Gen AI requires nonlinear, unpredictable thinking. She challenges audiences to restructure organizations, unlearn assumptions, embrace productive unpredictability, and rethink metrics like "speed" without knowing baselines. The speaker advocates for spotting talent at the edges, creating functional sandboxes, viewing competitors as partners, and embedding breakthroughs through constant feedback loops rather than traditional development cycles.

{% youtube https://www.youtube.com/watch?v=qVf2LqI5B2s %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/3e487d0dd6d7aa5c/0.jpg)](https://www.youtube.com/watch?v=qVf2LqI5B2s&t=0)

[![Thumbnail 20](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/3e487d0dd6d7aa5c/20.jpg)](https://www.youtube.com/watch?v=qVf2LqI5B2s&t=20)

### The Electricity Analogy: Moving Beyond the Light Bulb Moment in Gen AI

 Thank you all for coming today. I appreciate hearing from so many of you, and I'll do my best to stay focused. I want to start by getting your attention with this idea: many businesses are using Gen AI wrong.  I know this might not be the right conference to say that at, but I do believe it, and industry insights would support this. Let me think about something from the past that actually tells us this is true. When electricity arrived, how did we establish its history? The original intent of electricity was literally to make the room brighter. But was that actually the best innovation that came from electricity? We moved from candles to light bulbs, from light bulbs to generating power plants, from power plants to creating new cities, and from cities to creating new opportunities for us around the globe. When you think about what started as a candle to a light bulb, that was an amazing innovation. I'm not trying to diminish the light bulbâ€”it was an amazing innovation. However, the real transformation came when we actually started to exploit what electricity could do.

I would say that today in the Gen AI world, we're facing a similar moment. It's not about improving the old, which is what a lot of people are focused on, but about identifying the new. As we think about that today, we're going to talk about what you've done with Gen AI and more importantly, who's going to imagine what we have yet to do. For me, that is the most important thing we can take away from this: thinking about what we accomplish. So where do we start? As we think about Gen AI, one of the things I wanted to discuss are the three different levels of Gen AI, which many of you have probably heard about. The three levels are summarizing existing data sets, repacking data into insights, and finding new insights and collaborations. We know that most organizations todayâ€”actually 75 percent or moreâ€”are focused on the first two. If we use that example of the candle to the light bulb, you'd realize that perhaps the true value is in number three. Numbers one and two are table stakes. I'm not diminishing their importance, but they are table stakes.

Let me unpack this for a moment. How many of you have your greatest ideas baked into a strategy? Your greatest ideas, your most impulsive ideasâ€”do they align to your strategy? Or do they come when you're in the shower or taking a jog or not tethered to your desk? Most of your best ideas actually come from the edges, when you're not thinking about strategy, when you're allowing people to think outside of what they're most known to think about. We tend to run our businesses based on a very regimented strategy. What I will tell you is that this is actually eclipsing numbers one and two. It's not allowing number three to happen at its fullest extent. So we're going to uncover a couple of examples where we might be able to help your organizations look at number three.

### Why Organizations Are Stuck in Pilot Purgatory: The Linear Thinking Problem

When we think about the status quo, it's built on linear thinking. If I were to ask how many of you are non-traditional, nonlinear thinkers, a lot of people raise their hands, particularly in the tech field. However, most organizations are not built for nonlinear thinkers. Almost no organizationsâ€”I won't say all, but most are not built for nonlinear thinking. When you think about the hard work, how many of you are stuck in pilot purgatory, as everybody likes to call it? Latest statistics would say 95 percent of organizations are stuck in pilot purgatory. I would argue that part of the reason for that is that we haven't done the hard work of actually changing the infrastructure to enable people to think nonlinearly.

Gen AI is built on nonlinear thinking. Everybody's been talking about how we did this with cloud or we did it with cyber. We've done it previously. Those are actually all technologies that are built on linear thinking. They're zeros and ones. They're actually predicting an if-then statement. AI, as we all know, is not. It's an unpredictable learning mechanism. So how is it and why are we surprised that 95 percent of our pilots are stuck in purgatory? They're working on an infrastructure and an organization that's built for linear thinking. So how do we actually disrupt that a bit to enable us to think about the edges and actually do some of the harder work, which again I would argue would be restructuring your organization, restructuring your infrastructure, and unlearning the things that you think you know?

[![Thumbnail 110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/3e487d0dd6d7aa5c/110.jpg)](https://www.youtube.com/watch?v=qVf2LqI5B2s&t=110)

[![Thumbnail 290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/3e487d0dd6d7aa5c/290.jpg)](https://www.youtube.com/watch?v=qVf2LqI5B2s&t=290)

As we think about that, what is this productive unpredictability?  I've talked to countless amounts of executives, architects, and humans who are interested in Gen AI.  The value of AI is that it actually democratizes innovation. It allows people who don't necessarily need to be coders or thinkers or people educated in AI technology to be able to actually explore.

But when you think about organizations, those organizations aren't necessarily built to envelop that thought. If I were to ask any of you how many of you appreciate diverse thinking, I hope all of you raise your hand and say we appreciate diverse thinking. But the organizations aren't built that way. Performance expectations aren't built that way. Infrastructures aren't built to learn. People aren't built to advance because they think you should have a certain title or a certain role or a certain goal.

All those things put parameters on unpredictable thinking. If we go back to the notion that AI is built on unpredictability and it will truly thrive in unpredictable ways, if the organization and the infrastructure isn't built to support that, we're limiting our thinking. We're limiting our opportunity and we're actually doing things based on what we think we know versus allowing our egosâ€”and I mean that because everybody has an ego, it's a good thing to have egosâ€”to put that aside and unlearn what you think you know.

[![Thumbnail 390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/3e487d0dd6d7aa5c/390.jpg)](https://www.youtube.com/watch?v=qVf2LqI5B2s&t=390)

When we think about how to go about doing that, I get asked a lot: "I believe in all that, Deb. I believe in nonlinear thinking. I believe in changing our infrastructure, but we don't know what to do." I constantly get told by people that they're stuck in cement. So I look at how do we harness the unpredictable thinking. I'll talk through a couple of different assumptions  that I would say we need to unlearn.

### Unlearning Assumptions: From Hackathons to Metrics

Thinking about how to spot the edges, we all say we want to spot new talent. Look at examples like boards. Most boards are set up by people that are sitting in executive management, not actually new people who could bring new thinking and new processes to enable that new thinking. It's not to say that boards are bad things. It's to say how do we rethink structure to be able to not just spot the edges, but to translate them into sparks.

I often have this conversation with people who say we need to do an ideathon or a hackathon. The number one problem with hackathons and ideathons is they almost never get implemented and they almost never actually scale. If you were an employee who came up with an amazing idea in a hackathon, how do you think it feels for that person to never have anything come to fruition with their idea? When we think about whether the system in that instance of the hackathon or ideathon matches the outcome, we actually want to change our organization and bring ideas to fruition.

What usually happens is you tell the person with a brilliant idea that their idea is brilliant, but we can't do anything with it. That probably defeats the purpose. Instead, how do we actually look at bending that and using AI to help enable those humans who have these amazing ideas to bring them into fruition? What we're seeing a lot on the Gen AI front right now is table stakes for operational efficiency. Most of that operational efficiency is to automate existing processes.

Why are we not stopping to say do we need the process at all? Why do we not stop and say is there a better way to connect these dots so that perhaps instead of just automating the broken process, we actually are looking at completely restructuring the way we think and the way that we operate to not just get operational efficiency, but to actually create new processes that will actually be able to spot people at the edges? That's harder work but bigger return on the outside.

The other one is how do we translate the sparks? How many of you got your greatest insight from a pilot or a prototype? If you did, how did you actually put that into action? The statistics are high. Seven out of ten pilots and prototypes that are found are often not actually put into execution. Based on other research, the numbers are actually even higher. Why is that? Is it because a person didn't like the idea? Is it because the system in the organization wasn't allowing it to happen?

But we do it over and over again because we want predictability. The question I'll also ask: how many of you need a playbook? Playbooks are things of the past. AI can't work on a playbook. It's not built to build on a playbook. Back to the unpredictable learning, but as organizations we're used to having playbooks. How do we run it? How do we scale it? How do we thrive with it? Is there a playbook for that? Is there a rule set for that?

How instead do we actually start to question how do we have creative thinking? Perhaps we don't need a playbook, but that doesn't mean we have chaos. Chaos actually turns to a very different trajectory if not actually managed in some way. The last one is how do we embed the breakthroughs. The best thing I love to talk about is metrics. If we were to talk about metrics, how many of you have been told that your best metric for AI implementation is speed?

My follow-up question would be: how many of you know your actual baseline for what you're measuring speed against? Almost nobody does. When you sit there and think about that, if you're told you need to get AI implementation into your environment faster, faster, faster, faster.

But fast was never a metric unless you actually know what you're measuring. So how do we rethink metrics? How do we rethink performance? If we do need it fast, what is fast? Is fast in seconds? Is fast in months? Is fast the same for my company as it is for your company? What does fast mean? Because we're running towards this notion of fast without actually understanding how to embed breakthroughs into our organization.

### Embracing Productive Unpredictability: Practical Steps for AI Implementation

I often get the question: "Okay, Deb, these all sound great and logical, but we can't do that in our organization." Why? It's typically because we want the status quo and we don't like to have friction. AI will inevitably create friction. It's positive friction, and I would say embrace that chaos because positive friction actually can create change. We're afraid of what we don't know.

I sat on a board last week at a Fortune 50 company, and the organization said, "Deb, we don't even understand how to utilize Gen AI." We spent 15 minutes utilizing AI to create a candy company. They're not in the candy business, by the way, but we did demographic research, created a presentation, had a jingle and a logo. We did all kinds of things in 15 minutes simply so that people could start to understand the value of what they could see.

I also did the opposite though. It's not just letting AI run for the sake of AI. How do we actually make them understand things around hallucinations and how do you actually think in an unpredictable scenario? We created this candy company that all of a sudden I had taking over the world in about 7.5 minutes to help show the point of hallucinations. How do you start to think about what AI is learning when you're not paying attention to it? How do you start looking at AI and asking it different questions so that if you have a space or a typo, you get a different answer?

These are things that people aren't paying attention to because they think it's great that they can type and misspell and still get an answer. So I went to another screen and said, "Well, what if you type it correctly? Do you realize you get two very different answers?" Do you also understand that you have hallucinations? If I happen to word my question and ask what kind of pet should I get tomorrow, and I infer that I like a cat, I'll get a cat as an answer. If I infer I like a dog, I get a dog as an answer.

I'll ask by show of hands: how many of you thank your AI? Most people don't. If you thank it, you get better answers. So there are lots of ways here that yes, AI is going to allow us to democratize innovation and put new technology into our organizations, but you have to understand how to manipulate this unpredictable learning.

I did this whole candy store in 7 minutes, and then we did it again with all misspellings. I just misspelled the whole thing and we got a totally different candy company. I said, "These are the things you need to understand, not because you should be afraid of using AI or allowing people to play around with it or do different things with it, but understand what it really means to have a human in the loop."

[![Thumbnail 790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/3e487d0dd6d7aa5c/790.jpg)](https://www.youtube.com/watch?v=qVf2LqI5B2s&t=790)

[![Thumbnail 810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/3e487d0dd6d7aa5c/810.jpg)](https://www.youtube.com/watch?v=qVf2LqI5B2s&t=810)

Historically, when we think about human in the loop, we think about it as checks and balances.  You had 5 things, I need to have 5 things. Human in the loop in an AI world is not just checks and balances. It's you looking at that scenario and saying, "Did someone write the AI code and all of a sudden I ended up with a dog when I wanted to have a cat?" Understanding what that difference is is super important as we think about how to put these into practice. 

So I'll spend a little bit of time talking about how you can actually go about doing it realistically. As we forge this path, and I know we're talking a little bit about Gen AI, but it would be applicable for a broader AI and agentic AI, the number one thing that we tend to get is, "Well, it's going to replace people." It will change our talent trajectory as a co-pilot. I don't actually ever talk about it in the factor of humanity being gone tomorrow. It is actually a co-pilot for us as we think about innovation.

How do we spot the things that others overlook? I'm often an outlier. I love it. I wear that with a badge of honor to be an outlier, but we want other outliers. We want to be able to spot that there are people who are hungry to bring new ideas into your organization. It's not always easy as we think about traversing an organization. There's performance metrics, there's titles, there's roles, there's things that fit into neat little boxes.

There's homework that needs to be done to restructure organizations while we're working on operational efficiencies and we're working on all the table stakes. The competitive advantage is going to be to create new businesses. The business that you see today probably isn't going to exist in that same way in 3 to 5 years. Studies would say 10 years, but at some point in time in the future, most people will say, "Well, Deb, that's not my problem, it's the next leader's problem." It's everybody's opportunity. Flip the script. Unlearn what you think you know to be able to get there.

To that point, how do you translate discoveries into new ways of working? I'm a huge believer in sandboxes, but I'm a huge believer in sandboxes that actually represent your organization.

Most sandboxesâ€”I think it's 8 out of 10â€”don't replicate your current environment by people, process, technology, infrastructure, ecosystem, and third parties. Part of what's going to be advantageous as we think about an AI-forward world is going to be an ecosystem. What better place to talk about that on this floor when all you see is ecosystems? But I mean looking at your competitors as your partners, not as competitors. What you think is competitive advantage is probably not going to be competitive advantage in a year, and I don't say it to make us all worried or concerned or dystopian. It is to look at the opportunity. How do you unlearn what competitors mean in this world of AI?

And then lastly, embed what works. We're very afraid to put Generative AI directly into an environment and actually test it, learn from it, and make decisions in 30 days, 45 days, 90 days. It's not the traditional 6 months. How many of you walk through an airport, a bathroom, a doctor's office and see the happy button? Those buttons ask, are you happy today? I don't know. I just walked out of the bathroom of an airport. I don't know if I'm supposed to be happy.

But the way this works is because in today's age, the constant feedback loop means your consumer and your customer want constant feedback. They want to be involved in the process. They want to understand what your product is going to look like tomorrow. The question for you as leaders and as organizations is: are you going to change your product development life cycle? Are you going to actually take all that feedback? What happens if you lose your customer? Can I utilize AI to change what this experience is? Consumers want more impact. They want more input. I started hitting the unhappy button a lot. Will I get an email? Will I have input into what this new bathroom is going to look like? Candidly, no, nothing actually happens.

I've talked to some of those companies as well. I ask them, what are you expecting? What's your metric? And candidly their metric is just a happy place. I say, well, what's happy for me might not be happy for you. So again, what's the metric of measurement? And then as we think about what the future holds and we think about automating predictability, I am the biggest believer in opportunity here. My mother died when I was young, and no child should ever have to suffer anything of that nature. If we can use technology to solve for problems that we've never imagined solvable, we're in that moment right now to be able to solve for tomorrow.

So all these are to say that diving in and making that work, the winners, quote unquote, won't be those that automate the unpredictability out. It's going to be those that can actually embrace what predictability thinks about and unpredictability by design. How do you build that unpredictability into your people, into your process, into what an organizational structure even looks like? I was working with somebody a couple of weeks ago. What if we got rid of an organizational structure? Three people in that conversation's mind exploded. They said, we can't get rid of an organizational structure. What would happen? I said, I don't know what would happen. Perhaps we can scenario what that would look like. Perhaps we could use AI to help us figure out what that would look like. But are we willing to break what we think we know in order to see the biggest amount of competitive advantage?

[![Thumbnail 1110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/3e487d0dd6d7aa5c/1110.jpg)](https://www.youtube.com/watch?v=qVf2LqI5B2s&t=1110)

I'd encourage all of you to think about all the amazing ideas you've had, likely in the shower or on a run or doing something where your brain is free to think about it. And think about how you can employ AI while still doing it in a trustworthy, secure,  and safe fashion, and at the same time showing that value and showing that growth to others around you. That will be your competitive advantage. With that, I like to talk about speed and delight to be able to get that done in 20 minutes. I think I've got 60 seconds, but that being said, that is my discussion today. If you have any questions at all, please feel free to find me or find me on LinkedIn. Otherwise, I greatly appreciate all of your time today, and that's it. So thank you.


----

; This article is entirely auto-generated using Amazon Bedrock.
