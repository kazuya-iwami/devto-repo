---
title: 'AWS re:Invent 2025 - Make Attackers Cry: Outsmart Them With Deception (SEC326)'
published: true
description: 'In this video, Fastly presents their deception technology for cybersecurity, using behavioral science concepts of "nudge" and "sludge" to influence attacker decision-making. The speakers explain how their NextGen WAF incorporates inline deception for account takeover attacks by scrambling valid credentials and returning false negatives, creating psychological costs like frustration and confusion without alerting attackers they''ve been detected. Unlike traditional honeypots requiring separate infrastructure, this approach integrates directly into the WAF workflow with configurable triggers based on signals like bad bots, IP addresses, or paths, making it easier to deploy and maintain as part of a defense-in-depth strategy.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f4257b6649d1819c/0.jpg'
series: ''
canonical_url: null
id: 3086348
date: '2025-12-05T11:49:23Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project enhances multilingual accessibility and discoverability while preserving the original content. Detailed transcriptions and keyframes capture the nuances and technical insights that convey the full value of each session.

**Note**: A comprehensive list of re:Invent 2025 transcribed articles is available in this [Spreadsheet](https://docs.google.com/spreadsheets/d/13fihyGeDoSuheATs_lSmcluvnX3tnffdsh16NX0M2iA/edit?usp=sharing)!

# Overview


ðŸ“– **AWS re:Invent 2025 - Make Attackers Cry: Outsmart Them With Deception (SEC326)**

> In this video, Fastly presents their deception technology for cybersecurity, using behavioral science concepts of "nudge" and "sludge" to influence attacker decision-making. The speakers explain how their NextGen WAF incorporates inline deception for account takeover attacks by scrambling valid credentials and returning false negatives, creating psychological costs like frustration and confusion without alerting attackers they've been detected. Unlike traditional honeypots requiring separate infrastructure, this approach integrates directly into the WAF workflow with configurable triggers based on signals like bad bots, IP addresses, or paths, making it easier to deploy and maintain as part of a defense-in-depth strategy.

{% youtube https://www.youtube.com/watch?v=jml0p7sgp5g %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f4257b6649d1819c/0.jpg)](https://www.youtube.com/watch?v=jml0p7sgp5g&t=0)

### Leveling the Playing Field: Using Behavioral Science and Sludge to Frustrate Attackers

 How are you doing? Do we have any golfers here? Anybody who plays golf or likes golf? Good. I have a great golf story for you. This goes back to 1958 in Fort Worth, Texas, where the Blind Golfers Association held their championship award ceremony for the best blind golfer. There was a guy named Charlie Boswell who was the national champion blind golfer. Because of that achievement, he got the opportunity to play a round of golf with Ben Hogan, who was the premier golfer of that eraâ€”at the level of Arnold Palmer, Jack Nicklaus, and Tiger Woods.

Charlie was very thrilled to meet his idol. However, Charlie had lost his sight during World War II. He was a really good athlete who played football and baseball. During World War II, he tried to save one of his comrades in a burning tank, and when a shell exploded, he lost his sight. He didn't know what to do when he came back, so he took up golf, which he had never played before. Now he gets to meet the best golfer of that era and play with him.

Ben Hogan was in awe of Charlie because he could play golf while blind. Charlie said, "How about if we play for money?" Ben responded, "Wait, I'm the best golfer in the world. I can't play for money with you. That's unfair because you're blind." Charlie was undeterred and said, "$1000 a hole." Ben replied, "I can't play golf. No, that would be unfair." Charlie then asked, "Are you chicken?" Ben is very competitive, so he said, "No, I'm not chicken. Okay, you want me to play, I'll play. I'm not going to hold back. I'm going to play hard." Charlie responded, "That's what I would expect from you." Ben then asked, "Okay, what time?" Charlie said, "Tonight at 10."

This is an example of how the playing field can be evened out. Now, if you switch to another sport like football, who has the advantageâ€”the offense or the defense? The offense obviously has an advantage. The quarterback gets to call the play in the huddle, comes to the line, sees what the defense is set, and figures out what to do. The defense has to guess. It's first down, maybe they're going to run. It's third down, maybe they're going to pass, but maybe they're going to fake them out. Are they going to pass? Are they going to hand off? Are they going to fake the handoff and pass or run around? There are so many things that could be done.

[![Thumbnail 210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f4257b6649d1819c/210.jpg)](https://www.youtube.com/watch?v=jml0p7sgp5g&t=210)

[![Thumbnail 220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f4257b6649d1819c/220.jpg)](https://www.youtube.com/watch?v=jml0p7sgp5g&t=220)

So we want to ask: how can we even out the field? How can we get into the minds of the attackers and make that playing field level, just like Charlie was able to level it out with the world's greatest golfer?  I'm going to pass it over to Memo here, and he's going to talk about what our new deception technology does. Thank you, Rick.  Now let's focus our attention on the attackers, just like Rick was mentioning. When we are defending our systems, sometimes we focus our attention on designing defense strategies, and we focus on the attacks, but not on the attackers. By doing this, we can overlook something super important: the humans. The attackers are just humans like everyone in this room. Humans with a brain that works the same way as ours. Understanding this is key to implementing defense strategies that are much more efficient.

[![Thumbnail 280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f4257b6649d1819c/280.jpg)](https://www.youtube.com/watch?v=jml0p7sgp5g&t=280)

We want to influence the decision-making of the attackers to protect our systems. But how can we influence the decision-making processes of our attackers?  To answer this, let me introduce two concepts from behavioral science: nudge and slouch. Both are ways of describing how to influence decision-making, but in opposite ways. On this side, we have nudge, which is influencing in a positive wayâ€”making it easier and more simple. For example, here we have a password strength meter to help users create a strong password.

This is a very simple example. On the bottom part, we have a reminder of an application to do your daily exercise. This is an example of nudge. On the other hand, we have sludge, which is to make the process more complicated, add steps, add complexity, and add friction. This is an example of sludge.

In the center, we have a captcha. A captcha has good intentionsâ€”it's to block bad actorsâ€”but sometimes captchas add friction and complexity. Legitimate users sometimes see this as additional steps and end up just giving up and going elsewhere. This is an example of sludge. We can think of many examples. I'm sure everyone here has experienced subscription services on the internet. It's always super easy to subscribeâ€”just one click away. What happens when you want to cancel? There are several steps. Sometimes you get an offer for one free month. Don't cancel, just extend three months more. This is a very common example of sludge and nudge.

[![Thumbnail 390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f4257b6649d1819c/390.jpg)](https://www.youtube.com/watch?v=jml0p7sgp5g&t=390)

In the case of attackers, we want to use sludge for good. We want to add friction. We can impose friction to attackers for our benefit to create better defense strategies. We can influence their behavior and decision-making with sludge.  What is the cost to attackers if we add friction? There are different costs: quantitative costs and qualitative costs. First, we have the obvious. If we add friction into the process and make it more difficult for attackers, we have everything that costs money and effort. We have quantitative costs and all the foregone opportunities.

[![Thumbnail 410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f4257b6649d1819c/410.jpg)](https://www.youtube.com/watch?v=jml0p7sgp5g&t=410)

But there's also qualitative cost. We have reputation. If we make attackers fail, they will lose credibility. It will be harder to recruit. It will be more difficult to get new clients. We also have informational costs, which refers to the effort that attackers put into getting more information about the next targets. If we add invaluable information, we create more cost to them.  Finally, and this is the reason for the title of this presentation, there is the psychological cost. If we add frustration, shame, and confusion to attackers by making the process more difficult and adding friction, we add this cost.

[![Thumbnail 500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f4257b6649d1819c/500.jpg)](https://www.youtube.com/watch?v=jml0p7sgp5g&t=500)

Now let's see how Fastly is using sludge for good, and this is with deception. Deception has been used over the course of history in many contexts, especially in warfare. That's why we have the Trojan horse, which the Greeks used against the Trojans to win the war.  In cybersecurity, we all know about the concept of honeypot, which is a way to deceive attackers to get more information about their tactics. In nature, we also have many examples like animals changing their appearance to hunt their prey or protect against predators. Deception is not playing dirty. Deception is about leveraging what we know about our enemy's tactics for our benefit. This is deception.

[![Thumbnail 550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f4257b6649d1819c/550.jpg)](https://www.youtube.com/watch?v=jml0p7sgp5g&t=550)

### Fastly's Deception Technology: In-Line WAF Integration for Account Takeover Defense

Now Rick is going to explain to you how Fastly is introducing deception into our cybersecurity products.  This is the brainchild of our Product VP who has a deep security background and a background in behavioral economics. We want to get into the head of these attackers. We want to make them frustrated so they'll go away or they won't bother this particular site anymore. This is just the start of what we're doing. Right now, the way we're going to do it is we're looking at account takeovers. This is our WAF product, NextGen WAF from Fastly, where you can set the parameters on when you want to trigger the deception to happen.

Basically, what it's going to do is once we hit that deception trigger, the deception will be activated.

You can trigger deception through various signals, such as identifying a bad bot or suspected bad bot, or by detecting certain paths, IP addresses, or countries. All of this is open and configurable, so you can decide the trigger point for when you want to start deceiving. Once deception begins, an attacker who has paid for credentials will iterate through usernames and passwords trying to find one that works. We're going to make all of them bad. If the attacker has a good username and password, we scramble it and send it back to the origin, which responds that it's a wrong username and password. Everyone will start seeing this response, and the attacker won't get any feedback on what's wrong.

[![Thumbnail 670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f4257b6649d1819c/670.jpg)](https://www.youtube.com/watch?v=jml0p7sgp5g&t=670)

If we simply blocked the attacker, they would think, "I've been blocked" or "Maybe I've been rate limited. I logged in more than 10 times a minute, so I'll try again at 90 times per minute, or I'll try a different path." In this case, the attacker doesn't know what's happening. We're effectively blocking them and frustrating them. 

What makes this more important is that when an attacker is under attack and gets the signal, they can retool. They see the offense or the defense you have in place and think, "I know how to get around that. I could go this way or that way." But here, they don't know. They think they have a bad list, and they don't know what we're doing. Honeypots have been around for a while, but the problem is they're typically a separate infrastructure. You have your production environment, and then you have your honeypot. You have to keep them in sync, keep them exact, and run two instances. It would be costly and require a lot of engineering work. It could be worth it, but it's a lot of effort.

[![Thumbnail 750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/f4257b6649d1819c/750.jpg)](https://www.youtube.com/watch?v=jml0p7sgp5g&t=750)

In this case, the genius is that we put it right in line with your normal WAF workflow. We can take those triggers and instead of blocking, we're just scrambling the password and username and sending back a message that it was a bad one. We're not blocking them. It's easy to put it in and out and tune it without having to create all this other infrastructure, which is costly and difficult to maintain. 

This is a start. We're doing it with account takeover, and we plan on expanding it into other areas, APIs, and other types of attack vectors that we're going to make look deceptive in different ways. The beauty here is that it allows security people to easily use this without having to go deep into the code and build things that might be more difficult and costly to maintain. It's a GUI-driven interface, very easy to enable and log, or even try it and see what it would have deceived before you're ready to really put it into production.

This is all part of defense in depth. There's a whole myriad of tools that you need to have in place to protect against attackers, and this is something that Fastly provides. Deception is just one part of our WAF. We can also do rate limiting. We have DDoS on the front end, which can intelligently detect DDoS attacks and block them. We're secured by design deep inside our CDN and our WAF. We make sure all the code and everything there is secure, and you have this whole defensive depth that's all logged. It's all API-driven and driven by Terraform. It's very easy to roll it forward, roll it back, and manage it and iterate on it.

We want to even the playing field and try to fool those attackers before they can do their damage.


----

; This article is entirely auto-generated using Amazon Bedrock.
