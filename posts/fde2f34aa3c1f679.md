---
title: 'AWS re:Invent 2025 - Continuous integration and continuous delivery (CI/CD) for AWS (DVT202)'
published: true
description: 'In this video, Steve Rice and Mihai Balaci discuss the evolution and future of CI/CD on AWS. They cover AWS''s three-pillar release approach: gradual deployment, automatic rollback, and validation. Mihai demonstrates deploying applications using the AWS MCP server (Model Context Protocol) with AI-powered IDEs like Kiro, showing how to go from local development to production in minutes using infrastructure as code through CDK. The demo includes automated pipeline creation, troubleshooting, and GitHub integration via CodePipeline and CodeConnections. Steve then explores continuous configuration and feature flags using AWS AppConfig, demonstrating how to toggle logging verbosity in production without code changes, and automating flag switches through CloudWatch alarms to respond to suspicious activity instantly.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/0.jpg'
series: ''
canonical_url: null
id: 3085377
date: '2025-12-05T05:23:38Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Continuous integration and continuous delivery (CI/CD) for AWS (DVT202)**

> In this video, Steve Rice and Mihai Balaci discuss the evolution and future of CI/CD on AWS. They cover AWS's three-pillar release approach: gradual deployment, automatic rollback, and validation. Mihai demonstrates deploying applications using the AWS MCP server (Model Context Protocol) with AI-powered IDEs like Kiro, showing how to go from local development to production in minutes using infrastructure as code through CDK. The demo includes automated pipeline creation, troubleshooting, and GitHub integration via CodePipeline and CodeConnections. Steve then explores continuous configuration and feature flags using AWS AppConfig, demonstrating how to toggle logging verbosity in production without code changes, and automating flag switches through CloudWatch alarms to respond to suspicious activity instantly.

{% youtube https://www.youtube.com/watch?v=rm9gPOlUxNY %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/0.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=0)

### Welcome to re:Invent: Setting the Stage for CI/CD Innovation

 This is Continuous Integration and Continuous Delivery on AWS. The session is DVT202. If that's what you're expecting, you're in the right place. My name is Steve Rice. I'm General Manager for AWS AppConfig as well as Parameter Store. I'll be joined later by Mihai Balaci, who's going to talk about the state of CI/CD. But first, I'm going to ask you all: how many people is this their first re:Invent? Would you mind raising your hand? This is awesome. I love seeing so many new people.

How many people have gone to two re:Invents? Three? Four? Five? Six? Seven? Seven back there, all right. Okay, anybody above seven? I can't see if there's anybody. These lights are a little bright, but thank you all for coming. re:Invent is one of my favorite times of the year. I apologize that it's right after US Thanksgiving. If you're American, it's a little bit challenging to come here right after you left your family. I actually had a flight that arrived here late last night. I was here at three in the morning my time, so I'm fully caffeinated now, but I didn't sleep much last night.

Hopefully now that you're here, you're fully engaged and you're here to learn. That's one of the key things about re:Invent: you're going to learn a lot and you're probably going to be overwhelmed. I hope you're taking some notes. The good news is that a lot of these sessions are recorded and you'll be able to watch some of them later on YouTube or some of the streaming services that are out there. The other thing that we really want you to do at re:Invent is meet each other and be aggressively friendly to those around you so that you can network.

### From CD-ROMs to AI: The Evolution of Software Release Practices

It's really cool when we see our customers all talking to each other and not sitting there talking to an AWS employee. So I hope that happens over the next week. Now, back to this. We are going to be talking about CI/CD. I'm going to go way back in time. You can see I have gray hair and I've been doing software for 25 years. I remember back in the day when I first was building software. I worked for a company called AOL and we would release a piece of software once a year on a CD. I was the engineering lead for AOL 7.0.

What that meant was that I had to go and talk to about 200 different engineers and coordinate to make sure that we were ready to do our build once every two weeks. I would reach out on Instant Messenger and say, "Are you ready yet?" "Oh, I'm all ready, yep." Then on build day, which was on Wednesday, I would merge all the code and do a build and it would never work. So then I'd figure out where the failures were. I'd go talk to probably 50 of those 200 engineers and I'd have to ask them to make a fix.

We used Visual Source Safe, if you remember that. I can see some gray-haired people out there. It was a very strenuous process. We were supposed to build on Wednesdays. Usually we'd end up building on Friday or the following Monday because there were so many build failures. Then we moved to a build system that actually used branches and that was a huge innovation in source management. We would be able to develop on our own branch and then merge in. The auto-merges were amazing. That was something that really moved us forward faster.

Looking back, those were sort of the dinosaur days. We were not making as much progress as we do today, but that branching was a big innovation. Then we moved to CI/CD where all of this was automated. I'd commit some code and then it would be out there through a process to production after some testing. That was a revolutionary thing. Today, we're going to talk about looking forward and some new innovations in CI/CD. I think that AI will be a big thing that you hear a lot at re:Invent, but I think there are areas where we've seen tremendous success and tremendous opportunity for development with AI.

[![Thumbnail 280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/280.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=280)

### AWS Release Philosophy: Three Pillars of Gradual Deployment

One is code writing, obviously. It's pretty amazing what AI agents can do. The other is in the CI/CD space. That's going to be transformed over the next three to five years and the way we do things today is going to be very different than the way we're going to do things by the end of next year and the year after that. So I'm going to dive into a couple of things. Our agenda today: we talked a little bit about the state of where things are with CI/CD. Mihai's going to talk to you about how to deploy to AWS using agents.  And then sort of a workflow of that: previewing your app, going live, and troubleshooting.

[![Thumbnail 300](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/300.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=300)

I'm going to come back later and talk about something called continuous configuration and feature flagging, and then we'll wrap up with key takeaways. We're not going to do questions in the room. We are going to do questions outside the room. So we're going to try to end with about 10 minutes left  so that you all can ask us questions and/or get to your next session. This slide shows how AWS releases software.

If you didn't know, all of our tools that we have externally are either the exact same or very similar to the tools we use internally. I just want you to know, this is our mindset of how we release things at Amazon. I always say we develop very quickly and release very slowly.

There are three pillars to every release mechanism that we use. One is we release gradually. You can see here we have several waves. If you look at the right-hand side, wave one, wave two, wave N. We release things very slowly and gradually. That helps us limit the blast radius of changes. The second thing that we do is we always have automatic rollback configured. A lot of tools will have an automatic rollback, but if an alarm goes off during the deployment of new code or new configuration, we're going to have auto-rollback. It's sort of like having auto-braking in a car. Today, almost all cars have some sort of crash collision detection. I personally wouldn't drive a car if it didn't have that now. It's really nice. It just automatically rolls back if something strange is detected.

And then the third thing we do is always sort of validation along the way. You see that we do things like integration tests. Sometimes with configuration data, we might validate that there's no typos because, unfortunately, we've seen a lot of outages caused by typos in configuration, including at Amazon. Those three pillars are reflected here. Going from left to right, source, build, package. Then we have a gamma thing. It sits there, it bakes, and then we put in the first wave, second wave.

For Amazon, as you probably know, we have over 30 regions, and we use those partitions as waves. So the first wave is a small region for us. The second wave might be two regions. The third might be a bigger region. Most of the time, whatever we change in a small region, if it works okay, it's going to work in the other regions. But there are times when we will discover something only at scale, only at US East 1, the problem occurs, and it was fine in the other regions.

But again, for you all, I would recommend thinking about how can you partition your releases in a way that allows you to release gradually and be able to test it, let it bake a little bit. That is some culture changing you need to do with your marketing teams. Marketing would love it if you could just release it everywhere all at once. But again, it makes a much better experience if you're releasing something to 1% of your customers, 10%, then maybe if something goes wrong, only 10% see that problem and it gets rolled back. So you have to work with marketing and other teams about doing gradual releases.

[![Thumbnail 470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/470.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=470)

Okay, so at AWS, we have a full set of tools.  We also know that a lot of companies have been around for a while and been using other tools as they're moving to AWS. So we built these tools in a way so that they can be mixed and matched. You don't have to use all the tools. We have a lot of customers using Jenkins, for example, and that fits into this suite of tools as well. We expect that to be there.

You can see on the left-hand side, Codewhisperer, that's a relatively new offering. It's using AI. I'm going to ask, has anybody used Codewhisperer in the room yet? Okay, great. It's sort of a spec-driven development thing. I've been super impressed with it, and I promise it's not just because I work at AWS. It's a really impressive tool for sort of getting off the ground, starting a new project. It's really engaging.

And then we're going to be moving across the way here and talk about some. Mihai's going to talk about some of these other tools. We're not going to talk about, on the right-hand side, a lot of the monitoring tools. That is an important part of your CI/CD plan. And I told you, the second to the right, AWS AppConfig, I'm going to talk a little bit about that at the end. Okay, I am going to hand it over to Mihai to talk about some of the very exciting changes that are happening, both in the industry and at AWS.

[![Thumbnail 570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/570.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=570)

### The SDLC Maturity Journey and Modern CI/CD Pain Points

Thank you, Steve. Good morning, everybody. I hope you're doing good so far. You know what I like about this slide the most is the fact that we have so many tools and we have so many stages that we developed over the years. And this makes it very interesting  because if we look at how many stages we have these days, maturing your software development life cycle is a challenging journey by now. Having sustainable CI/CD maturity both requires and reinforces the SDLC maturity.

Do we have vibe coders in the room today, in the audience? We have one, good. Let's imagine you have that brilliant idea, the billion dollar idea, and you're about to start right now. Your SDLC maturity would be very low at this point. Your focus will be entirely on speed of implementation.

And you will probably have no test, not enough security, and not so much platform knowledge. But as you evolve into a growing startup, your SDLC maturity level reaches a medium stage. Your focus also changes from speed to collaboration. As you grow into a scale-up, your focus changes again, and your SDLC maturity becomes even higher. You start having all the steps covered properly in the SDLC pipeline, but your focus changes as well and moves towards scaling the technology.

[![Thumbnail 670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/670.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=670)

On the last stage of your growing business, you will end up becoming an enterprise, and you will have all the stages well-defined and fully covered. Your focus changes again, and you will start looking more into security, auditing, and how to scale governance.  Organizations encounter various pain points across their maturity journey of their CI/CD pipelines. In the last five to ten years, if we think about how fast those tools have been evolving, this evolution makes it almost impossible for teams and organizations to stay current. Teams struggle to balance between adopting new practices versus maintaining stability.

They also struggle when standardization is pushed not just to one single team, but to multiple teams. This is always very time-consuming. Security vulnerabilities can be introduced at any point in the pipeline stage, and by now you need to have continuous security scanning and compliance checks in place. You need to do all this without slowing down the delivery process. Pipeline performance will degrade over time with increased codebase and the number of teams using that pipeline. A pipeline that once was very efficient can become a bottleneck, lead to slow delivery times, and become even more expensive.

[![Thumbnail 780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/780.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=780)

Pipeline failures can be introduced at any stage, but they can also be very difficult to diagnose and even reproduce. Complex integration points create multiple failure possibilities. The infrastructure cost for CI/CD grows with scale. In software development, the need for seamless collaboration,  continuous integration, and delivery is paramount today. Having multiple complex possibilities to orchestrate your CI/CD pipelines is extremely valuable, but what we have observed over time is that orchestrating a deployment on AWS can become very complex. At Amazon, we believe that in this new world of vibe coding and AI-driven innovation, all this complexity should be triggered by simple interactions. Let's just imagine what if a deployment was as simple as describing what you want.

[![Thumbnail 820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/820.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=820)

[![Thumbnail 850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/850.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=850)

[![Thumbnail 880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/880.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=880)

### Deploying to AWS Using AI: A Live Demo with MCP Server and Kiro

 What I'm going to show you today is how to orchestrate a deployment on AWS using AI and the AWS MCP server. We will use best practices like infrastructure as code through CDK to keep our environment consistency, and I'm going to show you how to bring your brilliant idea to production in a matter of minutes. There are so many innovations happening right now  in the AI space, and MCP is one of them. Does anyone know about MCP in the audience? One, two, three, all right. MCP stands for Model Context Protocol, and it is a way to enhance the model's knowledge and capabilities. I like to think that deploying using the AWS MCP should be your first DevOps hire,  especially if you are in the first quadrant, the zero to one quadrant that I showed you before.

[![Thumbnail 890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/890.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=890)

Do we have any Joe in the audience?  Congratulations, Joe, looks like you're about to release a new company. Joe is a vibe coder who just created his first project on a vibe coding platform, and he wants to share a link of that application to his family, friends, and stakeholders.

[![Thumbnail 920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/920.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=920)

Joe heard about AWS releasing the MCP server and just wants to try it out. Let's look at his journey as he creates this link  where his application can be accessed. First, Joe will use his ID of choice. In our case, we will show you Kiro, it's our ID of choice. He will install and configure the AWS MCP server, and Joe will simply start his flow, his preview flow, by asking Kiro what he wants. To deploy this, we will use agent SOPs. These are standard operating procedures for agents, and their SOPs are usable workflows written in markdown for agents to follow. These SOPs are all part of the AWS MCP server. At the end of this flow, when these checks are completed, Joe will end up having his link, a CloudFront link, where his application will be running.

[![Thumbnail 980](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/980.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=980)

[![Thumbnail 1000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1000.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1000)

[![Thumbnail 1020](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1020.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1020)

[![Thumbnail 1030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1030.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1030)

[![Thumbnail 1040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1040.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1040)

[![Thumbnail 1050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1050.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1050)

[![Thumbnail 1070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1070.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1070)

[![Thumbnail 1080](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1080.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1080)

[![Thumbnail 1090](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1090.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1090)

[![Thumbnail 1100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1100.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1100)

Let me show you how this works.  Joe goes to his GitHub repository where his Lovable application was saved. Joe is using a standard Lovable app this time. I'm going to demo you a standard Lovable app.  This has a React front-end, has an authentication mechanism, a Supabase database, and a Lambda serverless function. The first thing that Joe will do is to test his application locally.  As we can see here, localhost 8080, the application is loading. Let's see also if the functionality is what we expect it to be.  Joe is placing a new order. Okay, it works.  The checks are in place.  Now, Kiro has native support for MCP. The next step in this flow would be for Joe to configure and set up the AWS MCP server.   This seems to work as well.  Now, Joe is checking his AWS credentials. All works well. And now, Joe will ask Kiro to deploy his app. 

[![Thumbnail 1110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1110.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1110)

[![Thumbnail 1120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1120.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1120)

[![Thumbnail 1130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1130.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1130)

[![Thumbnail 1140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1140.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1140)

[![Thumbnail 1150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1150.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1150)

[![Thumbnail 1160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1160.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1160)

[![Thumbnail 1180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1180.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1180)

[![Thumbnail 1190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1190.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1190)

[![Thumbnail 1200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1200.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1200)

I'm going to pause right now.  Oh, he's not pausing, no. All right, so Kiro will load an agent SOP  which will follow a series of steps to deploy this app. Once Kiro scans the application code, we'll understand the type of application  and we'll generate the type of components that will be further deployed using CDK to AWS.   As you can see in the interaction, Joe constantly receives the output from AWS  into a readable format in the chat. So those actions can be performed once by asking Kiro to do it, copy pasting the commands in the CLI or going to the AWS console, logging in the AWS console by using those links and perform the actions.  Now, we have the application live. We have a CloudFront link. And let's see if the order  that we previously created is still there and check again the functionality of the application. Joe is placing another order.  Looks like we have a technical issue here.

[![Thumbnail 1210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1210.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1210)

[![Thumbnail 1220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1220.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1220)

[![Thumbnail 1230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1230.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1230)

 As you can see in the AWS console, we have two resources created. We have a CloudFormation stack for the API  and another stack for the front-end component. In the IDE as well, the model has generated the infrastructure code files and the Lambda function. 

[![Thumbnail 1250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1250.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1250)

[![Thumbnail 1280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1280.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1280)

There are two new markdown files that Kiro will create guided by the SOP.  One is the agents.md file. This file will allow the model to work more effectively with Joe's application after scanning that code. The second one is the skills file. We will see that now we have four identified skills mapping the application components that have been discovered by the model when scanning on the third stage. 

[![Thumbnail 1290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1290.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1290)

[![Thumbnail 1310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1310.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1310)

Now for this flow, on AWS, we are using CloudFront, AWS S3, an API Gateway, and we are translating the serverless function from Lovable into a Lambda function.  Things have progressed. Joe is very happy and he's very confident that he wants to go live on production with his application. He wants to take full advantage of best practices without putting too much effort into setting them himself, and he's proceeding. 

[![Thumbnail 1340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1340.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1340)

In order to deploy to production, Joe will go back to Kiro and tell his AI chatbot that he wants to deploy the application to production. The model will get the relevant details like getting the GitHub token, identify the missing components in this case, and it will call the right tools under the AWS MCP server and will start creating the deploy for the pipeline. 

[![Thumbnail 1400](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1400.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1400)

[![Thumbnail 1420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1420.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1420)

Joe is having a great time. The application is live on production. It works, customers and friends are using it, but he's also receiving a lot of new feature requests. He's finishing working on a feature request. He's pushing a commit and it fails. Before having the AWS MCP and before having Vibe coding in IDE, Joe was supposed to go back to the AWS console, log in, identify the pipeline, inspect the logs, inspect his code base, and then troubleshoot the pipeline errors. This time, with all these new tools in place, his troubleshooting flow would be as simple as asking Kiro to fix the problem. Joe continues his chat with Kiro,  and he will ask the model very soon to deploy the application. 

[![Thumbnail 1430](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1430.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1430)

[![Thumbnail 1440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1440.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1440)

[![Thumbnail 1450](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1450.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1450)

[![Thumbnail 1460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1460.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1460)

The model is now identifying the type of components  that the CI/CD pipeline will require, and because we're using best practices, the model is also going to suggest two stages for this pipeline.  And as you can see, there is one component that has been identified and generated. In order to connect CodePipeline with the customer,  in this case, Joe's repository, GitHub repository, we need a CodeConnection instance to be created. 

[![Thumbnail 1480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1480.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1480)

[![Thumbnail 1490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1490.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1490)

The model now is generating the pipeline stack, and this pipeline stack, once created, will be deployed using CDK.   Joe is asked to authorize this deployment.

[![Thumbnail 1500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1500.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1500)

[![Thumbnail 1510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1510.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1510)

[![Thumbnail 1520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1520.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1520)

[![Thumbnail 1540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1540.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1540)

[![Thumbnail 1550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1550.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1550)

[![Thumbnail 1570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1570.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1570)

[![Thumbnail 1600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1600.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1600)

[![Thumbnail 1640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1640.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1640)

[![Thumbnail 1660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1660.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1660)

[![Thumbnail 1670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1670.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1670)

[![Thumbnail 1680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1680.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1680)

[![Thumbnail 1690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1690.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1690)

[![Thumbnail 1700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1700.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1700)

[![Thumbnail 1710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1710.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1710)

[![Thumbnail 1730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1730.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1730)

[![Thumbnail 1740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1740.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1740)

[![Thumbnail 1750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1750.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1750)

[![Thumbnail 1760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1760.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1760)

[![Thumbnail 1770](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1770.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1770)

[![Thumbnail 1780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1780.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1780)

[![Thumbnail 1790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1790.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1790)

   The model is performing a CDK bootstrap, which will start building the components on AWS. By now, Joe should have a pipeline created with multiple stages.  Every time a component is created, the model will retrieve the link to access it in the AWS console.  The only action that Joe needs to do right now is to activate the AWS CodeConnections instance to connect CodePipeline with GitHub. By following this link, he will authorize GitHub now. We identify the connection, and the connection will be enabled.  Next, Joe will need to fill in the secrets for both dev and prod environments.  The pipeline is now created and is running all the tests. We can also see that in CodeBuild, we have multiple projects created according to the number of stages we have in the pipeline.  The pipeline is running all the tests, builds the backend and the frontend components, and then first deploys the dev environment, then the production environment.  When all this is completed, the IDE, Kiro, will present Joe the links to access all these components.  Let's see if the application works now.   This has been successful in the IDE. Joe has both links to dev and prod.  Joe is taking in new feature requests and he's working on delivering new capabilities for his application. But unfortunately, the pipeline gets an error in the build stage for the frontend.  The troubleshooting session in this case would be as simple as going back to Kiro, going back to the IDE, and asking the agent to troubleshoot.  The agent will do two things. It will read the agents.md file and the deployment.md file to understand how this application has been deployed before and to get all the relevant information about the codebase after the scanning session to understand what type of application it's dealing with.  Then, third, we'll call the MCP, which will call AWS APIs. In this case, we will call the CodePipeline APIs to understand the status of the pipeline.  Because Kiro has access to the entire codebase, it will easily identify where the problem is, what files are affected by the change, and fix them.  As previously instructed, Kiro is allowed to do git push and git commit.  The moment a git commit is done, then the pipeline, being a self-mutating pipeline, would automatically restart and rebuild the changes.  

[![Thumbnail 1810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1810.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1810)

For this production stage  on AWS, in terms of CI/CD components, we're using CodePipeline, CodeBuild, and CloudFormation. We are also creating a CodeConnection instance that can connect to your repository of choice. In this case, it's GitHub, but you can use it with GitLab or Bitbucket as well with CodePipeline.

[![Thumbnail 1840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1840.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1840)

With the power of AI, we can optimize time-consuming tasks  like setting up a pipeline or performing multi-stage deployments. Tasks that once required hours or days of configuration you can now accomplish in a couple of minutes. By using the AWS MCP server, you get out-of-the-box infrastructure code with best practices. You run all the necessary testing steps, code scanning, and pipeline notifications.

[![Thumbnail 1870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1870.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1870)

A few ideas for the future: we are thinking of supporting more complex applications like full-stack applications. We will propose ways to speed up slow pipelines and we will use smart scaling based on historical deployment patterns. We are also looking into agents that continuously monitor your system, detect anomalies, and propose corrective actions without requiring manual intervention. We're also looking at AI-generated pipeline templates based on the type of application that will include the best practices for your specific application type. 

[![Thumbnail 1920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1920.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1920)

Deploy with AWS MCP has revolutionized our deployment process. With just a few prompts, we have a fully functional, secure, and scalable CI/CD pipeline that deploys directly on AWS. What excites me about this is that every minute we spend on configuring CI/CD is a minute we don't spend on innovation. We are giving developers this time back. 

[![Thumbnail 1980](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/1980.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=1980)

### Continuous Configuration and Feature Flags: The Secret Weapon for Speed

I'm going to ask Steve to come on stage and continue with some more time-consuming actions and examples. Hopefully you saw some new things there that you haven't seen before. We'll be happy to talk to you after about how you may apply this when you go back to your jobs next week. I'm going to switch gears a little bit and talk about something called continuous configuration  and using feature flags.

How many people in the room are using feature flags today? Good amount, great. Feature flagging is the secret weapon, I think, about moving fast and getting some of that time back that was talked about. I'm going to talk at a high level about how we use it at AWS. We did not invent feature flagging, but we use it at scale. Some of the benefits for those that might want to fine-tune how they're using it or maybe introduce it into their set of tools for CI/CD are significant.

[![Thumbnail 2020](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2020.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2020)

[![Thumbnail 2040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2040.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2040)

So you should think about what happens after CI/CD.  You go ahead and develop your software, run it through your pipeline, and it goes to production. Depending on how complex things are, that might take fifteen minutes, it might take a couple of hours, it might take a couple of days. At AWS, it's actually weeks of time  that we roll out our changes across all of our regions.

I'm going to zoom in on this side here that's in the box, the release part. If you have a change that you want to make and you don't want to go through all of CI/CD, you can use something like AWS AppConfig or there are other feature flagging solutions out there that are great to tweak the behavior of software on production so you're not having to go through that fifteen minutes. I'll give you an example. Let's say you have something where you have a bad actor on your system and you want to block that bad actor. If you have your configuration of allow lists or block lists embedded with your code and you want to make a change and you're not using feature flags, what's going to happen is you're going to update your block list to prevent that bad actor from doing things.

You're going to send it through CI/CD and that could take, as I said, fifteen minutes, a couple of hours, or even days, and you want to be able to react much more quickly than that. So what you're going to have is an application out there that is dynamically fetching and reading configuration data on production and it's tweaking the behavior of that software while it's on production

[![Thumbnail 2110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2110.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2110)

without going and changing any code.  This concept of continuous configuration allows you to do a few different things. When people hear feature flags, they often think of releasing a new feature. That is a very common use case and we call that a release flag. The way you do that is you have your code. Remember earlier I was talking about these long-lived branches. You don't have long-lived branches anymore. You have your code on the trunk but the access to that code or that feature is controlled by a small configuration Boolean. If feature enabled, let people use the new code. If feature not enabled, don't let them use the new code and hide the code.

This allows your software engineers to develop something and push it to production even if it's not all the way done. Nobody can access it because the feature flag is off in that state. They can continue to develop it over weeks or months, however long it takes to develop that feature. Then you can turn on that feature and you turn it on for a small set of users. It might just be for a couple developers at first. Then it might be for all internals and then it might be for 10% of users, 20%, and so on. You release it slowly over time.

Feature flags and continuous configuration allows you to turn on features slowly. It also allows you to turn off features. This is a really powerful thing. It's a kill switch. Let's say something at 20% you're realizing this thing is killing our CPU, we gotta turn it off. You don't want to have to go back and change all your code and then redeploy. Instead, you can just turn off that feature. Of course, you can roll back code more quickly but what's really cool about continuous configuration and feature flags is this scenario: let's say you have a push, a big push and there's 10 features in it and it's going through and you're releasing it slowly and there's a problem with one of those 10 things.

Instead of rolling everything back and rolling back all 10 features, you can have a feature flag just turn off the one feature that's not working so well and then you can fix it and move forward that way. Another use case of feature flagging are what we call operational flags. I'm going to do a demo a little bit later of an example of an operational flag. The allow list or the block list might be something like that. You also might want to do things like limit the number of background processes. We used to do that at a company I worked at before. During peak times, we actually turned off non-essential things so that CPU would stay at a manageable rate and then once things settled back down, we would turn on those features again.

[![Thumbnail 2290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2290.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2290)

And then again, this idea of just limiting the impact of a change. I think you all know most outages are caused by a software change of some sort and so you want to always make sure you're releasing things in a way that limits the blast radius of those things. And again, with feature flags, you're doing all this without changing any of your code. You're just changing the configuration data. You make that change, you push that change out of the configuration data and your application's dynamically reading that change and within seconds, it'll update itself.  So, some benefits here. No long-lived branches. Again, when I was getting back, at least in my career, branch merges can slow you down. We've had customers that say that they can only release once every month because they have a very long process to resolve merge conflicts.

So with feature flags, you're developing what's called trunk-based development. It's part of the well-architected framework if you want to look that up. And you are just deploying that capability behind a feature flag. You're really separating the idea of a feature release from a code deployment. That's tremendously powerful. You have control about when the code goes out. You're not waiting and trying to time a release with something that's happening on stage. For AWS AppConfig, which is the feature flagging solution that almost every AWS service uses, this is a really big week for us.

[![Thumbnail 2370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2370.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2370)

As we're launching all of these new features on AWS for customers this week, these features have actually been out there for a couple weeks. The code has been out there, but they've been all hidden by feature flags, and they've been turned on just for a couple users. And this week, a lot of feature flags are getting turned on. And I already talked a little bit about this fast rollback. Speed really matters, and so the idea of I want to be able to roll back the change, and just that one change, very quickly, feature flags allow you to do that.  This will result in allowing you to respond to problems on production much faster. Your MTTRs will really decrease, which is fantastic.

You'll also be able to validate in production. If you have a QA group, and they have QA environments, and this always happens, well, it didn't fail in QA, but it failed in production. What you're doing with the feature flag is you're allowing access to test that new capability just to maybe QA accounts, or internal accounts, on production, so you can really validate with whatever the data texture is on production that you have.

Some people use feature flags for A/B testing. I always say this is a way to eliminate the loudest voice in the room or the most senior voice in the room. People say, "I really think that blue button is going to perform much better than that green button, so we're going to have a blue button." With a feature flag, you can actually split your traffic and have 10% see blue and another 10% see green, and really look at the real world data over the course of a couple weeks to see what actually performs better rather than relying on somebody's opinion. You'll see some increases in your software release frequency, which is critical in moving fast.

[![Thumbnail 2440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2440.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2440)

I think you've all heard many quotes from Werner.  I know he's doing a keynote later. The famous one he always says is, "Everything fails all the time," and design with this in mind. This is another quote from a blog post he did around continuous configuration. Having this capability is a secret weapon to be able to tune your software in production. I like this second paragraph here: "In the future, we'll be able to respond to events before they've even happened." This is the promise of AI agents that are going to go out there, test on production, theorize that something is not right, and actually address the issue with just a very small configuration change.

[![Thumbnail 2480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2480.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2480)

### AWS AppConfig in Action: Automating Logging Verbosity with Feature Flags

I'm going to do a quick demo here.  The demo will show you the use of a feature flag. The use case is an operational flag that toggles the verbosity of your logging. When something critical is happening in production, you might want to toggle from info to debug. You don't want to do that kind of thing in your code. You don't want to make that change in the code and push it through your CI/CD pipelines. You want to be able to respond more quickly. If there's suspicious activity happening on production, you want to do that very quickly. A feature flag is a good use case for that.

[![Thumbnail 2520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2520.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2520)

[![Thumbnail 2530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2530.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2530)

What I'm showing you here is the console for AWS AppConfig.  This is a capability that some other feature flagging services have as well. AppConfig has a couple of different types of configuration. We have something called a feature flag.  We also have open-ended, free-form configuration. Here I'm setting up what's called a configuration profile, which is just a collection of flags. There are times when you want to group multiple flags together and deploy them as a single deployable unit, so AppConfig allows you to group these things.

[![Thumbnail 2550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2550.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2550)

[![Thumbnail 2570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2570.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2570)

[![Thumbnail 2580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2580.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2580)

I'm going to create a flag that  is logging verbosity essentially, and I'm going to have a friendly name. I'm going to have how I reference it in the code, which is listed there. One problem with feature flags that we hear a lot from customers or that we see internally is this idea of feature flag clutter. You might have flags littered all throughout your code  that nobody even knows what they do anymore. They were used two years ago and you're afraid to remove them. So AppConfig actually has something where you can designate a flag to be short-term.  Here I'm turning on the flag to be on so it's active, and then I'm going to set up a value for the logging verbosity.

[![Thumbnail 2590](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2590.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2590)

[![Thumbnail 2600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2600.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2600)

[![Thumbnail 2610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2610.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2610)

[![Thumbnail 2630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2630.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2630)

[![Thumbnail 2640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2640.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2640)

 So here I'm going to create the key. I'm going to set a value as info to debug, so I'm setting it up as a type string  and then I'm going to make sure that it is info. That's the normal state.  I'm going to go ahead and save this, and then what I'll do here is actually set up the flag. First you save it, and then we think of flags and configuration data just like code. You actually deploy the flag. So some solutions out there might have something  where you just update a record in a database that's there immediately for everybody. That way you're not getting the benefit of a slow deployment and auto-rollback. So here I'm doing a deployment.  I'm going to deploy that configuration change out to production, and then my application is reading it. It's actively saying, oh, logging verbosity should be info, should be info.

[![Thumbnail 2660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2660.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2660)

[![Thumbnail 2700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2700.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2700)

All right, I'm going to jump ahead very quickly here and set up a CloudWatch alarm.  You could do this with other solutions like Datadog or New Relic as well, and I'm going to be monitoring for suspicious activity. An example of that might be something like somebody calling the API to list IAM roles. That is a normal cycle that goes through the week, but if something happens where that spikes up, that sounds suspicious. Something weird is going on, and that's a use case where you might want to turn on the verbosity to debug so you get a lot more information about what's happening. This is just a sample alarm. It goes through the normal patterns here throughout the day, and I set a threshold.  It's really doing anomaly detection that says this is fine, the number of times that this API is called.

[![Thumbnail 2720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2720.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2720)

I've pre-configured an action here. CloudWatch allows you to do this, and other APM solutions will allow you to set an action when an alarm goes off, beyond just an alarm. You can actually set up an action. In this case, I've decided to create a Lambda  that will toggle the verbosity flag inside of AppConfig. That's the action that gets triggered when the alarm goes off.

[![Thumbnail 2740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2740.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2740)

[![Thumbnail 2750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2750.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2750)

I also have the ability to notify because I certainly want to know when this is happening. In this case, there are other solutions  that you can use, such as SMS, SQS, or Event Bridge for those kinds of notifications. I'm going to jump ahead here. I had something already pre-configured  where the alarms did go off. If you see those two or three peaks, they indicate an anomalyâ€”something strange is happening. You can see on the green and red bar at the bottom that something strange happened here. The system automatically flipped the feature flag from info to debug without anybody having to do anything. This is part of the idea to automate some of your operations.

[![Thumbnail 2780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2780.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2780)

If you go back into AppConfig, you can see that the value of the flag  is now set to debug because the alarm triggered that action. To recap what I just showed you, you can set up a feature flag or an operations flag inside of AppConfig. It's very flexible. You can set it to be strings, numbers, or whatever you need, and then use that configuration in your application. You can even automate the flipping of the feature flag.

[![Thumbnail 2810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2810.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2810)

### Key Takeaways: Embracing AI and Feature Flags for Faster Development

Now let me bring it home. A couple of key takeaways from what you saw today . I said at the beginning of this talk that things are changing very quickly, and I hope you're here to learn some new things, not just to see what happened last year, but instead what's going to be happening this year and beyond. Mihai is developing some very cool capabilities to simplify the CI/CD process. MCP really does allow teams to move faster, and probably the most important resource you have in your company is time. People are important too, but time is critical. Any tools or technology that allows you to move faster is going to be critical.

[![Thumbnail 2860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/fde2f34aa3c1f679/2860.jpg)](https://www.youtube.com/watch?v=rm9gPOlUxNY&t=2860)

At the end, I would highly recommend looking at feature flags and continuous configuration to allow you to respond to issues in production faster and allow your teams to release software more frequently. I think that's my last slide. A couple of thank yous here. One, thank you for sitting through this . Hopefully you learned some takeaways and you're going to go and action some things starting next week. Thank you all very much and enjoy the rest of your re:Invent.


----

; This article is entirely auto-generated using Amazon Bedrock.
