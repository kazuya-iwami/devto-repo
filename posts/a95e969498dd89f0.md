---
title: 'AWS re:Invent 2025 - Beyond web browsers: HITL and tool integration for Nova Agents (AIM3334)'
published: true
description: 'In this video, Amazon''s AGI lab introduces Nova Act, a frontier-class AI model for browser automation that achieves over 90% reliability on enterprise workflows. The team explains how Nova Act uses reinforcement learning on web simulations and advanced element understanding to interact with browsers like humans do, overcoming limitations of legacy code-based solutions. Key features include human-in-the-loop capabilities, tool use beyond browsers, and full AWS integration with SDK, IDE extension, and CLI. Design partners demonstrate real-world applications: 1Password uses Nova Act to build universal sign-on by gathering website-specific intelligence at scale, Amazon Leo automated QA testing across web and mobile platforms achieving 60 dev days saved, and Sola powers enterprise process automation with near 100% reliability for clients like R1 RCM. The platform offers complete developer experience from online playground prototyping to production deployment with observability through AWS console.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/0.jpg'
series: ''
canonical_url: null
id: 3087901
date: '2025-12-06T00:57:01Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Beyond web browsers: HITL and tool integration for Nova Agents (AIM3334)**

> In this video, Amazon's AGI lab introduces Nova Act, a frontier-class AI model for browser automation that achieves over 90% reliability on enterprise workflows. The team explains how Nova Act uses reinforcement learning on web simulations and advanced element understanding to interact with browsers like humans do, overcoming limitations of legacy code-based solutions. Key features include human-in-the-loop capabilities, tool use beyond browsers, and full AWS integration with SDK, IDE extension, and CLI. Design partners demonstrate real-world applications: 1Password uses Nova Act to build universal sign-on by gathering website-specific intelligence at scale, Amazon Leo automated QA testing across web and mobile platforms achieving 60 dev days saved, and Sola powers enterprise process automation with near 100% reliability for clients like R1 RCM. The platform offers complete developer experience from online playground prototyping to production deployment with observability through AWS console.

{% youtube https://www.youtube.com/watch?v=uOMh88Fz40M %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/0.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=0)

[![Thumbnail 20](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/20.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=20)

### Introducing Amazon Nova Act: From Answers to Actions in Browser Automation

 Welcome everyone. We're going to get started. Thank you all for joining us for our breakout session on Amazon Nova Act. My name is Kelsey, and I am here from our Amazon AGI lab based in San Francisco. We are a team within the Amazon Artificial  General Intelligence organization that is specifically focused on pursuing long-term research bets. The focus of our lab over the course of the last year or so has been specifically on agents. We are really excited about this paradigm shift that we're seeing in the industry from models that give us answers to models that take actions. I know this is not the first time you've heard about agents this week. They've certainly gotten a lot of talk over the course of re:Invent.

[![Thumbnail 50](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/50.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=50)

[![Thumbnail 60](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/60.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=60)

We started with the browser because this is as close as we can get to a near universal action space in the digital  world. We've been working on this problem of training models and providing solutions that allow for human-like performance when using a computer. What's been interesting about this problem is that  it has existed for a long time. People have wanted to automate computer tasks basically as long as computers have existed, and the solutions have also existed for a long time. Some of you in this room may have used more legacy browser automation solutions that are code-based and involve writing a considerable amount of logic to specify exactly what you want an automation to do to use a computer and perform a task.

[![Thumbnail 100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/100.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=100)

Here's an example for grabbing the weather from Weather.com. These solutions were a really great starting point to this problem, but they came with certain challenges. What we hear from customers is challenge one: these solutions took many months to get  up and running in many cases. They were great for one static website or one static workflow, but as soon as a website changed, they would break. There was a pretty large maintenance burden involved with this approach. The biggest thing is there was really limited generalizability because as a developer you had to specify every step of the workflow.

[![Thumbnail 150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/150.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=150)

If you created one workflow for one geography or one SKU, but all of a sudden you had to scale to the full scale of your organization and your business, and generalize to fifty different states or hundreds of different insurance companies, all of a sudden that problem became untenable. The technology was not really working with you to get to the scale that you need. What's interesting about this problem though is that as people, we do not run into these same constraints when we face problems related to computer use. Regardless of which email client you use and  love, if I show you any email client and ask you to write an email, I'm fully confident that everyone in this room could figure it out.

The way that you would know how to do this is actually kind of hard to encode in a rules-based way because you probably look at this screenshot and you're looking for a whole combination of things. You're looking for maybe a pen icon or a button that says compose, maybe it says draft, maybe it says new. It's probably towards the top of the page because writing an email is a key piece of functionality for an email client. So maybe it's separated from the other functions in some way. All of this is intuition that we've built through millions and millions of examples of using UIs and recognizing these common patterns. But software doesn't have that inherently.

[![Thumbnail 200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/200.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=200)

[![Thumbnail 210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/210.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=210)

[![Thumbnail 220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/220.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=220)

What we've been really excited to do as part of the lab is build models that treat computer use more like how humans do.  That's what we've built with Nova Act. The goal here is to train models that interact with a browser like a person. They look at a screen, they take a task, they understand what's  going on, and they determine what to do next. Once they've performed an action, they repeat that same loop. They take another screenshot, they understand what's going on in light of the previous action,  and they take another action to continue on the journey just like we do as people.

[![Thumbnail 230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/230.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=230)

[![Thumbnail 240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/240.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=240)

These systems are way more robust. They don't fail due to a small change. You can get up and running much more quickly through natural  language, and you can scale just in the same way that we know how to perform that flow across any email client. These models can also generalize across different environments.  But if you've been following the agent space, that's not the first demo you've seen of agents or of computer use in particular. The biggest bottleneck we hear from customers is reliability. We hear from a lot of customers that they're super excited about agents, they believe in the future, and they're very quick to build a prototype or a proof of concept, and then they get stuck.

[![Thumbnail 270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/270.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=270)

[![Thumbnail 280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/280.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=280)

### Achieving Reliability Through Element Understanding, Reinforcement Learning, and Human-in-the-Loop

While these models hold lots of promise and these solutions are very exciting, they don't actually work in a repeatable, scalable way that you need when you're trying to solve real business problems. This has been a core focus of Nova Act.  We've approached reliability as the P-zero as we've been solving this problem, and we've done so in a few different ways.  The first is really zeroing in on element understanding. For a model to work end to end in a reliable way, it needs to really understand web elements in the way that humans do. There are a number of culprits that typically stump agents, including date pickers, drop downs, and certain types of filters. These components are different on every site, and often agents don't know exactly how to handle them.

[![Thumbnail 320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/320.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=320)

We spent a lot of time collecting training data specifically on these components and evaluating our models in these areas to make sure we achieve end-to-end reliability, including handling the correct amount of time to load after you type in a zip code and other such idiosyncrasies. 

The second approach is using reinforcement learning specifically on web simulations or gyms. We've built hundreds of examples of mock websites that have similar components and types of UI patterns that you see across the web in the workflows that our customers are performing every day. We tell the model to go complete a task, and we don't specify the workflow or the steps that the model should take. We just validate that the end state is successful. This allows our model to do a large amount of exploration of these different platforms to really understand what's possible, what happens when I do A, what happens after that, and to understand different patterns for success. This has been a really key part of achieving reliability.

[![Thumbnail 370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/370.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=370)

Lastly, we've kept real world evaluation as our focus.  You'll see some exciting benchmark results with the latest release of Nova Act. We're really excited to see that our model is outperforming models of similar size like Haiku and even much larger ones like Sonnet. Ultimately, the metrics we care most about are related to customer success. What we're seeing with Nova Act is that early customers are seeing upwards of 90% reliability on the workflows that they're deploying in production. This is really important to us because we believe that an agent that is 50% reliable is 0% useful. Customers need agents that actually work in production, and this is what we're seeing today that we're really excited about.

[![Thumbnail 410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/410.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=410)

[![Thumbnail 420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/420.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=420)

[![Thumbnail 440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/440.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=440)

Even the most reliable agents  need help and need human oversight sometimes. With this release at re:Invent this year, we are excited to launch human-in-the-loop capabilities with Nova Act.  This allows you as a developer to configure the ability for the agent to call on a human either to take over on a task or to review a task before the agent continues. You can do this through platforms like Slack or through custom integrations, such as a custom UI, and facilitate this human supervision of fleets  of agents.

[![Thumbnail 450](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/450.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=450)

We're also expanding beyond the browser. As I mentioned, the browser is the place that we started with Nova Act. What we've heard from customers is that folks are excited  to extend that same level of reliability across their full workflows even beyond the browser. We're getting started on this in preview with Nova Act now, and we see customers doing things like reading their QA tests from Jira and then implementing them using Nova Act in the browser, or taking form fill inputs from Excel and then filling out that form in the browser. We're just getting started on this journey, but we're really excited to extend beyond what the browser itself is capable of.

[![Thumbnail 480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/480.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=480)

All of this is very exciting, but what we've  also learned is that having a really reliable model is necessary but not sufficient for building great agents at scale. Customers run into these questions: How do I debug? How do I measure success and deploy and scale? These are equally important questions in the journey to developing agents that really have true business impact. So now I'll have my colleague come along and talk about how we've tackled this problem as well.

[![Thumbnail 510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/510.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=510)

[![Thumbnail 520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/520.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=520)

### Building an End-to-End AWS Platform: From Prototype to Production Deployment

Thanks, Kelsey. My name is Ian. I'm a product manager and a member of technical staff  at the AGI Lab, and it's great to see everybody here. Let's go back a little bit to how we started on this journey.  In March of 2025, we released a research preview, and since then, we've had a bunch of people using our product and system, and they gave us a lot of feedback. Some of the feedback was about reliability, about the 90% reliability that Kelsey mentioned, which is absolutely critical. But we also got feedback that in order to release an agent into production in an enterprise, we need security. It needs to have all of the AWS security capabilities that everybody here has come to know and love.

[![Thumbnail 600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/600.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=600)

In July, we did our first integration with AWS, and our first users were able to use AWS authentication and S3 for saving the logs and things like that. That was our very first attempt at integrating into AWS. This week, we're happy to announce that we've launched as a fully generally available end-to-end AWS service, fully integrated with an AWS console and basically everything that you expect from a proper AWS service. I'll walk you through them now. Our new AWS service includes the following.  First of all, it includes a frontier-class, state-of-the-art model.

[![Thumbnail 610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/610.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=610)

[![Thumbnail 620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/620.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=620)

[![Thumbnail 630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/630.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=630)

As Kelsey mentioned, this is a state-of-the-art model that is as good as anything on the market, if not better.  We have a new AWS service and console, which I'll walk you through in a few minutes.  We also have a new playground where you can all go to our online playground and try out the product without having to download an SDK or write any code. You can see if it works for you online, and if it does, then we have the SDK, which you can use for coding in Python. 

[![Thumbnail 640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/640.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=640)

[![Thumbnail 660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/660.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=660)

We have an updated version of our existing SDK that uses our new model and is able to work with the new capabilities like human-in-the-loop.  We also have a new version of our IDE extension, which I'll show you in a few minutes, designed to use the new model and the new capabilities. We've built a CLI which makes it really easy once you've built your agent to package everything up into an image and deploy it.  We have these new capabilities like human-in-the-loop and tool use, and we're very excited about this end-to-end platform.

[![Thumbnail 700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/700.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=700)

[![Thumbnail 710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/710.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=710)

[![Thumbnail 720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/720.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=720)

[![Thumbnail 730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/730.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=730)

We feel that this platform provides several benefits to you. First, frontier-class accuracy. More importantly, while benchmarks are important, real-world reliability is actually much more important to our users.  We've spent a lot of time training our model to make sure that it can achieve over 90% reliability on the sort of typical day-to-day enterprise use cases.  Thirdly, cost-effectiveness. We've priced it very aggressively, and we feel that it is the most cost-effective solution on the market for similar products.  Lastly, time to value. We're really proud of the work we've done in building a terrific developer experience. Simply put, we feel that Nova Act is the best service for creating AI browser-based agents and creating ones that you want to actually use in production in the enterprise. 

[![Thumbnail 750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/750.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=750)

[![Thumbnail 760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/760.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=760)

[![Thumbnail 780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/780.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=780)

Let me walk you through that developer journey. First, you can prototype on the online playground, build with the SDK and our IDE extension, deploy to AWS, and get observability via the AWS console. Now I can show you some examples. This is what our online playground looks like.  You can see on the left that you can enter natural language prompts. On the right, we've got an embedded browser which is currently running a web gym, a simulation of a travel site.  We mocked up a travel site for buying tickets to other planets. On the bottom, you can see the agent's thinking steps, so you can try out your use case and see if it works here. When you're ready, you can click download, and it'll download the agent you've developed as a Python script, which you can then continue developing on your laptop. 

[![Thumbnail 790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/790.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=790)

[![Thumbnail 810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/810.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=810)

[![Thumbnail 820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/820.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=820)

[![Thumbnail 830](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/830.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=830)

[![Thumbnail 840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/840.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=840)

On your laptop, you can use the Nova Act SDK, and we highly recommend you try out our VS Code IDE extension.  It works on any VS Code compatible IDE and has a really terrific UI that simplifies things. On the left, you can see a notebook-style UI where all of the agent steps can be broken out into separate cells.  This gives you the ability to iterate and keep tweaking an individual step until you've got it exactly right. Without this, you have to keep rerunning your agent from the beginning, and it's a real pain waiting for it to go through 30 steps until it gets to the one that you've tweaked.  Our initial users have said that it can save them up to 80% of the time.  On the right, we've embedded a browser right in your IDE, so we've got everything that you need in one space. 

[![Thumbnail 850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/850.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=850)

[![Thumbnail 860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/860.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=860)

[![Thumbnail 870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/870.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=870)

[![Thumbnail 880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/880.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=880)

[![Thumbnail 890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/890.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=890)

[![Thumbnail 900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/900.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=900)

When you're ready, we have a deploy tab, and this makes it super easy to insert your AWS credentials. With one click, it'll build the agent image that you need to deploy. It'll use your Python script and the SDK.  It'll also take care of allocating the resources for you, the ECR repository, S3 bucket, set up your IAM execution roles and things like that, and deploy everything to AWS for you.  So it's super simple.  Once you've deployed your agent to AWS, you can use our console and see all of the agents that you've deployed.  For each agent, you can see a record of every single agent run. You can scroll down and see all of the screenshots, all of the thinking statements, the prompts, and all of the actions that the agent took.  This is terrific for troubleshooting and for customer support. 

[![Thumbnail 910](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/910.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=910)

[![Thumbnail 930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/930.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=930)

[![Thumbnail 940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/940.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=940)

[![Thumbnail 970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/970.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=970)

[![Thumbnail 990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/990.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=990)

[![Thumbnail 1000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1000.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1000)

[![Thumbnail 1010](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1010.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1010)

Thirdly,  you can also use Nova Act as part of a multi-agent framework. Here's a demo of something that we built that uses Nova Act in conjunction with two other Nova models: a Nova Chat LLM model and Nova Sonic, which is a voice model. I'll play this video for you to see.  Hey Nova, I'd like to plan a trip to the closest exoplanet.  Maybe something warm with a beach. The closest exoplanet we know of is Proxima Centauri B orbiting the star Proxima Centauri, which is just 4.24 light years away. Proxima Centauri B has abundant green oceans and beautiful beaches of fine orange sand. The average temperature is 86 degrees Fahrenheit. What date would you like to travel? In one month.  So January 3rd. Okay, great. Would you like me to book a flight to Proxima Centauri B? Let's do it. Got it. Let me generate instructions.  Okay, first, I need to find a ticket from San Francisco to Proxima Centauri B for January 3rd, 2026.  So I think you get the idea.  The basically the idea here is that you can build really cool experiences by using multiple agents together in the same agent agentic solution.

[![Thumbnail 1030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1030.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1030)

[![Thumbnail 1050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1050.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1050)

[![Thumbnail 1060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1060.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1060)

[![Thumbnail 1070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1070.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1070)

[![Thumbnail 1080](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1080.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1080)

### Four Key Use Cases: Web QA Testing, Data Entry, Data Extraction, and Checkout Flows

 As we've been working with design partners and with the initial users over the last year, we've seen a lot of different use cases appear. In fact, if you think of Nova Act, it's a very powerful and very low level primitive that can be used for innumerable use cases, literally thousands and thousands of use cases.  But as we saw what people are doing, we've seen that four typical clusters of use cases appear most often, and these are use cases that we feel are the lowest hanging fruit and will allow you to really get a lot of value in the near term.  The first one is web QA testing.  So today, if you want to build a regression test on a web application, you need an engineer who needs to write code using something like Selenium or Playwright, and that code is brittle. If a button moves on the website, then suddenly that code doesn't work anymore. With Nova Act, you can use natural language prompts, and it'll understand what the site is supposed to do, understand if the design has changed, and it'll just work. 

[![Thumbnail 1090](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1090.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1090)

 Next example is data entry. Every company has many workflows that involve doing things that involve manual transactions with websites. For example, salespeople, after a meeting, have to come in and enter a bunch of information into a CRM system. People have to file taxes, people have to file licenses or apply for licenses in different governmental websites. So there's tons of these undifferentiated manual tasks that people have to do that don't really add that much value. Wouldn't it be great if we could help you automate those so people can do what they really like to do at work, which is be strategic and creative and do what their real job is?

[![Thumbnail 1140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1140.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1140)

[![Thumbnail 1170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1170.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1170)

Similar for data extraction,  there's many industries like healthcare or logistics and many others where there's thousands of fragmented businesses and websites, and none of them are going to have APIs in the near future. So having a system that can automatically reach out to these different systems and collect data from them is of huge value and saves a ton of time. And checkout flows for e-commerce and for travel and things like that. We've also seen as being a very popular use case, and people are automating thousands of these at scale. 

[![Thumbnail 1180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1180.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1180)

[![Thumbnail 1200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1200.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1200)

### 1Password's Universal Sign-On: Scaling Website-Specific Intelligence with Nova Act

So now what I'd love to do is introduce you  to some of our design partners. They're going to walk you through a little bit about their company and how they've been able to innovate using Nova Act. So the first one, I'd like to invite Floris to the stage from 1Password. Thanks.  Hey, everyone.

[![Thumbnail 1210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1210.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1210)

Hi, I'm Floris from the engineering team at 1Password, and today I'm going to show you  how 1Password is using agentic AI to improve our own product in a way that just wouldn't be possible in the pre-AI era. The star of the show here is really Nova Act. A little bit about 1Password: we secure 1.3 billion credentials for 180,000 businesses and millions of users who use 1Password every day to log into their favorite websites. We don't just store logins for the developers in the room; we also store SSH keys and sensitive .env files, and these come with native integrations in the desktop apps.

[![Thumbnail 1250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1250.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1250)

[![Thumbnail 1280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1280.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1280)

Let's talk about autofill.  We have a browser extension that adds a small 1Password icon next to your login forms. If you click on that icon, you can choose a credential that you want to use to log in, and 1Password does the tedious work of filling out the form and getting you logged into your website. This has been out for a while and it's been working great, but it's time now for the next generation of autofill.  This is what we're calling universal sign-on.

[![Thumbnail 1320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1320.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1320)

With universal sign-on, we want to take the experience from "hey 1Password, fill in this form for me" to a more high-level approach where you say "hey 1Password, just log me in. Just do whatever it takes to log me in regardless of the login method, whether that's a username and password, TOTP MFA, enterprise SSO, a passkey, or signing with GitHub or Google, which you probably forgot which one you use with which website again." Here's a preview of what this looks like.  Now you can just click on a website and it'll immediately navigate to the login page and immediately log you in with a password and MFA token, and you're just logged in like that.

[![Thumbnail 1340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1340.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1340)

Now let's talk about how this works. Unfortunately, there's not a standard protocol for logging into websites. It's basically a free-for-all of HTML, and there's a lot of ambiguity out there. Every website does it slightly differently. The classic autofill algorithm solved the ambiguity with a one-size-fits-most algorithm based on heuristics, and it's been working quite well. It's being used millions of times every single day.  However, with the vision that we have for universal sign-on, we're running into the limits of the heuristics that we can articulate in our code.

[![Thumbnail 1390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1390.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1390)

Right now, the browser extension doesn't just need to know how to fill in a form, but also how to navigate to the form and how to navigate through the form, which is just a lot more complex. To make this a success, we're going to need website-specific logic and website-specific instructions on how to complete the login.  As you can guess, this doesn't scale if you need to do this by hand because there are millions of websites out there that offer a login. Even if we were to undertake this massive effort, it would be very brittle because we would see breaking changes on a daily basis, which is really not acceptable.

[![Thumbnail 1420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1420.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1420)

This is where Nova Act comes in. What we've done is built an AI agent that uses Nova Act and goes out and browses all these websites.  It collects the necessary information about the specific oddities of each website. Then we have a second agent that validates this intelligence that we've gathered and passes it on to what we call the site intelligence engine. The site intelligence engine makes it available to our browser extension, and the browser extension runs on the user's device. The nice thing about this is that all the information gathering and validation can run on our infrastructure out of band, and the browser extension login flow will remain blazingly fast and also deterministic, which is really important. The validation can also run on a periodic basis to see if the intelligence that we've gathered is still accurate and correct, and if not, we invalidate it.

[![Thumbnail 1470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1470.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1470)

[![Thumbnail 1480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1480.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1480)

[![Thumbnail 1490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1490.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1490)

[![Thumbnail 1500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1500.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1500)

Let's look at an example of a Nova Act agent in practice.  Here  it's going to navigate to the AWS re:Invent website, and this is actually a pretty simple example because its job here is to get to the login form.  As you can see on the top right, it has a big login icon, so this is a pretty simple one. Let's see if it's able to find it.  There we go. Now it found the login form and it knows that it completed its task. Now let's look at a slightly more complex example.

[![Thumbnail 1520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1520.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1520)

[![Thumbnail 1530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1530.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1530)

[![Thumbnail 1540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1540.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1540)

This one is a bit trickier. This is Duolingo, and it doesn't have a traditional login button at the top right. Instead, it has a button that says "I already have an account." To make it more complicated, it doesn't have an href tag.  It has a JavaScript handler, and this would be a bit more tricky to build with a heuristics-based algorithm. However, for humans it's super easy because it's just "I already have an account."  Because Nova Act takes the same human approach, it's able to get to the login form just as easily. 

Now let's look at the logs here. Along the way, Nova Act will log the steps that it takes as part of the evaluation loop. Here you can see it really thinks like a human. It knows what it needs to do and it says it found the button that says "I already have an account." Then it figures out that it should click it, does the actual click, and then evaluates the result again. It knows that it found the login form and that it completed its task and needs to return now.

[![Thumbnail 1580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1580.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1580)

To recap, website-specific intelligence can  meaningfully improve the 1Password products, and Nova Act is really the thing that enables us to do it at this scale in a way that we just couldn't have done in the pre-AI era. We still have a long way to go here. We're just scratching the surface, but you can already try out the new universal sign-on UX in the latest beta version of the 1Password browser extension if you're interested.

[![Thumbnail 1630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1630.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1630)

### Amazon Leo's QA Automation: From Prototype to 200 Live Scenarios in Five Weeks

I'll pass it on now. Perfect. Thank you, Floris. That was super interesting. Now I'd like to invite Matthew from Amazon Leo. Hey folks, I'm Matthew. I'm from Amazon Leo. Amazon Leo is the next generation of satellite Internet connectivity that Amazon is building. We currently have 158 satellites  in space right now, and we're always launching more. Space always elicits a little sense of wonder and whimsy, right? As we get closer to launching our beta product, we had a really big task because we set zero critical customer bugs being reported across our web and mobile browsers. That's really aggressive, right? We have hundreds and hundreds of test cases we need to perform.

[![Thumbnail 1680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1680.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1680)

We have an aggressive timeline because we're always building and always shipping, and we have weeks to do this, not months. I'm going to talk a little bit about how we leverage Nova Act to go from a prototype into a production-grade QA automation system today. Traditionally, you see that our  traditional automation has really complex code. You have to work with multiple frameworks, and each of those is really its own unique specialty, right? You need people who understand Appium selectors for mobile if you want to serve Android and iOS. You need somebody who really understands Selenium or Playwright and knows how to handle page jitter and how long you should wait. You've got to get it just right.

[![Thumbnail 1710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1710.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1710)

Nova Act likes to invert that, right? I don't need to know that anymore. I don't need that specialty. Instead, what I can do  is turn something else into it. What we've done is taken a more opinionated approach to natural language. We had hundreds and hundreds of these Gherkin test cases, you know, given-when-then, for our customers. We built an agentic framework around it. On one side, we take this given-when-done statement, we use a Strands agent like we saw earlier today, and we convert that into the Nova Act command on the fly. Then we determine what type of test this is. Is this a web test? Is this a mobile test?

[![Thumbnail 1780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1780.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1780)

If it's web, we use the Playwright actuator that comes baked in with Nova Act. For mobile though, Nova Act doesn't support it, but they do have a really extensible SDK framework that allowed us to write our own Appium actuator to go in and start performing these actions in our mobile app. So we have one SDK, one unified interface, with no platform considerations anymore. You just run the test, and it figures everything else out for you, right? One of the other things we talked a lot about today is the 90%,  right? When you're running QA automation and you're looking for understanding the perfect customer experience, you need that to really get closer to 100%, right?

One of the other things that Nova Act provides us is the ability to export a trajectory. What that is, is every piece of information that Nova Act performed during the test, it saves. It saves a picture of the page, the DOM, where it clicked, and how it thought about the problem.

We can then replay that deterministically for our next run. We've built a self-healing replay engine as well. As our page changes and our customer experience changes, our core mission of the test case hasn't changed, but the page has moved around a little bit. When we fail our test case because we couldn't match it in the deterministic way anymore, we rerun it intelligently and then save that. The next time through, it passes. We're running three times faster with no more non-deterministic behavior that we worry about repeatedly. We get really good confidence that our experience is shipping the way we want it to.

[![Thumbnail 1860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1860.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1860)

[![Thumbnail 1870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1870.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1870)

[![Thumbnail 1880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1880.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1880)

[![Thumbnail 1890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1890.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1890)

[![Thumbnail 1900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1900.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1900)

Let's take a look at what this looks like in action.  Step one: given a user successfully navigates to Leo.amazon.com.  Step two: when the user clicks on the join the list button in the header.  Step three: the user enters leo.user@amazon.com into the email input field. Step four: the user enters 98052 into the postal code input field.  Step five: the user selects United States from the country dropdown. Step six: the user clicks the submit button.  Step seven: then the user should see a confirmation message indicating successful submission.

What you got to see is that we transformed everything on the fly and we're running this in real time. We get to see how our systems are thinking about it. It's very easy for us to debug and it gives us really high confidence in both when we see a failure, understanding why we're failing, and when it's passing, knowing exactly why. We can see the type of customer behavior that's going to happen in real time.

[![Thumbnail 1940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/1940.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=1940)

 We went from prototype to production in five weeks. The first one or two weeks were really setting the groundwork, making sure our agents could handle throttling and all those little things when you're engineering. Weeks three and four, we got to production ready, moving it into accounts that can hold and manage all the data we're running through. Week five, we're now running 200 live scenarios with 3600 validation points across web, iOS, and Android. We've estimated and saved about 60 dev days to date and we're saving another 30 every month.

[![Thumbnail 2000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/2000.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=2000)

[![Thumbnail 2020](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/2020.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=2020)

### Sola's Agentic Process Automation: Powering Enterprise Workflows with Near 100% Reliability

Thank you and I will bring up Neil. Cool, thank you, Matthew. Now I'd like to introduce Neil from Sola. Thank you, everyone. I'm Neil,  co-founder and CTO of Sola. As we know, enterprise work today happens across more systems, teams, and tools than ever before, and process automation remains a massive challenge with teams struggling to get value.  So what do we need in this next generation of process automation tooling to automate meaningful core operations of businesses? We need the tool to understand what people do. That means observing their work, figuring out their process, and capturing logic and context effectively. We need it to generalize across all these systems on browsers, on desktops and beyond. We need it to handle challenging and dynamic digital work. And of course, we need the solutions we build to scale to enterprise volume.

[![Thumbnail 2060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/2060.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=2060)

This is where Sola comes in.  Sola is an agentic process automation platform. Some of the largest enterprises in the world, Fortune 500s and the largest private enterprises across verticals and industries use Sola to power their businesses, building intelligent, flexible automations that do everything from medical data entry to financial compliance to legal back office and much more. Sola automations sit on top of systems and interact directly with digital applications. Underneath the hood, this is powered largely by computer use agents. They're the systems that everyone's been talking about today. They are systems that can see, understand, and operate applications just like you and me.

[![Thumbnail 2110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/2110.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=2110)

In this video, we can see a Solobot running a  generalizable track and trace workflow. The Solobots can understand how a workflow is done by watching someone do it, converting their process into a visual diagram that users can modify. Then it can execute real executions of these workflows, adapting to dynamic interfaces and automatically updating the diagram based on encountered scenarios. It does all this while providing observability and learning from human intervention when needed, becoming better and better over time. These bots help handle some of the most complicated manual workflows for businesses at scale.

[![Thumbnail 2150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/2150.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=2150)

 A lot of what powers this is Claude models, and we use a variety of them under the hood. Nova Act in particular fills an important niche for what Sola does. It's a powerful workhorse for our computer use needs. Nova Act is steerable, adheres to complex instructions reliably, and allows us to enforce strict guardrails to guarantee the reliability that enterprises need. It's able to handle complex interfaces with state-of-the-art intelligence while operating in real time.

[![Thumbnail 2190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/2190.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=2190)

Here's a simplified diagram of how a  Solobot can use Nova Act, and generally it's a reliable framework for using Claude models. If there's an instruction that's been scoped to Nova Act, the Solobot will hand off the task to an orchestrator agent. This agent has those instructions along with context about the workflow, the current execution, previous executions, business context and logic, and more. Given all that information, the agent will break down the task into subtasks. In this case, we have action A, action B, and so on. The actions will be handed off to Nova Act sub-agents, which will go off and complete those tasks.

[![Thumbnail 2240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/2240.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=2240)

Then given all the context described before, along with the output of the Nova Act sub-agent, which has transparent reasoning and action traces, the orchestrator can validate that action and plan and update subsequent tasks accordingly.  Nova Act is specially built for this kind of UI automation. The piece I mentioned before is just one part of our agent harness. We have many places we use Claude models. The Nova Act SDK makes it straightforward to integrate across our entire platform while also automating and supporting the observability that we need for monitoring. Its extensibility allows us to set up custom tools to complement the rest of our harness.

[![Thumbnail 2280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/2280.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=2280)

As a workhorse model, Nova Act is fast and reliable, keeping workflows moving in real time, while also automatically handling edge cases like complex error states and conditional logic, while also effectively calling human-in-the-loop when needed.  Here's a more advanced fleet orchestration pattern that the Solobot can deploy, which I also think is a good framework example. Similar to before, the orchestrator can break down actions into tasks, but here these are handled by Nova Act sub-agents in parallel. The thinking and action traces and the results of each of these Nova Act sub-agents are aggregated via an aggregation agent that's then passed back to the orchestrator to plan and conduct future tasks. With this kind of system, we can achieve near 100% reliability on these core enterprise workflows.

[![Thumbnail 2320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/2320.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=2320)

Here we can zoom in on a specific case.  On the right we can see a representation of the visual diagrams on the Sola platform. On the bottom left we can see an example of a portion of this workflow where it's logging into a medical portal, navigating to the patient, and updating the patient field. On the upper left we can see the agent traces. This is the model doing that update patient field. In this case, it's non-trivial. It's not just updating one specific field. The model needs to understand that it needs to click on a button to add an entry, and then it needs to look over the entire form, figure out exactly where in the form that update needs to happen, and then put the relevant information in very reliably.

[![Thumbnail 2360](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/2360.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=2360)

So Sola is a customer of  Nova Act, but downstream of that, companies like R1 RCM, one of the largest revenue cycle management platforms in the US with tens of thousands of employees, use Sola to tackle back office work. For definitions, RCM stands for revenue cycle management. It's basically how your doctors get paid. Because Sola workflows are adaptable, they can handle the hundreds of different payment platforms that a portal like R1 needs to interact with on a regular basis.

[![Thumbnail 2390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/a95e969498dd89f0/2390.jpg)](https://www.youtube.com/watch?v=uOMh88Fz40M&t=2390)

 Nova Act has been integral to the Sola platform, allowing us to push the boundaries of what computer use models are capable of to conduct real world work for enterprises. With partners like AWS we're able to support automating the most core and critical operations of businesses today.


----

; This article is entirely auto-generated using Amazon Bedrock.
