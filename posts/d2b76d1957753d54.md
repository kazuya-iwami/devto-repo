---
title: 'AWS re:Invent 2025 - Transforming Cable Network Reliability with Agentic AI & Graphs (IND3332)'
published: true
description: 'In this video, AWS and Cox Communications demonstrate their journey toward autonomous, self-healing cable networks using AWS''s AI and analytics framework. Cox reduced customer calls by 22%, truck rolls by 10%, and impaired minutes by 48% through their Service Health ecosystem, which combines digital twin technology with real-time telemetry from 40,000 nodes. The solution leverages Amazon Neptune for topology graphs, OpenSearch for event management, and processes 200 million transactions daily. Cox deployed "Anton," a Strands-based agentic AI assistant that provides root cause analysis in minutes versus hours of manual work. The presentation details their progression from reactive troubleshooting to proactive network operations, emphasizing data foundation as essential before implementing AI, and introduces Amazon Bedrock Agent Core for production-scale agent deployment with standardized tools, memory systems, and observability capabilities.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/30.jpg'
series: ''
canonical_url: null
id: 3093139
date: '2025-12-08T20:35:00Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project enhances multilingual accessibility and discoverability while preserving the original content. Detailed transcriptions and keyframes capture the nuances and technical insights that convey the full value of each session.

**Note**: A comprehensive list of re:Invent 2025 transcribed articles is available in this [Spreadsheet](https://docs.google.com/spreadsheets/d/13fihyGeDoSuheATs_lSmcluvnX3tnffdsh16NX0M2iA/edit?usp=sharing)!

# Overview


ðŸ“– **AWS re:Invent 2025 - Transforming Cable Network Reliability with Agentic AI & Graphs (IND3332)**

> In this video, AWS and Cox Communications demonstrate their journey toward autonomous, self-healing cable networks using AWS's AI and analytics framework. Cox reduced customer calls by 22%, truck rolls by 10%, and impaired minutes by 48% through their Service Health ecosystem, which combines digital twin technology with real-time telemetry from 40,000 nodes. The solution leverages Amazon Neptune for topology graphs, OpenSearch for event management, and processes 200 million transactions daily. Cox deployed "Anton," a Strands-based agentic AI assistant that provides root cause analysis in minutes versus hours of manual work. The presentation details their progression from reactive troubleshooting to proactive network operations, emphasizing data foundation as essential before implementing AI, and introduces Amazon Bedrock Agent Core for production-scale agent deployment with standardized tools, memory systems, and observability capabilities.

{% youtube https://www.youtube.com/watch?v=TeJCah7NeC8 %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 30](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/30.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=30)

### Introduction: From Data Analytics to Agentic AI in Cable Networks

Good morning everyone. At AWS, we believe that the future of network operations is not about just collecting data, not even analyzing it. It's about data that acts. Today we are going to talk about how Cox is pioneering on that journey along the continuum from data analytics to agentic AI, transforming their cable network  from reactive troubleshooting to self-healing autonomous networks. I am Pooja Chikkala, AWS Solutions Architect focused on end-to-end transformation for Cox. I'll have my fellow presenters introduce themselves.

Hi, I'm Joe Keller, Vice President of Network Analytics and Reliability Enablement. I'm Brad Pfaff, AVP of Data Science at Cox Communications. Hi everyone, I'm Imen Grida Ben Yahia, Principal AI Scientist at AWS working on network and AI.

[![Thumbnail 70](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/70.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=70)

[![Thumbnail 90](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/90.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=90)

Okay, so let me start. First of all, we will start by presenting  the AWS solution framework for the network and AI use cases, and then we will focus on the autonomous network journey as well as the solution on AWS, namely Service Health. Then we will finish by the next steps and how we are assessing new services in the journey towards autonomous networks. 

[![Thumbnail 100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/100.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=100)

### The Telco Autonomous Network Journey: From Manual Operations to Closed-Loop Systems

So let's get started. For CSPs across the globe, all of them started or are starting their autonomous network journey. So let me emphasize the word journey here. There  is no one product that will make it for all the network operations, the capacity planning, and the optimization. It is a data pipeline and it is a journey. It means we start now and you keep enriching until you are satisfied with the different use cases that you are going to put in place to optimize your network operation.

So what is the telco autonomous network journey? It is structured by TM Forum as different phases. It goes from manual operation where you need to manage your thresholds, your rules, your hardcoded scripts that you put across different network segments to the top level, which is closed-loop-based operation. So what does it mean? It means your network is capable of sensing the data, understanding the data, reasoning on top of the data, and taking actions from the data as Pooja was introducing.

[![Thumbnail 170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/170.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=170)

For that, we want to introduce the requirements that take us from this high-level description of autonomous networks to what are the requirements that we need to go there. Basically, this will go from  the data part until the autonomous execution. The first layer is about the data. The data is your fuel. The data from the network is, for example, the KPIs, the key performance indicators. It is the telemetry by means of the syslog, the counters, even the alarms that are coming from the different networks, and also the configuration files. So all of this needs to be extracted and put available so that you can on top of it prepare the processing, the normalization, and the transformation of the data.

So all of this will happen in the second layer, which is the knowledge fabric. Your machine learning, deep learning, analytics, and agents need knowledge to listen. They need knowledge to be able to produce for you the insights that you need for the network operation. So the knowledge fabric will go from the transformation of your counters, the raw counters, into time series, which is a tabular format from which you can have forecasting, you can have anomaly detection, or you can have deviation detection when you are monitoring your network.

It goes also to the capturing of the dependencies between the different network nodes and the changes over time. So this is useful for change management, useful for root cause analysis, useful for service impact assessment and different use cases. It is also about having the embeddings by means of the service level agreement documentation, the different vendors' documentation, the description of the alarms, the description of your equations, and any documentation that are relevant for the network domain.

So once you cover the knowledge fabric, then the fun part will start, and the fun part is where you are going to enrich with intelligence. It goes from the simple analytics layer to the machine learning and deep learning, as well as to the foundation models. And what I love in Cox's approach is that they really work their data foundation very well in the sense that they have the right intelligence for the right data format, and now with agents they are capable of having the right agent because all the data foundation is available in terms of spatial information and temporal information that they are leveraging from the network.

[![Thumbnail 320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/320.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=320)

So for those from the telco autonomous journey to the  requirements, what are we offering in terms of services? How are we enabling our customers to go into that journey of autonomous networks?

### AWS Solution Framework: Services and Tools for Network Intelligence

First of all, it was about the execution, about the agentic part. For the agent, first of all, you need to create the agent, and to create the agent you need a framework. Here is Strands Agents. It's an open source framework that you can use to create the agent, to create the interaction between the agents, to enable the different communication between the agents. The second part is about the life cycle. An agent is a piece of software that needs to be updated, governed, and observed, and this is all through Amazon Bedrock AgentCore, and we will touch base on that in the last part of the presentation.

Here I will leverage a sentence that our VP mentioned about the autonomous, automated reasoning. We don't want the foundation model to be creative for the network here, especially in our domain. We want it to be exact, accurate, and generate for us the right configuration or generate for us the right troubleshooting that we will be executing in the network, and this is all through our automated reasoning framework that is part of Amazon Bedrock today. The last part is just to mention that AgentCore is for any model and any framework, so we are open. You are capable of using open source frameworks or any custom model that you have, and then you can leverage AgentCore for the observability and the maintenance of your agent.

[![Thumbnail 420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/420.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=420)

The next part is about the purpose-built databases. As I said, the data is the fuel and the agent  or the machine learning, deep learning, they all would need the data to be able to build the insights for you. So the first part for the Amazon S3 vector, this is one of the most common use cases in the network domain. You have a lot of documentation and you want to go for the agentic RAG architecture at scale. Amazon S3 vector is proved to be cost effective and can enable you to extract the information from this documentation from the network.

The graph part, and when I say graph, I don't mean just graph, I mean graph techniques, and graph techniques are very suitable for the network today because the network by definition is a graph and you want to capture the dependencies in between. So there is a huge change from the legacy graph databases to the loosely coupled techniques of graphs that we have now. We have Amazon Neptune for the graph storage databases for the persistent workload. We have the graph analytics where you can run different graph algorithms to have statistics on graphs, to have, for example, the most important node, to have what is the shortest path from a node to another, and you can leverage this for different network operation tasks. And you have the graph deep learning framework. It's an open source framework that you can use for forecasting, for anomaly detection, and for different deep learning on the network data.

So this will take us to the three types of intelligence, and this is also in Cox's approach, and Joe and Brad will mention it later on. They have the different layers of intelligence. So the analytics part, which is the statistics on your data, is very important. The aggregation of your data is very important. You cannot skip the analytics part and go to the agentic part. So here we offer different tools for the intelligence part from Amazon SageMaker for the deep learning and machine learning in general, as well as the graph analytics in the database and the analytics engine, as well as built-in algorithms that you can find already in SageMaker.

The last part that was announced this week is about the customization. So as you know, the network is a domain where you have different vocabulary that is specific to the network, and for that, the trend that we are seeing now to scale and to be able to capture the majority of the information that you have on the data, the customization of the models is very important in the network domain. And here we just announced this week several techniques for customization that will enable you to specialize the model in an easier way, and then you can have at scale different small models instead of large models for all the tasks that you are doing for the network.

[![Thumbnail 580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/580.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=580)

[![Thumbnail 590](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/590.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=590)

So this is to insist on the graph part because this is also in Cox's approach, one of the most important  pieces that we've used, and around this, of course, all the other techniques of intelligence that are federated with it.  So we are using different services to be able to build this journey towards the autonomous network, and those databases, the first layer is the database layer. Again, it's about the data, and as I was explaining, it goes from your embedding to your topology to the events that you are collecting from the network.

Then you have different tools for the intelligence part, from SageMaker as a framework, Bedrock as a framework for the foundation models and large language models, and Neptune Analytics for the analytics part. Then the rest, as I was explaining, is the execution autonomous layer. As I was explaining, it's all about the agentic AI that will go and grab the insights from those different layers.

[![Thumbnail 640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/640.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=640)

### Agentic AI Use Cases: From Orchestration to Autonomous Execution

So what we were doing  across the different customers, from cable networks to mobile networks, and this goes to the radio access network, transport, and backbone, different use cases were coming up all the time from different customers. I will not go through all of them, but I want to mention that we have three big categories. The green part is about the orchestration, the governance, and the planning. So in this category, you will have an agent that will be triggered by the events happening in the network, for example, severe alarms occurring or spikes coming from the volume of alarms. This will trigger the orchestrator to understand what's happening on the network and trigger other sub-agents in order to make sense of what's happening in the network.

So this is the green part, and in the green part also you have the guardrail and evaluation. This means that you have an agent that will make sure that you are triggering the right agent, that this agent has the right to access this data, and has the right to share this to the users that are requiring this for the troubleshooting. So this is all to secure your data and make sure that you have the right agent with the right authorization to access your sources of information.

The pink part is where the subject matter expertise about the different use cases resides. The observability on demand is all about you talk to the network and extract the information. It can be troubleshooting, it can be for recommendation, or it can be for assessing the health of the network. So it is a what-if scenario where you connect to the performance management data, to the alarm data, to the topology data, and to the embedding, and then everything for different purposes.

The proactive manner is triggered by events happening in the network and sharing with you the reporting, so you don't need to ask questions. It's the network talking to you and giving you the event analysis, the event prioritization, as well as recommendations of what to do. So this is one of the most asked and used use cases across the globe today for mobile and cable networks.

The second one is about root cause analysis or service impact. It is more of a what-if scenario where the dependencies matter a lot. Dependencies means change management and service impact. I have a failure and I want to know what was impacted on the network, or I have a problem on the run but I see impact across the different network segments. How can I capture all this dependency? And this is also, we will see it in the case of Journey to Autonomous Network, how they were leveraging the concept of digital twin inside their Service Health platform.

The other use cases I will not go there, but it's more to go to the closed-loop configuration generation and activation of the network. This is more to say how we can recover from the problem in the network, not only recommending what to do but also restarting, for example, the network node, the base station, or it could be reconfiguring the capacity for the different network nodes in order to absorb, for example, the congestion that was happening in the network.

The yellow part are completely new use cases, so these are more in the ideation phase. But how to explain them in an easy way? It is that 80% of the work today is the preparation of the data, of the network data. So our customers are asking us how we can infer the topology from raw data instead of me writing hundreds of jobs. How can I shorten the data engineering part by having agents that will understand my data and prepare it in the right tabular format, for example, from heavy XML and into ready tabular data that I can use for different purposes? Or how can I build the feature engineering for my classic models? For example, the congestion run, I will know what are the exact features from hundreds of them.

So this is all to accelerate the path towards using more and more AI in the network, and of course the two bottom layers, network knowledge and the intelligence on the top, as I was showing in the previous slide. Now we will focus on the digital twin concept and how this fits the Service Health platform that the team will be showing you.

[![Thumbnail 880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/880.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=880)

### Digital Twin Architecture: Mirroring Networks in Real Time

So basically, first, a definition. Digital twin is a buzzword.  Here we have an exact, precise definition of what we want from this digital twin and how we are using it in the different network use cases. So think of it as mirroring your network in real time. It is the way that your data from the spatial and temporal perspectives are federated together in order for you to build on top of it all the insights.

So basically, it is not only showing you how your networks are connected, but how your network nodes are evolving over time and how they are impacting each other. And again, when I say as a graph, it doesn't mean only database. It is also the graph analytics, the graph deep learning, and it's also the federation with all the purpose-built databases for time series and for tabular data. This is very important.

[![Thumbnail 930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/930.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=930)

The next part is to show you  a possible flow of how you construct your digital twin. And you will see in the approach how they are building it with two major components: the event-based part and the graph-related part with all the telemetry. So here it will walk you through the different steps. We start by constructing and discovering the network nodes from the topology and different operators. They don't have accurate inventories today, so we need to work out how to construct this in an automated way. That's the first step.

The second step involves techniques that help you with the data quality so you can figure out if some links are missing or some information is missing from this graph representation. And step three is where you bring the telemetry, the alarms, all together in a federated representation that mirrors your network in real time. And of course, this is all automated and maintained over time to reflect the exact status of your network.

Steps four and five start again. Once you have step three done and you have your federated representation of the network, it's where you can start building all the intelligence or leveraging this data with different machine learning and analytics parts. Here I just want to mention option two. So usually you need to train models for you to do the forecasting. We announced one month ago a model called Chronos 2, and it is for multivariate time series, so you use it as is to predict the next value, for example, the spikes of your alarms and what will be the next values. So this is again an easier way for you to leverage more intelligence and of course deliver this to the agent to make sense of it for different use cases.

[![Thumbnail 1040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1040.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1040)

So from  that view of flow, this is how it looks like when it is put into an architecture, and this architecture again is very high level and data driven. Again, this is to show you that I don't have a pointer, but if you look at the agentic part on Bedrock and Strands, you cannot connect them directly to the raw data that is in S3 bucket here. You need to go through those steps. There is no magic. It's a data pipeline. You need to prepare the data in a way that the agent will consume it in the right way.

An agent by definition is instructions, tools, and tasks to do the task that the use case would need to be done, but you cannot connect it directly to the raw data. You need to go through the processing, enriched with intelligence or enriched with normalization and transformation of the data in general. When you have the network knowledge, then you are ready to leverage this information with your agent. So this is just to give an example.

[![Thumbnail 1100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1100.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1100)

So if I zoom in the previous slide, if I zoom on  the Strands agent icon there, we have a lot of them. So a lot of them means it depends on the use case, on the task, and on the different compositions of agents that need to be interacting together. So here we've seen these are the patterns that are coming back from different use cases: troubleshooting or recommendation or root cause analysis. You always need to have the observability layer, and the observability layer again is your agent connected to your data and bringing you the information in an on-demand aggregation or on-demand correlation of the data through these subagents together.

And through the observability layer, you decide to trigger, for example, the digital twin for the root cause analysis or for the change, but you are always basing that on first analysis of the data. This is always for cost effectiveness because the data in the network is huge and you have millions of events happening, so you need a way to filter before triggering the different layers of intelligence step by step. And of course, the last part is where you go to the actuation.

The actuation can go from simply creating a ticket on your system and then generating a report to the field engineer, but it can also be reconfiguration, again as I said, of a full slice of cloudified network, or it can be also triggering of a DevOps pipeline to do the change in the network. So these are the different steps and the most recurrent agents that are coming back across different customers.

So what we've seen in the first part of the presentation: What is the telco autonomous network journey? What are the requirements, the four layers, as I said, the data, the knowledge fabric, the predictive intelligence, and the autonomous execution? What are the services and the framework?

And now we will focus on how Cox is leveraging this toward their journey of autonomous network. Again, it is a journey, and Joey will join us. You will see how the digital twin concept is reflected into an implementation that is in production today.

[![Thumbnail 1230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1230.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1230)

[![Thumbnail 1240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1240.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1240)

### Cox Communications: Evolution from Reactive Troubleshooting to Reliability Operations

All right, so Imen provided us a nice background for the toolbox that we're leveraging from AWS to achieve our service health ecosystem. But first, before I get into that,  who are we? What's Cox Communications? Cox Communications is a multiple-service operator providing data, video, and voice services to over 6 million  customers, both residential and business. We deliver those services over 180,000 miles of hybrid fiber coax and fiber to the home networks, and we employ over 20,000 people. Of those 20,000 people, about 100 make up my team, Network Analytics and Reliability Enablement.

[![Thumbnail 1260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1260.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1260)

At Cox, we believe that one of the most critical  initiatives of our time is instilling reliability in our network services. A big focus for us has been and continues to be reliability. Historically, our industry relied upon our customers to serve as our primary diagnostic. Customers would have to call us, they'd have to describe the issues that they're experiencing, those symptoms, and we'd have to troubleshoot those issues to resolve their problems.

Transitioning from 2018 in that sort of antiquated way of approaching customer reliability, we started to focus on harnessing the power of data to understand what was going on across different systems, processes, and policies in order to identify opportunities for improvement. We really focused our lens through transaction reduction. The idea being that if we can reduce the calls and trucks, we're effectively hitting the root causes that are systemic to impacting our customers' issues. We really focused on beginning our data structuring journey around BI quality type data sets.

[![Thumbnail 1350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1350.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1350)

From there we began to transition into 2022, 2024, this novel approach that we have of service health, and this is where we really started to embark on our analytics journey, harnessing the power of all the massive telemetry and data available to us in our industry in order to better detect and correct or predict and prevent customer issues from happening. Ultimately, that has set us up for where we are now, a reliability operations focused organization that harnesses the power of that data to prioritize our labor  to go focus on the things that are most impactful to our customers first.

We have about 800 technicians serving over 40,000 nodes. Think of a node as sort of a neighborhood with about 200 customers on a node. We have to be able to effectively prioritize that labor in order to ensure that we're maintaining reliability for our customers. Prioritizing that labor is a big part of the equation, and also being able to isolate points of interest in that network, leveraging what Imen referred to as the geospatial components, the topology, coupled with the time series based telemetry. We'll talk about that a little bit more in a minute.

That has set us up for this really awesome time that we're in now. This novel time where we have this concept of agentic AI, and because we ate our vegetables, as I like to say, because we built the data sets, we started establishing traditional analytics applications, we can now harness the power of agentic AI to scale operationally in ways that humans would never be able to do.

[![Thumbnail 1420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1420.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1420)

### Service Health Ecosystem: Network, Node, and Premise Health Domains

This is our service health ecosystem, the high level capabilities that we've instilled over the course of 2022  to present, building through that data structuring journey. Really three domains to think of here. Network health, which is everything north of the head end. Think of the head end as sort of where all the signals come together, reach out to the public internet, access the fiber backbone. We have node health, which is everything from the cable modem termination server downstream into the neighborhoods, those 40,000 nodes I mentioned, 40,000 neighborhoods with 200 or so customers per node. Then you've got the premise, everything from the tap to the home.

Now service health is plumbed into all of our operational platforms. This is not an offline sort of analytics function. These are analytics applications built by data scientists and developers, integrated to the platforms that service our customers for self-service troubleshooting, up to and including rolling a truck to their home, that power all of our agent desktops for troubleshooting, and that also enable us to prioritize labor and ensure that we've got the right technicians going to the right place at the right time.

Starting with the left with network health, we're leveraging all of the probe data that we've collected through SNMP traps to aggregate and correlate to the topology that we have for our backbone, for everything that's north of the head end. This is probably our most nascent form of the domains that we're talking about here. We're just starting to embark on this journey. We should see a lot of that materialize over the course of 2026.

The middle section is very mature node health. This is where we leverage all the geospatial information relative to a node, line extenders, amplifiers, and all the cascades that happen in an HFC network, coupled with time series based telemetry. That would be all of your poll-based data from CPE or customer premise equipment, set-top boxes, cable modems, as well as all the information that we have for real-time streaming, online and offline traps. This is when a device loses its connectivity to the CMTS, to the head end. It fires off a trap that allows us to determine that that device is offline.

All that aggregates together to provide us three classifications of what we call events. First, there are urgent events. Think of this as your traditional outage, historically captured by customers calling us in. A certain number of customers over a given time period would trigger an outage. We now have telemetry-based online offline traps, as well as an awesome model that Brad and his team has built that allows us to predict imminent impairments and outages based on things like forward error correction and other issues with telemetry transmitting and received power levels. Then we have the critical events, which are effectively repeat urgents or repeat outages, scenarios where our business processes have failed and we need to provide special weapons and treatment to go address those issues.

Finally, we have impaired events. Think of impaired as your service is working, but it has hiccups or it's degraded. It's slow speeds, intermittent connectivity issues. Impaired nodes are a really big focus for us, and we've been prioritizing our labor based on the amount of healthy minutes that a customer has for their services. So for example, if you have 75% healthy minutes for a given node, you're going to prioritize that over a customer who has 90% healthy minutes for their node.

[![Thumbnail 1640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1640.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1640)

Finally, premise health allows us to certify the home and allow us to differentiate between issues that require an outside plant maintenance technician, those 800 technicians serving 40,000 different nodes or neighborhoods, from our home technicians that need to go to a home to fix an impairment that is resident in the home. Now the results speak for themselves. We've had a 22% reduction in call volumes, a 10%  reduction in truck rolls, and we've cut in half the number of impaired minutes that we have for our customers over the course of this year alone. So that's setting us up nicely for the agentic opportunities that we have because we have spent the time investing in these data sets and traditional analytics methods. We now have the ability to start expanding to support Agentic.

[![Thumbnail 1680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1680.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1680)

[![Thumbnail 1690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1690.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1690)

### Service Health Demo: Real-Time Visibility into 40,000 Nodes

I'm going to turn it over to Brad, who is going to walk us into a little bit of a view under the hood of Service Health and give you guys a taste of what we've done. Great, thanks, Joe. All right, so we're going to get into a little bit of a demo.  Let me give a little bit of context. So Joe mentioned that we have 40,000 nodes in the network, roughly neighborhoods  that we need to prioritize every single day. We have about 800 field technicians. Those are our plant techs. They're the ones driving the bucket trucks around the neighborhoods, climbing the poles, and fixing the issues. There's another probably 200 support staff between the NOC, the supervisors, and the leadership of our field teams. So they need visibility into where their techs are headed and what they need to be focused on any given day.

This view in Service Health is what we call our reliability view for our node health domain. It is showing all 40,000 nodes broken out by work zone, which is how we're routing our technicians, and it's a little bit more of a supervisor view. All of the ticketing and prioritization is automated out of Service Health, so these techs are already moving in the directions that we need them to go. But this gives the supervisors and our support staff the ability to quickly look at the nodes, where the technicians are, and any of the active issues in those nodes. So if they need a little bit of an eye in the sky or some support help, they can get it right here.

[![Thumbnail 1770](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1770.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1770)

[![Thumbnail 1790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1790.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1790)

I'm going to quickly click through the demo and kind of talk through what it's doing. So if you look over here on the left, this is the list of nodes. We're just quickly scrolling down the list right now. We're filtered to urgent nodes, so these are all those nodes that are going to have specific outages. We've clicked on a node and it pulled up  some information. You can see over there there's some technician history, so it's got recent tickets and tech activity just to kind of give a little bit of context to who might be out there and what might be going on. Then we're going to dive into kind of the core of the node health side of the application. So this is the UI that gives  essentially our digital twin for our node.

I'm going to pause right here. Right there, perfect. So if you think about what we described as the digital twin, there's really two main components of a digital twin. There's topology, so that is all of the assets in the network and how they're connected.

And then there's really all of the data flowing over the network. So that's all of our network telemetry. We even bring in a few more things into that concept, so customer transactions are really, really important. They're not our primary telemetry source anymore, but they're a really good additional value for prioritization because if the customers are feeling it and they're letting us know, we really want to make sure that we're elevating them.

[![Thumbnail 1830](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1830.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1830)

 So if you look at this UI, obviously the map stands out. That's one of those neighborhoods we were talking about, and so this is a neighborhood in Phoenix, Arizona, one of our biggest markets. If you look at the left side, you can see this is all time series data, so it's currently zoomed into about 14 days, and there's not a lot going on the first 13 or so of those days, which is great. That's what we want to see. It means the node is really healthy. Not seeing anything interesting in this view is essentially the goal.

Obviously in the last couple days you see that big spike of that pink and blue right there. That is the RF telemetry coming off of this node in real time. It's an aggregate of a bunch of different polling systems, and then right below that is all the customer transactions. So that's an aggregate of about 14 different contact points for Cox. Think of those as our mobile application, our website, our call center, various, our Wi-Fi application. Any time a customer's clicking and asking for help, there's nobody who wants to call their cable company for fun, so pretty much any time they're reaching out to us on any platform, it's interesting to us because they're looking for something. You can see in the time series view all of these things align, and so that's really, really powerful to see for our technicians.

[![Thumbnail 1920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1920.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1920)

[![Thumbnail 1930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1930.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1930)

[![Thumbnail 1940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1940.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1940)

So I'm going to let it scroll through for a second. I love a live demo. I'm going to let it catch back up.  And as that's catching back up, so the other thing that's going to highlight is our point of interest capability. So when the map pulls back up,  I'm not going to pause it again just so that we don't run into that. But I want to highlight the area in yellow on the map, and so as soon as it pulls up you'll  see it. There's a grouping of homes in that top section of that node that is an offline point of interest.

[![Thumbnail 1950](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1950.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1950)

[![Thumbnail 1960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1960.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1960)

[![Thumbnail 1970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1970.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1970)

And so when you think about that digital twin concept, essentially that's real-time telemetry coming  off of the modems in those homes aggregated through the topology into a least common ancestor, and we're going to go into the architecture of how we built all this in just a second.  So you can see the RF telemetry, we're seeing forward error correction, that's essentially packets are being dropped. We're panning over the customer interactions right now.  So this is our IVR, so that's our call center applications.

[![Thumbnail 1980](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1980.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1980)

[![Thumbnail 1990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/1990.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=1990)

[![Thumbnail 2000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/2000.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=2000)

Down here you're going to see these are the actual modems, the online offline traps that Joe was talking about, and then down below we actually have a bunch of process  information. So this is things like anomaly detection models and ticket information, so anytime there's a ticket that's active in the network,  it's all in real time in this system and the technicians can drill in and get a lot more detail into anything that they need here. So let's fast  forward.

### Under the Hood: Time Series Event System and Neptune-Based Digital Twin

All right, we're going to get into a little bit of the weeds here. This is a, I would say, a high level architecture view of what I think is probably the core of Service Health. This is really the time series event system for everything that we do. And when you think of that digital twin, remember it's time series data as well as topology data. So if you look on the far left, you can see the blue boxes. It's a little abstracted, but essentially, we're a hybrid team, right?

So we are analytics developers, so we manage production applications. In the case of Service Health, everything you saw is running in production in real time, high availability all day every day. But we're also an analytics team, so we do deep forensics into the network partnering very closely with our engineering teams, and so we need this system to be able to facilitate both the production use cases, but also anything that we want to experiment with or test or run side by sides.

And so from an input perspective, any telemetry event, any anomaly detection model, anything that my team is interested in just creating because they want to track it in the same system goes through a common framework here into an SQS feed, and we convert it into what we call an event. And an event in this case is essentially a pattern of interest with a start time and an end time and some aggregation of topology, and that's a key. So if you look down at the bottom, you can see where we have that digital twin. I'm going to call out Amazon Neptune, dig into there in just a little bit, but essentially any event we create, let's say we have an anomaly detection model for a node.

When an anomaly detection model identifies an issue for a node, we create the model and send it through the system. The system standardizes the format and enriches it based on all the customers that are on that node by bouncing it off our topology system. It then manages the open and close of that event in real time in OpenSearch. Pretty much every piece of data we have in Service Health goes through this standardization and gets managed in that OpenSearch database. We manage about 200 million transactions through the system daily, and we manage about 50 million events daily in this system. So this is really a workhorse, but that standardization gives us incredible capabilities to layer things on top.

Also, if you look on the right, those external applications, it makes the integration of those really easy. For instance, we are integrated into essentially any touchpoint at Cox. This system is also managing the customer communications about outages and issues. And if we have a new use case or a new feature we want to add, we don't need a new integration point. The data model doesn't change, and so it's very easy to iterate and adapt and add features.

If you look at that top flow, you can see that we also have this system producing all of our analytics assets for our team and the rest of the company. It goes through some processing, but eventually it lands in an S3 bucket where we can access it via Athena. That's where a lot of our data quality monitoring happens, but it's also where we are doing our analytics, and so everything you saw in the UI and management flows directly from this system.

[![Thumbnail 2210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/2210.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=2210)

So let's dig a little bit further into the digital twin.  Okay, so this is where I wish I had magic, but we don't. A very common and difficult challenge in any network, especially cable networks, is asset management. Cox is no different. We have probably 30 different sources of assets and topology across our domain.

If you think about the network, there are tens of millions of devices, dozens of layers, hundreds of vendors, and everything is managed a little bit differently. Some of these pieces of equipment have been in the network for 30 or 40 years, and so you're always at the mercy of how well the engineering team maintained their records or sometimes what is automatically searchable. But then you're at the mercy of firewalls, so there is really no magic here. This data is difficult. It is very difficult.

One of the things that really has helped us differentiate is our operational model where our team is very closely tied to the engineering and construction teams, and data quality is a focus. So it's not enough to have a working network. It needs to be a working network that is documented, that has those assets in the systems in ways that we can inherit and understand. Because none of the automation or the agentic or anything else is going to solve this problem.

What we have essentially done is defined a standard for our systems which we take from multiple different sources. We do quite a bit of transformation and a lot of quality checking to make sure that it is meeting those standards. And the part you're not seeing here is there's a lot of compliance reporting and a lot of goals around data quality for Cox. So these are things that the engineering team is accountable for, and we have robust feedback systems as well where when we aren't seeing something correct in our topology, we're flagging it upstream. Our users have the ability to flag that and it has processes that are going and getting that corrected in the source systems.

Ultimately though, we're processing it into a standard form, and we're managing it in AWS Neptune. We've been Neptune users for about seven years now. I can tell you that we are experts in everything not to do in Neptune, and we have broken it probably every different way that you can. But once you mature in that space, it's a really incredible system to use.

It manages tens of millions of devices in our graph cluster for our digital twin today, and it allows us to do some really powerful things like points of interest and clustering. One of the things that you'll see here is we do have a Strands agent that is sitting on top of our Neptune database. This is a little bit of a new venture for us. We actually partnered with AWS and did a workshop on this in the last couple of months.

Essentially what it does is it looks for places where we have known data quality issues. We have orphaned assets. We have assets that aren't connecting right, and we can find those things because we know generally how these layers of the network are supposed to look, and these are things that don't look like that. So what this agent is doing is it's pulling that data and it is looking at the right patterns. We've given it rules on what it should look like and then it's making recommendations on how to essentially repair the data in our network and then creating those edges in our graph as inferred edges.

So it keeps our systems running. They may not be perfect, but perfect isn't necessary here. Any connection is better than no connection in this case, and this system is all managed through a Lambda service, which is really our inroad for any of our other applications that need to understand this.

So the way that that Lambda works at a very high level is if I come in with a request from anything, one of our analytics users, another application for an event creation at some router node, doesn't matter, some piece of the network, it will bounce off this system. It understands all of the downstream devices and customers connected to that system, and so it can enrich that event with all of that rich detailed information, which allows us to do some really powerful joins and analytics with all of the other telemetry. The other thing it does is imagine you have a customer who is impacted by something. You can query this service for that customer, it will follow the chain of their topology all the way up through the network, and then you could very quickly join all of the other events and things that may be touching or influencing them. And so you can get some really powerful correlation going very quickly because it's all kind of a standard format.

[![Thumbnail 2490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/2490.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=2490)

All right, going to move quick through this one, Digital Twin Point of Interest. So you saw the Point of Interest.  This is essentially a closed loop system. So we have some configurability here, but essentially we're telling the system what events are interesting. Go pull those events from OpenSearch anytime you see them, run them off of that topology that we mentioned through some custom least common ancestor techniques that we've put together, and then create another event. So that's the big key here is it pulls from our event OpenSearch environment, does some analytics, creates another event, right? So it doesn't change any of the flows. It's very easy to kind of keep sourcing, and you don't have to have multiple endpoints for everything.

[![Thumbnail 2540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/2540.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=2540)

[![Thumbnail 2570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/2570.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=2570)

### Meet Anton: AI Chat Assistant for Network Troubleshooting

Let's quickly get into, I'm clicking the wrong button, good times. Okay, let's quickly get into  some of the agentic stuff. So this is one of the things that we started doing a couple months ago. We have all of this rich information, but we're still sending tickets to people who need to do research, right? And so this is where the agent capability really shines. So I'd like to introduce you all to Anton.  This is Anton. So Anton is named after one of our more senior developers. He's been with the company for 20 years. He's a staple of the team, but essentially this is a chat assistant that lives directly in Service Health in production, and all of our technicians have access to it.

[![Thumbnail 2590](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/2590.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=2590)

[![Thumbnail 2600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/2600.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=2600)

And so when you look at what Anton can do, I will quickly run this is the executive summary prompt. It's just a pre-canned prompt. You can ask him anything you want. It's a fully fledged  chatbot, but in this case this is that same node, and I'm going to let it scroll through real quickly, and I really want to highlight here the root cause. So if you look at what Anton did,  he has tool access to everything in OpenSearch, he has tool access to everything in Neptune, and he has tool access to all of that rich data and is able to really quickly compile it all into something that would take a human upwards of a couple hours, right, combing through tickets and events and logging into systems, specifically that root cause there. So the root cause of this faulty customer drop at an element right there was introducing significant upstream noise to the network. The issue was initially resolved with a multibranch connector with a temporary service interruption to the rest of the node.

So that is super powerful, right? Essentially what happened is a customer had a bad drop, ingress got into the network, technician got out there. The big offline spike you saw was actually our technician fixing the issue, which took the node down for just a minute, and then they put it back and everything got repaired. This is kind of the beginnings of our AI capability. So let's quickly show you how we did it.

[![Thumbnail 2670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/2670.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=2670)

Okay, high level design for this is relatively straightforward.  Some of you are probably looking at this and saying, well, I don't see AgentCore. That's true. We started our agentic journey about a month and a half before AgentCore was announced, and so one of our philosophies is we need to get things out. So we locked our architecture and said we're going to go to production as is and we're going to build our own thing. We're currently looking at AgentCore and are likely to convert here in the next quarter, but the way we did it is we have a routing Lambda which manages all of our agents. Then we essentially have SQS backlogs where we send all of the input token requests into a backlog for whatever agent it is.

The agent scales out and chews through them as necessary, sends it back through another SQS, same to that same routing Lambda. So that routing Lambda acts as essentially an asynchronous API for anybody that's requesting it. It could be another agent, it could be the front end of our Service Health application, could be a user in SageMaker. We also have OpenSearch down there as a vector store for caching, and then we are using obviously Strands and Bedrock as our core component. And then we have a common tool set off of all the architecture that I just mentioned that's accessible by all of our agents.

[![Thumbnail 2760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/2760.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=2760)

[![Thumbnail 2770](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/2770.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=2770)

### Agent Core and Key Takeaways: Building Production-Grade Autonomous Networks

So that's a lot. You're gonna hear a little bit more about Agent Core, so Pooja, the floor is yours. That was insightful.  So let's talk about Agent Core and how it fits into Cox's autonomous network vision.  Right, today, as Brad pointed out, there are agents that are deployed using Strands, and they're running on Amazon EKS. But as we move towards the next level of self-healing networks, from level 3 where these agents recommend actions, to level 4 and eventually level 5 where agents detect, diagnose, and remediate actions, we need a more production-grade, robust system, and that is where Agent Core comes in.

[![Thumbnail 2840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/2840.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=2840)

Agent Core is Amazon Bedrock's comprehensive agentic platform that lets you deploy agents at scale in production. It has modular components for runtime, memory, identity, gateway, and more, and also the newly announced Agent Core evaluations. But for today, we'll only focus on gateway, memory, and observability. So let's talk about Agent Core Gateway.  Today, agents access various tools like Neptune for topology, OpenSearch for events, but each of these integrations is custom built. Agent Core Gateway changes that in a way that it provides standardized communication platform using Model Context Protocol or MCP, and adding new capabilities now becomes just plug and play.

[![Thumbnail 2890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/2890.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=2890)

Want to add an automated remediation tool? Just register it with Agent Core Gateway. Want to add self-healing smart amplifier workflow? Same thing, register and go. No code changes needed. There is a consistent API that agents use to access these tools. Now about Agent Core Memory  and how they can transform the current agents who are right now working in isolation on the current incident to an intelligent system where they can learn and improve over time.

Today these Strands agents have some context of the incident that they're troubleshooting, but they're largely working independently on that issue. Agent Core Memory brings two components, short-term memory and long-term memory. This is just like human memory, right? So short-term memory provides the current context, the incident at hand, the telemetry readings that you are seeing, what actions have already been taken. This lets the agent focus on the current incident.

But where the real transformation comes is from long-term memory, because now you can have institutional knowledge. Each agent has access to this system which has insights into what has happened on this node in the past, what actions have been taken, what resolutions have worked, what specialized technicians are best suited for a specific type of issue. Think of this like each agent having 20-year veteran experience at hand every time. This memory architecture brings continuous improvement. Every issue makes the agent smarter. Every resolution adds to the knowledge base.

[![Thumbnail 3000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/3000.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=3000)

And finally, coming to Agent Core Observability.  As we move towards highly autonomous networks, visibility into what your agents are doing becomes more important,

and Agent Core observability provides that visibility at various levels. At the agent level, you can trace into what these agents are doing, what it costs, how many tokens they are using, and with that you can optimize your performance and control the costs. At the workflow level, you can trace how your supervisor agent is calling these specialized agents, what their reasoning process is, what tools they are invoking, and then you can correlate this with business outcomes like custom impact metrics, truckload reductions, and service reliability improvement. This lets you tie directly into business impact.

With observability, you can prove that agents are making the right decisions, identify when your agents need better tools or training, and link that to business impact and showcase value to business stakeholders. So now we have talked about how Agent Core can take us on the journey to the next level of self-healing autonomous networks. We have partnered through this journey very closely with Cox, and AWS is committed to partnering further as Cox continues to push the boundaries on what is possible for the future of network operations. With that, I will hand over to Joe for key takeaways.

[![Thumbnail 3120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/3120.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=3120)

[![Thumbnail 3140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/3140.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=3140)

Thanks. Right, exciting stuff, right? So a couple of things that we've learned on our journey. As Brad said, there's no shortcut, and so a lot of these results are the result of  hard work and effort put into eating our vegetables, building out our data sets, investing in understanding how analytics applications work, partnering, and working through organizational challenges. Again, 22% reduction in calls, 10% in truck rolls, and a 48% reduction, cutting in half our impaired  customer minutes. Pretty amazing stuff for us.

Here's really where the takeaways that we want you guys to take back to your companies, to your employers. Data is everything. There is no shortcut from here to there. You cannot skip go and go straight to AI. You've got to take the time to work on high velocity data, understanding high quality. Brad mentioned a lot of the measurement systems we put in place, inline analytics applications plumbed into operational platforms, and then being able to have that observability that you build to understand how the network is performing, continuously innovating on building out and improving on those structures.

[![Thumbnail 3190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d2b76d1957753d54/3190.jpg)](https://www.youtube.com/watch?v=TeJCah7NeC8&t=3190)

Intentional innovation is something that we hold dear. We think of ourselves as having a startup mentality within the organization.  Again, breaking barriers, having a one team mentality with our engineering partners, our outside plant maintenance teams, our home technicians, our network operations technicians, and our engineering teams. As I was saying, intentional innovation means data scientists and developers side by side, shoulder to shoulder with engineering experts and outside plant maintenance experts, and really the power of our unifying goal. I mentioned what we believe to be the most important challenge of our time, reliability.

All of our teams are monitoring our reliability dashboards daily. Once a week we sit down across those organizations, we evaluate how the network's performing, and we start identifying opportunities for improvement, trying out and trialing new things with engineering, new novel approaches to things like OFDMA or OFDM, and taking a look at what we can do better and different. And then finally, adopt and go. Brad mentioned it. Agent Core wasn't ready when we needed to get going, so we made a decision, we moved forward and we started forging new territory, new ground, and a lot of the things that we're finding we're now partnering with AWS on, understanding how we can continuously innovate with them, understanding things that we have in terms of needs and collaborating with them on that roadmap for the future.

I'd say finally is building for change. The big theme that we had for this year was adaptation, adaptability. So everything we do is built with change in mind, having the ability to pivot. As Brad mentioned, we've created a framework that allows us to introduce new data sets, create new events, evaluate those events, and continuously iterate towards improving customer experience and reliability. So with that, we'll leave you all. If you guys are interested and have questions, you can meet us out in the hallway. We'd be happy to entertain any of your questions and talk to you a little bit offline. Thanks very much.


----

; This article is entirely auto-generated using Amazon Bedrock.
