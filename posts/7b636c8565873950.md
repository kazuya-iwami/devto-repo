---
title: 'AWS re:Invent 2025 - Migrating a Leading Global Sports League to AWS (SPF306)'
published: true
description: 'In this video, Mike Lally from AWS and Jesse Robbins and Mark Bennett from the NBA discuss their successful cloud migration completed in just months. They detail their "go slow to go fast" strategy, spending significant time on Well-Architected Reviews and design decisions before rapid execution. Key to success was leveraging AWS native services like Control Tower, Cloud WAN, and Config for automation and governance across 15+ technology teams. They achieved zero critical production issues since season start, improved VOD closed captioning by 60% using AWS Transcribe, and enhanced performance with MemoryDB and S3 file system. The presentation emphasizes automation, multi-account architecture, trust in teams, progress over perfection, and building repeatable operations for future scalability.'
tags: ''
series: ''
canonical_url: null
id: 3085186
date: '2025-12-05T03:44:57Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project enhances multilingual accessibility and discoverability while preserving the original content. Detailed transcriptions and keyframes capture the nuances and technical insights that convey the full value of each session.

**Note**: A comprehensive list of re:Invent 2025 transcribed articles is available in this [Spreadsheet](https://docs.google.com/spreadsheets/d/13fihyGeDoSuheATs_lSmcluvnX3tnffdsh16NX0M2iA/edit?usp=sharing)!

# Overview


ðŸ“– **AWS re:Invent 2025 - Migrating a Leading Global Sports League to AWS (SPF306)**

> In this video, Mike Lally from AWS and Jesse Robbins and Mark Bennett from the NBA discuss their successful cloud migration completed in just months. They detail their "go slow to go fast" strategy, spending significant time on Well-Architected Reviews and design decisions before rapid execution. Key to success was leveraging AWS native services like Control Tower, Cloud WAN, and Config for automation and governance across 15+ technology teams. They achieved zero critical production issues since season start, improved VOD closed captioning by 60% using AWS Transcribe, and enhanced performance with MemoryDB and S3 file system. The presentation emphasizes automation, multi-account architecture, trust in teams, progress over perfection, and building repeatable operations for future scalability.

{% youtube https://www.youtube.com/watch?v=oA8YjULXmKw %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/0.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=0)

[![Thumbnail 20](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/20.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=20)

### Introduction: NBA and AWS Strategic Partnership for Cloud Migration

Good afternoon everybody and thank you for coming out to hear us talk. A little disclaimer before we get started: the majority of the images that you'll see in our slides today were created using the Amazon Nova Canvas model. So a little shout out to AWS Gen AI there.  

The NBA is an always-on enterprise. By that I mean they've got a global fan base that wants access to content 24 hours a day, 7 days a week, 365 days a year. They've got to be able to deliver that content and services to their fans and partners. In that context, how do you migrate a leading global sports league like the NBA with a full-scale cloud migration in just a matter of months? That's what we're going to be talking about today. My name is Mike Lally. I'm a Senior Solutions Architect at AWS and I have the great privilege of working with these two gentlemen, Jesse Robbins and Mark Bennett at the NBA, my awesome customers. Thank you.

[![Thumbnail 80](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/80.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=80)

[![Thumbnail 120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/120.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=120)

[![Thumbnail 130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/130.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=130)

[![Thumbnail 140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/140.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=140)

[![Thumbnail 150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/150.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=150)

On October 1st, the NBA and AWS announced a five-year strategic partnership.  This partnership is really special, and one of the key things about it is that it's designed to power a new era of innovation not only for the NBA but really for AWS. We're working together collaboratively to drive innovation in sports. That's right, Mike. We're super excited at the NBA. We're working lockstep with AWS to bring our fan engagement up and bring them closer to the game through unique stats and advanced technology. We're also committed to deepening our fan engagement through a diverse fan base. Let us show you what that looks like here on the screen.    

### Strategic Approach: Going Slow to Go Fast with Multi-Account Architecture

All right, isn't that great? So let us talk about our strategy. When we're thinking about moving to the AWS cloud, there's a lot of principles and strategies we wanted to make sure we got right. The first one we're going to talk about is to go slow to go fast. What does that really mean at the end of the day? Well, one of our objectives was to get all our design requirements and principles, and all those key architectural decisions agreed upon. We spent a lot of time on this. I think we did about 15 sessions on a Well-Architected Review with many iterations of those sessions, making sure that we understood what each of the service components would do, what the objectives of those were, and making sure we had tight agreements around that.

[![Thumbnail 220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/220.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=220)

[![Thumbnail 240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/240.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=240)

Now that slowed us down, but as a result of getting all those agreements ahead of time, when it came to execution, we could go fast. So why are we doing this?  Well, for us from a strategy perspective, it's always about the fan. You saw in the video we want to drive better fan engagement. We have a global fan base and we want to make sure everything we do within the platform, within our designs is focused around the fan. But at the same time, we have to keep the long-term vision intact. 

[![Thumbnail 280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/280.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=280)

So what does that mean at the end of the day? When you're building the foundation through your design, you need to get there fast. We had less than a few months to get everything going. We had to be ready by Summer League in July. But we also knew that because of that speed, we couldn't do trade-offs long term. We knew that whatever we built had to handle key moments at the NBA. Think of critical moments like the NBA Finals and our draft. Those moments we needed to be able to scale up and handle at peak capacity. 

In our project timeline, we covered discovery, planning, and execution, but we had to get that done fast. Having that speed and scale was critical for us. By Summer League, we had to have everything ready to go and production-ready. Mike had mentioned the partnership on October 1st. I think we're three months out from being ready to go so that way we could test workloads. So come October 1st, we could be launched.

[![Thumbnail 310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/310.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=310)

 Jesse, do you want to talk about team commitments? Sure. For a project like this, it really requires commitment across upwards of 15 disparate technology teams. The migration planning included deliberate reasoning, cross-team debate, and alignment on key architecture decisions. We never allowed perfect to get in the way of good. Aligning early ensures fewer bottlenecks and conflicting opinions across the project timeline.

[![Thumbnail 350](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/350.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=350)

[![Thumbnail 340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/340.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=340)

Speed and scale, embracing changeâ€”we worked closely with AWS  and embraced our multi-account architecture, granting our DevOps and engineering teams more autonomy while also ensuring ambitious standards for things like identity management, compliance, and security.  I'll turn it over to Mark to talk more about speed and scale. Yeah, let's talk about speed and scale. When we were thinking about that short timeline where we had to get services out quicklyâ€”I mentioned the July timeframe, a few months to goâ€”it was our time to embrace change as Jesse mentioned by leveraging coordinated products across AWS.

Things we took advantage of at our disposal included AWS Control Tower so we could get configuration management through AWS Config rolled out. We also had AWS Private Certificate Authority, where we struggled in the past with managing IP space. We had the ability to roll out different space assignments as a result of that with Amazon Route 53. Most importantly was AWS Cloud WAN. When you're managing lots of accounts and lots of VPCs, the ability to manage that at scale was critical for us. Having those native products in our suite enabled us to go really fast.

[![Thumbnail 370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/370.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=370)

At the same time, we had to handle scale well. Having those products allows you to scale across multi-regions. We could leverage the AWS multi-account architecture and put us in a great spot for high availability and the resiliency that we need to run a high-end consumer app.  With speed and scale comes span of control. We knew we were going to have lots of accounts and lots of services running across AWS, and we needed control. One of the things we wanted to make sure we did as part of our deployment implementation was to have service control policies rolled across key accounts and key services.

[![Thumbnail 440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/440.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=440)

Using AWS Config, we wanted to make sure certain flags were turned on across our accounts. We wanted to make sure certain routes were in place through AWS Cloud WAN. Having those key service control policies gave us the control we needed. In contrast, we can also segment our accounts if needed. Not only does it give you the ability to control policy, but when you're managing multiple accounts and multiple services, if we need to segment accounts or segment services, we could do that with AWS. We're excited that we have that ability where in prior situations we didn't. 

[![Thumbnail 510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/510.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=510)

[![Thumbnail 530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/530.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=530)

[![Thumbnail 540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/540.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=540)

### Platform Migration: Three Pillars and Performance Improvements

Here's a look at some of the services we use at AWS, specifically the ones I've been highlighting.  AWS Cloud WAN, Amazon Bedrock, Amazon Nova, AWS Configâ€”we have that as a key service for usâ€”AWS Lambda. You can see how many native products we're using across the AWS infrastructure to really help us out.  Jessie, do you want to talk about the consumer? Sure. The scope of our platform services for the migration encompassed three pillars.  First, our middleware components, which are made up of our core platform, our core API deliveries, our identity platform which powers NBA ID, our media services which is effectively our live streaming orchestration platform, all of our VOD delivery for encoding, streaming, and ad delivery, and our back-end systems including our content management system and our game media scheduling system as well.

Leveraging AWS services across these three pillars allowed us to achieve significant performance and scalability improvements, specifically around moving to a service like Amazon MemoryDB, which allowed our core platform and API services to scale and improved our performance significantly. So much so that we had zero critical production issues since the start of the season.

[![Thumbnail 630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/630.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=630)

A highlight for us is an improvement to our VOD closed captioning generation, which was improved by 60% using the AWS Transcribe system. Finally, a key highlight for us was leveraging the new S3 file system for our content management system, which also helped improve our performance and scalability on that platform. 

With a project like this comes some challenges along the way. Real-time video processing at scale is incredibly important for us, so our multi-region redundancy setup really helped us in that area. Some of our legacy systems also had to be refactored and rebuilt. We moved to containerized applications on EKS, and a lot of our third-party and vendor systems were also undergoing migration in parallel. These are some of the challenges that we experienced along the way, but in the end we were able to deliver successfully for the start of the season.

[![Thumbnail 680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/680.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=680)

[![Thumbnail 700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/700.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=700)

Some of the key services on the platform side are EKS for all of our managed Kubernetes, Amazon S3 for storage, Lambda for automation, and we leverage SQS for our queue-based services significantly. On the database side, we use everything from MemoryDB and DocumentDB all the way to AWS OpenSearch.  

[![Thumbnail 710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/710.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=710)

### Analytics, Logging, and Infrastructure as Code: Building Enterprise Governance

With that, I'll pass it back to Mark for analytics and logging. Thanks, Jesse. One of the key decisions that we spent a lot of time on in the front end was talking about how to log observability.  When we were doing the Well-Architected Review, we ended up with about a 56-page document where we had laid out all the approaches, the options, and one of those sections was explicitly on analytics and logging. What we knew at that time is we wanted to bring everything back to a centralized pane of glass for AWS.

As part of that mapping, we identified the key elements that we wanted to bring into our logging system. Bringing that back into CloudWatch enabled us to get insights across the infrastructure in a way that we didn't have before. Now we can compare regions, we can compare services, and we can do a lot of different things that we couldn't do before in our monitoring.

[![Thumbnail 780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/780.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=780)

We talk about distributed monitoring too. It's not which one is betterâ€”we do both. We have a lot of spoke monitoring, and now we have an enhancement on top of that monitoring that gives us a full capability and a full view of our insights across the application.  That oversight that we now have really puts us in a position to monitor and alert more effectively. We can leverage workflows to generate tickets to AWS, and we can now integrate into our digital operations center with the AWS IDR team to get quicker response and more engagement, faster engagement, and hopefully reduce our MTTR at the end of the day.

[![Thumbnail 810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/810.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=810)

So that rapid response in live game broadcastâ€”we all know it's milliseconds, not secondsâ€”and we have to get teams quickly engaged.  With our analytics and logging on CloudWatch in addition to our other monitoring, we can get teams to engage quickly, get things fixed, and get our MTTR down. In addition, now we have parallel teams responding to incidents. We have our NBA SRE teams, our DevOps teams, and our developer teams engaged to get incidents fixed. But in addition, now we have AWS working in parallel with us.

[![Thumbnail 850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/850.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=850)

Let's talk a little bit about the benefits of enterprise infrastructure.  Running at scale, you need governance. We have security governance and compliance governance, and one of the things that I would tell you is most importantly to embrace that multi-account architecture. Use the service control policies and use tools like Control Tower to work across your different workloads and different accounts. It also provided us opportunities where we can manage IP space differently. Having that flexibility where we can do different things at the governance scale that we couldn't do before, but having clear ownership across your accounts is key, and having that governance is the way to do it. When you have your control policies, that means you can push more autonomy out to your teams.

[![Thumbnail 920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/920.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=920)

Your DevOps teams can have more ownership to manage their accounts because you're now putting governance on the account at the enterprise level versus coming in and trying to correct things after the fact and tell them what to do. We just pushed governance from the front, and then they can operate effectively. 

[![Thumbnail 970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/970.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=970)

Remove the engineers. I know you've probably heard this many times, but you don't want your engineers involved in every process. Even at the keynote, we're talking about the new DevOps agent, which is cool. The less people involved in change management, the better, and the more automation we can do, the better. For us, one of the challenges we had in our prior life was managing a lot of IP space. Deploying products like IPA really gave us a lot of automation and removed a lot of our engineers from the process, so we could scale out and do things differently. Any time you're struggling with manual work, really dig down deep, challenge yourself, and think about how to remove that engineer because you'll be thankful at the end of the day. 

[![Thumbnail 1020](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1020.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1020)

It's a common issue I see everywhere in your pipelines, in your deployment, your config management, and your automation through the platform. AWS Control Tower is a good example. AWS Cloud WAN is another one we really embraced from the start. We spent a lot of time in our design trying to figure out how to make sure we didn't have any manual intervention. As a result of manual intervention, you're going to have reactive work because someone's made a change you're not aware of. But if you're coming through the pipeline and the process, it's easier to understand the impact of those changes. One of the things we wanted to make sure was happening was infrastructure as code everywhere. But when you get to that point, it moves you into the concept of infrastructure as a service because the engineers aren't in the way. Everything's coming through the pipeline, and then change management can happen more fluidly. 

[![Thumbnail 1030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1030.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1030)

### Collaboration and the AWS Well-Architected Framework: Keys to Successful Migration

Let's talk about trusted advisors. We knew at the NBA we needed our subject matter experts doing this work. We needed well-trained individuals to come in and help execute in the short timeframe. We also needed the right people in the design session, so we identified those key people. We also identified areas where we didn't have the skill set and brought in people to help with that. 

When you work on an account like the NBA, everybody wants to help out, which is awesome. It wasn't difficult to find the specialists we needed when we had to dive deep on something like MemoryDB or DocumentDB and understand the trade-offs between different services. We were able to get those folks pulled in very quickly. Having that deep bench of specialists and service teams at AWS really willing to dive deep with the NBA and help us out on those design decisions was critical to getting the trusted advisors we needed to make those decisions.

[![Thumbnail 1140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1140.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1140)

One thing I want to add is that as part of that design review, you need to be open-minded to healthy challenge. When you're in those sessions, don't think you know it all the time. Hear people out and make sure you're thinking through the challenges about maybe how to do things differently, because that's why we wanted to spend so much time on the front end working through those agreements. It's really key that you lean on them, trust some of the guidance you're getting, and that's not just from AWS. It's really from all your engineers who may have had different experiences. Sometimes there is a different and better way to do things. Some of the meetings we had allowed our product teams to learn from the NBA, which drove what we call product feature requests that we were able to feed back in. It really was a collaborative situation. 

The other thing we figured out is that it takes two. We had one team really focused on day-to-day operations and another team focused on design and implementation, and that was across the board. On the NBA side and AWS side, we had both of those teams working jointly and in parallel. That helped us determine things like the right way to engage with the NBA for a support model. What is our enterprise support, our technical account manager team, and our IDR team? What's the best mechanism and path for us to engage with the NBA? Is that using Slack channels? Yes, it absolutely is. The NBA loves to use Slack, and we all do. Using Slack was just a natural way for our support teams to engage with the NBA when they ran into issues or even just testing to make sure we were prepared to address issues as they came up. From design and implementation, we also had your solutions architecture team and the service teams engaged to ensure that throughout the entire migration and going back to the very early stages of planning, we knew which services mapped best to meet the requirements of the NBA.

[![Thumbnail 1220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1220.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1220)

[![Thumbnail 1260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1260.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1260)

[![Thumbnail 1270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1270.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1270)

 With a project like this, even the best decisions may change, and there will be many failures along the way, and that's perfectly okay. What was the expression you used before? It was also about saying you can't miss a shot you don't take, so you know, basketball. Exactly. So get it working, scale up the resources you need, and work on cost optimizations and deploying the right level of resources that you need later down the road. It's really don't let the object of perfect get in the way of good.  Is that what made the integration successful?  So one of the key things, and we've touched on this quite a bit already, is probably a variation on a theme that you're hearing, but we just had a really strong one team approach to the entire migration with incredible collaboration between the NBA and AWS. We both really leaned in to make sure that this was going to be successful from the beginning.

That went back to before we had a single bit of code written or anything was ever running in AWS. We were working through what the best way to architect these solutions and workloads for AWS would be. We looked through the best way to make sure that we had all the pipelines for analytics and logging built out and all that was designed. We had all the stakeholders aligned on how that was going to work. What that allowed us to do was jointly make sure that we had from planning through execution true alignment on goals and priorities, and that was absolutely key to making sure that this migration was successful.

[![Thumbnail 1330](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1330.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1330)

One of the mechanisms that we employed very frequently and as Mark alluded to earlier, sometimes iteratively, was the AWS Well-Architected Framework.  The Well-Architected Framework is comprised of six pillars: operational excellence, security, reliability, performance efficiency, cost optimization, and sustainability. For each of the workloads that we migrated to AWS, we applied a Well-Architected Framework review to that workload. Sometimes the review was focused on maybe one of the pillars like security, other times it was focused on multiple pillars like reliability or sustainability. For some workloads we were really deeply focused on cost optimization because we knew that was an area with great potential for improvement for that given workload.

[![Thumbnail 1380](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1380.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1380)

Mark, how about you tell us about automation?  I think this one's self-explanatory. Just automate everywhere. Use the tools you see ICD everywhere. You have to think about that from the beginning. You have to identify those opportunities. If not, you're going to be in manual work and toil, and that's not a place you want to be. So think about those opportunities and where you can go and think through the pipeline, think through the build process and make sure that you automate those as much as possible.

On the other side of it, you have to think scale. As you're thinking across the services, we flashed up there a little bit earlier all the different AWS services. When you're thinking of the connectivity that's happening through all your logging and analytics, think about quotas. For example, when you're about to hit a quota, do you have the right scaling alerts that are happening? Do you have the right scale triggers in place for the service you're using? Do you understand what the scale trigger is and how long it takes? Spending time in defining those and making sure those triggers are effective will get you into a highly scalable environment.

[![Thumbnail 1460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1460.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1460)

[![Thumbnail 1480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1480.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1480)

[![Thumbnail 1490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1490.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1490)

### Key Takeaways: Empowerment, Progress Over Perfection, and Building for the Future

For a project like this, alignment, communication, collaboration, and transparency are key.  During the course of the project, specific to our internal teams, we conducted regular team syncs. This helped ensure and maintain momentum and also helped us quickly resolve issues along the way.   Some of the key takeaways that we want to make sure you take home with you today is leverage AWS. I know you hear that all the time, but leverage them. Use the Well-Architected Framework. It will help you work out bad decisions and spend the upfront time thinking about your tooling and how to automate it.

You have to use those native services effectively. Really think about how to automate through the native tools. We talked about IPA, AWS Cloud WAN, and AWS Config. You really have to think about the security tools, and when you're thinking about your scalability, understand the quotas and the triggers that you need in place to make sure those things scale effectively. The more you do in that space and invest time, the more successful you're going to be.

[![Thumbnail 1550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1550.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1550)

Empowering the teams, especially across 15 disparate technology teams, was really key. Empowering those teams to take the reins and help get the project over the finish line, trusting your leads to make the right decisions, and defining clear roles really helped accelerate our innovation and accelerate our delivery timeline. 

I just want to add to this. It's not an understatement to say you really need trust and verify, but the trust part is probably the more important part. When you have as many teams working on the deployment and execution as we had, I think it was 15 or more different work streams happening to execute. You have to trust everybody's working towards the objective. You have to make sure everybody understands the objective. The only way to get there is to make sure you're giving them autonomy and trusting them to deliver.

[![Thumbnail 1620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1620.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1620)

When things go wrong, and they will go wrong, it's how you handle the wrong that makes sure the teams are still empowered to go forward. It's such a critical thing how you lead from the front in those critical moments. That's going to really define the execution of your project. 

Progress over perfection is another key aspect. Don't let perfect get in the way of done. I had an old manager who had this huge poster up on his wall in his office that said "done is better than perfect," and that's true. You can't get stuck and mired down in analysis paralysis trying to get to the perfect solution when sometimes a good enough solution will get you there. By doing so, you give your team the ability to adapt and to continuously improve and iterate over a solution to get it closer and closer to perfect.

At Amazon, we have a concept called one-way doors versus two-way doors. A one-way door decision is a decision that you walk through and you really can't easily turn back and fix it. If we were to choose a given service that had a very distinct set of criteria, we wouldn't be able to change it very easily. A two-way door is one where you can make the decision, but it's relatively low impact to go back and change that decision if you find that your initial decision was not correct.

A great example of this was when we were going through the exercise of determining MemoryDB as a solution. We'd already decided that managed Redis was not the right way to go, and at that point it became a decision as to what type of key-value store we wanted to look at. We were looking at DynamoDB and MemoryDB at the same time. Both are highly performing key-value stores with slightly different value propositions, but based on the requirements we had at the time, really either of them would have met the requirements. The decision to go with MemoryDB because of the lower latency ended up working out, and we had zero production impacts as a result of it. That was a two-way door decision, and had we chosen DynamoDB and found out that it didn't work, it wouldn't have been a heavy lift to then switch the code to utilize MemoryDB instead.

[![Thumbnail 1750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1750.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1750)

We're a global international sports league and a global direct-to-consumer business, so scalability and reliability are tenets of our business.  Leveraging AWS and our multi-region redundant architecture, we were able to achieve those goals successfully as part of our season launch this year.

[![Thumbnail 1770](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1770.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1770)

On the operations side, there's always the concept of "I did it one time, I got it fixed," but there's a concept of repeatable operations. When you're in the process of designing the platform and scaling out, especially on the infrastructure side and how you're thinking about things, you have to think about repeatable operations. Everything from repeatable operations and how we do security, how we scale out, how we deploy, how we manage configs, and how we manage IP space.  The more you get into that mindset of repeatable operations, the more sustainable you get.

For us, that was a key objective. We wanted to make sure that at the end of the day when we get into AWS, our services are running in a repeatable operational framework. I would highly suggest that you spend a lot of time thinking about that operational bucket. A lot of people don't want to spend time on it because it's not the fun stuff and it's not the innovation, but it is critical. If your team is spending time on operations, they're not spending time on innovation, so automate that work.

I'll highlight one area where I think AWS truly has a best-in-class solution, and that's what you did with AWS Control Tower and Account Factory. The way you designed and implemented SCPs and the way accounts are automatically created is impressive. You touched on IP addressing with different t-shirt sizes for different IP ranges. It's truly a best-in-class solution. As a result of the fact that we spent so much time on the front end thinking through what that had to look like, we set ourselves up for success.

[![Thumbnail 1870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1870.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1870)

The last thing is to build for the future, and this actually harkens back to where we started with going slow to go fast. Really focusing on the Well-Architected Framework reviews, ensuring that there's a solid foundation architecturally, not just from an account structure but for all of the applications that are getting deployed in those accounts. Really thinking through all of the connective tissue through things like AWS Cloud WAN ahead of time before you get to the point of deployment is key.  It allowed us to very quickly achieve this migration, but it's also going to allow us to innovate in the future.

[![Thumbnail 1930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7b636c8565873950/1930.jpg)](https://www.youtube.com/watch?v=oA8YjULXmKw&t=1930)

When we get to those next innovative workloads and how those get deployed and how they rapidly scale up and rapidly scale down, because that's another important part of thinking about scaling, the fact that we've really thought through all of this and we know that we've got a solid foundation that's built for the future is going to lead us to success.  So with that, now you know where to go watch the game. If you don't know where to go to watch the game, go to NBA.com, click on the game, and watch now, and we'll take you to the right place. Also make sure that you check out the NBA AWS Play Finder experience in the back there. It's really cool. So with that, are there any questions?


----

; This article is entirely auto-generated using Amazon Bedrock.
