---
title: 'AWS re:Invent 2025 - Seamless data sharing in Amazon Redshift (ANT348)'
published: true
description: 'In this video, Saman Irfan, Senior Solutions Architect at AWS, explains how Amazon Redshift data sharing enables live data sharing across warehouses without copying or moving data. The session covers the architecture leveraging Redshift managed storage, three data sharing options (Redshift managed, Lake Formation managed, and AWS Data Exchange), and four key use cases: workload isolation, cross-group collaboration, data as a service, and development agility. Customer success stories from Peloton and Fannie Mae demonstrate real-world implementations. The presentation also addresses how AWS Lake Formation simplifies permission management in complex topologies and concludes with best practices including cost considerations, security features, and performance optimization strategies.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/0.jpg'
series: ''
canonical_url: null
id: 3086634
date: '2025-12-05T13:51:07Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Seamless data sharing in Amazon Redshift (ANT348)**

> In this video, Saman Irfan, Senior Solutions Architect at AWS, explains how Amazon Redshift data sharing enables live data sharing across warehouses without copying or moving data. The session covers the architecture leveraging Redshift managed storage, three data sharing options (Redshift managed, Lake Formation managed, and AWS Data Exchange), and four key use cases: workload isolation, cross-group collaboration, data as a service, and development agility. Customer success stories from Peloton and Fannie Mae demonstrate real-world implementations. The presentation also addresses how AWS Lake Formation simplifies permission management in complex topologies and concludes with best practices including cost considerations, security features, and performance optimization strategies.

{% youtube https://www.youtube.com/watch?v=82XldgCK414 %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/0.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=0)

### Introduction to Amazon Redshift Data Sharing: Solving Traditional Data Movement Challenges

 Hello and good evening everyone. First of all, thank you very much for joining this session, and I wish you a great start to the re:Invent. My name is Saman Irfan and I work as a Senior Solutions Architect here at AWS in the analytics team. In the next 20 minutes, you're going to learn how Amazon Redshift data sharing can improve the agility of your organization by sharing live data with relative security and ease across Amazon Redshift warehouses for analytics as well as AI workloads.

[![Thumbnail 60](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/60.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=60)

Before I start the session, I have a quick question for everyone here. Who here uses Amazon Redshift in production? Even if you're not using it in production, I am sure that if you learn about this capability of Amazon Redshift, you will start thinking about using  this. Let's first dive into the agenda for today's session. We are going to start with a brief introduction of Amazon Redshift data sharing. We are also going to talk about some of the technical aspects of the data sharing architecture in Amazon Redshift. Then we are going to dive deep into some of the use cases that customers use data sharing architecture for and some of the customer success stories who have implemented data sharing in Amazon Redshift and are seeing business as well as technical benefits.

[![Thumbnail 130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/130.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=130)

[![Thumbnail 140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/140.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=140)

We're also going to be talking about how in a complex data sharing topology, AWS Lake Formation, which basically centralizes the permission management of the data shares, can improve the governance aspect of this data sharing architecture. I'm also going to talk about some of the best practices and considerations so in case you want to start the data sharing journey with Amazon Redshift, this is going to be important learnings for you. And then in the end I'm going to conclude this session by providing you with some of the artifacts that can help you get started with Amazon Redshift data sharing.  Let's first look into why traditional data sharing is broken in most organizations today. 

If we look at traditional data sharing, it often involves manual data copying and movement, which is tedious as well as time-consuming. Customers have to build and maintain complex ETL pipelines which are complex in terms of maintenance, and they require constant updates as well as monitoring. In case there is a delay in the ETL pipeline, the data becomes stale, and by the time it reaches the end users, it's often outdated. In this whole situation, security becomes a nightmare because each data copy creates new governance challenges. Results teams working with inconsistent and incomplete data lead to poor decision making. These are exactly the challenges that Amazon Redshift data sharing was designed to solve.

[![Thumbnail 200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/200.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=200)

 With Amazon Redshift data sharing feature, you can share live data securely and easily across Amazon Redshift warehouses, whether they are provisioned or serverless in the same AWS account, across different AWS accounts, or even across different AWS regions as well for read as well as write workloads. It does this by giving you instant, granular, and high performance access to your data across Amazon Redshift warehouses without the need to copy or move it manually. Just to reiterate, data sharing is not a new feature of Amazon Redshift. It's already a well-established and mature capability with thousands of customers using this feature in production environments.

[![Thumbnail 260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/260.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=260)

Now let's take a look at how this data sharing works behind the scenes.  As you might be aware, the Redshift architecture supports isolation of storage and compute, and this is what powers the data sharing architecture. The storage layer of Amazon Redshift is called Amazon Redshift managed storage, which you can see in this visual. You can have multiple producer warehouses sharing the data for read as well as write purposes through Redshift managed storage to multiple consumer warehouses for read and write workloads. These consumer warehouses can also share the data that they own through Redshift managed storage to multiple Amazon Redshift warehouses. All of this happens without having to copy the data.

[![Thumbnail 330](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/330.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=330)

Users and applications can see the most up-to-date and consistent information as it is updated in Amazon Redshift warehouse. Now, let's take a look at the different options to create data shares and manage permissions. The first option is Redshift managed data share.  In this option, you create the data share inside a producer Redshift warehouse. You perform permission management of these data shares inside the Redshift warehouse, and then you directly share these data shares with multiple consumer warehouses. We recommend this topology to customers who have a relatively simpler data sharing architecture to implement. They have a few number of producers and a few number of consumers, and the management of permissions in this case inside the Redshift warehouse is relatively simpler to handle.

[![Thumbnail 370](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/370.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=370)

The second option is Lake Formation managed data share.  In this option, you create the data share inside a producer warehouse and instead of directly sharing these data shares with consumer warehouses, you share those data shares with AWS Lake Formation. AWS Lake Formation is an AWS service which centralizes the permission management of your data and gives you the ability to easily share the data across your organization and externally. In this case, the permission management happens centrally at the AWS Lake Formation layer, and based on those permissions, access is granted to multiple consumer warehouses according to the permissions that are managed at the AWS Lake Formation level.

[![Thumbnail 420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/420.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=420)

[![Thumbnail 460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/460.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=460)

The third option is AWS Data Exchange for Amazon Redshift.  This option is used by customers who want to monetize their data. Behind the scenes, AWS Data Exchange for Amazon Redshift uses AWS Data Exchange where you can share your data as a data product into AWS Data Exchange and then subscribers can subscribe to that data product. All the management of billing and collection of money happens in the AWS Marketplace entitlements service.  Now let's look at the different use cases that customers use the data sharing architecture for in Amazon Redshift and examine some customer success stories who have successfully implemented these architectures according to these use cases, seeing the business as well as technical benefits.

[![Thumbnail 490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/490.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=490)

### Four Key Use Cases: From Workload Isolation to Cross-Group Collaboration

There are four common use cases that customers use Amazon Redshift data sharing for. These are not limited to these use cases,  but these are the four common use cases that we see customers adopting. The first one is workload isolation. The second one is cross-group collaboration. The third is to deliver data as a service, and the fourth one is development agility. I'm going to dive deep into each of these use cases, but at this point in time, just make yourself familiar with these use cases that customers use data sharing for.

[![Thumbnail 520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/520.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=520)

Now if we look at a customer's Amazon Redshift deployment,  they often start with a monolith Redshift warehouse. They have data coming in from a wide variety of sources, and then in the end they have different tools which they use to perform analytics or data visualization of the data using some visualization tools. In that monolith warehouse, they have a wide variety of workloads running such as ETL, business intelligence, data science, and ad hoc, everything running inside that single monolith Redshift warehouse. Redshift supports workload isolation. Behind the scenes, Redshift supports workload management capability, and that offers some aspect of workload isolation.

[![Thumbnail 580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/580.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=580)

But as your workload needs grow and your data volume grows, there comes a time where resource contention starts to happen between read as well as write workloads. When this happens, what we  recommend to our customers is to move away from the monolith architecture to a multi-warehouse architecture using Amazon Redshift data sharing. If you look at this visual, what we recommend to our customers is to split up your workloads into separate Redshift warehouses. Have a separate Redshift warehouse for ETL processing, then use the data sharing capability to share the data from the ETL warehouse to separate warehouses for different workloads.

For example, you can have a separate warehouse for ad hoc workloads, a separate warehouse for dashboarding workloads, and a separate warehouse for data science workloads. The good thing is that you can size and scale each of these warehouses according to your workload, price, and performance requirements. You can easily onboard new warehouses if a new workload comes in. For example, if an R&D workload emerges, you can simply plug in a new Redshift warehouse and create a data share from that ETL warehouse to that warehouse. You can have the producer and consumer warehouses either provisioned or serverless, depending on your workload requirement.

One of the best things is that you can pause and resume the producer and consumer clusters as necessary. What we see with customers is that they have a provisioned ETL Redshift warehouse and run an ETL nightly batch job. Once the nightly batch job is done, they pause that warehouse. If it's serverless, it's automatically paused, but if it's provisioned, they pause it manually. Even if it's paused, because the data is shared at the Redshift managed storage level, the consumer warehouses can seamlessly query and access the data. This is one of the uses of how you can perform workload isolation using Amazon Redshift data sharing.

[![Thumbnail 700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/700.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=700)



One of the customers who successfully implemented this workload isolation use case is Peloton. Peloton is a fitness equipment company known for their internet-connected exercising bikes with fitness classes that are streamed on demand. They implemented this workload isolation use case by splitting a monolithic Redshift warehouse into a multi-warehouse architecture. They have an ETL Redshift warehouse and then multiple consumer warehouses for ad hoc workloads, Redshift workloads, and Tableau business intelligence workloads. With this architecture, they were able to quickly and easily start new data warehouses and share data across teams, vendors, and systems. After onboarding Redshift services into this architecture, they were able to save $3,000 annually using this architecture in Amazon Redshift.

[![Thumbnail 760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/760.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=760)



The next use case is to enable cross-group collaboration. Think of it this way: you have multiple teams in your organization, such as finance, sales, marketing, and R&D teams. Instead of all these teams using a monolithic Redshift warehouse, they can have separate Redshift warehouses which they can size according to their price and performance requirements. They are able to seamlessly collaborate across business groups for broader analytics and data science and analyze cross-product impact. Each of these virtual warehouses can be both a producer and a consumer of data. If the sales team needs to answer a question, for example, what are the total sales for a product and customers, and they need data from the finance or marketing team, they are able to easily get it through Amazon Redshift data sharing.

[![Thumbnail 820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/820.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=820)



One of the customers who successfully implemented this cross-group collaboration use case is Fannie Mae. Fannie Mae has data across Amazon Redshift warehouses and data lakes. They use their data to build a central data marketplace and publish their data as a data product in that central data marketplace. From there, they were able to access the data for different use cases such as data science, business reporting, BI dashboarding, query, and self-service analytics. With this capability, they were able to perform enterprise-wide data catalog for easy discovery and access. They implemented a data mesh kind of ecosystem using this data sharing capability of Amazon Redshift.

[![Thumbnail 880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/880.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=880)



The third use case is to deliver data as a service. Customers can use Amazon Redshift data sharing feature to offer data and analytics as a service within and across organizations and even with external parties using AWS Data Exchange for Amazon Redshift. They can securely share live data with Amazon Redshift warehouses in the same or different AWS accounts.

[![Thumbnail 920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/920.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=920)

As the data provider basically owns this data set, they can monitor and track the usage of the data and retain control of the data sets. The fourth use case is to share data between environments.  Now what we see at our customers is that they have different sets of warehouses for different environments such as development, test, and production. What we see is that they basically copy the data between these environments and create data replication and duplication. Now they can avoid this data movement and copying of this data using Amazon Redshift data sharing. They can easily provide the production data to the development or test environment and vice versa. With this, they can improve the agility of their organization by sharing the data between these environments at any granularity.

[![Thumbnail 980](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/980.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=980)

[![Thumbnail 990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/990.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=990)

[![Thumbnail 1000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/1000.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=1000)

### Simplifying Complex Topologies with AWS Lake Formation and Best Practices for Implementation

Now we have seen different use cases for Amazon Redshift. Let's take a look at what happens if you have a very complex data sharing topology to implement and how AWS Lake Formation can simplify and build an enhanced governance model for you.  Let's say you have multiple producer warehouses and you have multiple consumer warehouses. Now in case you need to establish data shares between these producers and consumer warehouses in  a many-to-many fashion, it's going to look something like this. In this situation, the permission management of the data shares  can be a nightmare if you have to manage the permissions in these Redshift warehouses.

[![Thumbnail 1010](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/1010.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=1010)

[![Thumbnail 1030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/1030.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=1030)

[![Thumbnail 1060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/1060.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=1060)

Now how you can simplify the permission management in this complex data sharing  topology is to use AWS Lake Formation in the center for these producer warehouses and consumer warehouses.  Amazon Redshift supports simplified governance of Amazon Redshift data sharing by using AWS Lake Formation to centrally manage the permissions of the data being shared across your organization. With Amazon Redshift data sharing implemented with AWS Lake Formation, you can manage the permission grants, view access controls, and audit the permissions on the tables and views in the Redshift data sharing using Lake Formation APIs or even through the AWS console.  You can centrally manage the permissions, implement those policies once, and enforce them across multiple virtual warehouses. There is no manual scripting or complex querying involved to implement this, and it basically simplifies the whole data sharing architecture for you if you have a very complex data sharing topology to implement.

[![Thumbnail 1080](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/1080.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=1080)

[![Thumbnail 1090](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/1090.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=1090)

[![Thumbnail 1110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/1110.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=1110)

I'm going to conclude this session by talking  about some of the best practices of Amazon Redshift data sharing that are very important if you want to start your journey with Amazon Redshift data sharing.  In Amazon Redshift data sharing, the producer warehouse is charged for the data storage only. The consumer warehouse is basically charged for the compute it uses to access the shared data and query the shared data in the same AWS region.  In case you have to implement cross-region data sharing because Redshift supports cross-region data sharing, then the consumer warehouse is also going to pay for the cross-region data transfer fees as well. Data sharing within the same region is free of cost.

[![Thumbnail 1130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/1130.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=1130)

[![Thumbnail 1140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/1140.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=1140)

[![Thumbnail 1160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/1160.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=1160)

[![Thumbnail 1180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/1180.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=1180)

[![Thumbnail 1190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/1190.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=1190)

The query speed  solely depends on the consumer cluster compute capacity and has zero impact on what's happening on the producer cluster.  In case you have to implement a cross-region data share, it might have high latency because the data needs to transfer across regions and there might be some network latency involved. Amazon Redshift also supports concurrency scaling for handling unpredictable workloads  and burst workloads. This concurrency scaling feature is basically supported on both producer as well as consumer warehouses, and we recommend customers to use the concurrency scaling feature if you have to improve the throughput of your Amazon virtual warehouse during periods of peak utilization.  Redshift also offers some system tables that you can use to audit the data share usage and changes.  In terms of security, data in transit is completely encrypted and data at rest is also encrypted using KMS keys. Even the producer and consumer warehouses can have different KMS keys if you want to implement them.

[![Thumbnail 1220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/1220.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=1220)

[![Thumbnail 1230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4f13198dbe1c6834/1230.jpg)](https://www.youtube.com/watch?v=82XldgCK414&t=1230)

Some calls to action: I have compiled a set of resources for you that you can take along. Once you scan this QR code,  you will get access to some blog posts and best practices documents that can help you get started with your data sharing journey on Amazon Redshift. Simply scan the QR code and you can get access to all of the documentation.  With this, I conclude the session and I kindly ask you to provide feedback for the session in the mobile application. Thank you very much.


----

; This article is entirely auto-generated using Amazon Bedrock.
