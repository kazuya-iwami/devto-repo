---
title: 'AWS re:Invent 2025 - [NEW LAUNCH] Whatâ€™s new with Amazon CloudWatch (COP363)'
published: true
description: 'In this video, Amazon CloudWatch''s product team presents their latest observability features across four key areas: building a unified data foundation with CloudWatch Pipelines and third-party connectors like Okta and CrowdStrike, gaining insights through Application Signals with automatic service discovery and the new Application Map feature, accelerating troubleshooting with AI-powered CloudWatch Investigations and Model Context Protocol servers, and monitoring AI workloads using CloudWatch Generative AI Observability Suite with 13 out-of-the-box evaluators for agent performance. The session includes live demonstrations of log facets for easier querying, S3 Tables integration in Apache Iceberg format at no additional cost, and field indexes supporting up to 10,000 log groups. Notable cost reductions include Lambda logs at 5 cents per gigabyte through volume tiered pricing and free AWS WAF logs.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/60.jpg'
series: ''
canonical_url: null
id: 3093247
date: '2025-12-08T21:45:56Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - [NEW LAUNCH] Whatâ€™s new with Amazon CloudWatch (COP363)**

> In this video, Amazon CloudWatch's product team presents their latest observability features across four key areas: building a unified data foundation with CloudWatch Pipelines and third-party connectors like Okta and CrowdStrike, gaining insights through Application Signals with automatic service discovery and the new Application Map feature, accelerating troubleshooting with AI-powered CloudWatch Investigations and Model Context Protocol servers, and monitoring AI workloads using CloudWatch Generative AI Observability Suite with 13 out-of-the-box evaluators for agent performance. The session includes live demonstrations of log facets for easier querying, S3 Tables integration in Apache Iceberg format at no additional cost, and field indexes supporting up to 10,000 log groups. Notable cost reductions include Lambda logs at 5 cents per gigabyte through volume tiered pricing and free AWS WAF logs.

{% youtube https://www.youtube.com/watch?v=MQmNzKZsx44 %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 60](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/60.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=60)

### From Calculators to Natural Language Queries: The Evolution of Data-to-Decision Tools

Wait, what are you doing here? We got a session to run. Oh, well, I'm trying to make a calculated decision, but I'm running out of fingers. Here, lend me yours. Okay, I'm not giving you any fingers, but we've got a better tool for that job. Here you go. Let's work with this. Oh, thank goodness. Seriously guys, welcome to the 1970s. We have calculators now. Ah, calculators, nice, Nikhil. Wait, hold on. I have something even better, spreadsheets. Look at all these columns of data. Let me see. Wait, I've got a yet better idea. My watch. Here we go. Show me the slowest Lambda executions from the last minute. The slowest execution. Okay. Natural language query generation, awesome. 

[![Thumbnail 70](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/70.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=70)

[![Thumbnail 90](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/90.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=90)

[![Thumbnail 100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/100.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=100)

So that silly little demonstration is meant to show you the progression that we've made through history, how the evolution of tools has helped  us go from data to decision faster and easier, and that's exactly our mission at Amazon CloudWatch, to help you collect your telemetry data, drive operational decisions, and build better systems. My name is Nikhil Dewan. I lead product for Amazon CloudWatch, and today our team is excited to show you the  latest and greatest features in CloudWatch that make your observability workflows faster and easier than ever. There's a lot to cover, so let's dive straight in. 

[![Thumbnail 130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/130.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=130)

We're going to cover four key areas today. How you can set up a solid observability data foundation with CloudWatch, how CloudWatch helps you gain insights from that data, how you can inform and accelerate your decision-making process with the help of AI, and if you have your own AI workloads, how you can use CloudWatch to monitor and improve them. And along the way, we have a couple of fun demos to show you all of this in action. 

[![Thumbnail 150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/150.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=150)

### Building a Unified Data Foundation: Breaking Down Security, Observability, and Audit Silos

Now before you can do anything with data, you have to be able to collect and access it. So first, we're going to talk about how CloudWatch can help you build that data foundation faster, simpler, and with more flexibility. This year, we have focused on three core areas of data foundation.  One, getting the data in as simply and easily as possible. Two, managing and accessing the stored data with more flexibility. And three, reducing costs.

[![Thumbnail 170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/170.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=170)

Now many AWS customers tell us that their data is across three separate silos,  security, observability, and audit, and that often there is significant duplication of the same data across these independent data stores. And they ask us, can AWS help me blur these lines across these silos? Now I want to be clear, we're not saying merge the security and observability teams themselves or somehow have the same folks do both observability and security. However, security, observability, and audit data in today's applications are closely related, so having it siloed in different stores leads to increased costs, missing data, and data inconsistency issues.

[![Thumbnail 220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/220.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=220)

Now often you need those audit logs when you're diving into operational issues involving a recent infrastructure change  or that very specific VPC flow log to get to the bottom of a security finding. We believe that the best way to blur the lines is how the data is stored, so having a unified data store that has all the information needed to solve a business problem. This got us thinking, how do we make it easy for you to get all the data that you need and make it accessible to your tool of choice so that you can get the best value from your data.

Decoupling the data store from the tools empowers you to focus on generating the best insights and leveraging the tools of your choice to solve real business problems. As an example, your security teams can leverage the unified data store for incident management and threat detection. Your observability teams can monitor and analyze the performance, health, and behavior of your applications and the infrastructure that it's built on. And using the same data store, you can generate automated and verifiable records for your compliance and audit use cases.

[![Thumbnail 290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/290.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=290)

So how do we go about building this unified store? We believe there are four components.  The first step is really around the collection of data. Customers spend a lot of time plumbing through all their telemetry. We call this the collection phase, where you need quick ways to bring your AWS telemetry, your application telemetry, as well as telemetry from non-AWS sources into a single store.

Next, customers want to shape or curate that data. They enrich the logs with relevant metadata, create indexes, convert logs to standardized formats such as OCSF, and they need a single store to curate all the telemetry data uniformly.

[![Thumbnail 360](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/360.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=360)

Third, customers want to store their data efficiently. They want flexibility in choosing their retention based on the data type so that they can keep the most useful bits with higher retention and control costs for lower value data. Customers also want flexibility in choosing how they store, like storing data in a single central account across all your regions and your organization. And finally, customers tell us that they want both amazing out-of-the-box analytics as well as the flexibility in analyzing  the data in the tool of their choice.

So today we are thrilled to announce a significant evolution of CloudWatch as a unified data store for your observability, security, and audit data. This launch has a host of features ranging from collection, curation, storage, to best-in-class insights. If you look at that slide, all those boxes on the screen are net new capabilities that we have recently announced for CloudWatch.

This enables easy collection with just a few clicks that goes beyond AWS data, including managed third-party connectors like Okta, CrowdStrike, and GitHub for audit logs. We also support org-wide enablement of AWS telemetry for consistent observability best practices across your organization. Powerful curation through transformations and pipelines lets you build a single security and observability data store at scale. And storage in an open Apache Iceberg format, enabling you to analyze your data with a wide variety of AWS and third-party tools.

[![Thumbnail 430](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/430.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=430)

[![Thumbnail 450](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/450.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=450)

### CloudWatch Pipelines and S3 Tables Integration: Seamless Data Collection at No Additional Cost

Now with this evolution of CloudWatch, your data stack could look like this  a wide variety of telemetry from AWS services and non-AWS sources landing in one unified data store, CloudWatch, and then you can analyze your data with a wide variety of analytical tools. Now, specifically to enable the easy and flexible data collection  and curation, we launched CloudWatch Pipelines. This helps you with seamless data enablement from your AWS resources, from your custom applications, as well as your third-party data sources.

[![Thumbnail 470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/470.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=470)

We also, as part of this launch, offer an intuitive visual pipeline building capability with industry standard processors.  We're excited to announce that you can now have your CloudWatch data also available in an S3 table in just a few clicks and at no additional cost. With our S3 Tables integration, you get Iceberg table support per data source and schema, and this unlocks loads of integrations.

[![Thumbnail 510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/510.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=510)

For example, here in the snapshot, you can see how we are using SageMaker Unified Studio to analyze your CloudWatch log data in place for AI and ML use cases. To help you make your log analysis more efficient, we have also launched field indexes for your log data.  You can index critical log attributes like request ID and transaction ID to accelerate your query performance and scan only the relevant data across your vast amount of logs.

Indexes help you deliver a consistent format and semantics to your logs for you to be able to do easier and faster log diving. Now gone are the days when you could just query 50 to 100 log groups at a time. With this launch, you can now query up to 10,000 log groups in one shot.

[![Thumbnail 550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/550.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=550)

Now we know that your telemetry is exploding and that you're already paying to ingest, store, and query your data.  So here is the best part. All of these capabilities that we talked about today, be it centralizing your logs, setting up indexes, or global controls, and even the S3 Tables integration are available to you at no additional cost.

[![Thumbnail 570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/570.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=570)

[![Thumbnail 600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/600.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=600)

We've also been hard at work to  lower your logging costs from your key AWS services. As an example, earlier this year we launched volume tiered pricing for Lambda logs, which drastically reduces your Lambda logging costs, especially at scale, all the way down to 5 cents a gigabyte. Similarly, your networking and security teams may be happy to learn that AWS WAF now includes free logs linked to your WAF request volume, and we're going to continue on this momentum in making lower costs for you to use AWS service logs. 

[![Thumbnail 610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/610.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=610)

### Comprehensive Analytics Across the Stack: From Application Signals to Log Facets

So now that we have built a solid data foundation, the next step in the data to decisions journey is getting insights from it.  Amazon CloudWatch offers a comprehensive set of analytical capabilities to cover multiple layers of your stack. As an example, for your network, you can use Internet Monitor to analyze your internet performance, as well as Flow Monitor to monitor your network performance information. For your infrastructure, you get out of the box insights and curated dashboards for your containers and Lambdas, or Database Insights that allow you to monitor database performance issues in real time.

[![Thumbnail 670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/670.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=670)

For your application, we have Application Signals which helps you automatically detect and monitor your application KPIs and define SLOs to maintain service quality commitments. And for end user monitoring, we have CloudWatch RUM, or Real User Monitoring, as well as CloudWatch Synthetics that produces canaries that simulate your end user behavior and alert you to availability issues or performance degradation.  Now, as a quick recap, in previous years, we launched Application Signals, which is CloudWatch's APM solution to enable observability through an application first lens. It automatically discovers services and topologies using the OpenTelemetry SDK.

It offers pre-built dashboards with standard metrics and the four golden signals, that's volume of request, latency, faults and errors for your application. And it has a guided workflow that helps you get from the metrics and the golden signals to the root cause in just a few clicks. You can also set up your own SLOs to have reliability goals based on business objectives to help you further benchmark the performance and quality of your operations.

[![Thumbnail 710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/710.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=710)

 This year, we are making it even more flexible with the new Application Map feature. Now this feature, the Application Map, is a central view of all of your applications, and we provide easy filters to help you narrow down on the application that needs attention. For example, if you want to see applications that are breaching SLIs in the last one hour, that's just a matter of two clicks. This view makes it really simple to go from an impacted application to the underlying service that is failing, seeing what's changed using change indicators, to drilling into traces which capture the exceptions that help you root cause the issue.

[![Thumbnail 760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/760.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=760)

We also now do automatic application discovery, not just for your instrumented apps, but also for your uninstrumented apps by inferring dependency  relationships between the AWS resources. For use cases on the go, we have also launched Real User Monitoring for mobile with mobile native SDK support and comprehensive dashboards for both web and mobile applications. These new views have mobile specific features that our customers have been asking for, including activity and fragment lifecycle events, mobile specific unhandled exceptions and system crashes, and slow rendering mobile events.

[![Thumbnail 790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/790.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=790)

 Lastly, with our new capability Log Facets, you no longer have to select log groups or write queries before you search through your log data. Instead, you can simply start with a data source, example, VPC Flow Logs, or high value fields such as a service or severity, and we automatically show you the value enumerations and distribution across these key fields, so it's always clear and intuitive what you are searching for. This leads to less guessing on what is the exact field and value that you need to query on. Matt will show you more soon in his demo.

[![Thumbnail 850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/850.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=850)

### AI-Powered Troubleshooting with CloudWatch Investigations and Model Context Protocol Servers

So that concludes my whirlwind tour of a host of our new data and analytic features, and next, I invite my amazing colleague Wei to talk about AI in CloudWatch. Thank you. Thank you, Nikhil. My name is Wei. I'm a Principal Product Manager  working on AI and CloudWatch. Some of you may be thinking, with all the great analytics features, how do I take my data to decisions process to the next level? How do I further automate and expedite diagnostics, remediation, and even learning for my team?

[![Thumbnail 880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/880.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=880)

So next, I'm going to talk about exactly that, how you can use CloudWatch with the help of AI to accomplish those goals. We  launched the general availability of CloudWatch Investigations in June this year. As an operations troubleshooting assistant powered by generative AI, it provides an end to end guided troubleshooting experience. It automates the tedious and manual aspects of searching through data and correlating signals and really speeds up the investigation workflow, getting to the root cause and remediation.

[![Thumbnail 910](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/910.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=910)

It is integrated throughout the AWS console.  So for the starting point, just look for the investigate button wherever you see telemetry or events in the AWS console, whether it's a CloudWatch alarm, a log query, the Lambda console, or RDS or anywhere else. It just works out of the box and there's no setup required.

[![Thumbnail 950](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/950.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=950)

Now, of course, optionally, you can configure CloudWatch alarms to automatically trigger these investigations, and the root cause hypothesis will be ready to go when you start responding to an incident and start investigating.  Now CloudWatch Investigations automatically correlates resources and dependencies as well as the corresponding telemetry. It intelligently crafts an investigation plan. It surfaces top root causes, as I mentioned, and suggests next steps for further investigation as well as remediation.

Each investigation, as you see on the screen, consists of an originating issue as the goal of the investigation, trying to figure out what caused it or how do I fix it. As the agent scans and analyzes data, it displays a set of hypotheses of what happened and why. When more data and events are surfaced to provide further details on these hypotheses, it intelligently updates them with newer versions. Only the most important telemetry supporting these hypotheses will be displayed underneath, whether it's a metric, log, or change event. But outside of the main screen, you can always expand the individual hypotheses further to review the details and all the telemetry that the agent has scanned.

[![Thumbnail 1040](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1040.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1040)

Now, the human user does have the ultimate control. So you can accept or rule out the hypothesis that the agent generates as a way to change or influence the investigation.  So when you click into a hypothesis, you can review it in more detail. It provides you with a summary of the events, a graph of the relevant resources and their dependency relationship, and the reasoning and supporting data that led to this hypothesis.

[![Thumbnail 1060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1060.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1060)

[![Thumbnail 1090](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1090.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1090)

 The agent is smart enough to not just scan the data, but identify what is relevant and what isn't based on direct and indirect dependency relationships, co-occurrence, semantics, among many other signals. For example, it can automatically write and run log queries for you and show you the exact set of error messages that have been spiking in your logs. It's also integrated with tools like Slack and Teams, so instead of going somewhere else,  it fits seamlessly into your existing workflows.

[![Thumbnail 1110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1110.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1110)

Tens of thousands of customers are now using CloudWatch Investigations to help troubleshoot their AWS workflows, and we've received a tremendous amount of positive feedback. Since the initial launch though, we have been continuously making improvements by listening to our customers. It is now smarter than ever.  It's more agentic in the way it plans investigations and how it uses the different tools and data sources inside of CloudWatch, and it works better on a wide variety of AWS tools.

[![Thumbnail 1130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1130.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1130)

Now this year, in addition to investigating and resolving operations  issues, we also launched the incident report generation feature to facilitate post-investigation learning. With this feature, you can create a comprehensive post-incident analysis report in a few minutes, automatically collating data and events, writing detailed analysis in the Amazon Correction of Error format, and facilitate reflection and learning with your team. It guides you through the 5Y analysis as a problem solving technique, which does the traditionally manual part of getting the information, so you can really focus on the learning and the thinking and the sharing with the rest of your team.

[![Thumbnail 1180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1180.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1180)

Now, while CloudWatch Investigations provide  out of the box troubleshooting experience, some of our customers may prefer to build their own agents for specialized use cases, or maybe you're integrating with other agents. We launched the CloudWatch Model Context Protocol or MCP servers, which makes it easy for your agents to leverage the same underlying cloud telemetry and tools. For example, you can use the Application Signals MCP

[![Thumbnail 1210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1210.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1210)

server  and connect it to your AI coding agent, such as Curo, to identify the exact file, function, or even line of code responsible for a spiking latency, errors, or an SLO violation. A few lines of MCP JSON configuration that you see on the screen are all you need to get that set up, after which Curo can immediately start leveraging the data underneath. By the way, both CloudWatch Investigations and the MCP servers are free, so give them a try today if you haven't already.

[![Thumbnail 1260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1260.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1260)

### Hands-On Demo: Log Facets, Unified Data Store, and Application Map in Action

Next, my amazing colleague Matt will showcase some of the features that we discussed. All right, thanks Wei, everybody. Yeah, so let me press the button over  here, over to demo. Let's pull up the screen. Hopefully you can see okay. So I'll warn you in advance, I'm going to be jumping around showing a bunch of different stuff because we covered a lot of topics. So we'll be moving in pretty quickly, but I hope you at least get the gist of actually seeing a lot of these features my colleagues just talked about in action.

[![Thumbnail 1330](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1330.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1330)

So let's start here in the CloudWatch Logs Insights view. If you're not familiar, it's our query engine for logs. And one of the things Nikhil talked about was facets, so let me show you what that looks like because I'm a little biased because I'm excited about this one. So I was actually in a customer call or conversation here at re:Invent earlier, and a customer was, let's say, giving me some feedback about how he disliked having to come into CloudWatch Logs Insights and wander through his list of log groups and try and pick the ones he was looking for, and it was a real headache that he's been suffering from. So I've heard this from many a customer. The great thing is with this facets view, now instead of coming over here and stumbling around trying to pick out my log groups, I can just come over here and, for example, let's say I've logged the  application name in my logs. I can simply click one of my application names. I don't have to worry about any log group or anything and start running queries.

[![Thumbnail 1340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1340.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1340)

[![Thumbnail 1360](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1360.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1360)

Similarly, I can come down here  where I have my log level or severity and start clicking in, and maybe I just want to see error and critical logs. So it just makes interacting and running log queries in Logs Insights much easier. Now during Nikhil's conversation, he was also speaking about this concept of this unified  data source. So let's take a look at how that manifests in Logs Insights as well, the query interface, and then I'll take you around and show you a little bit about how that gets set up.

[![Thumbnail 1390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1390.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1390)

[![Thumbnail 1400](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1400.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1400)

[![Thumbnail 1420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1420.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1420)

So here I was looking by log source or app name, or I'm sorry, app name or log severity. So I can also come over here and start viewing my logs by source. So this is just like  Nikhil mentioned, we're automatically extracting the type of logs from the logs, so I can pivot into my CloudTrail logs, my EKS logs, etc.  And then I'll actually jump over here to my central monitoring account because another benefit of this is that you can collect all these logs and telemetry in one central spot. So here in this account I've actually linked multiple AWS regions, so I have logs aggregated from 10 different regions and  as well as several different accounts can all be linked and shown up in this one view, and then you can easily click through and query these logs in one central place.

[![Thumbnail 1450](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1450.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1450)

[![Thumbnail 1460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1460.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1460)

So this is a capability that's really helping with a lot of customers who have been dealing with headaches with account boundaries because now you can easily just pull everything in one place and you've got a really quick and easy way to query things once they're there. So how did I get to this? Let's go take a look at a couple of other things.  So I'll come over here to this. So if I go on my CloudWatch page down here to the setup,  I'll see ingestion, and this is where I'll find that pipelines capability you might have heard Nikhil mentioning with a PowerPoint slide earlier.

[![Thumbnail 1480](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1480.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1480)

[![Thumbnail 1490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1490.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1490)

[![Thumbnail 1500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1500.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1500)

So essentially what this is about is helping make it easier to bring and collect your data into this unified data store in CloudWatch. So we have these integrations,  these configurable data sources. These are all the, what we're looking at now are the AWS ones. Those will just automatically pull out, figure out the data source type.  You really don't have to do much configuration or setup. You can also optionally pivot over to third party, and we've created these new pipeline integrations to help you pull in  third party data sources such as CrowdStrike, GitHub audit logs, Office 365, those kind of sources.

So typically more relevant to a security team, but it's all about this idea of the unified data store and we can get all these logs in one place and make them available to different analytics tools. Essentially the idea is it's a new tool for bringing logs in and getting them into this data store.

[![Thumbnail 1530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1530.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1530)

[![Thumbnail 1550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1550.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1550)

Another problem I've heard about from customers  is that when they're bringing their logs in, many of our customers are running some sort of ETL jobs. They're running Kinesis and Lambda, piping logs through some funnel to do some sort of transformations, normalization, maybe enrich it with some extra data or maybe normalize it to some other standard. With this CloudWatch Pipelines capability over here, you can now basically  set that up to work out of the box and offload all that compute onto CloudWatch. You can set up pipelines to do common transformations like converting to OCSF format, which is a standard log format for security folks, or you can do things like enrichment, like adding extra fields into some JSON block in your logs to put in account ID, app name, those kinds of things. Essentially what it is enabling customers to do is, one, make it easier to get rid of all that extra overhead they had from those processes they were running to do ETL, and two, this Pipelines capability is available at no cost, so it's letting them free up some cost savings on that.

[![Thumbnail 1600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1600.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1600)

[![Thumbnail 1610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1610.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1610)

[![Thumbnail 1640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1640.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1640)

From here, I'll just look at one more  thing on this whole unified data store. I'm going to go over to my log management view. I'll see we've automatically  pulled out a bunch of data sources. This is kind of like a new way of viewing your logs. This is just like a different representation of the same data that I already have in my logs. We're just slicing it out and kind of grouping it by type and putting it into a more tabular format. What does that give us? One, like I looked at earlier, I can now slice and search my logs in Logs Insights by the source type, which is pretty convenient. But the other great thing is that I can come into this view, and if I  check a couple of boxes and I come up here to this S3 Tables integration and click associate data source, what this will do is automatically start making all the logs that come in of this data source type available on an S3 data table in an Apache Iceberg compatible format at no additional cost.

[![Thumbnail 1670](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1670.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1670)

[![Thumbnail 1680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1680.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1680)

[![Thumbnail 1690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1690.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1690)

What I can do is after I turn that on, I basically just come over here to S3.  I go into the table buckets as opposed to general purpose buckets, and now I see this AWS CloudWatch. All I did was check that box, basically,  and now all my logs are available over here as well. If I come into one of these, I can do a quick preview.  You kind of get an idea that we've converted into this tabular format by extracting fields from your logs. What I can do from here is now my logs are, essentially a mirror of my logs is available in S3, and I can now expose this table for use by maybe the security team running their security tools, audit team running whatever tool they're running. So long as the tool can look at Apache Iceberg compatible data, it can come in and pull data from here and query it. It's really helping customers offload all these ETL jobs they've been running and help in some cases save costs on pushing data around and having multiple copies of their logged data in multiple tools.

[![Thumbnail 1740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1740.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1740)

Let's keep going. We've got more features to cover yet.  Now I'm going to jump over. We've looked at the unified data store. We've looked at that facets thing that made querying my logs easier. Now I'm going to take a look at that Application Map thing that Nikhil was talking about. Here when I'm troubleshooting myself sometimes, I want to dive straight into the logs because I kind of know what I'm looking for, but sometimes I want a dashboard that's giving me a general overview of my application's health. This Application Map is pretty good for that, for getting that visual kind of representation of your data to help those folks who might want to troubleshoot that way or just get a general overview of what's happening with their application.

[![Thumbnail 1800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1800.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1800)

The cool thing about this is it just automatically works. You'll find it within the CloudWatch APM tab, but even if you are not using APM, it will still work. You just might get a little less bells and whistles in here. All of these little blocks are my applications, and if I click into one, I can get a more detailed view  of all the resources composing that application.

[![Thumbnail 1810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1810.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1810)

[![Thumbnail 1820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1820.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1820)

[![Thumbnail 1830](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1830.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1830)

Then I could click through any resources that have errors, you know, they're looking red and  get a detailed view of the metrics associated with this resource. In this case, it looks like this is an EKS cluster.  We're capturing any changes by looking at CloudTrail. So if there have been any changes, any deployments to this resource, that will be captured here as well. And then I can dive into tracing spans, all that  as well. So, in short, it's a new visual representation for helping troubleshooting workflows. It works out of the box and like the other things we're going to talk about, available at no additional cost. So go try this out if that looks cool to you.

[![Thumbnail 1860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1860.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1860)

[![Thumbnail 1870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1870.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1870)

[![Thumbnail 1880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1880.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1880)

[![Thumbnail 1890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1890.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1890)

### Automating Root Cause Analysis and Incident Reports: CloudWatch Investigations and Correction of Errors

All right. Okay, no, I knew this was going to happen. Hold on. Counsel, time out.  Okay. So now we've looked at query, we've looked at DataStore, we've looked all over the place. So I'll bore you with a couple more things.  Let's go over here to CloudWatch alarms. And I'm going to talk about AI ops and how our customers have been using this. So Wei mentioned this CloudWatch Investigations  thing. So a lot of our customers have been asking me, hey, we're trying to get started with AI ops. We're not really sure what to do. So let me show you what a lot of our customers have started doing.  As Wei mentioned, we got several thousands on here already.

So traditionally if my alarm's firing, I've got to go in here, maybe figure out what this application is composed of, what's underpinning this availability. We've got a drop in availability, what API, you know, is it calling some Lambda that's calling some other thing that's calling some other thing. I've got to go figure out where all the telemetry is, run a bunch of queries. So basically the idea of this CloudWatch Investigations capability is to make that whole process easier, faster, and hopefully get you to the answer of what happened a little more quickly.

[![Thumbnail 1940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1940.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1940)

[![Thumbnail 1950](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1950.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1950)

[![Thumbnail 1960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1960.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1960)

[![Thumbnail 1970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/1970.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=1970)

So I can either do this manually by clicking this Investigate button up in my top in the top right, but what a lot of our customers are doing is setting up these investigations to trigger automatically  as soon as their CloudWatch alarm fires. You can do it on other things besides alarm, by the way, but we're just on that for today. So what I'll do is just go into my alarm history  and go into the investigation that triggered it as soon as that alarm went into an alarm or flashing red condition. And what I'll see here is that hopefully by the time I went and logged  onto my AWS console, the AI already produced a root cause analysis that I can review and use to hopefully give me a more informed opinion of what happened.  So essentially it's AWS telling me here's what we think was the root cause of this alarm firing.

So now, as opposed to me starting with just here's some alarm, it's red, I don't know what happened, I've at least got a starting point. I've at least got an opinion on what the problem was. And 100% of the time it's perfectly correct, the AI is never wrong. That was a joke. That's not true, but it normally helps customers get to the answer faster. So we've got root causes. We've got what happened. We've got evidence. Next steps. I won't get into all the details, but hopefully you get the idea. It's a great starting point. It's available at no cost. So a lot of customers are kind of getting their toe in the door with AI ops by taking advantage of this feature, and a lot of customers are saving a lot of time on their troubleshooting.

I'm going to show you one more thing before I pause my little demo here. So this is great and this kind of tool helps you go put out the fire and solve the issue hopefully quicker and easier. But after you've remediated the issue, a lot of our customers tell me that they're always in firefighting mode. It's always, you know, the poor development teams and SREs and DevOps folks are always fighting one alarm to the next and never really catching up and struggling to really improve their operations.

So internally on Amazon we have a process that we talked about and mentioned. It's called the Correction of Errors process and after an incident we basically produce an incident report to help that team learn from the incident. It's not about assigning blame. It's more about taking learnings and figuring out how you can improve your operations, improve your applications availability, and share those learnings with other parts of your organization. So we've now launched this incident report generation capability which helps customers to automatically generate a report based on our own internal reporting format of how we do this at Amazon.

[![Thumbnail 2100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2100.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2100)

So now this capability will extract all the data out of that investigation I just ran. So it's actually working with my telemetry and contextualizing everything in this report to what actually happened. And it gives me a great summary, metrics,  and a rundown of the entire incident as well as providing recommended next steps and things I can do to improve my application.

So the idea is you can take this, generate the report, tweak it a little, and then go share it with your team and use it to drive process improvements. If you want, you can just export it as is and go tweak the rest in your Word doc or just dump it in your ticketing system. Or if you want, you can provide some additional input to augment what the AI was able to come up with.

[![Thumbnail 2130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2130.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2130)

[![Thumbnail 2140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2140.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2140)

[![Thumbnail 2160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2160.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2160)

 One really cool thing that I've liked using is this Five Whys workflow. So Wei also mentioned this, but this is a process originally developed over at Toyota, and it's  an integration we built through Amazon Q. It's pretty simple. It just asks you the same question five times in a row: Why, why, why? But that pivots the report out of, oh, this incident occurred because of an IAM policy change into understanding the process gaps that maybe allowed that to happen and enables you to recommend some specific  improvements. So it's a really cool little feature that helps you really dive into the underpinning causes of a particular incident.

[![Thumbnail 2200](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2200.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2200)

### Observing Generative AI Workloads: CloudWatch Support for Bedrock Agent Core and Quality Evaluations

So that's it for this demo. I'm going to bring my colleague up, Wei, and everything we've been looking at is really great for traditional application observability, but he's going to talk to you about how customers are doing observability around AI-based workloads. Thank you for the great demo, Matt. Now many of, in addition to using AI for your operations, many of our customers are actually actively adopting AI technology, moving from hackathons to prototypes  to even, you know, full production, sophisticated usage of AI and especially generative AI as a new type of resource. So you may be asking, how about my own AI workloads? What are the unique challenges and ways I can drive decisions with data on them and make them better?

[![Thumbnail 2230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2230.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2230)

[![Thumbnail 2250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2250.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2250)

So looking back at the graph that Nikhil displayed,  some of your stacks may now look like this with generative AI workloads as an additional layer. So to help with that, we launched CloudWatch Generative AI Observability Suite in general availability. It's easier than ever to build agents using Amazon Bedrock Agent  Core, which provides secure, scalable infrastructure for AI agents with a wide selection of models and includes essential tools, contextual memory, and credential management, all while working seamlessly with popular frameworks like LangGraph or CrewAI and so on. All of that comes with native CloudWatch Generative AI Observability support with no need for manual, troublesome instrumentation. You get all the native features such as out-of-the-box dashboards, end-to-end prompt tracing, and quality monitoring.

[![Thumbnail 2290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2290.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2290)

 But you also don't have to use Agent Core or even Bedrock at all. You can build and run your own agents on AWS services like EKS or EC2, or even your own data centers or multi-cloud. As long as you send your data in industry-standard OpenTelemetry format, you get all the same benefits and all the same great features and full flexibility. So let's talk about how you monitor these workloads and what you monitor for.

[![Thumbnail 2320](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2320.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2320)

[![Thumbnail 2340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2340.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2340)

 Those of you that have been observability practitioners know the three foundational pillars of observability: metrics, logs, and traces, and those still very much apply, although they may come in slightly different flavors as you see on the screen.  If we look at the golden signals, there are four general metric categories which closely reflect those for traditional workloads. For each invocation, as opposed to like a traditional request, you have token usage, which is how much and the size that we're consuming or producing with the model. You have latency, how fast or slow is the performance of my workload. Throttling, which could be hardware or software, or you know, you could run into limits or quotas. And lastly, errors, which could both be by design as well as unintended.

[![Thumbnail 2390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2390.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2390)

So this is what the invocation dashboard looks like in CloudWatch Generative  AI Observability. It gives you a set of golden metrics, as I discussed, without the burdensome configuration. You can easily manipulate the data so you can triangulate the issues of your generative AI workloads.

These have been available out of the box in general availability since earlier this year, along with logging capabilities for Bedrock that have been available previously. And of course, in addition to the pre-built invocation dashboard that we're showing here, you can use other already available CloudWatch tools, such as alarms, Logs Insights, log patterns, anomaly detection, and even CloudWatch investigations on the underlying data.

[![Thumbnail 2440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2440.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2440)

Now, what's new at re:Invent is  we're bringing the other side of generative AI observability in agent core evaluations. So we all know large language models can occasionally hallucinate, but evaluations cover much more than that. They're how you check whether your generative AI systems are doing exactly what you intended and what you actually want. Things like accuracy, for example. Is your code agent applying the right functions? Are your AI systems working safely? Is your agent producing content that may be harmful to your users? Reliably, does it work consistently regardless of small prompt variations, and in a way that users find helpful? For example, is the response too long or too short?

With the proliferation of generative AI systems, evaluations play a more and more critical role in the success of building and operating today's AI environments. A lot of this has been done in the past with human evaluations. Because generative systems are often open-ended and eyeballing just a few examples and just trusting it is usually not sufficient. So, the human evaluations can be really high effort and tedious and not very scalable. Well, there definitely still is a place for human evaluations. Our goal is really to try to automate as much of the evaluations as possible and make things simpler and easier.

[![Thumbnail 2540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2540.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2540)

 Now the new capability helps you test and continuously monitor your agent performance with 13 out of the box evaluators. Therefore, common quality dimensions such as helpfulness, tool selection, and accuracy, you can also easily create your own scoring systems with large language models as a judge. All these quality metrics are available through a unified dashboard in CloudWatch, so all of your generative AI monitoring is centrally accessible and manageable right alongside with the rest of your system. Now let's welcome Matt back onto the stage to show you how these features make data-driven decisions better and easier when it comes to monitoring and improving your AI workloads.

[![Thumbnail 2610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2610.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2610)

### Live Demonstration of Agent Core Observability and Evaluators: Measuring AI Quality Beyond Traditional Metrics

All right, thanks, Wei. Here I am again, folks. Let's look at the console again. All right, so this one will be pretty quick, but I wanted to give you a quick demo of the capabilities that Wei just referred to. So essentially these are a couple offerings to help customers that are building new workflows, leveraging AI either by directly invoking  models or by building agents. So what a lot of customers are experiencing right now is like a year or two back they were doing a lot of hackathons, a lot of POCs, and building these out, and now as they're starting to productionalize these workflows either already or they're looking to do so soon, they need robust tools for observability around these basically totally novel workloads.

[![Thumbnail 2650](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2650.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2650)

[![Thumbnail 2660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2660.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2660)

So this model invocations view is kind of giving you a view essentially of all your calls into and out of Bedrock. So you can come up here, those golden metrics that we referred to, we've captured all of those by default, so you've got a great  view of these. You can break it down by which model you want to dive in on and see latency, token count, etc. Where we've done a lot of work though  is over here in the agent core observability. So this is a real trend toward these agentic development workflows and application models that our customers are going through. So this product really helps with that use case.

[![Thumbnail 2680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2680.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2680)

[![Thumbnail 2700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2700.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2700)

So I've got a great overview dashboard. I've got one agent running in my account, so I'll dive into that agent  and in this view again, all this is being derived from OpenTelemetry compatible data, but if I look at sessions, session corresponds to essentially an entire conversation with an agent. Within a session I have various traces, and a trace is kind of like in  this, in this kind of workflow an individual interaction, so prompt response between the user and the agent or an agent and another agent.

[![Thumbnail 2720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2720.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2720)

[![Thumbnail 2730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2730.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2730)

[![Thumbnail 2740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2740.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2740)

[![Thumbnail 2750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2750.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2750)

What I can do with this workflow is it's really helpful for what I would call maybe traditional type troubleshooting. So maybe some agent's throwing some error and something's broken, so I can quickly dive  into any errors, go into the underlying trace, and then see the entire sequence of what all calls happened either  in this tree view or timeline view. And then I can quickly filter by individual interactions  with errors and dive into those and help understand those. So the idea is  that you can quickly identify any errors occurring in your agentic app and dive in and troubleshoot those very easily.

[![Thumbnail 2790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2790.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2790)

[![Thumbnail 2800](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2800.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2800)

But let's talk about the whole evaluations thing. What a lot of customers have found is like, okay, troubleshooting an error looks much like troubleshooting a traditional REST, you know, microservices-based app. But the really tricky thing with these new agentic workloads is they're non-deterministic, so it's really hard to measure like if everything's green and there's no errors, but is it actually doing a good job? Is it actually being accurate? So that's where that whole evaluators thing comes in. So I'll jump over  to the Agent Core dashboard to show you how that's set up. So we launched this just as a preview,  but this is built to help customers answer that question of like how well is my agent actually doing.

[![Thumbnail 2820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2820.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2820)

[![Thumbnail 2850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2850.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2850)

[![Thumbnail 2860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2860.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2860)

So if I come in here, I can either point it at one of the agents I'm hosting in Bedrock Agent Core on AWS, or if I'm ingesting the logs from an agentic workflow  hosted somewhere else, I can just point it at those CloudWatch logs where the agent logs are going. Down here, I can select various pre-built evaluators for things like correctness, faithfulness, coherence. So you're looking to help measure the, essentially, again, the quality of your responses and if you're doing things like perhaps leaking data it shouldn't be, looking for, you know, maybe it's spouting out foul language at your users, who knows what that agent is doing. So it's really  helping customers to identify and troubleshoot those kind of things. And then finally, I can set a sampling rate on that. 

[![Thumbnail 2870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2870.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2870)

[![Thumbnail 2890](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2890.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2890)

[![Thumbnail 2920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2920.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2920)

[![Thumbnail 2930](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2930.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2930)

[![Thumbnail 2950](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/2950.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=2950)

So then if I go back into my CloudWatch,  I'll go over here to Gen AI observability and back into that Bedrock Agent Core. And what I'll find here is that, actually, I need to dive back into that agent. I can now see reporting on the top evaluators. So what's happening is now on whatever  sample rate I set up in that configuration, it's going to run these evaluators on the entire interaction of that agent and report on the results, and I can see these in aggregate and kind of get an overall view. So here we can see, for example, it looks like the tool selection accuracy has been trending downward. So if I didn't have this, I probably wouldn't know anything about what was even happening, but now I've at least got a starting point,  and oops, I clicked the wrong thing. And I can go in and actually troubleshoot and identify why. I clicked the wrong button, but  all right, so I'll go ahead and wrap up the demo there and invite my colleague Nikhil back to wrap things up. Thank you Matt. 

So as we wrap up, let's distill the essence of our journey today in a few key takeaways. First, CloudWatch helps you build a strong data foundation through the Unified Data Store through several of our new features on pipelines, AWS-wide enablement, third-party connectors, schema mapping, as well as field indexes. Second, we have unlocked better insights on your data with new features such as the new S3 table integration that allows you to query your CloudWatch data in place with the tool of your choice, simpler in-console querying with the log facets experience that Matt demoed, as well as several enhancements to our Application Signals experience with application maps and discovery of uninstrumented apps.

Third, we are enabling you to expedite your operational decisions with AI using CloudWatch Investigations and our MCP interfaces. And finally, as AI becomes central to modern applications, CloudWatch helps you monitor and improve your AI workloads through generative AI observability and the Agent Core evaluators. Together, these capabilities give you a unified, intelligent observability platform that helps you scale your business.

[![Thumbnail 3050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/7ebb90057c5bb3c1/3050.jpg)](https://www.youtube.com/watch?v=MQmNzKZsx44&t=3050)

Now we really hope that you enjoyed today's session and we'll give the new CloudWatch capabilities a try soon. Please reach out to any of us and we can help you get started. And last but not the least, we would really appreciate if you could just quickly take out your phones and fill up the session survey in your mobile app. Your feedback is really important to us as it helps us tailor the future sessions we deliver to align with what matters most to you. Thank you so much. Me, Matt, and Wei will stick around here, and we'll be happy to answer any questions you have. Thank you all. 


----

; This article is entirely auto-generated using Amazon Bedrock.
