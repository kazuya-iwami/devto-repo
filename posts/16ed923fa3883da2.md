---
title: 'AWS re:Invent 2025 - Cut costs & operate efficiently on Amazon RDS for SQL Server & Oracle (DAT325)'
published: true
description: 'In this video, Mehul Shah, Director at AWS, presents cost optimization strategies for RDS SQL Server and Oracle. Key topics include the new additional storage volumes feature enabling up to 256TB total storage across four volumes, mixing IO2 and GP3 volume types, and dynamic volume management without downtime. For SQL Server, he demonstrates 74% cost savings using Developer Edition for dev/test environments, 58% savings with Web Edition''s new Multi-AZ support for web applications, and up to 55% reduction by upgrading to 7th generation instances with Optimize CPU. For Oracle, switching to EC2 bare metal instances provides 25% cost savings for large databases while maintaining full RDS functionality.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/0.jpg'
series: ''
canonical_url: null
id: 3092957
date: '2025-12-08T18:52:34Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project enhances multilingual accessibility and discoverability while preserving the original content. Detailed transcriptions and keyframes capture the nuances and technical insights that convey the full value of each session.

**Note**: A comprehensive list of re:Invent 2025 transcribed articles is available in this [Spreadsheet](https://docs.google.com/spreadsheets/d/13fihyGeDoSuheATs_lSmcluvnX3tnffdsh16NX0M2iA/edit?usp=sharing)!

# Overview


ðŸ“– **AWS re:Invent 2025 - Cut costs & operate efficiently on Amazon RDS for SQL Server & Oracle (DAT325)**

> In this video, Mehul Shah, Director at AWS, presents cost optimization strategies for RDS SQL Server and Oracle. Key topics include the new additional storage volumes feature enabling up to 256TB total storage across four volumes, mixing IO2 and GP3 volume types, and dynamic volume management without downtime. For SQL Server, he demonstrates 74% cost savings using Developer Edition for dev/test environments, 58% savings with Web Edition's new Multi-AZ support for web applications, and up to 55% reduction by upgrading to 7th generation instances with Optimize CPU. For Oracle, switching to EC2 bare metal instances provides 25% cost savings for large databases while maintaining full RDS functionality.

{% youtube https://www.youtube.com/watch?v=06l39fx_AXY %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/0.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=0)

### Introduction to RDS for Commercial Database Engines: Why SQL Server and Oracle on AWS

 Hello everyone. Welcome to session DAT325. We'll talk about how you can cut costs and operate more efficiently with RDS for SQL Server and Oracle. My name is Mehul Shah. I'm a director at AWS for RDS databases, SQL Server, Oracle, DB2, and also Oracle Database at AWS. Before we get started, I just want to get a pulse of the audience. Can I get a raise of hands of folks who already use Amazon RDS? Most of you. Okay. And how many of you use SQL Server? About half of the audience, more than 50% of the audience. And how many of you use Oracle? Okay. A good number. Good. So I think we have the right audience. Let's get started.

[![Thumbnail 50](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/50.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=50)

 This is our agenda for today. We're going to start with a short introduction to RDS, then we're going to deep dive into some improvements that we are making into how you can use storage volumes. There are some recent features that we have launched that give you more flexibility in how you can use storage volumes and operate a little bit more efficiently than what you could before. And then we'll talk about some new service features that help you reduce your costs when you're running SQL Server or Oracle on RDS.

[![Thumbnail 100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/100.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=100)

[![Thumbnail 110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/110.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=110)

[![Thumbnail 120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/120.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=120)

So relational databases at AWS. When you look at relational databases, Amazon offers Aurora, which offers a PostgreSQL compatible edition, a MySQL compatible edition, and then we have Aurora DSQL, which is our serverless distributed SQL service. You also have Amazon RDS for open source  databases. This includes RDS for PostgreSQL, RDS for MySQL, and RDS for MariaDB. And then you have RDS for commercial database  engines, which includes RDS for Oracle, SQL Server, and DB2. Most of our discussion today is going to focus on RDS for commercial database engines,  which include SQL Server and Oracle.

[![Thumbnail 130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/130.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=130)

Now why do we offer RDS for commercial database engines?  First, ease of migration. We know that thousands of customers already use Oracle and SQL Server on-premises. When these customers move to the cloud, move to AWS, the easiest migration is to use the same database and run on AWS because you don't have to change your applications. You don't have to go change your schema and write to a new database schema. You don't have to change your stored procedures. It just works as is. So it becomes an easier migration when you take your applications running on-premises on SQL Server or Oracle and run it on the cloud and you have the same database, SQL Server or Oracle.

Flexible licensing options. So many customers have long-term agreements with Microsoft for SQL Server or with Oracle for using Oracle, which includes licensing and support terms. So those customers often use what we call a bring your own license model where you can take your existing agreements, existing support model, and just run it on AWS as is. But then we also offer license included offering, and this is particularly compelling for many customers for a few reasons.

First, the license included offering includes the license along with the software and the server usage, everything combined. And you're effectively paying for both the usage of the server as well as licenses, only for the period that you're using it by the hour. So if your needs change over time, so if you need more licenses, less licenses, more usage, less usage, you're just paying for what you actually need versus signing up for a long-term contract.

It also becomes particularly interesting because many customers want to over time change to a different database. For example, your applications may change from using SQL Server to using an open source database, or it may change from using a relational store to a non-relational store. When that happens, you're usually changing things over a period of time and you can't always predict when it's going to happen and how it's going to happen. So having a usage-based model allows you to make sure that you're using as much as you need it, and then you can gradually shift over and that's where the license included model becomes very compelling for many, many customers.

Third, RDS gives you a managed service for running these engines. Operations like software patches, software updates, backups, storing backups in a different region for disaster recovery, all of those operations are automated for you. For example, if you want to do software updates, RDS offers the latest updates. You simply specify your maintenance window, and RDS applies the updates in a maintenance window. You can choose when you want to apply updates, but you can also tell RDS just apply the updates automatically.

In fact, we recently released a new feature which allows you to stage your upgrades. So many of you, when you have a test environment, a dev environment, and a production environment, you can just tag your different instances and say, this is my test instance, this is my production instance. When you do that, the software updates are automatically applied to your test instances first and then after a few weeks they get applied to your production instance.

What it does is it allows you to have some time to test it and make sure you don't get surprised because the update showed up in a production instance and suddenly the performance of your application changed or something like that. So you get some time. All of those are automated for you and you don't have to do any manual work around that. So the managed service gives you a bunch of benefits that frees up your time to do some more application-specific work.

[![Thumbnail 360](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/360.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=360)

Lastly, you have a lot of options to get high availability. RDS offers a Multi-AZ configuration which allows you to recover much more easily when you have, let's say, a hardware failure or a software failure or a power failure, and recover quickly and fail over to your standby instance. These options are configurable, so you simply specify what you want. You can say I want a highly available service in a Multi-AZ configuration. You can specify you want a read replica, and the installations are automatically handled  for you.

### Identifying Storage Limitations in Multi-AZ Configurations

Let's look a little bit into what a typical Multi-AZ configuration looks like. You have an application. The application talks to an RDS instance endpoint. The instance endpoint talks to an instance, typically your primary instance in an Availability Zone. Your database instance is backed by an EBS volume, a storage volume. When you specify you want a Multi-AZ configuration, RDS automatically sets up a standby instance for you in a different Availability Zone, which protects you against failures that may happen in your instance. Your standby instance has its own storage volume in EBS, and then the data is synchronously replicated from your primary instance to your standby instance. It's synchronous, which means as your transactions are written, they're written into both primary and standby before the transactions get committed.

[![Thumbnail 420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/420.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=420)

Now we work with thousands of customers over the years, and we found a few areas where we could make the service better for our customers. Let me give you some examples.  RDS lets you choose the storage size you want, but the size of the volume can go up to 64 terabytes. Now we saw a few customers who have very, very large databases, and they take up more than 64 terabytes. It doesn't happen frequently, but sometimes it happens. Even if it doesn't happen, if you're reaching 40 or 50 terabytes, you want to know that the service continues to work and you have a path to scale forward in case your storage sizes grow over time.

[![Thumbnail 450](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/450.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=450)

The ability to scale up and down.  Many times you have scenarios where you want a large amount of storage for a short period of time. You may be running some data processing jobs every month, once a month, or you may have a peak season in a year where the storage volume grows. Or maybe you're restoring a backup in Oracle, so you want to copy your backup to a volume, restore from the backup, delete the backup file, and then bring your storage size down. So there is a need for many scenarios to be able to increase storage and reduce storage over time.

[![Thumbnail 490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/490.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=490)

IO2 and GP3. So EBS offers different volume types.  You can choose IO2 storage for your databases, or you can use GP3 storage for your databases. We recommend IO2 for critical workloads. IO2 offers our highest level of availability, durability, and consistent low latency performance, which you would expect in a production, highly transactional workload. We also offer GP3, or our general purpose EBS volumes. GP3 volumes tend to be more cost effective, and in many cases, a GP3 volume is sufficient for running a production workload.

When you have a database where a subset of data requires high performance, high transaction, high durability, low latency all the time, and then there's some data which is not used frequently, it's infrequently accessed, maybe it's old data, but every now and then it's accessed as part of the same database, ideally you would want to be able to choose like I want IO2 for this data and I want GP3 for this data so that you can more efficiently cost optimize and use the right storage volume for the right sets of data. But you have to choose one. So in most cases you end up choosing IO2 even though you may not need IO2 for the entire storage that you have for your database.

[![Thumbnail 570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/570.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=570)

Lastly, when we replicate data from your primary to your standby instance, we have a replication channel.  The replication channel has a throughput of about 625 megabytes per second. When you have large amounts of data that you're writing in a short period of time, on occasions, you may run into limitations of this throughput in the channel of replication, and when that happens, your transaction rates can go down. So we wanted to look at ways that we could improve this as well.

[![Thumbnail 600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/600.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=600)

### Additional Storage Volumes: Expanding Capacity and Flexibility with Up to 256 Terabytes

To address this, we added something called the ability to have additional storage volumes. How does this work? 

[![Thumbnail 620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/620.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=620)

[![Thumbnail 630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/630.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=630)

[![Thumbnail 640](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/640.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=640)

This picture shows the same environment, a multi-AZ configuration with your application instance endpoint, primary instance, and a standby instance, each backed by an EBS volume. But what you can now do is have an additional volume at a different mount point that you can add to the same instance. And you can add up to three additional  volumes in addition to your primary volume. What this does is that you now have the ability to have four times the storage.  So you can now have up to 256 terabytes of storage for your database instances. You also have the ability to add and remove storage volumes over a period of time,  so it doesn't mean that when you start, you need to have all the volumes. So as your data grows, you can add volumes. If you don't need the storage, you can remove a volume, and you can do this without having any application downtime. So this gives you more flexibility to be able to adjust storage based on your needs.

[![Thumbnail 680](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/680.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=680)

[![Thumbnail 710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/710.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=710)

And even though the example here shows Oracle, the feature is available for both RDS for Oracle and for RDS for SQL Server. You can use it the same way in both database engines. Let's see how we can use it. So in this case, I have a database instance that I just created. The primary instance is using Oracle and has a single volume.  If I want to add more storage, I have a command called modify DB instance. I specify my database instance, in this case it's called my instance. I specify the volume name that I want to use and refer to my volume mount point. I call it rdsdbdata2 and specify properties like the storage type IO2, the amount of storage I need, and the amount of IOPS I need for my additional volume. When I do that, I get a second volume, and I can reference that volume using the name that  I specified. In this case, I'm using rdsdbdata2.

[![Thumbnail 720](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/720.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=720)

[![Thumbnail 730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/730.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=730)

[![Thumbnail 750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/750.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=750)

[![Thumbnail 760](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/760.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=760)

Now that I've added a volume, you want to be able to use the volume from your database.  The easiest way to do it if you're using Oracle is to update the default location that Oracle uses to create new data files. I can do that easily by just updating a parameter  if I'm on RDS. So there's a parameter called DB_CREATE_FILE_DEST that tells you what the default destination for new storage tablespaces is. And in this case, the default happens to be the primary volume rdsdbdata. I use an alter session command  to change the default location, and I change it to rdsdbdata2. And then after I change it, I want to confirm that the change is applied, so I call show parameter  again, and as you can see, the default location is now changed to rdsdbdata2. Once I do that, if I create new tablespace files, they get automatically created in my additional volume. So if you're growing storage over time, this may be an easy way that you can start having new tablespaces go into your new volume.

[![Thumbnail 790](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/790.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=790)

[![Thumbnail 810](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/810.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=810)

[![Thumbnail 820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/820.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=820)

But there are some more interesting things that you can do with additional storage volumes. Let's say that you want to move a tablespace  from your primary volume to your additional volume that you just added. Maybe that tablespace has been growing, or you expect it to grow quite large for a short period of time. In that case, I just want to move the existing tablespace from my primary volume to my additional volume that I just created. And maybe I want to allow it to grow for some period of time. It grows and grows,  and maybe after a few weeks, I don't need that storage anymore. The data size goes down, and maybe after a few weeks, I want to bring it back to my primary volume  and then delete my additional volume because you don't want to pay for storage that you're not using. So what this allows you to do is move it to an additional volume, use it for a short period of time, bring it back to your primary volume, and remove the additional volume. How would you do that?

[![Thumbnail 840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/840.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=840)

[![Thumbnail 860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/860.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=860)

[![Thumbnail 880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/880.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=880)

 To move my tablespace to my additional volume, I call a select command. In this case, my tablespace is called my tablespace. I call the command to get the properties of the tablespace. I see that the tablespace has a file ID 6, and the tablespace resides on my primary volume rdsdbdata, and I have the file name for the tablespace. I  then call a command, move datafile, and I say that I want to move the datafile with file ID 6 to my additional volume called rdsdbdata2. After I execute the command, I call a select command again to say, let me see the properties of the tablespace, and as you can see, the file for the tablespace has been moved  to my new storage volume that I just added, rdsdbdata2. Now you can do this without any application downtime. This happens in the background.

Let's say I use the tablespace for a while. It grows, it changes over time, and now it's pretty small again, and I want to bring it back to my primary volume and delete my additional volume. To do that, I want to first clear the additional volume.

[![Thumbnail 940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/940.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=940)

So I start with, let me look at all table space files which were created in my additional volume. So I call a select command and say show me all the table space files in my additional volume. I again see just one file with file ID 6. I then call and execute command again, move data file to move it back to my primary volume. And then I verify it again to say, is the file name moved to my primary volume. I see it's moved back to rdsdbdata, which is my primary volume. And then I call a command to say, is  there any more table space files remaining in my additional volume, and I see that there are no more table space files. The volume has been cleaned up.

[![Thumbnail 950](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/950.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=950)

[![Thumbnail 960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/960.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=960)

[![Thumbnail 970](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/970.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=970)

After the volume has been cleaned up, I can now remove the volume.  To do that, I delete the storage volume by calling a command modify DB instance again. And I mark it to say set for delete equals  true. When I do that, the volume is marked for deletion, and you are no longer charged for the volume that you used before.  Now, in case there are files being used when you call the command to remove the volume, you will get an error, and so it protects you from accidentally deleting volumes which are actually being used. So as long as you make sure that all the files have been moved away from the volume, you can delete the volume and stop incurring costs for that additional volume.

[![Thumbnail 990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/990.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=990)

[![Thumbnail 1010](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1010.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1010)

 Now there are some more interesting things that the volumes can give you. You can now combine io2 and gp3 volumes. So in many cases, for example, if you have some old data which is infrequently used, you can move the table space files for those data tables into your additional volume by creating a gp3 volume. So now you can mix and match your volumes,  and you can mix and match volume types however you want when you're using RDS. We usually recommend if you're mixing and matching, we usually recommend having an io2 volume for your primary volume. Why is that? When you write to a database, databases write to a write-ahead log first. Your write-ahead logs are always in your primary volume. And that's why if you're using a combination of io2 and gp3, we recommend that you use an io2 volume for primary volumes and gp3 for your additional volumes.

[![Thumbnail 1050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1050.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1050)

[![Thumbnail 1060](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1060.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1060)

[![Thumbnail 1070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1070.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1070)

You also get benefits in a Multi-AZ replication scenario. As I mentioned, when you write your transactions,  your data gets replicated to two zones before it gets committed. And a single channel of replication in a single volume  gives you 625 megabytes per second. But when you add a second volume, you have a second channel of replication for replicating the second volume. Third volume has its own channel. Fourth volume has its own channel.  So now you effectively get more throughput. So if you're writing large amounts of data in a short period of time in certain tables, or in case of SQL Server, when you have multiple databases in the same instance and some databases write a lot of data, it may be beneficial for you to put those databases or those table space files in an additional volume which gets its own dedicated channel to replicate data in a Multi-AZ configuration.

[![Thumbnail 1100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1100.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1100)

[![Thumbnail 1110](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1110.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1110)

[![Thumbnail 1120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1120.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1120)

[![Thumbnail 1140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1140.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1140)

So in summary,  when you use additional storage volumes, you can use it for multiple benefits. You can use it to get more storage. The feature is available for both SQL Server and for Oracle.  You have the ability to add and remove volumes without having any downtime. You can use the additional volume for temporary storage for short-term needs. Even in some cases  in SQL Server when you create temp files, many applications and workflows and jobs create temp files in SQL Server. You can use additional volumes when you're running those jobs that require a large amount of storage in a temp file while the jobs are running. After the jobs finished running, you can remove the additional storage volumes.  You can combine io2 and gp3 volumes. And when you use RDS and you're setting up a Multi-AZ configuration, whenever you add or remove volumes, your changes are automatically replicated in both your primary and the standby instance by RDS behind the covers, so you don't have to do any management tasks or any operational tasks to make sure things are being done consistently.

[![Thumbnail 1170](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1170.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1170)

### SQL Server Developer Edition: Reducing Dev and Test Costs by 74%

Now, let's talk about some new service features that can help you reduce your costs.  SQL Server Developer Edition. So Microsoft offers SQL Server Developer Edition that's now fully supported in Amazon RDS. What that means is that you can now use Developer Edition of SQL Server with all the features that you normally use with Amazon RDS. Now SQL Server Developer Edition is a full-featured version of SQL Server. It has all the features that are available in SQL Server Enterprise, and it is free from licensing costs because it is intended for non-production usage and dev and test usage.

[![Thumbnail 1210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1210.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1210)

[![Thumbnail 1220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1220.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1220)

When we see most development environments, most developers have a development environment where they build new applications. You often have a test  environment or a pre-production environment where you bring in all your applications and do performance testing and application testing, and then you have a production instance where you're running your production workloads.  In this case, you can now start to switch to using Developer Edition for all your development and test environments and test instances, and use the Standard or Enterprise Edition only for your production instances. What happens if you were to do that? Let's look at the costs when you start using different editions.

[![Thumbnail 1240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1240.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1240)

 Now, this picture just shows you examples of different editions and the costs that you incur per hour when you use different editions of SQL Server. In this case, I just take two instance types, M6i XL and R6i XL, and these are the costs of different editions. These are just public pricing in the Virginia region, but if you're using it in other regions, pricing is similar and the variations are similar. If I switch from Standard Edition to Developer Edition for an M6i XL instance, my price changes from $0.977 per hour to $0.60 per hour. If you switch from Enterprise Edition to Developer Edition, let's say for your pre-production testing, your price changes from $2.501 per hour to $0.74 per hour.

[![Thumbnail 1290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1290.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1290)

[![Thumbnail 1310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1310.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1310)

So simply by switching all your development and test  environments to use Developer Edition, you're effectively reducing your cost by 74% for all your development and test environments. And all you have to do is to just start using Developer Edition for these environments. How do you use them? It's pretty easy. You first download the ISO image for SQL  Server Developer Edition from the Microsoft website. This is required for licensing compliance. You are informing us that you are using SQL Server Developer Edition, download it from the website, and this is the instance you want to use for development and test purposes and non-production purposes.

[![Thumbnail 1330](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1330.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1330)

[![Thumbnail 1340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1340.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1340)

After you download the ISO image, just upload it to an S3 bucket.  You can upload it to any S3 bucket you want. In this case, I just use S3 CP to upload it, and I upload it to a bucket called My Test Bucket, but you can upload it to any bucket you prefer.  Once you upload your ISO image, you inform us and you create what we call an RDS custom engine version. Why do we need that? Well, once you have a Developer Edition image, you want to be able to use the Developer Edition for multiple development and test environments, multiple instances.

[![Thumbnail 1380](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1380.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1380)

So you build what we call a custom image once, which is a Developer Edition image based on the ISO image that you give us, and then you can use it for all your instances for development and test. To do that, use a simple RDS command called create DB engine version. You specify the bucket name where you uploaded  your ISO image. In this case, it was My Test Bucket. You specify the file name that you uploaded for the ISO image, and then you name your engine version. These are names that you can name so that you can easily remember what is the engine version you're using.

[![Thumbnail 1410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1410.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1410)

[![Thumbnail 1420](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1420.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1420)

So for example, if you're using different versions of SQL Server, we recommend putting the name of the version of SQL Server that you're using so that you can easily remember when you're creating instances. Once you do the custom engine version,  you can start creating instances using Developer Edition. To do that, use the same create DB instance command from RDS. It's the same command that you use  for creating production instances or development instances. The only variation is you specify the custom engine version that you just created.

[![Thumbnail 1450](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1450.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1450)

I created the engine version called My RDS SQL Server 22 Dev in the previous step. I specified the same engine version, and then I specify my instance name and instance properties. For example, which region do I want to create the instance in, and what is the configuration of the instance? Is it a single Availability Zone instance, a Multi-AZ configuration? You can specify all those configurations. That's it.  Once you do that, you now have an RDS instance for SQL Server. It's using SQL Server Developer Edition, and now all the features that are available in RDS are now available to use for your development and test environments.

[![Thumbnail 1470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1470.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1470)

### High Availability for SQL Server Web Edition Through Block-Level Replication

SQL Server Web Edition.  This is also something that Microsoft offers. The Web Edition is designed for web hosting providers. It's optimized for web hosting. So if you have websites, if you have web services, if you have ASP pages, if you have internal web applications, and if you're using the database to power those web applications, SQL Server Web Edition is designed for that. It also has lower licensing charges compared to SQL Server Standard Edition or SQL Server Enterprise Edition.

[![Thumbnail 1500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1500.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1500)

 Now when you have web applications and websites, you want high availability for your website, right?

[![Thumbnail 1520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1520.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1520)

[![Thumbnail 1540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1540.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1540)

You want to make sure that things are not going down, your web service is not going down, and so you want to make sure that you have high availability and you can recover from failures in case there is a hardware failure or a power failure.  So we looked at high availability features in different SQL Server editions, and SQL Server uses something called Always On Availability for high availability. But when we looked at the availability of the feature, it's available for Enterprise Edition, it's available for Standard Edition, but it's not available for Web Edition. And so we asked ourselves, how can we fix  this?

[![Thumbnail 1550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1550.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1550)

We're now launching support in Amazon RDS for high availability for SQL Server Web Edition. How do we do this?  We do it using synchronous block-level replication in a Multi-AZ configuration, very similar to what you saw in the Oracle example earlier. You have an application that talks to an RDS instance endpoint. The instance endpoint talks to a SQL Server primary instance which is backed by an EBS volume, but then we do block-level replication from the EBS storage in your primary instance to the EBS storage for your standby instance that happens to be in the second availability zone.

[![Thumbnail 1600](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1600.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1600)

[![Thumbnail 1610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1610.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1610)

[![Thumbnail 1620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1620.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1620)

[![Thumbnail 1630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1630.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1630)

We also make sure that your licensing is only for one instance at a time for your usage, because you're only using one instance, which is your primary instance, and the data is just simply being replicated to your standby instance, not actually being used, so you're not using SQL Server in the standby instance. Now, RDS also automatically detects failures.  So we have your RDS instance endpoint that routes requests to your primary instance. In case we detect that there's a failure in your primary instance, we automatically detect the  failure. We stop the block-level replication that was going from your primary to your standby. We route requests to your standby instance.  In this case, now your standby instance becomes your new primary instance and then we replicate the other way around from your standby or your new primary into the  previous primary instance and now your previous primary instance becomes a standby instance.

[![Thumbnail 1650](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1650.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1650)

[![Thumbnail 1660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1660.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1660)

So all of this happens behind the covers, the detection, the switchover, the transfer, creation of a new standby. RDS is doing all of that behind the covers so that you have high availability. So what's the benefit?  The benefit now is that many applications, web applications that you were previously running with SQL Server Standard Edition can now start running on Web Edition.  What's the benefit? Let's look at the prices, and again these are prices with public prices for license included in the US East Virginia region, but similar prices are applicable for all other regions.

[![Thumbnail 1690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1690.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1690)

[![Thumbnail 1700](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1700.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1700)

[![Thumbnail 1710](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1710.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1710)

In this case, these are prices for a Multi-AZ configuration. So I take two instances, M6i XL and R6i XL. If I switch from Standard Edition to Web Edition, my price goes down from $2.45 per hour to $1.01 per hour.  For R6i, if I switch, my price goes from $3.04 per hour to $1.69 per hour. So simply by switching from Standard Edition to  Web Edition for all your web applications or ASP pages or web services, you can again reduce your cost by up to 58% for running RDS SQL Server.  If you only use Web Edition and you're using it in a single AZ configuration, you can now use Multi-AZ configuration for high availability, and doing that is pretty simple.

[![Thumbnail 1730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1730.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1730)

[![Thumbnail 1750](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1750.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1750)

### vCPU-Based Licensing Optimization: Lowering Costs with SMT Configuration and 7th Generation Instances

If you want to do it from the console, there's an option called Modify DB Instance.  There's an attribute called Multi-AZ deployment. You simply change the value of the attribute and say, yes, I want a Multi-AZ deployment. And when you apply the change, RDS will create a standby instance for you behind the covers, and that's it. Your applications can keep running. There is no change required in your application.  vCPU-based licensing charges. This is also something very interesting. When you use Microsoft SQL Server, your charging for licenses is based on the number of vCPUs or virtual CPUs that you use in an instance.

[![Thumbnail 1770](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1770.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1770)

[![Thumbnail 1780](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1780.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1780)

Now in a typical Intel  instance, for each physical CPU core, you have two virtual or two logical CPUs. Why is that?  For a technology called SMT or Simultaneous Multi-Threading. What SMT does is that it allows you to run two parallel threads on each physical CPU core. Now you don't get double the performance because the physical CPU core is just one. In this example, I just have two physical cores, so I don't get the performance of four CPUs.

[![Thumbnail 1830](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1830.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1830)

However, it's not 2x the performance for every core. The licensing charges that you pay are 2x. So you get a small performance boost, but you're paying twice the licensing charge for each physical CPU core. So we asked ourselves, how can we take advantage of this and become more cost performant? What it turns out is you can turn off SMT in an instance. 

[![Thumbnail 1840](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1840.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1840)

[![Thumbnail 1850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1850.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1850)

When you turn off SMT in the instance, you now have one logical CPU for each physical CPU. But your licensing charges are now for half the number of vCPUs that you were running before.  So let's take some examples. Many database workloads tend  to be memory bound or IO bound, and not CPU bound.

[![Thumbnail 1860](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1860.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1860)

[![Thumbnail 1870](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1870.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1870)

[![Thumbnail 1880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1880.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1880)

In this example, I'm using metrics for a workload on an R7i  8xlarge machine. As you can see, the available free memory on this workload is about 25%. So it's using about 75% of memory  available on the instance, which seemed like good utilization for the machine. Then I look at CPU utilization. On the same machine, CPU utilization is only about 10%. 

[![Thumbnail 1920](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1920.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1920)

So this is what it would look like if your workload is a memory-bound workload, not a CPU-bound workload. So what happens in this kind of a workload if I turn off SMT? So I tried turning it off. In this case, when SMT is turned on, my utilization was about 10%, and I was using 32 vCPUs and I was incurring licensing charges for 32 vCPUs. I turn off SMT, now I have 16 vCPUs, same number of physical CPUs. All physical CPUs are available and being used. 

[![Thumbnail 1940](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1940.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1940)

[![Thumbnail 1960](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1960.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1960)

And my performance is still under 20%. So CPU is still underutilized. But what happened here is my licensing charges switched from licensing for 32 vCPUs to licensing for 16 vCPUs. So what we did in RDS is to take advantage of this with  a feature called Optimize CPU. Now what we do is for 7th generation instances and for all future instances going forward, we're going to optimize the SMT settings for the instances depending on what the size looks like, what the performance looks like, so that you get better cost performance out of the box in those instances. 

[![Thumbnail 1990](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/1990.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=1990)

[![Thumbnail 2000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2000.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2000)

So as a result of that, if you simply switch from a previous 6th generation instance to a 7th generation instance, you get a lower price. You get a lower price because it has an optimized CPU setting. So if I was using SQL Server Enterprise with an R6i 2xlarge instance, and I simply upgrade to an R7i 2xlarge instance with the same number of physical CPU cores, my price goes down from $7.202 per hour  to $3.868 per hour. If I'm doing SQL Server Standard, my price goes from $6.080 per hour to $2.848  per hour.

[![Thumbnail 2030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2030.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2030)

This was just the R6i example. If I take an M6i instance and upgrade that to M7i, again, I'm taking an M6i 2xlarge and upgrading to M7i 2xlarge. I have the same number of physical CPU cores, and the price goes for Enterprise from $6.657 to $3.295. For Standard it goes from $5.096 to $2.275. So as you can see, you get up to a 55% lower cost simply by doing an upgrade  to a newer generation instance. You don't change your application. You have the same amount of memory, same amount of physical CPUs. You're simply doing an instance upgrade, and now you have a lower price.

[![Thumbnail 2050](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2050.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2050)

[![Thumbnail 2070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2070.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2070)

This is what you get simply by upgrading, but you can do more. You can fine tune performance even more.  In the previous example, you saw that even if I optimized and turned off SMT, I was still utilizing CPU by about 20%, which means that 80% of CPU is still underutilized. In scenarios like those, you can fine tune the CPU settings in the feature called Optimize CPU. 

[![Thumbnail 2100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2100.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2100)

In this case, it allows you to configure the number of active CPUs, and you can do this by turning on or turning off physical cores in the machine. So in this case, I have an instance where the default number of physical cores is 8. It is using one thread for each physical core, so SMT is turned off, but you can change the value of 8 to a lower value, 7 or 6, to what your application requires. And when you do that, the number of vCPUs reduces, and remember, a lower vCPU count  equals a lower software licensing charge for you.

You can get a large performance boost by upgrading to 7th generation instances. If you want to fine-tune further, you can configure your settings for optimized CPU and adjust them for your applications to get even greater cost benefits.

[![Thumbnail 2120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2120.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2120)

[![Thumbnail 2150](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2150.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2150)

### EC2 Bare Metal Instances for Oracle and Key Takeaways for Cost Efficiency

For RDS for Oracle,  we have support for EC2 bare metal instances. What are EC2 bare metal instances? An EC2 bare metal instance is an instance that's backed by a full physical server. It bypasses the hypervisor, so there is no hypervisor layer. Your application software talks directly to the physical hardware because there is no hypervisor. When you have a large database using a large virtual memory  instance, you can switch over to using a bare metal instance which offers the same amount of CPU and the same amount of memory while bypassing the hypervisor. In this example, I have an m7i.24xlarge instance with 96 vCPUs and 384 GiB memory, and I can switch over to using a metal instance which offers the same amount of vCPUs and the same amount of memory.

[![Thumbnail 2180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2180.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2180)

[![Thumbnail 2190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2190.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2190)

[![Thumbnail 2210](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2210.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2210)

We have similar metal instances available for r7i.24xlarge with a different CPU and memory profile,  but consistent between a virtual machine and a physical machine. The same applies for x2iedn instances where a large VM and a bare metal  instance will have the same amount of memory and the same amount of CPU. All RDS features and all Oracle features work exactly as they did in the virtual instance. There is no change to the application, and you get better performance. When you switch over from a large virtual machine to a bare metal instance, you  get a 25% cost benefit by switching over. So when you have large Oracle databases running on a large VM, in most cases you will have a cost benefit by switching over to a bare metal instance for the same application performance and better cost.

[![Thumbnail 2230](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2230.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2230)

[![Thumbnail 2240](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2240.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2240)

[![Thumbnail 2250](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2250.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2250)

[![Thumbnail 2260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2260.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2260)

In summary,  we talked about how RDS helps you and gives you a managed service for running SQL Server and Oracle. We talked about how you can use additional storage  volumes to give you more flexibility and more cost efficiency. We talked about how you can use the new RDS features to reduce your costs.  We talked about how you can use RDS SQL Server Developer Edition for all your dev and test environments. We talked about how you can use RDS SQL  Server Web Edition for your web applications. In many cases, you can downgrade from using SQL Server Standard Edition to SQL Server Web Edition, get the same high availability, and lower your costs.

[![Thumbnail 2280](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2280.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2280)

[![Thumbnail 2290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2290.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2290)

[![Thumbnail 2310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/16ed923fa3883da2/2310.jpg)](https://www.youtube.com/watch?v=06l39fx_AXY&t=2310)

We talked about how you can simply upgrade to 7th generation instances for M  instances, R instances, and other instance types, and get a lower cost out of the box because of optimized CPU. If you want to further reduce cost, you can fine-tune optimized CPU settings.  Finally, we talked about how you can use bare metal instances if you're using RDS for Oracle compared to a large VM to reduce your cost by 25% or more. That concludes my talk, but there's still some time to get some swag.  If you go to the Venetian and you go to the expo hall of the Venetian, you can go to the databases booth and tell them about the one unique thing you learned from the session. You can tell them that you learned about how you can upgrade to newer instances to reduce cost, or you can tell them how you can use metal instances to reduce your cost, and you can get your swag. Thank you.


----

; This article is entirely auto-generated using Amazon Bedrock.
