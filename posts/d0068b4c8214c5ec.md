---
title: 'AWS re:Invent 2025 - Autonomous AI agents you can truly trust (AIM234)'
published: true
description: 'In this video, Neil LeBlanc from IBM and Diana Griffin from KPMG discuss AI governance for autonomous agents. They highlight how agentic AI promises $4.4 trillion in annual value (McKinsey) but creates challenges around transparency, explainability, and tracking who builds agents and how they''re tested. The speakers demonstrate watsonx.governance''s capabilities for monitoring agent performance, evaluating quality, and managing risks through automated questionnaires and approval workflows. They emphasize that governance should be viewed as guardrails that accelerate innovation rather than blockers, helping organizations avoid shadow AI while enabling developers to build approved use cases faster. The discussion covers practical challenges like identifying governance committees and assessing agents based on process outcomes rather than automating existing tasks.'
tags: ''
cover_image: 'https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/0.jpg'
series: ''
canonical_url: null
id: 3086304
date: '2025-12-05T11:33:07Z'
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Autonomous AI agents you can truly trust (AIM234)**

> In this video, Neil LeBlanc from IBM and Diana Griffin from KPMG discuss AI governance for autonomous agents. They highlight how agentic AI promises $4.4 trillion in annual value (McKinsey) but creates challenges around transparency, explainability, and tracking who builds agents and how they're tested. The speakers demonstrate watsonx.governance's capabilities for monitoring agent performance, evaluating quality, and managing risks through automated questionnaires and approval workflows. They emphasize that governance should be viewed as guardrails that accelerate innovation rather than blockers, helping organizations avoid shadow AI while enabling developers to build approved use cases faster. The discussion covers practical challenges like identifying governance committees and assessing agents based on process outcomes rather than automating existing tasks.

{% youtube https://www.youtube.com/watch?v=RhRJsjr-I3I %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/0.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=0)

### The Rise of Agentic AI and the Growing Need for Governance

 Hello, everybody. Good afternoon and welcome to Autonomous AI Agents You Can Trust. My name is Neil LeBlanc and I am with IBM, where I lead our go-to-market for watsonx.governance. My name is Diana Griffin and I am with KPMG, focused on AI governance and part of the alliance with IBM. Hopefully you all didn't get too stuffed at lunch, but if you did, we're here to keep you awake and burn off some calories.

[![Thumbnail 40](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/40.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=40)

Over the course of the last two or three years, I don't think too many people would have predicted just how powerful AI would become or where we would have gotten.  As we look at agents and you walk around the expo floor and look through the thousands of sessions in the catalog, there's a lot about agents. As they've evolved over the course of the last year or so, they have certainly become more powerful and it's expected that they will become even more powerful and sophisticated. However, this comes with concerns around their potential impact, ethical ramifications, and impacts on society.

[![Thumbnail 80](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/80.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=80)

As we look at the promise of agentic AI and agents, there have been a number of talks about how they could be used in different ways. Certainly they could be used to help humans effectively perform tasks and achieve business outcomes. They could be used to augment human intelligence.  They can help automate many of the mundane and time-consuming tasks that we typically have done over the course of the last little while. They can help improve efficiency and productivity, and they can also help us improve our decision-making as well as the quality of the responses that we give.

[![Thumbnail 130](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/130.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=130)

There are studies that come out all the time, and I think if we wait a week or two or three weeks, we're going to get more studies.  McKinsey came out with a study saying that agentic AI and agents are going to help contribute to an added value of about 4.4 trillion dollars of profit annually. BCG recognized that agents are here to stay and that they're going to lead to about 45 percent growth over the course of the next five years. Gartner has said that basically by 2028, one-third of all of our interactions with generative AI is going to be through the use of action models or through autonomous agents.

[![Thumbnail 190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/190.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=190)

Agents are everywhere. You walk around the show floor and everyone's talking about agents. It's not that they're only everywhere, it's that they come from everywhere and organizations don't know where.  Organizations are faced with a dilemma where they're struggling to get a handle on where they originated, who built them, how they were tested, and what data they were tested on. That's a concern because you don't know what is being used within an organization.

[![Thumbnail 220](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/220.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=220)

When we talk to our customers about their AI strategy, obviously they want to get as much return out of their AI as possible.  That's only going to be possible if there's good AI governance put in place. When we look at some of the reasons why governance is critical, if we look back probably two or three years ago, it was probably a lot easier to understand when we're looking at traditional and predictive machine learning. We knew how many models were being used and what the use cases were. Then we saw generative AI and RAG use cases, and we started to lose track. We know potentially what LLMs and foundation models we have, but we don't know what the use cases are. We don't know what all the prompt templates are, and we started to lose sight.

Now with agentic AI, it's becoming even more apparent. We're losing transparency into who's building them, how they're being built, where they're being built, and how they're being trained. That's cause for some concern as well. The inability to explain behavior is another concern. When it was traditional predictive machine learning, you kind of knew that the models were going to run and spit some outcome or output out.

[![Thumbnail 360](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/360.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=360)

Even with generative AI, there was some human in the loop. Someone would put in a prompt, get a response back, and say, "No, that doesn't look right," and was able to make a decision. With agents, especially with multi-agentic systems as they start to talk to each other and become autonomous, the inability to understand the decisions that were made and the lack of explainability is a major concern. There are still challenges around manual, error-prone testing, and there's even more concern around bias, around drift, and around the general health and quality of agents. There are a number of disparate tools, and of course, there's the lack of those guardrailsâ€”those safety guardrails that are put in place to ensure that agents are behaving the way they're supposed to behave and that they're being used the way they're supposed to be used. 

[![Thumbnail 460](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/460.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=460)

### watsonx.governance: Addressing AI Agent Risks Through Observability, Evaluation, and Optimization

As we look at watsonx.governance, we address some of these concerns and risks. The first thing we look at is observability. How do we monitor the agents for their performance? How do we know that they are performing the way they're supposed to perform and that they're producing the output they're supposed to produce? This is continuous monitoring, continuously raising alarm bells if something should happen. 

There are evaluation capabilities, evaluating at build time, at testing time, and continuously evaluating even when agents are in production. We ensure that the same quality is adhered to in production that was met prior to deployment. Then there's optimization. It's not just good enough to understand the behavior or to understand the score and results coming out. It's about optimization. How do you know what is the right agent for the job? How do you know if something is starting to fail, if the quality is degrading, if the agent is starting to hallucinate? How do I go back and fix it? What are the steps that I need to take? These are capabilities that we look at with watsonx.governance.

[![Thumbnail 500](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/500.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=500)

I'm going to walk through a quick demo hereâ€”or rather, a lightning demo since this is a lightning round. Let me set up the demo. What we're about to see is a scenario where somebody wants to onboard a new use case for banking tooling. As part of that use case, they want to onboard a new agent, and we're going to go through and identify the use case and identify some risks. 

[![Thumbnail 510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/510.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=510)

This is watsonx.governance, and this is what we call the governance console. This is the landing page, and it gives you a landscape of AI and how it's being deployed across the organization. From this area, we're able to start drilling down and getting into the details. 

[![Thumbnail 520](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/520.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=520)

Now we can start seeing the inventory of the agents that have been onboarded within my organization, within my department, within my enterprise. We can drill down even further to start looking at some of the metadata. We can see who built it, when it was built, and what its purpose is. 

[![Thumbnail 530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/530.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=530)

The other area is around being risk-averse. Within watsonx.governance, we have the ability through what we call a questionnaire to ask a series of questions. This is a bit of a cooking show, so we're not going to go through and answer all 60 questions, but we're going to get to the outcome quickly. 

[![Thumbnail 540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/540.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=540)

Based on the responses to the questions, it will automatically identify what risks we need to be concerned with and how to go and mitigate those risks. What are the controls that we need to put in place, and how do we have an audit that we know we've actually taken the necessary steps and appropriate actions to mitigate those risks and document that? So when auditors come in, they'll know what steps have been taken. 

[![Thumbnail 550](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/550.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=550)

All of this could happen before we onboard a new agent or at the time of the use case to understand the use case, the desire, and what we actually want to do. Here are the agents or the assets we want to use. It doesn't necessarily need to be a single agent; it could be multiple. 

[![Thumbnail 560](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/560.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=560)

Here are the agents that we want to use, the assets we want to use, and then we combine the two so we understand what the use case is and what the agents areâ€”it might be one or multiple. That same agent might be used on multiple use cases, so understanding that relationship between them is important. 

[![Thumbnail 570](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/570.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=570)

[![Thumbnail 580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/580.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=580)

[![Thumbnail 590](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/590.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=590)

Then, as we're going through this and understanding the risk posture and as we get into the approval, it's now saying yes, I approve this, let's   

[![Thumbnail 610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/610.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=610)

[![Thumbnail 620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/620.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=620)

go ahead and approve this use case and onboard  the agents. As a bit of a shameless plug, analysts agree that Watson X governance has been recognized as one of the leaders in AI  governance. With that, I think let's have a conversation about what we just saw. So quickly, Diana, one of the things we've heard is that governance has this notion that it's more of a hindrance, more of a hurdle. I'm curious to get your take on that.

[![Thumbnail 660](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/660.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=660)

### Governance as an Accelerator: Practical Insights on Implementing AI Guardrails

I think that we should look at AI governance as guardrails and not as a blocker. Traditionally, governance is seen as a blocker, but when we think of it as how do we adopt, a lot of organizations don't know how to get going and they're using  the lack of a plan or the lack of guardrails as an inhibitor. When you actually put governance in place and put thoughtful governance in place around what you're going to accept, it allows your innovation to accelerate. Organizations and your innovative people now know what they need to do in order to get those use cases passed.

[![Thumbnail 740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/740.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=740)

A tool such as Watson X allows you to build it in with use cases already approved, so a developer can go in and say, I can start from this use case. I can use this type of code. I know that will get approved and go through the workflow and get it approved quicker. I have clients who have really great ideas and they're really excited for them, and they take nine months to be able to get the AI agent idea approved before they can even start to build because they don't know what the governance is. By having strong and clear governance guardrails, it accelerates innovation. So we need to change our paradigm on how we look at governance, and by using tooling, it allows us to share that information and create a streamlined approach to getting it approved  and monitoring it.

Yes, I think you're absolutely right that so many people were nervous and saw governance as being that blocker, but really it can help accelerate and help generate the return on investment on the AI investment that customers have made. When you don't know the governance and you don't know how to adopt it, it actually prohibits people from innovating and also encourages them to build it on the side of their desk. You don't know what's going on in your environment and you're increasing your risk profile. You don't want shadow AI. You want people to create this. You don't want to actually stop them. People think, oh, if I don't tell them how to do it or if I don't give them governance, then they're not going to do it. They're doing it anyway. So you want to provide those guardrails and provide people with an instruction manual of sorts in order to know how to accelerate their innovation.

But what are you seeing as some of the challenges that customers are seeing in terms of being able to adopt or implement governance, implement those processes, and implement those practices? By the way, we only have seven and a half minutes. So some of the things that I personally see is they don't even know what they're looking at. This is all happening fast. No one necessarily is an expert in this space. People just have maybe a few more at bats than others, so they don't know what to do, so they hide their head in the sand. That's one thing.

We don't know who is the AI governance committee. We don't know who the right people are, so they can't make a decision because there's no consensus. The old ways of working no longer work, and so they don't want to trust it. They think that they don't have the risk assessment and they don't have all these things, they're just going to be able to stop it. You're not stopping it. So you're not governing it. You don't know what the words are and you don't know how to get going, so you're just not doing it. But that's exposing your organization to so much risk.

Yeah, I think if you're in a boardroom and you ask a group of people whose responsibility is it for AI governance, everybody would look around and go, well, maybe that person. But at the end, it's everybody's. You're right that they don't know how to get started. What are you seeing? How do you see the agentic and agents sort of increasing the need for agentic? I think that with the increase and the promise of agentic and agents, it makes AI governance even more important because you need to know that the agent is now autonomous and is actually doing what it says it's supposed to do.

Through a tool like Watson X, you can monitor it for drift, you can monitor it for bias, you can actually set these thresholds and understand whether your agent is performing, whether it's doing what you said it's supposed to do, and whether it's acting in the use case that you've designed it for. You can also ensure it continues to perform. This allows you to get out of pencils and spreadsheets and gives you a better understanding that it is actually doing what it says it's going to do.

I think that's so important with the invention of agents and the adoption of agents, especially agents doing agents upon agents. If you don't have governance tooling, how do you know what's happening? With a dashboard, you can see if there's a problem. The whole autonomous nature of things and not knowing what's happening with agents on top of agents is critical. If you put a prompt in and ask a question with generative AI using a RAG use case, you get a response back, and as a human, you can make a decision about whether it's the right response. With agents, if you make a small mistake on that initial agent that's calling the second one, it's just going to continue to get amplified.

Is there anything specific that you could guide or advise the audience on when assessing agents and looking for different kinds of agents to be used? When I look across the landscape, I start with the process and identify where the pain points are in your process. I focus on outcomes. I know probably a lot of people talk about this, but you should not automate your tasks and the specific things you're doing now. You want to look across your landscape of your process and identify where your opportunities are, and then automate that outcome level. Then you can have agents automating on top of monitoring that to make sure it's performing as planned.

You don't want to just automate your bad process. When I used to do software development, people would say they really want this red button. They didn't really want the red button. That was their pain point. Don't automate that red button. Look at what your outcome needs to be, and that's how you can design and build your agents. One of the things I'm most excited about with adopting and looking across this is how you can get so much more with this. This is no longer just prompt engineering or machine learning. Those were ways you could have done those things using your traditional means. With the evolution of where we sit today, you have to think about an AI governance tool.

If you don't have an AI governance tool in place, it's going to make it really difficult for you to know that the agents you're installing and building are actually performing and you're getting the value from them. You don't want a bunch of people building things on their desks that are now in your system and expose you to penetration, expose you to bias, or other things that could cause a lot of risk into your environment. I think that tooling helps you understand what you're building and what you're deploying. IBM Watson X is hybrid, purpose-built, and open, so it's not telling you how to build your agents or what tooling to use. It can monitor your entire environment. I think it's a really strong platform that really opens you up to accelerate your innovation.

[![Thumbnail 1160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/d0068b4c8214c5ec/1160.jpg)](https://www.youtube.com/watch?v=RhRJsjr-I3I&t=1160)

So there are a couple of things we're working on. We're working on governance and delivering a development kit around AgentOps. We have a booth back there with a big IBM sign and a big bumblebee  outside. With that, thank you very much for your time today and enjoy the rest of the conference.


----

; This article is entirely auto-generated using Amazon Bedrock.
