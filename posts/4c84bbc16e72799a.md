---
title: 'AWS re:Invent 2025 - Driving AI Innovation at the Enterprise Level with MDB Atlas (DAT103)'
published: true
description: 'In this video, Angie Guemes from MongoDB''s Industry Solutions Team explores how to transform siloed enterprise data into AI-driven innovation through the Operational Data Layer (ODL). She demonstrates AI capabilities including Generative AI, AI-powered search, RAG, and agents through two demos: an e-commerce system generating personalized digital receipts with recommendations, and a financial portfolio management system with market-scanning agents. She explains why many AI initiatives fail, citing incomplete and fragmented data as a key issue. The ODL architectural approach consolidates data from disparate legacy systems into MongoDB Atlas, which natively integrates capabilities like vector search, flexible document models, and agent memory. Real-world examples include Nova Nordisk reducing clinical report generation from 12 weeks to 10 minutes using MongoDB Atlas Vector Search with AWS Bedrock. The session emphasizes that investing in the right data foundation today prepares organizations for future innovation waves.'
tags: ''
cover_image: https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/0.jpg
series: ''
canonical_url:
---

**ðŸ¦„ Making great presentations more accessible.**
This project aims to enhances multilingual accessibility and discoverability while maintaining the integrity of original content. Detailed transcriptions and keyframes preserve the nuances and technical insights that make each session compelling.

# Overview


ðŸ“– **AWS re:Invent 2025 - Driving AI Innovation at the Enterprise Level with MDB Atlas (DAT103)**

> In this video, Angie Guemes from MongoDB's Industry Solutions Team explores how to transform siloed enterprise data into AI-driven innovation through the Operational Data Layer (ODL). She demonstrates AI capabilities including Generative AI, AI-powered search, RAG, and agents through two demos: an e-commerce system generating personalized digital receipts with recommendations, and a financial portfolio management system with market-scanning agents. She explains why many AI initiatives fail, citing incomplete and fragmented data as a key issue. The ODL architectural approach consolidates data from disparate legacy systems into MongoDB Atlas, which natively integrates capabilities like vector search, flexible document models, and agent memory. Real-world examples include Nova Nordisk reducing clinical report generation from 12 weeks to 10 minutes using MongoDB Atlas Vector Search with AWS Bedrock. The session emphasizes that investing in the right data foundation today prepares organizations for future innovation waves.

{% youtube https://www.youtube.com/watch?v=PzSJZjH9-fU %}
; This article is entirely auto-generated while preserving the original presentation content as much as possible. Please note that there may be typos or inaccuracies.

# Main Part
[![Thumbnail 0](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/0.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=0)

### Introduction: AI Innovation Capabilities and Real-World Success Stories

 Hi, everyone. Welcome and thank you for joining me in this lightning session. For the next 20 minutes, we are going to explore how you can turn siloed enterprise system data into AI-driven innovation. My name is Angie Guemes, and I am a Senior Specialist in the Industry Solutions Team at MongoDB. What we do is help organizations maximize the value of their data by providing industry-specific solutions, either to help them tackle specific challenges or improve customer experiences.

[![Thumbnail 50](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/50.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=50)

 The agenda for today is as follows. First, we're going to talk about AI innovation and its challenges, what it is, and we're going to explore some vision of that through a couple of demos. We are also going to talk about why some of these AI initiatives are not getting to production. Then we're going to talk about the Operational Data Layer as a solution, what it is, and the layers that compose it. Finally, we're going to talk about the benefits that you will get from using MongoDB Atlas as your Operational Data Layer.

[![Thumbnail 80](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/80.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=80)

 Getting started, these are some AI concepts or capabilities that have been broadly talked about, especially over the last couple of years, and they are becoming increasingly fundamental across industries, generating key areas of opportunities for many use cases. Let's explore them in a bit more detail.

[![Thumbnail 100](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/100.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=100)

 First, we have Generative AI. This is what's been allowing companies to streamline and automate processes. For example, based on the picture of a product, they can generate multilingual descriptions of it, but these descriptions match the tone and essence of the brand.

[![Thumbnail 120](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/120.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=120)

 AI-powered search is allowing us to discover data in a much smarter way, searching through semantic meaning rather than just keywords. This is how companies are able to match a customer to a specific product or an employee to a specific insight instantly.

[![Thumbnail 140](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/140.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=140)

 Then we have Retrieval-Augmented Generation, or RAG. This is very critical for reducing hallucinations and expanding LLM capabilities through proprietary data as context, which is critical for trusted and grounded AI responses. And last but not least, we have agents and multi-agents.

[![Thumbnail 160](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/160.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=160)

 These have added a new layer of decision-making and reasoning. They are able to act, not just answer, so they are able to streamline processes and workflows end to end. Ultimately, all of these have one shared goal, which is to improve customer experiences and enhance operational efficiency.

[![Thumbnail 180](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/180.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=180)

 There's also something really exciting about all of this, and that is we are already seeing these happen across different use cases and customer success stories. Just to provide a bit more insight, I'll go through the last two.

[![Thumbnail 190](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/190.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=190)

 Nova Nordisk is a leading healthcare company, and they are augmenting LLMs with their own proprietary data to make the generation of clinical study reports faster. It used to take them 12 weeks to generate these reports, and now it only takes them 10 minutes with only a fraction of the resources that it would have taken them in the past. Thanks to this, they are able to hit faster times to market for new treatments. As part of these initiatives, they are leveraging different AWS technologies like Bedrock, specifically using Claude and Titan, and also MongoDB Atlas Vector Search.

Then DevRev provides support chatbots for their internal teams. As part of these initiatives, they are also using MongoDB Atlas on AWS and other products like AKS and VPC peering for support and connectivity.

[![Thumbnail 260](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/260.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=260)

### Demonstrating AI-Driven Innovation Through E-Commerce and Financial Portfolio Management

 I brought a couple of demos to paint a clearer picture of these AI initiatives.

[![Thumbnail 270](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/270.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=270)

 With this first one, we are going to explore how you can take advantage of fresh purchase data to enhance the experience of your customers. In this case, the user is at the e-commerce store.

[![Thumbnail 290](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/290.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=290)

 The user will be at the e-commerce store, where they will go to their cart and place an order.

[![Thumbnail 310](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/310.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=310)

[![Thumbnail 330](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/330.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=330)

[![Thumbnail 340](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/340.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=340)

When customers place an order in their cart, this triggers our invoice and recommendation microservice. When the user clicks on See Details, they are given a popup with their digital receipt, encompassing relevant order transaction and loyalty information. If they scroll down from the receipt, they can see a list of recommendations with products they might also like based on the items purchased in this order.   Every single digital receipt will contain a unique and relevant set of suggestions, leading to a more engaging shopping experience.  Customers can also download the PDF version at any point in time and leverage this for their finances.

[![Thumbnail 360](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/360.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=360)

Ultimately, if a customer makes a purchase at a store physically, they expect to see that same history inside their account. So if they then go to the landing page, we are able to leverage that data as well.  This is how we can instantly activate fresh purchase data to continue the shopping experience beyond the checkout and also leverage that same data to further personalize, for example, the landing page in this case.

[![Thumbnail 390](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/390.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=390)

[![Thumbnail 410](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/410.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=410)

In this next example, we have a financial portfolio management system that continuously scans the market for insights. At the top we have performance and asset graphs, and at the bottom we have a table of diversified portfolio of ETFs.   Each of these contains a different indicator, for example, sensitivity around VIX, GDP, interest, and unemployment rates, as well as sentiment scores. All of these are calculated by three daily scheduled agents that continuously scan the market for insights.

[![Thumbnail 440](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/440.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=440)

[![Thumbnail 450](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/450.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=450)

[![Thumbnail 470](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/470.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=470)

[![Thumbnail 490](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/490.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=490)

Additionally, agents can also interact through this AI assistant so they can ask natural language questions and get insights from the latest data in the market and plan their risk-aware strategies.  Agents have already done all the heavy lifting of constantly scanning through different unstructured and semi-structured sources, such as financial analysis, financial news, and social media.  So portfolio managers can rest assured that they are actually interacting and getting the latest data from the market, and they can use that extra time to leverage their plans instead of having to make this discovery themselves while still retaining full control of their operations.  They can also see which tools were utilized to generate the responses for each of the questions. 

[![Thumbnail 510](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/510.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=510)

### Why AI Initiatives Fail: The Challenge of Fragmented Enterprise Data

All of this looks pretty amazing, right? We all want to have something like this. However, I hate to break it to you, but many of these AI initiatives are failing today. They are either being abandoned or they fail to meet their objectives.  So let's understand why. Why are some of these AI initiatives not being able to get to production?

[![Thumbnail 530](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/530.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=530)

[![Thumbnail 540](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/540.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=540)

Well, the first reason is misalignment with the organization's strategic goals. When you start planning and designing AI initiatives, this should be able to create tangible business value, enhance operational efficiency, and create a sustained competitive advantage.  Another reason, and the one I would like to focus on the most during this session, is incomplete and fragmented data.  When you start building your AI initiatives without first making a pause and taking a look at your data layer, at your foundational data layer, you will start fitting your initiatives with data that has poor quality, data that is insufficient or incomplete, or because many data is still scattered across different legacy systems, it becomes very hard to integrate or activate.

[![Thumbnail 580](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/580.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=580)

If you take that combination and pass it to a large language model, you will get inaccurate outcomes, hallucinations, and bad business consequences, including missed opportunities, bad user experience, and worst of all, damaging your reputation.  We know how hard it can be to build a strong loyalty base, and here's a little data: more than 60 percent of customers will change brands after a single bad user experience.

[![Thumbnail 610](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/610.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=610)

[![Thumbnail 620](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/620.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=620)

[![Thumbnail 630](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/630.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=630)

### The Operational Data Layer Solution: Building a Unified Foundation with MongoDB Atlas

So how can we guarantee complete, accurate, and real-time data?  Let me introduce you to the Operational Data Layer, or ODL.  This is an architectural blueprint or approach whose job is to consolidate siloed enterprise data into a single, reliable data layer.  Let me walk you through the five layers of an ODL that will guide a robust implementation using MongoDB Atlas as your core data layer.

[![Thumbnail 650](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/650.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=650)

First, we have the source systems or systems of record. This is where the actual data originates.  As you can see from the examples, many of these systems were built with a single use case in mind at the time, so their schema no longer accommodates modern-day applications. As a result, you will struggle to see a complete view of an entity. For example, a retailer that struggles to have a complete view of users throughout their shopping journey because operational sales are in one system, returns and refunds are in a different system, and their loyalty or preferences are in another system.

[![Thumbnail 690](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/690.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=690)

Data from the source systems is then ingested into the ODL layer through different mechanisms, including ETL, Change Data Capture, and you can also leverage MongoDB Atlas Stream Processing for handling large streams of data.  I think it is a good time to make a pause here and mention that if you are interested in any of the products I will be mentioning during the session, we have a booth right here behind us at Number 822, and we have many experts on site. We actually brought the demo so you can test them yourself if you are interested.

[![Thumbnail 730](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/730.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=730)

[![Thumbnail 740](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/740.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=740)

The third layer is the actual ODL.  Here it is represented by MongoDB Atlas, and it is where we consolidate structured, unstructured, and semi-structured data into a single flexible document.  Then we have the processing layer. This layer is in charge of making the data from the ODL available to the applications. This layer is very critical for security as it enforces governance through encryption, access control, and policy-based filtering.

[![Thumbnail 770](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/770.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=770)

The last but not least layer, and I think we can all guess what layer is next, are the actual applications.  These applications can include operational and system apps, business intelligence tools, and of course, the next generation applications with Gen AI and agents. So what are some key enablers that you will get from using MongoDB Atlas as your ODL? I really like this diagram because it encompasses the main benefit. All of these building blocks that you see here would usually come from single-purpose systems, such as smart search or embeddings, and globally the flexible schema. Here they are all natively integrated, living with your data.

[![Thumbnail 820](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/820.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=820)

[![Thumbnail 850](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/850.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=850)

[![Thumbnail 880](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/880.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=880)

Actually, we are actively working to integrate Voyage AI embedding models and rerankers to make this process even more seamless.  This is the biggest benefit we bring to development teams: simplicity. We are reducing the complexity of their operational overhead by having all the data and capabilities in one single trusted, reliable data layer. Some of the key enablers that you will get from this are, first, the unparalleled simplicity from the flexible document model.  You can store different complex data types, such as vectors and graphs, and AI embeddings. In this example, we have operational data living alongside AI, which allows us to query for relevant products in the digital receipt demo without having to move data outside of our system. 

[![Thumbnail 900](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/900.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=900)

Then we have agents' memory capabilities. Memory is a key capability for agents, allowing them to store context throughout interactions, learn from past interactions, and ultimately get better at their tasks. You can leverage Atlas as your agent's memory layer.  Another thing that you would get from this are powerful queries. We have full text search, semantic search, and hybrid search.

All of these are natively integrated. You can also have other powerful search queries, such as geospatial queries, and they're all within the same workflow. This makes operational overhead even less and allows more simplicity for your teams to develop faster and focus more on innovation, rather than spending time deciding what technologies to integrate to make all this happen. Here is an example of a vector search query that we are executing. I took it from the digital receipt demo as well.

[![Thumbnail 950](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/950.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=950)

Another thing, and the one I really like the most, is removing friction.  When you build AI, you really need to start integrating with data from different systems, and you can integrate different frameworks for developing AI. Atlas reduces friction with many of these. This is one example where we are leveraging the financial demo that I showed you earlier. We are using Amazon Bedrock to expand capabilities and have better responses. We are also initializing the memory layer using MongoDB Atlas, and then we are using LangGraph as an orchestrator of these agents. You can see it's just as simple as passing all this to the initializing function. We are leveraging Atlas again as the memory layer for the agents.

[![Thumbnail 1000](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/1000.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=1000)

Another example of ease of integration  with object storage, for example, is this one. In our digital receipt demo, when the user first downloads their digital receipt, we generate it and store it in Amazon S3 buckets. That URL is then embedded into the document as metadata inside the file_url field. For subsequent downloads, we just pull from that same URL.

[![Thumbnail 1030](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/1030.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=1030)

Last but not least, we have the enterprise ready factor.  We run in over 30 plus AWS regions. We also have many audits at the security level. For example, we are able to encrypt your data and keep it secure, not only at rest and in transit, but also during use. Ultimately, if you have everything in one place, it is easier to secure, easier to maintain, and easier to onboard new team members.

[![Thumbnail 1070](https://raw.githubusercontent.com/kazuya-iwami/devto-repo/main/posts/images/4c84bbc16e72799a/1070.jpg)](https://www.youtube.com/watch?v=PzSJZjH9-fU&t=1070)

As we wrap up, here are some of the key takeaways that I would like you to take from today's session. The first one is to keep innovating  and using all these trends, frameworks, and technologies that come from the AI innovation wave, but doing so without losing focus on what business value it brings to you. Last but not least, AI is just one of the many waves of innovation that are to come. We don't know what's going to be next in the next 15, 20 plus years, but what is a fact is that if you invest in the right data foundation today, you are going to be much better equipped to develop whatever comes tomorrow.

I really hope that you enjoyed today's session and that you learned something new. If you could please take a moment to evaluate the session through the app, I would appreciate that. Thank you, and keep enjoying this amazing experience of AWS re:Invent. Thank you.


----

; This article is entirely auto-generated using Amazon Bedrock.
